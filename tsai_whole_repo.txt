Repository: timeseriesai/tsai
Files analyzed: 77

Estimated tokens: 304.8k

Directory structure:
└── timeseriesai-tsai/
    ├── docker-compose.yml
    ├── environment.yml
    ├── .devcontainer.json
    ├── nbs/
    │   ├── 003_data.validation.ipynb
    │   ├── 006_data.core.ipynb
    │   ├── 008_data.metadatasets.ipynb
    │   ├── 010_data.transforms.ipynb
    │   ├── 015_data.mixed.ipynb
    │   ├── 016_losses.ipynb
    │   ├── 020_analysis.ipynb
    │   ├── 024_callback.core.ipynb
    │   ├── 025_callback.experimental.ipynb
    │   ├── 026_callback.noisy_student.ipynb
    │   ├── 027_callback.MVP.ipynb
    │   ├── 029_models.layers.ipynb
    │   ├── 030_models.utils.ipynb
    │   ├── 036_models.InceptionTimePlus.ipynb
    │   ├── 037_models.MLP.ipynb
    │   ├── 039_models.FCNPlus.ipynb
    │   ├── 046_models.RNN_FCN.ipynb
    │   ├── 049_models.TST.ipynb
    │   ├── 050_models.TSTPlus.ipynb
    │   ├── 053_models.ROCKET.ipynb
    │   ├── 056_models.MINIROCKET_Pytorch.ipynb
    │   ├── 058_models.XResNet1d.ipynb
    │   ├── 061_models.XCM.ipynb
    │   ├── 064_models.TabTransformer.ipynb
    │   ├── 066_models.TabFusionTransformer.ipynb
    │   ├── 067_models.TSPerceiver.ipynb
    │   ├── 069_models.TSSequencerPlus.ipynb
    │   ├── 070_models.MultiInputNet.ipynb
    │   ├── 073_wandb.ipynb
    │   ├── 078_models.TransformerRNNPlus.ipynb
    │   ├── 079_models.HydraPlus.ipynb
    │   ├── _quarto.yml
    │   ├── index.ipynb
    │   ├── nbdev.yml
    │   ├── renum.py
    │   ├── styles.css
    │   ├── data/
    │   │   ├── TSCategoricalEncoder.joblib
    │   │   ├── TSDateTimeEncoder.joblib
    │   │   └── TSMissingnessEncoder.joblib
    │   ├── models/
    │   └── multimedia/
    ├── tsai/
    │   ├── __init__.py
    │   ├── all.py
    │   ├── index.py
    │   ├── callback/
    │   │   ├── __init__.py
    │   │   └── all.py
    │   ├── data/
    │   │   └── __init__.py
    │   └── models/
    │       └── __init__.py
    ├── tutorial_nbs/
    │   ├── 00_How_to_efficiently_work_with_very_large_numpy_arrays.ipynb
    │   ├── 00b_How_to_use_numpy_arrays_in_fastai.ipynb
    │   ├── 00c_Time_Series_data_preparation.ipynb
    │   ├── 01_Intro_to_Time_Series_Classification.ipynb
    │   ├── 01a_MultiClass_MultiLabel_TSClassification.ipynb
    │   ├── 02_ROCKET_a_new_SOTA_classifier.ipynb
    │   ├── 03_Time_Series_Transforms.ipynb
    │   ├── 04_Intro_to_Time_Series_Regression.ipynb
    │   ├── 05_TS_archs_comparison.ipynb
    │   ├── 06_TS_to_image_classification.ipynb
    │   ├── 07_Time_Series_Classification_with_Transformers.ipynb
    │   ├── 08_Self_Supervised_TSBERT.ipynb
    │   ├── 09_PredictionDynamics.ipynb
    │   ├── 10_Time_Series_Classification_and_Regression_with_MiniRocket.ipynb
    │   ├── 11_How_to_train_big_arrays_faster_with_tsai.ipynb
    │   ├── 12_Experiment_tracking_with_W&B.ipynb
    │   ├── 13_Hyperparameter_optimization_with_Optuna.ipynb
    │   ├── 14_Inference_Partial_Fit_and_Fine_Tune.ipynb
    │   ├── 15_PatchTST_a_new_transformer_for_LTSF.ipynb
    │   ├── data/
    │   │   └── UCR/
    │   │       └── NATOPS/
    │   │           ├── X.npy
    │   │           ├── X_train.npy
    │   │           ├── X_valid.npy
    │   │           ├── y.npy
    │   │           ├── y_train.npy
    │   │           └── y_valid.npy
    │   ├── export/
    │   │   └── dls
    │   └── images/
    └── .github/
        └── workflows/
            ├── deploy.yaml
            └── test.yaml


================================================
FILE: docker-compose.yml
================================================
version: "3"
services:
  fastai: &fastai
    restart: unless-stopped
    working_dir: /data
    image: fastai/codespaces
    logging:
      driver: json-file
      options:
        max-size: 50m
    stdin_open: true
    tty: true
    volumes:
      - .:/data/

  notebook:
    <<: *fastai
    command: bash -c "pip install -e . && jupyter notebook --allow-root --no-browser --ip=0.0.0.0 --port=8080 --NotebookApp.token='' --NotebookApp.password=''"
    ports:
      - "8080:8080"

  watcher:
    <<: *fastai
    command: watchmedo shell-command --command nbdev_build_docs --pattern *.ipynb --recursive --drop
    network_mode: host # for GitHub Codespaces https://github.com/features/codespaces/

  jekyll:
    <<: *fastai
    ports:
     - "4000:4000"
    command: >
     bash -c "cp -r docs_src docs
     && pip install .
     && nbdev_build_docs && cd docs
     && bundle i
     && chmod -R u+rwx . && bundle exec jekyll serve --host 0.0.0.0"



================================================
FILE: environment.yml
================================================
name: tsai
channels:
- fastai
- pytorch
- fastchan
- conda-forge
- defaults
dependencies:
- fastai>=2.7.9
- pyts>=0.12.0
- imbalanced-learn>=0.8.0
- psutil>=5.4.8
- pytorch>=1.7.0



================================================
FILE: .devcontainer.json
================================================
{
    "name": "nbdev_template-codespaces",
    "dockerComposeFile": "docker-compose.yml",
    "service": "watcher",
    "settings": {"terminal.integrated.shell.linux": "/bin/bash"},
    "mounts": [ "source=/var/run/docker.sock,target=/var/run/docker.sock,type=bind" ],
    "forwardPorts": [4000, 8080],
    "appPort": [4000, 8080],
    "extensions": ["ms-python.python",
                   "ms-azuretools.vscode-docker"],
    "runServices": ["notebook", "jekyll", "watcher"],
    "postStartCommand": "pip install -e ."
}



================================================
FILE: nbs/003_data.validation.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp data.validation

"""
# Spliting data
"""

"""
>Functions required to perform cross-validation and transform unique time series sequence into multiple samples ready to be used by a time series model.
"""

#|export
from tsai.imports import *
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from matplotlib.patches import Patch
from matplotlib.colors import LinearSegmentedColormap
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold
from fastcore.xtras import is_listy
from tsai.utils import *

#|export
def RandomSplitter(valid_pct=0.2, seed=None):
    "Create function that splits `items` between train/val with `valid_pct` randomly."
    def _inner(o):
        if seed is not None: torch.manual_seed(seed)
        rand_idx = L(list(torch.randperm(len(o)).numpy()))
        cut = int(valid_pct * len(o))
        return rand_idx[cut:],rand_idx[:cut]
    return _inner

#|export
def check_overlap(a, b, c=None):
    "Checks if there's overlap between array-like objects"
    a = np.asarray(a).flatten()
    b = np.asarray(b).flatten()
    c = np.asarray(c).flatten() if c is not None else c
    ab = np.isin(a, b)
    ac = np.isin(a, c) if c is not None else np.array([False])
    bc = np.isin(b, c) if c is not None else np.array([False])
    if ab.sum() + ac.sum() + bc.sum() == 0: return False
    if c is None: return L(a[ab].tolist())
    return L(a[ab].tolist()), L(a[ac].tolist()), L(b[bc].tolist())

def check_splits_overlap(splits):
    return [check_overlap(*_splits) for _splits in splits] if is_listy(splits[0][0]) else check_overlap(*splits)

def leakage_finder(*splits, verbose=True):
    '''You can pass splits as a tuple, or train, valid, ...'''
    splits = L(*splits)
    overlaps = 0
    for i in range(len(splits)):
        for j in range(i + 1, len(splits)):
            overlap = check_overlap(splits[i], splits[j])
            if overlap:
                pv(f'overlap between splits [{i}, {j}] {overlap}', verbose)
                overlaps += 1
    assert overlaps == 0, 'Please, review your splits!'

def balance_idx(o, shuffle=False, strategy="oversample", random_state=None, verbose=False):
    assert strategy in ["oversample", "undersample"]
    if isinstance(o, list): o = L(o)
    idx_ = np.arange(len(o)).reshape(-1, 1)
    if strategy == "oversample":
        ros = RandomOverSampler(random_state=random_state)
    elif strategy == "undersample":
        ros = RandomUnderSampler(random_state=random_state)
    resampled_idxs, _ = ros.fit_resample(idx_, np.asarray(o))
    new_idx = L(resampled_idxs.reshape(-1,).tolist())
    if shuffle: new_idx = random_shuffle(new_idx)
    return new_idx

a = np.arange(10)
b = np.arange(10, 20)
test_eq(check_overlap(a, b), False)
a = np.arange(10)
b = np.arange(9, 20)
test_eq(check_overlap(a, b), [9])
a = np.arange(10)
b = np.arange(10, 20)
c = np.arange(20, 30)
test_eq(check_overlap(a, b, c), False)
a = np.arange(10)
b = np.arange(10, 20)
c = np.arange(10, 30)
test_eq(check_overlap(a, b, c), ([], [], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]))

y = np.concatenate([[i] * np.random.randint(10, 100) for i in range(5)])
train_split = np.random.choice(len(y), int(len(y) * .8), False)
c, v = np.unique(y[train_split], return_counts=True)
print(f"{'imbalanced:':25} {c} {v}")

oversampled_train_split = train_split[balance_idx(y[train_split], strategy="oversample")]
osc, osv = np.unique(y[oversampled_train_split], return_counts=True)
print(f"{'balanced (oversample):':25} {osc} {osv}")
test_eq(osv, [max(v)] * len(v))

undersampled_train_split = train_split[balance_idx(y[train_split], strategy="undersample")]
usc, usv = np.unique(y[undersampled_train_split], return_counts=True)
print(f"{'balanced (undersample):':25} {usc} {usv}")
test_eq(usv, [min(v)] * len(v))
# Output:
#   imbalanced:               [0 1 2 3 4] [24 43 64 41  8]

#   balanced (oversample):    [0 1 2 3 4] [64 64 64 64 64]

#   balanced (undersample):   [0 1 2 3 4] [8 8 8 8 8]


l = L(list(concat(np.zeros(5), np.ones(10)).astype(int)))
balanced_idx = balance_idx(l)
test_eq(np.mean(l[balanced_idx]), 0.5)
test_eq(isinstance(balanced_idx, L), True)

l = list(concat(np.zeros(5), np.ones(10)).astype(int))
balanced_idx = balance_idx(l)
test_eq(np.mean(L(l)[balanced_idx]), 0.5)
test_eq(isinstance(balanced_idx, L), True)

a = concat(np.zeros(5), np.ones(10)).astype(int)
balanced_idx = balance_idx(a)
test_eq(np.mean(a[balanced_idx]), 0.5)
test_eq(isinstance(balanced_idx, L), True)

t = concat(torch.zeros(5), torch.ones(10))
balanced_idx = balance_idx(t, shuffle=True)
test_eq(t[balanced_idx].mean(), 0.5)
test_eq(isinstance(balanced_idx, L), True)

a, b = np.arange(100_000), np.arange(100_000, 200_000)

soft_labels = True
filter_pseudolabels = .5
balanced_pseudolabels = True

pseudolabels = torch.rand(1000, 3)
pseudolabels = torch.softmax(pseudolabels, -1) if soft_labels else torch.argmax(pseudolabels, -1)
hpl = torch.argmax(pseudolabels, -1) if soft_labels else pseudolabels

if filter_pseudolabels and pseudolabels.ndim > 1:
    error = 1 - pseudolabels.max(-1).values
    filt_pl_idx = np.arange(len(error))[error < filter_pseudolabels]
    filt_pl = pseudolabels[error < filter_pseudolabels]
    assert len(filt_pl) > 0, 'no filtered pseudolabels'
    filt_hpl = torch.argmax(filt_pl, -1)
else:
    filt_pl_idx = np.arange(len(pseudolabels))
    filt_pl = filt_hpl = pseudolabels

pl_split = filt_pl_idx[balance_idx(filt_hpl)] if balanced_pseudolabels else filt_pl_idx
test_eq(hpl[pl_split].float().mean(), np.mean(np.unique(hpl)))

#|export
def TrainValidTestSplitter(n_splits:int=1, valid_size:Union[float, int]=0.2, test_size:Union[float, int]=0., train_only:bool=False,
                           stratify:bool=True, balance:bool=False, strategy:str="oversample", shuffle:bool=True,
                           random_state:Union[None, int]=None, verbose:bool=False, **kwargs):
    "Split `items` into random train, valid (and test optional) subsets."

    if not shuffle and stratify and not train_only:
        pv('stratify set to False because shuffle=False. If you want to stratify set shuffle=True', verbose)
        stratify = False

    def _inner(o, **kwargs):
        if stratify:
            _, unique_counts = np.unique(o, return_counts=True)
            if np.min(unique_counts) >= 2 and np.min(unique_counts) >= n_splits: stratify_ = stratify
            elif np.min(unique_counts) < n_splits:
                stratify_ = False
                pv(f'stratify set to False as n_splits={n_splits} cannot be greater than the min number of members in each class ({np.min(unique_counts)}).',
                   verbose)
            else:
                stratify_ = False
                pv('stratify set to False as the least populated class in o has only 1 member, which is too few.', verbose)
        else: stratify_ = False
        vs = 0 if train_only else 1. / n_splits if n_splits > 1 else int(valid_size * len(o)) if isinstance(valid_size, float) else valid_size
        if test_size:
            ts = int(test_size * len(o)) if isinstance(test_size, float) else test_size
            train_valid, test = train_test_split(range(len(o)), test_size=ts, stratify=o if stratify_ else None, shuffle=shuffle,
                                                 random_state=random_state, **kwargs)
            test = toL(test)
            if shuffle: test = random_shuffle(test, random_state)
            if vs == 0:
                train, _ = RandomSplitter(0, seed=random_state)(o[train_valid])
                train = toL(train)
                if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                if shuffle: train = random_shuffle(train, random_state)
                train_ = L(L([train]) * n_splits) if n_splits > 1 else train
                valid_ = L(L([train]) * n_splits) if n_splits > 1 else train
                test_ = L(L([test]) * n_splits) if n_splits > 1 else test
                if n_splits > 1:
                    return [split for split in itemify(train_, valid_, test_)]
                else:
                    return train_, valid_, test_
            elif n_splits > 1:
                if stratify_:
                    splits = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(train_valid)), o[train_valid])
                else:
                    splits = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(train_valid)))
                train_, valid_ = L([]), L([])
                for train, valid in splits:
                    train, valid = toL(train), toL(valid)
                    if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                    if shuffle:
                        train = random_shuffle(train, random_state)
                        valid = random_shuffle(valid, random_state)
                    train_.append(L(L(train_valid)[train]))
                    valid_.append(L(L(train_valid)[valid]))
                test_ = L(L([test]) * n_splits)
                return [split for split in itemify(train_, valid_, test_)]
            else:
                train, valid = train_test_split(range(len(train_valid)), test_size=vs, random_state=random_state,
                                                stratify=o[train_valid] if stratify_ else None, shuffle=shuffle, **kwargs)
                train, valid = toL(train), toL(valid)
                if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                if shuffle:
                    train = random_shuffle(train, random_state)
                    valid = random_shuffle(valid, random_state)
                return (L(L(train_valid)[train]), L(L(train_valid)[valid]),  test)
        else:
            if vs == 0:
                train, _ = RandomSplitter(0, seed=random_state)(o)
                train = toL(train)
                if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                if shuffle: train = random_shuffle(train, random_state)
                train_ = L(L([train]) * n_splits) if n_splits > 1 else train
                valid_ = L(L([train]) * n_splits) if n_splits > 1 else train
                if n_splits > 1:
                    return [split for split in itemify(train_, valid_)]
                else:
                    return (train_, valid_)
            elif n_splits > 1:
                if stratify_: splits = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(o)), o)
                else: splits = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state).split(np.arange(len(o)))
                train_, valid_ = L([]), L([])
                for train, valid in splits:
                    train, valid = toL(train), toL(valid)
                    if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                    if shuffle:
                        train = random_shuffle(train, random_state)
                        valid = random_shuffle(valid, random_state)
                    if not isinstance(train, (list, L)):  train = train.tolist()
                    if not isinstance(valid, (list, L)):  valid = valid.tolist()
                    train_.append(L(train))
                    valid_.append(L(L(valid)))
                return [split for split in itemify(train_, valid_)]
            else:
                train, valid = train_test_split(range(len(o)), test_size=vs, random_state=random_state, stratify=o if stratify_ else None,
                                                shuffle=shuffle, **kwargs)
                train, valid = toL(train), toL(valid)
                if balance: train = train[balance_idx(o[train], random_state=random_state, strategy=strategy)]
                return train, valid
    return _inner

#|export
def plot_splits(splits):
    _max = 0
    _splits = 0
    for i, split in enumerate(splits):
        if is_listy(split[0]):
            for j, s in enumerate(split):
                _max = max(_max, array(s).max())
                _splits += 1
        else:
            _max = max(_max, array(split).max())
            _splits += 1
    _splits = [splits] if not is_listy(split[0]) else splits
    v = np.zeros((len(_splits), _max + 1))
    for i, split in enumerate(_splits):
        if is_listy(split[0]):
            for j, s in enumerate(split):
                v[i, s] = 1 + j
        else: v[i, split] = 1 + i
    vals = np.unique(v)
    if 2 in vals and 3 not in vals:
        vals = [v + 1 if v == 2 else v for v in vals]
    plt.figure(figsize=(16, len(_splits)/2))
    if len(vals) == 1:
        v = np.ones((len(_splits), _max + 1))
        plt.pcolormesh(v, color='blue')
        legend_elements = [Patch(facecolor='blue', label='Train')]
        plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')
    else:
        colors = L(['gainsboro', 'blue', 'orange', 'limegreen'])[vals]
        cmap = LinearSegmentedColormap.from_list('', colors)
        plt.pcolormesh(v, cmap=cmap)
        legend_elements = L([
            Patch(facecolor='gainsboro', label='None'),
            Patch(facecolor='blue', label='Train'),
            Patch(facecolor='orange', label='Valid'),
            Patch(facecolor='limegreen', label='Test')])[vals]
        plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.title('Split distribution')
    plt.yticks(ticks=np.arange(.5, len(_splits)+.5, 1.0), labels=np.arange(1, len(_splits)+1, 1.0).astype(int))
    plt.gca().invert_yaxis()
    plt.show()

#|export
def get_splits(o, n_splits:int=1, valid_size:float=0.2, test_size:float=0., train_only:bool=False, train_size:Union[None, float, int]=None, balance:bool=False,
               strategy:str="oversample", shuffle:bool=True, stratify:bool=True, check_splits:bool=True, random_state:Union[None, int]=None,
               show_plot:bool=True, verbose:bool=False):
    '''Arguments:
        o            : object to which splits will be applied, usually target.
        n_splits     : number of folds. Must be an int >= 1.
        valid_size   : size of validation set. Only used if n_splits = 1. If n_splits > 1 valid_size = (1. - test_size) / n_splits.
        test_size    : size of test set. Default = 0.
        train_only   : if True valid set == train set. This may be useful for debugging purposes.
        train_size   : size of the train set used. Default = None (the remainder after assigning both valid and test).
                        Useful for to get learning curves with different train sizes or get a small batch to debug a neural net.
        balance      : whether to balance data so that train always contain the same number of items per class.
        strategy     : strategy to balance data ("undersample" or "oversample"). Default = "oversample".
        shuffle      : whether to shuffle data before splitting into batches. Note that the samples within each split will be shuffle.
        stratify     : whether to create folds preserving the percentage of samples for each class.
        check_splits : whether to perform leakage and completion checks.
        random_state : when shuffle is True, random_state affects the ordering of the indices. Pass an int for reproducible output.
        show_plot    : plot the split distribution
    '''
    if n_splits == 1 and valid_size == 0. and  test_size == 0.: train_only = True
    if balance: stratify = True
    splits = TrainValidTestSplitter(n_splits, valid_size=valid_size, test_size=test_size, train_only=train_only, stratify=stratify,
                                    balance=balance, strategy=strategy, shuffle=shuffle, random_state=random_state, verbose=verbose)(o)
    if check_splits:
        if train_only or (n_splits == 1 and valid_size == 0): print('valid == train')
        elif n_splits > 1:
            for i in range(n_splits):
                leakage_finder([*splits[i]], verbose=True)
                cum_len = 0
                for split in splits[i]: cum_len += len(split)
                if not balance: assert len(o) == cum_len, f'len(o)={len(o)} while cum_len={cum_len}'
        else:
            leakage_finder([splits], verbose=True)
            cum_len = 0
            if not isinstance(splits[0], Integral):
                for split in splits: cum_len += len(split)
            else: cum_len += len(splits)
            if not balance: assert len(o) == cum_len, f'len(o)={len(o)} while cum_len={cum_len}'
    if train_size is not None and train_size != 1: # train_size=1 legacy
        if n_splits > 1:
            splits = list(splits)
            for i in range(n_splits):
                splits[i] = list(splits[i])
                if isinstance(train_size, Integral):
                    n_train_samples = train_size
                elif train_size > 0 and train_size < 1:
                    n_train_samples = int(len(splits[i][0]) * train_size)
                splits[i][0] = L(random_choice(splits[i][0], n_train_samples, False).tolist())
                if train_only:
                    if valid_size != 0: splits[i][1] = splits[i][0]
                    if test_size != 0: splits[i][2] = splits[i][0]
                splits[i] = tuple(splits[i])
            splits = tuple(splits)
        else:
            splits = list(splits)
            if isinstance(train_size, Integral):
                n_train_samples = train_size
            elif train_size > 0 and train_size < 1:
                n_train_samples = int(len(splits[0]) * train_size)
            splits[0] = L(random_choice(splits[0], n_train_samples, False).tolist())
            if train_only:
                if valid_size != 0: splits[1] = splits[0]
                if test_size != 0: splits[2] = splits[0]
            splits = tuple(splits)
    if show_plot: plot_splits(splits)
    return splits

n_splits                = 5
valid_size              = 0.2
test_size               = 0.2
train_only              = False  # set to True for debugging (valid = train)
train_size              = 5000
stratify                = True
balance                 = False
shuffle                 = True
predefined_splits       = None
show_plot               = True


check_splits = True
random_state = 23

y = np.random.randint(0, 3, 10000) + 100

splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, balance=balance, stratify=stratify,
                    train_only=train_only, train_size=train_size, check_splits=check_splits, random_state=random_state, show_plot=show_plot, verbose=True)
splits
# Output:
#   <Figure size 1600x250 with 1 Axes>
#   (((#5000) [3490,2428,4475,8317,2802,6834,2954,7671,3383,9554...],

#     (#1600) [1680,6677,5879,4428,5511,8312,372,5127,7012,3021...],

#     (#2000) [1263,6498,1602,1838,1073,5304,1210,1037,8789,6175...]),

#    ((#5000) [3442,4237,470,3901,3808,3793,6286,8546,6254,9530...],

#     (#1600) [9160,5451,3628,143,2054,7225,7124,8057,1405,5089...],

#     (#2000) [1263,6498,1602,1838,1073,5304,1210,1037,8789,6175...]),

#    ((#5000) [9850,7451,7338,9742,3258,1527,4450,5678,2932,1693...],

#     (#1600) [6186,5970,376,7848,3786,1663,7193,3647,3277,553...],

#     (#2000) [1263,6498,1602,1838,1073,5304,1210,1037,8789,6175...]),

#    ((#5000) [1853,7308,7375,3851,1852,3820,2601,3868,8718,7190...],

#     (#1600) [4182,6419,6265,4837,168,9627,2500,9951,1610,7547...],

#     (#2000) [1263,6498,1602,1838,1073,5304,1210,1037,8789,6175...]),

#    ((#5000) [7878,6392,453,4817,4676,5738,6482,4033,8114,7337...],

#     (#1600) [7682,6416,2877,9164,1583,342,2916,4806,8776,2046...],

#     (#2000) [1263,6498,1602,1838,1073,5304,1210,1037,8789,6175...]))

train_size=256
y = np.random.randint(0, 3, 1000) + 100
splits = get_splits(y, train_size=train_size, train_only=True)
test_eq(splits[0], splits[1])
test_eq(len(splits[0]), train_size)
splits
# Output:
#   valid == train

#   <Figure size 1600x50 with 1 Axes>
#   ((#256) [550,813,388,595,948,198,354,749,175,812...],

#    (#256) [550,813,388,595,948,198,354,749,175,812...])

#|export
def get_walk_forward_splits(
    o, # 3D object with shape [samples x features x steps] containing the time series we need to split
    n_splits=1, # # of splits
    train_size=None, # optional: training set size as an int or a float. None when using and anchored strategy.
    valid_size=0.2, # validation set size as an int or a float
    test_size=0., # test set size as an int or a float
    anchored = False, # starting point for train set remains the same for all splits
    gap = 0., # # of samples to exclude from the end of each train set before the validation set. Entered as an int or a float
    test_after_valid = True, # flag to indicate if validation and test will be samples randomly or sequentially
    random_state = None, # integer that can be used to generate reproducible results
    show_plot=True, # plots the splits created
):

    if anchored:
        train_size = None
    elif isinstance(train_size, float):
        train_size = np.int32(np.floor(len(o) * train_size))
    if isinstance(valid_size, float):
        valid_size = np.int32(np.floor(len(o) * valid_size))
    if isinstance(test_size, float):
        test_size = np.int32(np.floor(len(o) * test_size))
    if isinstance(gap, float):
        gap = np.int32(np.floor(len(o) * gap))

    if train_size is not None:
        assert train_size + (valid_size + test_size + gap) * n_splits <= len(o), "reduce train_size, valid_size, test_size, gap or n_splits"
    else:
        assert (valid_size + test_size + gap) * n_splits < len(o), "reduce valid_size, test_size, gap or n_splits"

    if not test_after_valid:
        assert valid_size == test_size

    train_idxs = []
    valid_idxs = []
    test_idxs = []

    end = 0
    all_idxs = np.arange(len(o))
    for n in range(n_splits):
        if valid_size > 0 and test_size > 0:
            if test_after_valid:
                test_idxs.append(L(all_idxs[-test_size:].tolist()))
                all_idxs = all_idxs[:-test_size]
                valid_idxs.append(L(all_idxs[-valid_size:].tolist()))
                all_idxs = all_idxs[:-valid_size]
                if gap > 0:
                    all_idxs = all_idxs[:-gap]
                if anchored:
                    train_idxs.append(L(all_idxs.tolist()))
                else:
                    train_idxs.append(L(all_idxs[-train_size:].tolist()))
            else:
                valid_test_idxs = all_idxs[-test_size - valid_size:]
                np.random.seed(random_state)
                valid_test_idxs = np.random.permutation(valid_test_idxs)
                valid_idxs.append(L(valid_test_idxs[:valid_size]))
                test_idxs.append(L(valid_test_idxs[valid_size:]))
                all_idxs = all_idxs[:-test_size - valid_size]
                if gap > 0:
                    all_idxs = all_idxs[:-gap]
                if anchored:
                    train_idxs.append(L(all_idxs.tolist()))
                else:
                    train_idxs.append(L(all_idxs[-train_size:].tolist()))
        elif valid_size > 0:
            valid_idxs.append(L(all_idxs[-valid_size:].tolist()))
            all_idxs = all_idxs[:-valid_size]
            test_idxs.append(L([]))
            if gap > 0:
                all_idxs = all_idxs[:-gap]
            if anchored:
                train_idxs.append(L(all_idxs.tolist()))
            else:
                train_idxs.append(L(all_idxs[-train_size:].tolist()))

    splits = []
    for n in range(n_splits):
        if valid_size > 0 and test_size > 0:
            splits.append((L(train_idxs[n]), L(valid_idxs[n]), L(test_idxs[n])))
        elif valid_size > 0:
            splits.append((L(train_idxs[n]), L(valid_idxs[n])))
        else:
            splits.append((L(train_idxs[n]),))
    splits = tuple(splits)[::-1]
    if show_plot:
        plot_splits(splits)
    return splits

o = np.random.rand(10_000, 3,  50) # shape: [samples x features x steps]

splits = get_walk_forward_splits(
    o,
    n_splits=4,
    train_size=.6,
    valid_size=0.1,
    test_size=0.1,
    anchored = True,
    gap = 100,
    test_after_valid = True,
    random_state = None,
    show_plot=True,
)

splits = get_walk_forward_splits(
    o,
    n_splits=3,
    train_size=0.3,
    valid_size=0.1,
    test_size=0.1,
    anchored = False,
    gap = 0.,
    test_after_valid = False,
    random_state = None,
    show_plot=True,
)
# Output:
#   <Figure size 1600x200 with 1 Axes>
#   <Figure size 1600x150 with 1 Axes>

#|export
def TSSplitter(
    valid_size=0.2, # int or float indicating the validation set size
    test_size=0., # int or float indicating the test set size
    fcst_horizon=0, # int that indicates the number of time steps removed at the end of train (and validation)
    show_plot=True, # flag that indicates if a plot showing the splits will be created
):
    "Create function that splits `items` between train/val with `valid_size` without shuffling data."

    if fcst_horizon:
        fcst_horizon = fcst_horizon - 1

    def _inner(o):
        valid_cut = valid_size if isinstance(valid_size, Integral) else round(valid_size * len(o))
        if test_size:
            test_cut = test_size if isinstance(test_size, Integral) else round(test_size * len(o))
        else:
            test_cut = 0
        idx = np.arange(len(o), dtype=smallest_dtype(len(o)))
        if test_size:
            if len(idx) < 1_000_000:
                splits = (L(idx[:-valid_cut - test_cut - fcst_horizon].tolist()),
                          L(idx[-valid_cut - test_cut: - test_cut - fcst_horizon].tolist()),
                          L(idx[-test_cut:].tolist()))
            else:
                splits = (idx[:-valid_cut - test_cut - fcst_horizon],
                          idx[-valid_cut - test_cut: - test_cut - fcst_horizon],
                          idx[-test_cut:])
        else:
            if len(idx) < 1_000_000:
                splits = (L(idx[:-valid_cut - fcst_horizon].tolist()), L(idx[-valid_cut:].tolist()))
            else:
                splits = (idx[:-valid_cut - fcst_horizon], idx[-valid_cut:])
        if show_plot:
            if len(o) > 1_000_000:
                warnings.warn('the splits are too large to be plotted')
            else:
                plot_splits(splits) if test_size else plot_splits(splits[:2])
        return splits
    return _inner

TimeSplitter = TSSplitter

y = np.arange(1000) + 100
test_eq(TimeSplitter(valid_size=0.2)(y)[1], L(np.arange(800, 1000).tolist()))
test_eq(TimeSplitter(valid_size=0.2)(y)[0], TimeSplitter(valid_size=200)(y)[0])
TimeSplitter(valid_size=0.2, show_plot=True)(y)
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   ((#800) [0,1,2,3,4,5,6,7,8,9...],

#    (#200) [800,801,802,803,804,805,806,807,808,809...])

n_splits                = 5
valid_size              = 0.2
test_size               = 0
train_only              = False  # set to True for debugging (valid = train)
train_size              = None
stratify                = True
balance                 = True
shuffle                 = True
predefined_splits       = None
show_plot               = True


check_splits = True
random_state = 23

splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, balance=balance, stratify=stratify,
                    train_only=train_only, train_size=train_size, check_splits=check_splits, random_state=random_state, show_plot=show_plot, verbose=True)
split = splits[0] if n_splits == 1 else splits[0][0]
y[split].mean(), split
# Output:
#   stratify set to False as n_splits=5 cannot be greater than the min number of members in each class (1).

#   <Figure size 1600x250 with 1 Axes>
#   (601.11, (#800) [314,194,782,789,502,917,137,415,904,181...])

list([splits[0], splits[1], splits[2], splits[3], splits[4]])
# Output:
#   [((#800) [314,194,782,789,502,917,137,415,904,181...],

#     (#200) [362,151,934,378,95,597,500,117,980,844...]),

#    ((#800) [312,198,777,788,515,910,145,413,898,186...],

#     (#200) [352,133,955,396,64,596,442,79,991,882...]),

#    ((#800) [311,197,783,791,507,922,145,416,908,184...],

#     (#200) [338,125,912,361,54,594,486,88,994,859...]),

#    ((#800) [296,181,782,789,493,917,130,401,905,165...],

#     (#200) [405,199,953,444,113,610,515,137,997,881...]),

#    ((#800) [320,190,782,788,506,906,141,412,893,178...],

#     (#200) [336,149,942,358,49,582,472,70,990,907...])]

n_splits = 5
valid_size = 0.
test_size = 0.
shuffle = True
stratify = True
train_only = True
train_size = None
check_splits = True
random_state = 1
show_plot = True

splits = get_splits(y, n_splits=n_splits, valid_size=valid_size, test_size=test_size, shuffle=shuffle, stratify=stratify,
                    train_only=train_only, train_size=train_size, check_splits=check_splits, random_state=random_state, show_plot=show_plot, verbose=True)
for split in splits:
    test_eq(len(split[0]), len(y))
    test_eq(np.sort(split[0]), np.arange(len(y)))
# Output:
#   stratify set to False as n_splits=5 cannot be greater than the min number of members in each class (1).

#   valid == train

#   <Figure size 1600x250 with 1 Axes>

n_splits = 5
y = np.random.randint(0, 2, 1000)

splits = get_splits(y, n_splits=n_splits, shuffle=False, check_splits=True)
test_eq(np.concatenate((L(zip(*splits))[1])), np.arange(len(y)))

splits = get_splits(y, n_splits=n_splits, shuffle=True, check_splits=True)
test_eq(np.sort(np.concatenate((L(zip(*splits))[1]))), np.arange(len(y)))
# Output:
#   <Figure size 1600x250 with 1 Axes>
#   <Figure size 1600x250 with 1 Axes>

n_splits = 2
y = np.random.randint(0, 2, 1000)

splits = get_splits(y, n_splits=n_splits, test_size=0.2, shuffle=False)
for i in range(n_splits): leakage_finder(*splits[i])
test_eq(len(splits), n_splits)
test_eq(len(splits[0]), 3)
s = []
[s.extend(split) for split in splits[0]]
test_eq(np.sort(s), np.arange(len(y)))
s = []
[s.extend(split) for split in splits[1]]
test_eq(np.sort(s), np.arange(len(y)))
# Output:
#   <Figure size 1600x100 with 1 Axes>

y = np.random.randint(0, 2, 1000)
splits1 = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)
splits2 = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)
splits3 = get_splits(y, valid_size=.25, test_size=0, random_state=None, stratify=True, shuffle=True)
splits4 = get_splits(y, valid_size=.25, test_size=0, random_state=None, stratify=True, shuffle=True)
test_eq(splits1[0], splits2[0])
test_ne(splits3[0], splits4[0])
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>

y = np.random.randint(0, 2, 100)
splits = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True, shuffle=True)
test_eq(len(splits), 2)
# Output:
#   <Figure size 1600x50 with 1 Axes>

y = np.random.randint(0, 2, 100)
splits = get_splits(y, valid_size=.25, test_size=0, random_state=23, stratify=True)
test_eq(len(splits), 2)
# Output:
#   <Figure size 1600x50 with 1 Axes>

y = np.random.randint(0, 2, 100)
splits = get_splits(y, valid_size=.25, test_size=20, random_state=23, stratify=True)
test_eq(len(splits), 3)
leakage_finder(*splits)
# Output:
#   <Figure size 1600x50 with 1 Axes>

splits = TrainValidTestSplitter(valid_size=.25, test_size=20, random_state=23, stratify=True)(np.random.randint(0, 2, 100))
test_eq(len(splits[1]), 25)
test_eq(len(splits[2]), 20)

o = np.random.randint(0, 2, 1000)
for p in [1, .75, .5, .25, .125]:
    splits = get_splits(o, train_size=p)
    test_eq(len(splits[0]), len(o) * .8 * p)
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>
#   <Figure size 1600x50 with 1 Axes>

y = L([0] * 50 + [1] * 25 + [2] * 15 + [3] * 10)
splits = get_splits(y, valid_size=.2, test_size=.2)
test_eq(np.mean(y[splits[0]])==np.mean(y[splits[1]])==np.mean(y[splits[2]]), True)
splits
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   ((#60) [58,95,53,44,28,69,9,12,22,88...],

#    (#20) [89,71,60,4,19,37,75,13,46,30...],

#    (#20) [76,68,74,29,16,97,14,21,90,82...])

y = L([0] * 50 + [1] * 25 + [2] * 15 + [3] * 10)
splits = get_splits(y, n_splits=1, valid_size=.2, test_size=.2, shuffle=False)
# test_eq(splits[0] + splits[1] + splits[2], np.arange(100))
splits
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   ((#60) [0,1,2,3,4,5,6,7,8,9...],

#    (#20) [60,61,62,63,64,65,66,67,68,69...],

#    (#20) [80,81,82,83,84,85,86,87,88,89...])

splits = get_splits(np.random.randint(0,5,100), valid_size=0.213, test_size=17)
test_eq(len(splits[1]), 21)
test_eq(len(splits[2]), 17)
# Output:
#   <Figure size 1600x50 with 1 Axes>

splits = get_splits(np.random.randint(0,5,100), valid_size=0.213, test_size=17, train_size=.2)
splits
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   ((#12) [37,38,62,60,16,22,95,44,94,98...],

#    (#21) [88,93,5,31,57,23,90,18,15,40...],

#    (#17) [4,86,47,33,59,52,99,48,70,3...])

#|export
def get_predefined_splits(*xs):
    '''xs is a list with X_train, X_valid, ...'''
    splits_ = []
    start = 0
    for x in xs:
        splits_.append(L(list(np.arange(start, start + len(x)))))
        start += len(x)
    return tuple(splits_)

def combine_split_data(xs, ys=None):
    '''xs is a list with X_train, X_valid, .... ys is None or a list with y_train, y_valid, .... '''
    xs = [to3d(x) for x in xs]
    splits = get_predefined_splits(*xs)
    if ys is None: return concat(*xs), None, splits
    else: return concat(*xs), concat(*ys), splits

#|export
def get_splits_len(splits):
    _len = []
    for split in splits:
        if isinstance(split[0], (list, L, tuple)):  _len.append([len(s) for s in split])
        else: _len.append(len(split))
    return _len

X_train, y_train, X_valid, y_valid = np.random.rand(3,3,4), np.random.randint(0,2,3), np.random.rand(2,3,4), np.random.randint(0,2,2)
X, y, splits = combine_split_data([X_train, X_valid], [y_train, y_valid])
test_eq(X_train, X[splits[0]])
test_eq(X_valid, X[splits[1]])
test_type(X_train, X)
test_type(y_train, y)

X_train, y_train, X_valid, y_valid = np.random.rand(3,4), np.random.randint(0,2,3), np.random.rand(2,4), np.random.randint(0,2,2)
X, y, splits = combine_split_data([X_train, X_valid], [y_train, y_valid])
test_eq(X_train[:, None], X[splits[0]])
test_eq(X_valid[:, None], X[splits[1]])
test_type(X_train, X)
test_type(y_train, y)

"""
# Forecasting
"""

#|export
def get_usable_idxs(df, fcst_history, fcst_horizon, stride=1):
    if len(df) < fcst_history + fcst_horizon:
        return np.array([], dtype=int)
    usable_idxs = df[fcst_history - 1:len(df) - fcst_horizon].index.values
    if stride != 1:
        usable_idxs = usable_idxs[::-stride][::-1]
    return usable_idxs


def get_df_usable_idxs(
    df,                         # dataframe containing a sorted time series
    fcst_history,               # # historical steps used as input (size of the sliding window for the input)
    fcst_horizon,               # # steps forecasted into the future (size of the sliding window for the target)
    stride=1,                   # int or tuple of 2 int containing the strides of the sliding windows (input and target)
    unique_id_cols=None,        # str indicating the column/s with the unique identifier/s for each entity
    return_np_indices=False,    # bool indicating what type of indices are returned. Default to False (dataframe indices)
):
    "Calculates the indices that can be used from a df when using a sliding window"

    dtype = smallest_dtype(len(df))
    if unique_id_cols is not None:
        usable_df_idxs = np.sort(np.concatenate(df
                                                .reset_index(drop=True)
                                                .groupby(unique_id_cols)
                                                .apply(lambda x: get_usable_idxs(x,
                                                                                 fcst_history=fcst_history,
                                                                                 fcst_horizon=fcst_horizon,
                                                                                 stride=stride
                                                                                )).values, dtype=dtype))
    else:
        usable_df_idxs = np.sort(get_usable_idxs(df, fcst_history, fcst_horizon, stride).astype(dtype=dtype))
    if return_np_indices:
        usable_df_idxs = usable_df_idxs - (fcst_history - 1)
    return usable_df_idxs


#|export
def calculate_fcst_stats(
    df, # dataframe containing a sorted time series for a single entity or subject
    fcst_history, # # historical steps used as input.
    fcst_horizon, # # steps forecasted into the future.
    splits, # splits that will be used to train the model. splits[0] is the train split:
    x_vars=None, # features used as input
    y_vars=None,  # features used as output
    subset_size=None, # int or float to determne the number of train samples used to calculate the mean and std
):
    "Calculates the training stats required in a forecasting task"
    x_vars = list(df.columns) if x_vars is None else feat2list(x_vars)
    y_vars = list(df.columns) if y_vars is None else feat2list(y_vars)
    split = splits[0] if is_listy(splits[0]) else splits
    if fcst_history == 1:
        train_idxs = split
    else:

        if subset_size is None:
            idxs = split
        else:
            subset = int(subset_size) if isinstance(subset_size, Integral) else int(subset_size * len(split))
            idxs = random_choice(idxs, subset, replace=False)
        dtype = smallest_dtype(max(split) + fcst_history)
        train_idxs = np.unique((np.asarray(idxs, dtype=dtype).reshape(-1,1) + np.arange(fcst_history, dtype=dtype).reshape(1, -1)).flatten())
    mean = df.reset_index().loc[train_idxs, x_vars].mean().values.reshape(1, -1, 1)
    std  = df.reset_index().loc[train_idxs, x_vars].std().values.reshape(1, -1, 1)
    if x_vars == y_vars:
        return (mean, std)
    y_mean = df.reset_index().loc[train_idxs, y_vars].mean().values.reshape(1, -1, 1)
    y_std  = df.reset_index().loc[train_idxs, y_vars].std().values.reshape(1, -1, 1)
    return (mean, std), (y_mean, y_std)

#|export
def get_forecasting_splits(
    df,                         # dataframe containing a sorted time series
    fcst_history,               # # historical steps used as input (size of the sliding window for the input)
    fcst_horizon,               # # steps forecasted into the future (size of the sliding window for the target)
    stride=1,                   # int or tuple of 2 int containing the strides of the sliding windows (input and target)
    valid_size=0.,              # int or float indicating the size of the training set (based on datetimes)
    test_size=0.2,              # int or float indicating the size of the test set (based on datetimes)
    valid_cutoff_datetime=None, # first prediction datetime of validation dataset
    test_cutoff_datetime=None,  # first prediction datetime of test dataset
    datetime_col=None,          # str indicating the column with the datetime values
    use_index=False,            # flag to indicate if the datetime is in the index
    unique_id_cols=None,        # str indicating the column/s with the unique identifier/s for each entity
    show_plot=True,             # flag to indicate if splits should be plotted
):

    if unique_id_cols or valid_cutoff_datetime is not None or test_cutoff_datetime is not None:
        assert datetime_col is not None or use_index, \
        "you need to pass a datetime_col or set use_index=False to be able to access datetime"

    if valid_cutoff_datetime is not None or test_cutoff_datetime is not None:
        valid_size = 0
        test_size = 0

    use_valid = valid_cutoff_datetime is not None or valid_size != 0
    use_test = test_cutoff_datetime is not None or test_size != 0

    if valid_cutoff_datetime is not None:
        valid_cutoff_datetime = np.datetime64(valid_cutoff_datetime)
    if test_cutoff_datetime is not None:
        test_cutoff_datetime = np.datetime64(test_cutoff_datetime)

    if use_index:
        datetime_col = 'index' if df.index.name is None else df.index.name
        df = df.reset_index(drop=False)[feat2list(datetime_col) + feat2list(unique_id_cols)]
    elif datetime_col is not None:
        df = df[feat2list(datetime_col) + feat2list(unique_id_cols)]
    else:
        df = df.reset_index(drop=True)
        if unique_id_cols is not None:
            df = df[feat2list(unique_id_cols)]

    usable_df_idxs = get_df_usable_idxs(df, fcst_history, fcst_horizon, stride=stride, unique_id_cols=unique_id_cols)
    usable_np_idxs = usable_df_idxs - (fcst_history - 1)

    if datetime_col is not None:
        usable_steps = pd.to_datetime(df.loc[usable_df_idxs, datetime_col])
        cat = usable_steps.astype('category').cat
        usable_step_codes = cat.codes.values
    else:
        usable_step_codes = np.arange(len(usable_df_idxs))


    # test indices
    if test_cutoff_datetime is not None:
        test_start = np.argmax(cat.categories >= test_cutoff_datetime)
        test_idxs = usable_np_idxs[usable_step_codes >= test_start]
    elif test_size:
        if test_size < 1:
            if unique_id_cols is None:
                n_usable_steps = len(usable_step_codes) - (fcst_horizon - 1) * (int(valid_size > 0) + int(test_size > 0))
            else:
                n_usable_steps = len(usable_step_codes)
            test_size = round(n_usable_steps * test_size)
        test_start = np.sort(usable_step_codes)[- test_size]
        test_idxs = usable_np_idxs[usable_step_codes >= test_start]
    else:
        test_idxs = np.array([])
    test_size = len(test_idxs)

    # valid indices
    if valid_cutoff_datetime is not None:
        valid_start =  np.argmax(cat.categories >= valid_cutoff_datetime)
        if test_cutoff_datetime is not None:
            valid_end = test_start - (fcst_horizon - 1) // stride
            assert valid_start <= valid_end, "you need to modify valid_size and/or test_size due to lack of data"
            valid_idxs = usable_np_idxs[(usable_step_codes >= valid_start) & (usable_step_codes < valid_end)]
        else:
            valid_idxs = usable_np_idxs[(usable_step_codes >= valid_start)]
    elif valid_size:
        if valid_size < 1:
            if unique_id_cols is None:
                n_usable_steps = len(usable_step_codes) - (fcst_horizon - 1) * (int(valid_size > 0) + int(test_size > 0))
            else:
                n_usable_steps = len(usable_step_codes)
            valid_size = round(n_usable_steps * valid_size)
        if test_size:
            valid_end = test_start - (fcst_horizon - 1) // stride
            remaining_usable_step_codes = usable_step_codes[usable_step_codes < valid_end]
            valid_start = np.sort(remaining_usable_step_codes)[- valid_size]
            assert 0 < valid_start <= valid_end <= test_start, "you need to modify valid_size and/or test_size due to lack of data"
            valid_idxs = usable_np_idxs[(usable_step_codes >= valid_start) & (usable_step_codes < valid_end)]
        else:
            valid_start = np.sort(usable_step_codes)[- valid_size]
            valid_idxs = usable_np_idxs[usable_step_codes >= valid_start]
    else:
        valid_idxs = np.array([])
    valid_size = len(valid_idxs)

    # train indices
    if use_valid:
        train_end = valid_start - (fcst_horizon - 1) // stride
        assert train_end > 0, "you need to modify valid_size due to lack of data"
        train_idxs = usable_np_idxs[usable_step_codes < train_end]
    elif use_test:
        train_end = test_start - (fcst_horizon - 1) // stride
        assert train_end > 0, "you need to modify test_size due to lack of data"
        train_idxs = usable_np_idxs[usable_step_codes < train_end]
    else:
        train_idxs = usable_np_idxs
    train_size = len(train_idxs)


    if len(df) < 1_000_000:
        train_idxs = L(train_idxs.tolist())
        if len(valid_idxs):
            valid_idxs = L(valid_idxs.tolist())
        if len(test_idxs):
            test_idxs = L(test_idxs.tolist())

    splits = (train_idxs,)
    if valid_size:
        splits += (valid_idxs,)
    if test_size:
        splits += (test_idxs,)

    if show_plot:
        if len(df) > 1_000_000:
            warnings.warn('the splits are too large to be plotted')
        else:
            plot_splits(splits)
    return tuple(splits)

df1_len = 100
df2_len = 80

datetime_col = 'datetime'
df1 = pd.DataFrame(np.arange(df1_len), columns=['value'])
df1['datetime'] = pd.date_range(pd.to_datetime('1749-03-31'), periods=df1_len, freq='1D')
df1['type'] = 1

df = df1
display(df)

# settings
fcst_history          = 10
fcst_horizon          = 1
stride                = 1
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = False
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")

# settings
fcst_history          = 10
fcst_horizon          = 5
stride                = 5
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = False
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")
# Output:
#       value   datetime  type

#   0       0 1749-03-31     1

#   1       1 1749-04-01     1

#   2       2 1749-04-02     1

#   3       3 1749-04-03     1

#   4       4 1749-04-04     1

#   ..    ...        ...   ...

#   95     95 1749-07-04     1

#   96     96 1749-07-05     1

#   97     97 1749-07-06     1

#   98     98 1749-07-07     1

#   99     99 1749-07-08     1

#   

#   [100 rows x 3 columns]
#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [63, 9, 18] (90: [0.7, 0.1, 0.2])

#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [12, 2, 4] (18: [0.67, 0.11, 0.22])


df1_len = 100
df2_len = 80

datetime_col = 'datetime'
df1 = pd.DataFrame(np.arange(df1_len), columns=['value'])
df1['datetime'] = pd.date_range(pd.to_datetime('1749-03-31'), periods=df1_len, freq='1D')
df1['type'] = 1
df1_index = df1.set_index("datetime")

df = df1_index
display(df)

# settings
fcst_history          = 10
fcst_horizon          = 1
stride                = 1
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = True
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")

# settings
fcst_history          = 10
fcst_horizon          = 5
stride                = 5
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = True
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")
# Output:
#               value  type

#   datetime               

#   1749-03-31      0     1

#   1749-04-01      1     1

#   1749-04-02      2     1

#   1749-04-03      3     1

#   1749-04-04      4     1

#   ...           ...   ...

#   1749-07-04     95     1

#   1749-07-05     96     1

#   1749-07-06     97     1

#   1749-07-07     98     1

#   1749-07-08     99     1

#   

#   [100 rows x 2 columns]
#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [63, 9, 18] (90: [0.7, 0.1, 0.2])

#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [12, 2, 4] (18: [0.67, 0.11, 0.22])


df1_len = 100
df2_len = 80

datetime_col = 'datetime'
df1 = pd.DataFrame(np.arange(df1_len), columns=['value'])
df1['datetime'] = pd.date_range(pd.to_datetime('1749-03-31'), periods=df1_len, freq='1D')
df1['type'] = 1
df1_index = df1.set_index("datetime")
df2 = pd.DataFrame(np.arange(df2_len) * 10, columns=['value'])
df2['datetime'] = pd.date_range(pd.to_datetime('1749-04-15'), periods=df2_len, freq='1D')
df2['type'] = 2
df_comb = pd.concat([df1, df2]).reset_index(drop=True).reset_index(drop=True)


df = df_comb
display(df)

# settings
fcst_history          = 10
fcst_horizon          = 3
stride                = 1
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = False
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")
# Output:
#        value   datetime  type

#   0        0 1749-03-31     1

#   1        1 1749-04-01     1

#   2        2 1749-04-02     1

#   3        3 1749-04-03     1

#   4        4 1749-04-04     1

#   ..     ...        ...   ...

#   175    750 1749-06-29     2

#   176    760 1749-06-30     2

#   177    770 1749-07-01     2

#   178    780 1749-07-02     2

#   179    790 1749-07-03     2

#   

#   [180 rows x 3 columns]
#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [101, 16, 31] (148: [0.68, 0.11, 0.21])


df1_len = 100
df2_len = 80

datetime_col = 'datetime'
df1 = pd.DataFrame(np.arange(df1_len), columns=['value'])
df1['datetime'] = pd.date_range(pd.to_datetime('1749-03-31'), periods=df1_len, freq='1D')
df1['type'] = 1
df1_index = df1.set_index("datetime")
df2 = pd.DataFrame(np.arange(df2_len) * 10, columns=['value'])
df2['datetime'] = pd.date_range(pd.to_datetime('1749-04-15'), periods=df2_len, freq='1D')
df2['type'] = 2
df_comb = pd.concat([df1, df2]).reset_index(drop=True).reset_index(drop=True)
df_comb_index = df_comb.set_index("datetime")
df_comb_index.index.name = None


df = df_comb_index
display(df)

# settings
fcst_history          = 15
fcst_horizon          = 5
stride                = 1
unique_id_cols        = 'type'
datetime_col          = 'datetime'
use_index             = True
valid_size            = 0.1  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
test_size             = 0.2  # a percent (float) or a number of samples (int) - .1 means 10% of the dates
valid_cutoff_datetime = '1749-08-21' # first prediction datetime of validation dataset
test_cutoff_datetime  = '1749-12-24' # first prediction datetime of test dataset
valid_cutoff_datetime = None # datetime compatible with the datetime_col containing the starting date for the validation dataset
test_cutoff_datetime  = None # datetime compatible with the datetime_col containing the starting date for the validation dataset


splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, stride=stride,
                                unique_id_cols=unique_id_cols, datetime_col=datetime_col, use_index=use_index,
                                valid_size=valid_size, test_size=test_size,
                                valid_cutoff_datetime=valid_cutoff_datetime, test_cutoff_datetime=test_cutoff_datetime)

print(f"splits size   : {[len(s) for s in splits]} ({sum([len(s) for s in splits])}: {[round(len(s)/sum([len(s) for s in splits]), 2) for s in splits]})")
# Output:
#               value  type

#   1749-03-31      0     1

#   1749-04-01      1     1

#   1749-04-02      2     1

#   1749-04-03      3     1

#   1749-04-04      4     1

#   ...           ...   ...

#   1749-06-29    750     2

#   1749-06-30    760     2

#   1749-07-01    770     2

#   1749-07-02    780     2

#   1749-07-03    790     2

#   

#   [180 rows x 2 columns]
#   <Figure size 1600x50 with 1 Axes>
#   splits size   : [83, 14, 29] (126: [0.66, 0.11, 0.23])


#|export
def get_long_term_forecasting_splits(
    df, # dataframe containing a sorted time series for a single entity or subject
    fcst_history,   # # historical steps used as input.
    fcst_horizon,   # # steps forecasted into the future.
    dsid=None,      # dataset name
    show_plot=True, # plot the splits
):
    "Returns the train, valid and test splits for long-range time series datasets"

    if dsid in ["ETTh1", "ETTh2"]:
        border1s = [0, 12 * 30 * 24 - fcst_history, 12 * 30 * 24 + 4 * 30 * 24 - fcst_history]
        border2s = [12 * 30 * 24, 12 * 30 * 24 + 4 * 30 * 24, 12 * 30 * 24 + 8 * 30 * 24]
    elif dsid in ["ETTm1", "ETTm2"]:
        border1s = [0, 12 * 30 * 24 * 4 - fcst_history, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - fcst_history]
        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]
    else:
        train_size = .7 # default 0.7
        test_size = .2 # default 0.2
        num_train = int(len(df) * train_size)
        num_test = int(len(df) * test_size)
        num_vali = len(df) - num_train - num_test
        assert num_train + num_test + num_vali <= len(df)
        border1s = [0, num_train - fcst_history, len(df) - num_test - fcst_history]
        border2s = [num_train, num_train + num_vali, len(df)]

    train_split = L(np.arange(border1s[0], border2s[0] - fcst_horizon - fcst_history + 1).tolist())
    valid_split = L(np.arange(border1s[1], border2s[1] - fcst_horizon - fcst_history + 1).tolist())
    test_split = L(np.arange(border1s[2], border2s[2] - fcst_horizon - fcst_history + 1).tolist())
    splits = train_split, valid_split, test_split
    if show_plot:
        plot_splits(splits)
    return splits

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/003_data.validation.ipynb saved at 2023-07-01 12:22:02

#   Correct notebook to script conversion! 😃

#   Saturday 01/07/23 12:22:05 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/006_data.core.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp data.core

"""
# Data Core
"""

"""
>Main Numpy and Times Series functions used throughout the library.
"""

#|export
import warnings
from tsai.imports import *
from sklearn.model_selection import StratifiedKFold
from types import MethodType
from matplotlib.ticker import PercentFormatter
import matplotlib.colors as mcolors
from matplotlib import rcParams
from fastcore.transform import Transform, DisplayedTransform, Pipeline
from fastai.data.transforms import (RandomSplitter, ItemGetter, MultiCategorize, CategoryMap,
Category, MultiCategory, Categorize)
from fastai.data.core import TfmdLists, Datasets, TfmdDL, DataLoaders
from fastai.data.load import DataLoader
from fastai.data.block import CategoryBlock, DataBlock
from fastai.losses import MSELossFlat, CrossEntropyLossFlat, BCEWithLogitsLossFlat
from fastai.vision.data import get_grid
from tsai.utils import *

warnings.filterwarnings("ignore", category=UserWarning)

from tsai.data.external import get_UCR_data

dsid = 'OliveOil'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, on_disk=True, force_download=True)
X_on_disk, y_on_disk, splits = get_UCR_data(dsid, on_disk=True, return_split=False, force_download=True)
X_in_memory, y_in_memory, splits = get_UCR_data(dsid, on_disk=False, return_split=False, force_download=True)
y_tensor = cat2int(y_on_disk)
y_array = y_tensor.numpy()

#|export
class NumpyTensor(TensorBase):
    "Returns a `tensor` with subclass `NumpyTensor` that has a show method"

    def __new__(cls, o, dtype=None, device=None, copy=None, requires_grad=False, **kwargs):
        o = torch.asarray(o, dtype=dtype, device=device, copy=copy, requires_grad=requires_grad)
        res = cast(o, cls) # if the tensor results in a dtype torch.float64 a copy is made as dtype torch.float32
        for k,v in kwargs.items(): setattr(res, k, v)
        return res

    @property
    def data(self): return cast(self, Tensor)

    def __repr__(self):
        if self.ndim > 0: return f'NumpyTensor(shape:{tuple(self.shape)}, device={self.device}, dtype={self.dtype})'
        else: return f'NumpyTensor([{self.data}], device={self.device}, dtype={self.dtype})'


    def show(self, ax=None, ctx=None, title=None, **kwargs):
        if self.ndim == 0: return str(self.data)
        elif self.ndim != 2: self = type(self)(to2d(self))
        if not isinstance(self,np.ndarray): self = self.detach().cpu().numpy()
        ax = ifnone(ax, ctx)
        if ax is None: _, ax = plt.subplots(**kwargs)
        ax.plot(self.T)
        ax.axis(xmin=0, xmax=self.shape[-1] - 1)
        title_color = kwargs['title_color'] if 'title_color' in kwargs else rcParams['axes.labelcolor']
        if title is not None:
            if is_listy(title): title = str(title)[1:-1]
            ax.set_title(title, weight='bold', color=title_color)
        plt.tight_layout()
        return ax


class ToNumpyTensor(Transform):
    "Transforms an object into NumpyTensor"
    def encodes(self, o): return NumpyTensor(o)

#|export
class TSTensor(TensorBase):
    '''Returns a `tensor` with subclass `TSTensor` that has a show method'''

    def __new__(cls, o, dtype=None, device=None, copy=None, requires_grad=False, **kwargs):
        o = torch.asarray(o, dtype=dtype, device=device, copy=copy, requires_grad=requires_grad)
        res = cast(o, cls) # if the tensor results in a dtype torch.float64 a copy is made as dtype torch.float32
        for k,v in kwargs.items(): setattr(res, k, v)
        return res

    @property
    def data(self): return cast(self, Tensor)

    def show(self, ax=None, ctx=None, title=None, **kwargs):
        if self.ndim == 0: return str(self.data)
        elif self.ndim != 2: self = type(self)(to2d(self))
        if not isinstance(self,np.ndarray): self = self.detach().cpu().numpy()
        ax = ifnone(ax, ctx)
        if ax is None: _, ax = plt.subplots(**kwargs)
        ax.plot(self.T)
        ax.axis(xmin=0, xmax=self.shape[-1] - 1)
        title_color = kwargs['title_color'] if 'title_color' in kwargs else rcParams['axes.labelcolor']
        if title is not None:
            if is_listy(title): title = str(title)[1:-1]
            ax.set_title(title, weight='bold', color=title_color)
        plt.tight_layout()
        return ax

    @property
    def vars(self):
        return self.shape[-2]

    @property
    def len(self): return self.shape[-1]

    def __repr__(self):
        if self.ndim > 3:
            return f'TSTensor(shape:{tuple(self.shape)}, device={self.device}, dtype={self.dtype})'
        elif self.ndim == 3:
            return f'TSTensor(samples:{self.shape[-3]}, vars:{self.shape[-2]}, len:{self.shape[-1]}, device={self.device}, dtype={self.dtype})'
        elif self.ndim == 2:
            return f'TSTensor(vars:{self.shape[-2]}, len:{self.shape[-1]}, device={self.device}, dtype={self.dtype})'
        elif self.ndim == 1:
            return f'TSTensor(len:{self.shape[-1]}, device={self.device}, dtype={self.dtype})'
        else: return f'TSTensor([{self.data}], device={self.device}, dtype={self.dtype})'

#|export
class ToTSTensor(Transform):
    "Transforms an object into TSTensor"
    def encodes(self, o): return TSTensor(o)


@delegates(plt.subplots)
def show_tuple(tup, **kwargs):
    "Display a timeseries plot from a decoded tuple"
    if len(tup) == 1: title = 'unlabeled'
    elif is_listy(tup[1]): title = str(tup[1])[1:-1]
    else: title = str(tup[1])
    tup[0].show(title=title, **kwargs)

a = np.random.randn(2, 3, 4).astype(np.float16)
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

a = np.random.randn(2, 3, 4).astype(np.float32)
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

a = np.random.randint(10, size=10).astype(np.int64)
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

a = np.random.randint(10, size=10).astype(np.int32)
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

a = torch.rand(2, 3, 4).float()
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

a = torch.randint(3, (10,))
assert np.shares_memory(a, NumpyTensor(a))
assert np.shares_memory(a, TSTensor(a))

t = TSTensor(torch.randn(2, 3, 4))
p = torch.tensor(3., requires_grad=True)
test = torch.add(t, p)
test_eq(test.requires_grad, True)
test_eq(type(t.data), torch.Tensor)
test_eq(type(t), TSTensor)

l = L([0,1,2,3], [4,5,6,7], [8, 9, 10, 11])
TSTensor(l), TSTensor(l).data
# Output:
#   (TSTensor(vars:3, len:4, device=cpu, dtype=torch.int64),

#    tensor([[ 0,  1,  2,  3],

#            [ 4,  5,  6,  7],

#            [ 8,  9, 10, 11]]))

t = TSTensor(X_train)
for i in range(4):
    print(t, t.ndim, torch.is_tensor(t))
    if i < 3: t = t[0]
# Output:
#   TSTensor(samples:30, vars:1, len:570, device=cpu, dtype=torch.float32) 3 True

#   TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32) 2 True

#   TSTensor(len:570, device=cpu, dtype=torch.float32) 1 True

#   TSTensor([-0.6113752722740173], device=cpu, dtype=torch.float32) 0 True


TSTensor(X_on_disk)
# Output:
#   TSTensor(samples:60, vars:1, len:570, device=cpu, dtype=torch.float32)

ToTSTensor()(X_on_disk)
# Output:
#   TSTensor(samples:60, vars:1, len:570, device=cpu, dtype=torch.float32)

TSTensor(X_train).show();
# Output:
#   <Figure size 640x480 with 1 Axes>

TSTensor(X_train).show(title='1');
# Output:
#   <Figure size 640x480 with 1 Axes>

show_tuple((TSTensor(X_train), ['1', '2']))
# Output:
#   <Figure size 640x480 with 1 Axes>

show_tuple((TSTensor(np.arange(10).reshape(2,5)), 1))
# Output:
#   <Figure size 640x480 with 1 Axes>

show_tuple((TSTensor(np.arange(10).reshape(2,5)), '1'))
# Output:
#   <Figure size 640x480 with 1 Axes>

show_tuple((TSTensor(np.arange(10).reshape(2,5)), [1,2]))
# Output:
#   <Figure size 640x480 with 1 Axes>

show_tuple((TSTensor(np.arange(10).reshape(2,5)), ['1', '2']))
# Output:
#   <Figure size 640x480 with 1 Axes>

#|export
class TSLabelTensor(NumpyTensor):
    def __repr__(self):
        if self.ndim == 0: return f'{self.data}'
        else: return f'TSLabelTensor(shape:{tuple(self.shape)}, device={self.device}, dtype={self.dtype})'

class TSMaskTensor(NumpyTensor):
    def __repr__(self):
        if self.ndim == 0: return f'{self.data}'
        else: return f'TSMaskTensor(shape:{tuple(self.shape)}, device={self.device}, dtype={self.dtype})'

t = TSLabelTensor(torch.randint(0,10,(1, 2, 3)))
t, t[0], t[0][0], t[0][0][0]
# Output:
#   (TSLabelTensor(shape:(1, 2, 3), device=cpu, dtype=torch.int64),

#    TSLabelTensor(shape:(2, 3), device=cpu, dtype=torch.int64),

#    TSLabelTensor(shape:(3,), device=cpu, dtype=torch.int64),

#    7)

t = TSMaskTensor(torch.randint(0,10,(1, 2, 3)))
t, t[0], t[0][0], t[0][0][0]
# Output:
#   (TSMaskTensor(shape:(1, 2, 3), device=cpu, dtype=torch.int64),

#    TSMaskTensor(shape:(2, 3), device=cpu, dtype=torch.int64),

#    TSMaskTensor(shape:(3,), device=cpu, dtype=torch.int64),

#    1)

#|export
class ToFloat(Transform):
    "Transforms an object dtype to float (vectorized)"
    vectorized=True
    loss_func=MSELossFlat()
    def encodes(self, o:torch.Tensor): return o.float()
    def encodes(self, o): return np.asarray(o, dtype=np.float32)
    def decodes(self, o):
        if o.ndim==0: return TitledFloat(o)
        else:
            return TitledTuple(o.cpu().numpy().tolist())


class ToInt(Transform):
    "Transforms an object dtype to int"
    def encodes(self, o:torch.Tensor): return o.long()
    def encodes(self, o): return np.asarray(o).astype(np.float32).astype(np.int64)
    def decodes(self, o):
        if o.ndim==0: return TitledFloat(o)
        else:
            return TitledTuple(o.cpu().numpy().tolist())


class TSClassification(DisplayedTransform):
    "Vectorized, reversible transform of category string to `vocab` id"
    loss_func,order,vectorized=CrossEntropyLossFlat(),1,True

    def __init__(self, vocab=None, sort=True):
        if vocab is not None: vocab = CategoryMap(vocab, sort=sort, add_na=False)
        store_attr()

    def setups(self, dset):
        if self.vocab is None and dset is not None:
            dset = np.asarray(dset).flatten()
            self.vocab = CategoryMap(dset, sort=self.sort, add_na=False)
        self.c = len(self.vocab)
        self.vocab_keys = np.array(list(self.vocab.o2i.keys()))[:, None]

    def encodes(self, o:torch.Tensor): return o
    def encodes(self, o):
        try:
            if not hasattr(o, "ndim") or o.ndim <= 1:
                return TensorCategory((self.vocab_keys == o).argmax(axis=0))
            else:
                return TensorCategory((self.vocab_keys == o.flatten()).argmax(axis=0).reshape(*o.shape))
        except KeyError as e:
            raise KeyError(f"Label '{o}' was not included in the training dataset") from e
    def decodes(self, o):
        if not is_iter(o):
            return Category(self.vocab[o])
        elif o.ndim <= 1:
            return stack([Category(self.vocab[oi]) for oi in o])
        else:
            return stack(MultiCategory(self.vocab[o.flatten()])).reshape(*o.shape)


TSCategorize = TSClassification
TSRegression = ToFloat
TSForecasting = ToFloat

a = np.random.randint(0, 2, 10)
b = np.array(['1', '2', '3'])
c = np.array(['1.0', '2.0', '3.0'])
t = torch.randint(0, 2, (10, ))
test_eq(ToFloat()(a).dtype, 'float32')
test_eq(ToFloat()(b).dtype, 'float32')
test_eq(ToFloat()(c).dtype, 'float32')
test_eq(ToFloat()(t).dtype, torch.float32)

a = np.random.rand(10)*10
b = np.array(['1.0', '2.0', '3.0'])
t = torch.rand(10)*10
test_eq(ToInt()(a).dtype, 'int64')
test_eq(ToInt()(b).dtype, 'int64')
test_eq(ToInt()(t).dtype, torch.long)

t = TSClassification()
t.setup(y_on_disk[splits[0]])
y_encoded = t(y_on_disk)
print(y_encoded)
test_eq(t.decodes(y_encoded), y_on_disk)
# Output:
#   TensorCategory([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3,

#                   3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,

#                   1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])


y_multi= np.random.randint(0,3,20)
y_multi = np.asarray(alphabet[y_multi]).reshape(4,5)
tfm = TSClassification()
tfm.setup(y_multi)
enc_y_multi = tfm(y_multi)
test_eq(y_multi, tfm.decode(enc_y_multi))
enc_y_multi
# Output:
#   TensorCategory([[0, 1, 1, 1, 2],

#                   [0, 1, 2, 1, 0],

#                   [2, 1, 0, 1, 2],

#                   [0, 2, 0, 2, 2]])

#|export
class TSMultiLabelClassification(Categorize):
    "Reversible combined transform of multi-category strings to one-hot encoded `vocab` id"
    loss_func,order=BCEWithLogitsLossFlat(),1
    def __init__(self, c=None, vocab=None, add_na=False, sort=True):
        super().__init__(vocab=vocab,add_na=add_na,sort=sort)
        self.c = c

    def setups(self, dsets):
        if not dsets: return
        if self.vocab is None:
            vals = set()
            for b in dsets: vals = vals.union(set(b))
            self.vocab = CategoryMap(list(vals), add_na=self.add_na)
            if self.c is None: self.c = len(self.vocab)
            if not self.c: warn("Couldn't infer the number of classes, please pass a value for `c` at init")

    def encodes(self, o:torch.Tensor): return o
    def encodes(self, o):
        if not all(elem in self.vocab.o2i.keys() for elem in o):
            diff = [elem for elem in o if elem not in self.vocab.o2i.keys()]
            diff_str = "', '".join(diff)
            raise KeyError(f"Labels '{diff_str}' were not included in the training dataset")
        return TensorMultiCategory(one_hot([self.vocab.o2i[o_] for o_ in o], self.c).float())
    def decodes(self, o):
        if o.ndim == 2:
            return MultiCategory([self.vocab[o_] for o_ in o])
        else:
            return MultiCategory(self.vocab[o])

#|export
class NumpyTensorBlock():
    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):
        self.type_tfms  =                 L(type_tfms)
        self.item_tfms  = ToNumpyTensor + L(item_tfms)
        self.batch_tfms =                 L(batch_tfms)
        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)

class TSTensorBlock():
    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):
        self.type_tfms  =              L(type_tfms)
        self.item_tfms  = ToTSTensor + L(item_tfms)
        self.batch_tfms =              L(batch_tfms)
        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)

test_eq(NumpyTensorBlock().item_tfms[0].__name__, 'ToNumpyTensor')
test_eq(TSTensorBlock().item_tfms[0].__name__, 'ToTSTensor')

#|export
class TorchDataset():
    def __init__(self, X, y=None): self.X, self.y = X, y
    def __getitem__(self, idx): return (self.X[idx],) if self.y is None else (self.X[idx], self.y[idx])
    def __len__(self): return len(self.X)


class NumpyDataset():
    def __init__(self, X, y=None, types=None): self.X, self.y, self.types = X, y, types
    def __getitem__(self, idx):
        if self.types is None: return (self.X[idx], self.y[idx]) if self.y is not None else (self.X[idx])
        else: return (self.types[0](self.X[idx]), self.types[1](self.y[idx])) if self.y is not None else (self.types[0](self.X[idx]))
    def __len__(self): return len(self.X)


class TSDataset():
    _types = TSTensor, TSLabelTensor
    def __init__(self, X, y=None, split=None, sel_vars=None, sel_steps=None, types=None, dtype=None, device=None):
        self.X, self.y, self.split = X, y, split
        self.sel_vars = sel_vars
        self.sel_steps = sel_steps
        self.multi_idx = sel_vars is not None or sel_steps is not None
        if types is not None: self._types = listify(types)
        self.dtype, self.device = dtype, device
    def __getitem__(self, idx):
        if self.split is not None:
            idx = self.split[idx]
        if hasattr(self.X, 'oindex'):
            X = self._types[0](self.X.oindex[idx, self.sel_vars, self.sel_steps] if self.multi_idx \
                               else self.X.oindex[idx], device=self.device, dtype=self.dtype)
        elif hasattr(self.X, 'compute'):
            X = self._types[0](self.X[idx, self.sel_vars, self.sel_steps].compute() if self.multi_idx \
                               else self.X[idx].compute(), device=self.device, dtype=self.dtype)
        else:
            X = self._types[0](self.X[idx, self.sel_vars, self.sel_steps] if self.multi_idx \
                               else self.X[idx], device=self.device, dtype=self.dtype)
        if self.y is None:
            return (X, )
        if hasattr(self.y, 'oindex'):
            y = self._types[1](self.y.oindex[idx], device=self.device, dtype=self.dtype)
        elif hasattr(self.X, 'compute'):
            y = self._types[1](self.y[idx].compute(), device=self.device, dtype=self.dtype)
        else:
            y = self._types[1](self.y[idx], device=self.device, dtype=self.dtype)
        return (X, y)
    def __len__(self): return len(self.X) if self.split is None else len(self.split)

a = np.random.rand(5,6,7)
b = np.random.rand(5)
ds = NumpyDataset(a,b)
xb, yb = ds[[0,4]]
test_eq(xb.shape, (2,6,7))
test_eq(yb.shape, (2,))

#|export
def _flatten_list(lst):
    "Flattens a list of lists with splits"

    def __flatten_list(lst):
        if lst is None:
            return L([])
        if not hasattr(lst, "__iter__"):
            lst = [lst]

        # clean_up_list
        if len(lst) > 10:
            return lst
        else:
            lst = [l for l in lst if l is not None or (hasattr(l, "__len__") and len(l) == 0)]

        # count lists
        n_lists = sum([hasattr(l, "__iter__") for l in lst])
        if n_lists == 0:
            return lst
        elif len(lst) == n_lists == 1:
            return lst[0]
        else:
            output = np.concatenate([l if hasattr(l, "__iter__") else [l] for l in lst])
            if len(output) == 0:
                return L([])
            return output.astype(smallest_dtype(int(max(output))))

    output = __flatten_list(lst)
    if len(output) == 0: return output
    dtype = smallest_dtype(np.max(output))
    return np.asarray(output, dtype=dtype)

def _remove_brackets(l):
    return [li if (not li or not is_listy(li) or len(li) > 1) else li[0] for li in l]

class NoTfmLists(TfmdLists):
    def __init__(self, items, tfms=None, splits=None, split_idx=None, types=None, do_setup=False, **kwargs):
        self.splits = ifnone(splits, L(np.arange(len(items)).tolist(),[]))
        self._splits = _flatten_list(self.splits)
        store_attr('items,types,split_idx')
        self.tfms = Pipeline(split_idx=split_idx)
    def subset(self, i, **kwargs): return type(self)(self.items, splits=self.splits[i], split_idx=i, do_setup=False, types=self.types,
                                                     **kwargs)
    def __getitem__(self, it):
        if hasattr(self.items, 'oindex'): return self.items.oindex[self._splits[it]]
        else: return self.items[self._splits[it]]
    def __len__(self): return len(self._splits)
    def __repr__(self):
        if hasattr(self.items, "shape"):
            return f"{self.__class__.__name__}: {self.items.__class__.__name__}{(len(self), *self.items.shape[1:])}"
        else:
            return f"{self.__class__.__name__}: {self.items.__class__.__name__}(0)"
    def _new(self, items, split_idx=None, **kwargs):
        split_idx = ifnone(split_idx, self.split_idx)
        return type(self)(items, split_idx=split_idx, do_setup=False, types=self.types, **kwargs)
    def decode(self, o, **kwargs): return o
    def new_empty(self): return self._new([])

NoTfmLists.train, NoTfmLists.valid = add_props(lambda i,x: x.subset(i))

class TSTfmdLists(TfmdLists):
    def __getitem__(self, it):
        # res = self._get(it)
        if hasattr(self.items, 'oindex'): res = self.items.oindex[it]
        else: res = self.items[it]
        if self._after_item is None: return res
        else: return self._after_item(res)

items = X_on_disk
tl = TfmdLists(items, tfms=None, splits=splits)
test_eq(len(tl), len(X_on_disk))
test_eq(len(tl.train), len(splits[0]))
test_eq(len(tl.valid), len(splits[1]))
test_eq(tl[[0,4,7]], X_on_disk[[0,4,7]])
test_eq(tl.train[[0,4,7]], X_on_disk[splits[0][0,4,7]])
test_eq(tl.valid[[0,4,7]], X_on_disk[splits[1][0,4,7]])
test_eq(tl[0], items[0])
test_eq(tl[[0,1]], items[[0,1]])
test_eq(tl.decode(tl[0]), tl[0])
test_eq((tl.split_idx, tl.train.split_idx, tl.valid.split_idx), (None, 0, 1))

items = X_on_disk
tl = TSTfmdLists(items, tfms=None, splits=splits)
test_eq(len(tl), len(X_on_disk))
test_eq(len(tl.train), len(splits[0]))
test_eq(len(tl.valid), len(splits[1]))
test_eq(tl[[0,4,7]], X_on_disk[[0,4,7]])
test_eq(tl.train[[0,4,7]], X_on_disk[splits[0][0,4,7]])
test_eq(tl.valid[[0,4,7]], X_on_disk[splits[1][0,4,7]])
test_eq(tl[0], items[0])
test_eq(tl[[0,1]], items[[0,1]])
test_eq(tl.decode(tl[0]), tl[0])
test_eq((tl.split_idx, tl.train.split_idx, tl.valid.split_idx), (None, 0, 1))

items = X_on_disk
ntl = NoTfmLists(items, splits=splits)
test_eq(len(ntl), len(X_on_disk))
test_eq(len(ntl.train), len(splits[0]))
test_eq(len(ntl.valid), len(splits[1]))
test_eq(ntl._splits, np.arange(len(X_on_disk)))
test_eq(ntl.train._splits, np.arange(len(splits[0])))
test_eq(ntl.valid._splits, np.arange(len(splits[0]), len(X_on_disk)))
print(ntl)
print(ntl.train)
print(ntl.valid)
test_eq(ntl[[0,4,7]], X_on_disk[[0,4,7]])
test_eq(ntl.train[[0,4,7]], X_on_disk[splits[0][0,4,7]])
test_eq(ntl.valid[[0,4,7]], X_on_disk[splits[1][0,4,7]])
test_eq(ntl[0], items[0])
test_eq(ntl[[0,1]], items[[0,1]])
test_eq(ntl[:], X_on_disk)
ntl[0].shape, stack(ntl[[0,1]]).shape
test_eq(ntl.decode(ntl[0]), ntl[0])
assert id(items) == id(ntl.items) == id(ntl.train.items) == id(ntl.valid.items)
test_eq((ntl.split_idx, ntl.train.split_idx, ntl.valid.split_idx), (None, 0, 1))
# Output:
#   NoTfmLists: memmap(60, 1, 570)

#   NoTfmLists: memmap(30, 1, 570)

#   NoTfmLists: memmap(30, 1, 570)


subitems = X_on_disk
new_ntl = ntl._new(X_on_disk)
test_eq(new_ntl[:], X_on_disk)

idxs = random_choice(len(X_on_disk), 10, False)
new_ntl = ntl._new(X_on_disk[idxs])
test_eq(new_ntl[:], X_on_disk[idxs])

idxs = random_choice(len(X_on_disk), 10, False)
new_ntl = ntl.valid._new(X_on_disk[idxs])
test_eq(new_ntl[:], X_on_disk[idxs])

#|export
@delegates(Datasets.__init__)
class NumpyDatasets(Datasets):
    "A dataset that creates tuples from X (and y) and applies `tfms` of type item_tfms"
    typs = NumpyTensor,tensor
    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, inplace=True, **kwargs):

        self.tfms, self.inplace = tfms, inplace

        if X is not None:
            if not hasattr(X, '__array__'): X = np.asarray(X)
            elif hasattr(X, "iloc"): X = to3d(X)
        if y is not None:
            if not hasattr(y, '__array__'):  y = np.asarray(y)
            elif hasattr(y, "iloc"): y = toarray(y)

        if tls is None:
            items = tuple((X,)) if y is None else tuple((X, y))

            if tfms is None:
                self.tfms, lts = [None] * len(items), [NoTfmLists] * len(items)
            else:
                self.tfms = _remove_brackets(tfms)
                lts = [NoTfmLists if t is None else TSTfmdLists if getattr(t, 'vectorized', None) else TfmdLists for t in self.tfms]

            self.tls = L(lt(item, t, **kwargs) for lt,item,t in zip(lts, items, self.tfms))
            # if len(self.tls) > 0 and len(self.tls[0]) > 0:
            #     self.typs = [type(tl[0]) if isinstance(tl[0], torch.Tensor) else self.typs[i] for i,tl in enumerate(self.tls)]
            self.ptls = L([typ(stack(tl[:])) for i,(tl,typ) in enumerate(zip(self.tls,self.typs))]) if inplace else self.tls
        else:
            self.tls = tls
            # if len(self.tls) > 0 and len(self.tls[0]) > 0:
            #     self.typs = [type(tl[0]) if isinstance(tl[0], torch.Tensor) else self.typs[i] for i,tl in enumerate(self.tls)]
            self.ptls = L([typ(stack(tl[:])) for i,(tl,typ) in enumerate(zip(self.tls,self.typs))]) if inplace and len(tls[0]) != 0 else tls

        self.n_inp = 1
        if kwargs.get('splits', None) is not None:
            split_idxs = _flatten_list(kwargs['splits'])
        else:
            split_idxs = _flatten_list(np.arange(len(self)))
        self.split_idxs = split_idxs

    def __getitem__(self, it):
        if self.inplace:
            return tuple([ptl[it] for ptl in self.ptls])
        else:
            return tuple([typ(stack(ptl[it])) for i,(ptl,typ) in enumerate(zip(self.ptls,self.typs))])

    def subset(self, i):
        if is_indexer(i):
            return type(self)(tls=L([tl.subset(i) for tl in self.tls]), inplace=self.inplace, tfms=self.tfms,
                              splits=None if self.splits is None else self.splits[i], split_idx=i)
        else:
            splits = None if self.splits is None else L(np.arange(len(i)).tolist())
            return type(self)(*self[i], inplace=True, tfms=None, splits=splits, split_idx=ifnone(self.split_idx, 1))

    def __len__(self): return len(self.tls[0])

    def _new(self, X, y=None, **kwargs):
        return type(self)(X, y=y, tfms=self.tfms, inplace=self.inplace, do_setup=False, **kwargs)

    def new_empty(self): return type(self)(tls=[tl.new_empty() for tl in self.tls], n_inp=self.n_inp, inplace=self.inplace)

    def show_at(self, idx, **kwargs):
        self.show(self[idx], **kwargs)
        plt.show()

    def __repr__(self): return tscoll_repr(self)


def tscoll_repr(c, max_n=10):
    "String repr of up to `max_n` items of (possibly lazy) collection `c`"
    _len = len(c)
    if _len == 0: return coll_repr(c)
    return f'(#{_len}) {L(c[i] for i in range(min(len(c), max_n)))} ...]'

#|export
@delegates(Datasets.__init__)
class TSDatasets(Datasets):
    """A dataset that creates tuples from X (and optionally y) and applies `item_tfms`"""
    typs = TSTensor, torch.as_tensor
    def __init__(self, X=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None,
                 inplace=True, **kwargs):

        # Prepare X (and y)
        if X is not None:
            if not hasattr(X, '__array__'):
                X = np.asarray(X)
            X = to3d(X)
        if y is not None:
            if not hasattr(y, '__array__'):
                y = np.asarray(y)
            elif hasattr(y, "iloc"):
                y = toarray(y)

        # Prepare sel_vars and sel_steps
        self.multi_index = False
        if sel_vars is None or (type(sel_vars) == slice and sel_vars == slice(None)):
            self.sel_vars = slice(None)
        elif type(sel_vars) == slice:
            self.sel_vars = sel_vars
            self.multi_index = True
        else:
            self.sel_vars = np.asarray(sel_vars)
            if sel_steps is not None and type(sel_steps) != slice: self.sel_vars = sel_vars[:, None]
            self.multi_index = True
        if sel_steps is None or (type(sel_steps) == slice and sel_steps == slice(None)):
            self.sel_steps = slice(None)
        elif type(sel_steps) == slice:
            self.sel_steps = sel_steps
            self.multi_index = True
        else:
            self.sel_steps = np.asarray(sel_steps)
            self.multi_index = True
        self.tfms, self.inplace = tfms, inplace

        # Prepare tls (transform lists) and ptls (preprocessed transform lists)
        if tls is None:
            items = tuple((X,)) if y is None else tuple((X, y))
            if tfms is None:
                self.tfms, lts = [None] * len(items), [NoTfmLists] * len(items)
            else:
                self.tfms = _remove_brackets(tfms)
                lts = [NoTfmLists if t is None else TSTfmdLists if getattr(t, 'vectorized', None) else TfmdLists for t in self.tfms]
            self.tls = L(lt(item, t, **kwargs) for lt,item,t in zip(lts, items, self.tfms))
            # if len(self.tls) > 0 and len(self.tls[0]) > 0:
            #     self.typs = [type(tl.items[0]) if isinstance(tl.items[0], torch.Tensor) else self.typs[i] for i,tl in enumerate(self.tls)]
            if self.inplace and (tfms is None or tfms == [None] * len(self.tls)):
                for tl,typ in zip(self.tls, self.typs):
                    tl.items = typ(tl.items)
                self.ptls = self.tls
                self.no_tfm = True
            else:
                self.ptls = L([typ(stack(tl[:]))[...,self.sel_vars, self.sel_steps] if (i==0 and self.multi_index) else typ(stack(tl[:])) \
                    for i,(tl,typ) in enumerate(zip(self.tls,self.typs))]) if inplace else self.tls
                self.no_tfm = False
        else:
            self.tls = tls
            # if len(self.tls) > 0 and len(self.tls[0]) > 0:
            #     self.typs = [type(tl[0]) if isinstance(tl[0], torch.Tensor) else self.typs[i] for i,tl in enumerate(self.tls)]
            self.ptls = L([typ(stack(tl[:]))[...,self.sel_vars, self.sel_steps] if (i==0 and self.multi_index) else typ(stack(tl[:])) \
                for i,(tl,typ) in enumerate(zip(self.tls,self.typs))]) if inplace and len(tls[0]) != 0 else tls
            self.no_tfm = False

        self.n_inp = 1
        if kwargs.get('splits', None) is not None:
            split_idxs = _flatten_list(kwargs.get('splits'))
        else:
            split_idxs = np.arange(len(self), dtype=smallest_dtype(len(self)))
        self.split_idxs = split_idxs

    def __getitem__(self, it):
        if self.inplace or self.no_tfm:
            return tuple([ptl[it] for ptl in self.ptls])
        else:
            return tuple([typ(stack(ptl[it]))[...,self.sel_vars, self.sel_steps] if (i==0 and self.multi_index) else typ(stack(ptl[it])) \
                          for i,(ptl,typ) in enumerate(zip(self.ptls,self.typs))])

    def subset(self, i):
        if is_indexer(i):
            return type(self)(tls=L([tl.subset(i) for tl in self.tls]), inplace=self.inplace, tfms=self.tfms,
                              sel_vars=self.sel_vars, sel_steps=self.sel_steps, splits=None if self.splits is None else self.splits[i],
                              split_idx=i)
        else:
            if self.splits is None:
                splits = None
            else:
                min_dtype = np.min_scalar_type(len(i))
                splits = np.arange(len(i), dtype=min_dtype)
            return type(self)(*self[i], inplace=True, tfms=None,
                              sel_vars=self.sel_vars, sel_steps=self.sel_steps, splits=splits, split_idx=ifnone(self.split_idx, 1))

    def _new(self, X, y=None, **kwargs):
        return type(self)(X, y=y, sel_vars=self.sel_vars, sel_steps=self.sel_steps, tfms=self.tfms, inplace=self.inplace,
                          do_setup=False, **kwargs)

    def new_empty(self): return type(self)(tls=[tl.new_empty() for tl in self.tls], sel_vars=self.sel_vars, sel_steps=self.sel_steps,
                                           n_inp=self.n_inp, inplace=self.inplace)

    def __len__(self): return len(self.tls[0])

    def show_at(self, idx, **kwargs):
        self.show(self[idx], **kwargs)
        plt.show()

    def __repr__(self): return tscoll_repr(self)

dsets = TSDatasets(X_on_disk, y_on_disk, splits=splits, tfms=[None, TSClassification()], inplace=True)
i = random_choice(len(splits[0]), 10, False).tolist()
test_eq(dsets.subset(i), dsets.train.subset(i))
dsets.valid.subset(i)
dsets.valid.subset(i)[[0,6,8]]
test_eq(dsets.subset(i)[[0,6,8]], dsets.train.subset(i)[[0,6,8]])
dsets.subset([0,7,3])
dsets.subset(i), dsets.train.subset(i), dsets.valid.subset(i)
# Output:
#   ((#10) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3))] ...],

#    (#10) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3))] ...],

#    (#10) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(3))] ...])

tfms = [None, TSClassification()]
dsets = TSDatasets(X_on_disk, y_on_disk, splits=splits, tfms=tfms, inplace=False)
assert id(X_on_disk) == id(dsets.ptls[0].items) == id(dsets.train.ptls[0].items) == id(dsets.valid.ptls[0].items)

tfms = None
dsets = TSDatasets(X_on_disk, splits=splits, tfms=tfms, inplace=False)
assert id(X_on_disk) == id(dsets.ptls[0].items) == id(dsets.train.ptls[0].items) == id(dsets.valid.ptls[0].items)

#|export
def add_ds(dsets, X, y=None, inplace=True):
    "Create test datasets from X (and y) using validation transforms of `dsets`"
    items = tuple((X,)) if y is None else tuple((X, y))
    with_labels = False if y is None else True
    if isinstance(dsets, TSDatasets):
        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]
        new_tls = L([tl._new(item, split_idx=1) for tl,item in zip(tls, items)])
        return type(dsets)(tls=new_tls, sel_vars=dsets.sel_vars, sel_steps=dsets.sel_steps, inplace=dsets.inplace)
    elif isinstance(dsets, NumpyDatasets):
        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]
        new_tls = L([tl._new(item, split_idx=1) for tl,item in zip(tls, items)])
        return type(dsets)(tls=new_tls, inplace=dsets.inplace)
    elif isinstance(dsets, Datasets):
        tls = dsets.tls if with_labels else dsets.tls[:dsets.n_inp]
        new_tls = L([tl._new(item, split_idx=1) for tl,item in zip(tls, items)])
        return type(dsets)(tls=new_tls)
    elif isinstance(dsets, TfmdLists):
        new_tl = dsets._new(items, split_idx=1)
        return new_tl
    else:
        raise Exception(f"Expected a `Datasets` or a `TfmdLists` but got {dsets.__class__.__name__}")

@patch
def add_dataset(self:NumpyDatasets, X, y=None, inplace=True):
    return add_ds(self, X, y=y, inplace=inplace)

@patch
def add_test(self:NumpyDatasets, X, y=None, inplace=True):
    return add_ds(self, X, y=y, inplace=inplace)

@patch
def add_unlabeled(self:NumpyDatasets, X, inplace=True):
    return add_ds(self, X, y=None, inplace=inplace)

@patch
def add_dataset(self:TSDatasets, X, y=None, inplace=True):
    return add_ds(self, X, y=y, inplace=inplace)

@patch
def add_test(self:TSDatasets, X, y=None, inplace=True):
    return add_ds(self, X, y=y, inplace=inplace)

@patch
def add_unlabeled(self:TSDatasets, X, inplace=True):
    return add_ds(self, X, y=None, inplace=inplace)

dsets = TSDatasets(X_on_disk, y_on_disk, splits=splits, tfms=[None, TSClassification()], inplace=True)
print(dsets.train[0][0].shape, dsets.train[[0,1]][0].shape)
print(dsets.split_idx, dsets.train.split_idx, dsets.valid.split_idx)
print(dsets.new_empty())
dsets
# Output:
#   torch.Size([1, 570]) torch.Size([2, 1, 570])

#   None 0 1

#   (#0) []

#   (#60) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory(1))] ...]

dsets = TSDatasets(X_on_disk, y_on_disk, splits=splits, tfms=[None, TSClassification()], inplace=False)
print(dsets.train[0][0].shape, dsets.train[[0,1]][0].shape)
print(dsets.split_idx, dsets.train.split_idx, dsets.valid.split_idx)
print(dsets.new_empty())
dsets
# Output:
#   torch.Size([1, 570]) torch.Size([2, 1, 570])

#   None 0 1

#   (#0) []

#   (#60) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([0])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([0])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([0])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([0])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([0])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([1])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([1])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([1])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([1])), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), TensorCategory([1]))] ...]

dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, TSClassification()], splits=splits, inplace=True)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])

idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])
test_eq(dsets.train[idxs][1].numpy(), y_array[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])
test_eq(dsets.valid[idxs][1].numpy(), y_array[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, TSClassification()], splits=splits, inplace=False)
assert id(X_on_disk) == id(dsets.tls[0].items) == id(dsets.ptls[0].items)
assert id(X_on_disk) == id(dsets.train.tls[0].items) == id(dsets.train.ptls[0].items)
assert id(X_on_disk) == id(dsets.valid.tls[0].items) == id(dsets.valid.ptls[0].items)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])


idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])
test_eq(dsets.train[idxs][1].numpy(), y_array[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])
test_eq(dsets.valid[idxs][1].numpy(), y_array[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, splits=splits, inplace=True)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])

idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, splits=splits, inplace=False)
assert np.shares_memory(X_on_disk, dsets.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.ptls[0].items)
assert np.shares_memory(X_on_disk, dsets.train.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.train.ptls[0].items)
assert np.shares_memory(X_on_disk, dsets.valid.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.valid.ptls[0].items)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])

idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits, inplace=True)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])

idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])
test_eq(dsets.train[idxs][1].numpy(), y_array[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])
test_eq(dsets.valid[idxs][1].numpy(), y_array[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits, inplace=False)
assert np.shares_memory(X_on_disk, dsets.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.ptls[0].items)
assert np.shares_memory(X_on_disk, dsets.train.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.train.ptls[0].items)
assert np.shares_memory(X_on_disk, dsets.valid.tls[0].items)
assert np.shares_memory(X_on_disk, dsets.valid.ptls[0].items)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])

idxs = random_choice(len(dsets.train), 10, False)
test_eq(dsets.train[idxs][0].numpy(), X_on_disk[splits[0][idxs]])
test_eq(dsets.train[idxs][1].numpy(), y_array[splits[0][idxs]])

idxs = random_choice(len(dsets.valid), 10, False)
test_eq(dsets.valid[idxs][0].numpy(), X_on_disk[splits[1][idxs]])
test_eq(dsets.valid[idxs][1].numpy(), y_array[splits[1][idxs]])

dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, TSClassification()], splits=None, inplace=True)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])

dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, TSClassification()], splits=None, inplace=False)
assert id(X_on_disk) == id(dsets.tls[0].items) == id(dsets.ptls[0].items)
assert id(X_on_disk) == id(dsets.train.tls[0].items) == id(dsets.train.ptls[0].items)

idxs = random_choice(len(dsets), 10, False)
test_eq(dsets[idxs][0].numpy(), X_on_disk[idxs])
test_eq(dsets[idxs][1].numpy(), y_array[idxs])

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits)
test_eq(dsets.train[0:10], dsets.add_dataset(X_on_disk[0:10], y_array[0:10])[:])
test_eq(dsets.train[0:10][0], dsets.add_dataset(X_on_disk[0:10])[:][0])

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits)
torch.save(dsets, 'export/dsets.pth')
del dsets
dsets = torch.load('export/dsets.pth')
dsets
# Output:
#   (#60) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1))] ...]

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits)
torch.save(dsets.train, 'export/dsets.pth')
del dsets
dsets = torch.load('export/dsets.pth')
dsets
# Output:
#   (#30) [(TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(0)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1)), (TSTensor(vars:1, len:570, device=cpu, dtype=torch.float32), tensor(1))] ...]

dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits)
test_eq(len(dsets.train), len(X_train))
dsets = TSDatasets(X_on_disk, y_array, tfms=None, splits=splits)
test_eq(len(dsets.train), len(X_train))
dsets = TSDatasets(X_on_disk, y_array, tfms=[add(1), TSCategorize()], splits=splits)
test_eq(len(dsets.train), len(X_train))
# test_eq(dsets.train[0][0].data, tensor(X_train[0] + 1))
test_eq(dsets.train[0][1].item(), y_tensor[0])

dsets = TSDatasets(X_on_disk, y_on_disk, tfms=[None, TSCategorize()], splits=splits)
test_eq(len(dsets.add_test(X_train, y_train)), len(X_train))
test_eq(len(dsets.add_unlabeled(X_train)), len(X_train))

X_tensor = torch.randn(100, 4, 50)
y_tensor = torch.randint(0, 2, size=(len(X_tensor),))
tensor_splits = (np.arange(80), np.arange(80, 100))
dsets = TSDatasets(X_tensor, y_tensor, tfms=[None, TSClassification()], splits=tensor_splits)
test_eq(type(dsets[0][0]), TSTensor)

#|export
@patch
def _one_pass(self:TfmdDL):
    b = self.do_batch([self.do_item(0)])
    if self.device is not None: b = to_device(b, self.device)
    its = self.after_batch(b)
    self._n_inp = 1 if not isinstance(its, (list,tuple)) or len(its)==1 else len(its)-1
    self._types = explode_types(its)

#|export
_batch_tfms = ('after_item','before_batch','after_batch')

@delegates(TfmdDL.__init__)
class NumpyDataLoader(TfmdDL):
    idxs = None
    do_item = noops # create batch returns indices
    def __init__(self, dataset, bs=64, shuffle=False, drop_last=False, num_workers=0, verbose=False, do_setup=True, vocab=None,
                 sort=False, weights=None, partial_n=None, sampler=None, **kwargs):

        if num_workers is None: num_workers = min(16, defaults.cpus)
        if sampler is not None and shuffle:
            raise ValueError('sampler option is mutually exclusive with shuffle')

        for nm in _batch_tfms:
            if nm == 'after_batch' and kwargs.get('batch_tfms',None) is not None: kwargs[nm] = Pipeline(listify(kwargs.get('batch_tfms')))
            else: kwargs[nm] = Pipeline(kwargs.get(nm,None))
        bs = max(1, min(bs, len(dataset))) # bs cannot be 1
        if is_listy(partial_n): partial_n = partial_n[0]
        if isinstance(partial_n, float): partial_n = int(round(partial_n * len(dataset)))
        if partial_n is not None:
            partial_n = min(partial_n, len(dataset))
            bs = min(bs, partial_n)
        if weights is not None: weights = weights / weights.sum()
        self.weights, self.partial_n, self.sampler, self.sort, self.do_setup = weights, partial_n, sampler, sort, do_setup
        super().__init__(dataset, bs=bs, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers, verbose=verbose, do_setup=do_setup, **kwargs)
        if vocab is not None:
            self.vocab = vocab

    def new_dl(self, X, y=None, bs=64):
        assert X.ndim == 3, "You must pass an X iterable with 3 dimensions [batch_size x n_vars x seq_len]"
        if y is not None:
            y = np.asarray(y)
            assert y.ndim > 0, "You must pass a y iterable with at least 1 dimension"
        ds = self.dataset.add_dataset(X, y=y)
        return self.new(ds, bs=min(bs, len(X)))

    def create_batch(self, b):
        if self.shuffle or self.sampler is not None:
            if self.sort and hasattr(b, 'sort'): b.sort()
            self.idxs = L(b)
        else:
            if self.n is not None:
                b = slice(b[0], min(self.n, b[0] + self.bs))
            else:
                b = slice(b[0], b[0] + self.bs)

            self.idxs = b
        if hasattr(self, "split_idxs"):
            self.input_idxs = self.split_idxs[b]
        else: self.input_idxs = self.idxs
        return self.dataset[b]

    def create_item(self, s):
        if self.indexed: return self.dataset[s or 0]
        elif s is None:  return next(self.it)
        else: raise IndexError("Cannot index an iterable dataset numerically - must use `None`.")

    def get_idxs(self):
        if self.n==0: return []
        if self.partial_n is not None: n = min(self.partial_n, self.n)
        else: n = self.n
        if self.sampler is not None:
            idxs = np.array(list(iter(self.sampler)))
            if self.partial_n is not None: idxs = idxs[:n]
            return idxs
        if self.weights is not None:
            return random_choice(self.n, n, p=self.weights)
        if self.n is not None:
            if self.partial_n is not None:
                return random_choice(self.n, n, False, dtype=smallest_dtype(self.n)) # already shuffled
            else:
                idxs = np.arange(self.n, dtype=smallest_dtype(self.n))
        else:
            idxs = Inf.count if self.indexed else Inf.nones
        if self.shuffle: idxs = self.shuffle_fn(idxs)
        return idxs

    def shuffle_fn(self, idxs):
        return np.random.permutation(idxs)

    def unique_batch(self, max_n=9):
        old_bs = self.bs
        self.bs = 1
        old_get_idxs = self.get_idxs
        self.get_idxs = lambda: Inf.zeros
        out_len = len(self.items)
        types = self.dataset.types
        x, y = [], []
        for _ in range(max_n):
            out = self.one_batch()
            if out_len == 2:
                x.extend(out[0])
                y.extend(out[1])
            else:
                x.extend(out)
        b = (types[0](stack(x)), types[1](stack(y))) if out_len == 2 else (types[0](stack(x)), )
        self.bs = old_bs
        self.get_idxs = old_get_idxs
        return b

    def __len__(self):
        if self.n == 0: return 0
        elif self.partial_n is None: return super().__len__()
        return self.partial_n//self.bs + (0 if self.drop_last or self.partial_n%self.bs==0 else 1)

    @delegates(plt.subplots)
    def show_batch(self, b=None, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=None, unique=False, sharex=True, sharey=False, decode=False,
                   show_title=True, **kwargs):

        old_sort = self.sort
        self.sort = False # disable sorting when showing a batch to ensure varied samples

        if unique:
            b = self.unique_batch(max_n=max_n)
            sharex, sharey = True, True
        elif b is None: b = self.one_batch()
        if not decode:                                        # decode = False allows you to see the data as seen by the model
            after_batch = self.after_batch
            self.after_batch = Pipeline()
            db = self.decode_batch(b, max_n=max_n)
            self.after_batch = after_batch
        else:
            db = self.decode_batch(b, max_n=max_n)
        ncols = min(ncols, math.ceil(len(db) / ncols))
        nrows = min(nrows, math.ceil(len(db) / ncols))
        max_n = min(max_n, len(db), nrows*ncols)
        if figsize is None: figsize = (ncols*6, math.ceil(max_n/ncols)*4)
        if ctxs is None: ctxs = get_grid(max_n, nrows=nrows, ncols=ncols, figsize=figsize, sharex=sharex, sharey=sharey, **kwargs)
        if show_title:
            for i,ctx in enumerate(ctxs):
                show_tuple(db[i], ctx=ctx)
        else:
            db = [x for x,_ in db]
            for i,ctx in enumerate(ctxs):
                db[i].show(ctx=ctx)

        self.sort = old_sort

    @delegates(plt.subplots)
    def show_results(self, b, preds, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=None, **kwargs):
        t = self.decode_batch(b, max_n=max_n)
        p = self.decode_batch((b[0],preds), max_n=max_n)
        if figsize is None: figsize = (ncols*6, max_n//ncols*4)
        if ctxs is None: ctxs = get_grid(min(len(t), nrows*ncols), nrows=None, ncols=ncols, figsize=figsize, **kwargs)
        for i,ctx in enumerate(ctxs):
            title = f'True: {t[i][1]}\nPred: {p[i][1]}'
            color = 'green' if t[i][1] == p[i][1] else 'red'
            t[i][0].show(ctx=ctx, title=title, title_color=color)

    @delegates(plt.subplots)
    def show_dist(self, figsize=None, color=None, **kwargs):
        if self.c == 0:
            print('\nunlabeled dataset.\n')
            return
        b = self.one_batch()
        i = getattr(self, 'n_inp', 1 if len(b)==1 else len(b)-1)
        yb = b[i:][0]
        if color == "random": color = random_shuffle(L(mcolors.CSS4_COLORS.keys()))
        elif color is None: color = ['m', 'orange', 'darkblue', 'lightgray']
        figsize = ifnone(figsize, (8, 6))
        plt.figure(figsize=figsize, **kwargs)
        ax = plt.axes()
        ax.set_axisbelow(True)
        plt.grid(color='gainsboro', linewidth=.1)
        plt.title('Target distribution in a single batch', fontweight='bold')
        if self.cat:
            if yb.ndim == 1:
                yb = yb.flatten().detach().cpu().numpy()
                data = np.unique(yb, return_counts=True)[1]
                data = data / np.sum(data)
            else:
                yb = yb.detach().cpu().numpy()
                data = yb.mean(0)
            plt.bar(self.vocab, data, color=color, edgecolor='black')
            plt.xticks(self.vocab)
        else:
            yb = yb.flatten().detach().cpu().numpy()
            weights=np.ones(len(yb)) / len(yb)
            plt.hist(yb, bins=min(len(yb) // 2, 100), weights=weights, color='violet', edgecolor='black')
        plt.gca().yaxis.set_major_formatter(PercentFormatter(1))
        plt.show()

    @property
    def c(self):
        if len(self.dataset) == 0:
            return 0
        if hasattr(self, "vocab"):
            return len(self.vocab)
        else:
            return 1
#             return self.d if not is_listy(self.d) else reduce(lambda x, y: x * y, self.d, 1)

    @property
    def d(self):
        if len(self.dataset) == 0: return None
        b = self.one_batch()
        if len(b) == 1: return None
        i = getattr(self, 'n_inp', len(b)-1)
        yb = b[i:]
        if len(yb[0].shape[1:]) == 0: return None
        elif len(yb[0].shape[1:]) == 1: return yb[0].shape[-1]
        else: return list(yb[0].shape[1:])

    @property
    def cat(self): return hasattr(self, "vocab")

    @property
    def cws(self):
        if self.cat:
            if self.ptls[-1].ndim == 2: # one hot encoded
                pos_per_class = self.ptls[-1].sum(0)
                neg_per_class = (len(self.ptls[-1]) - pos_per_class)
                pos_weights = neg_per_class / pos_per_class
                pos_weights[pos_weights == float('inf')] = 0
                return torch.Tensor(pos_weights).to(self.device)
            else:
                counts = torch.unique(self.ptls[-1].flatten(), return_counts=True, sorted=True)[-1]
                iw = (counts.sum() / counts)
                return (iw / iw.sum()).to(self.device)
        else: return None

    @property
    def class_priors(self):
        if self.cws is not None:
            cp = 1. / (self.cws + 1e-8)
            return (cp / cp.sum()).to(self.device)
        else: return None


class TSDataLoader(NumpyDataLoader):
    @property
    def vars(self):
        if len(self.dataset) == 0: return 0
        b = self.one_batch()
        i = getattr(self, 'n_inp', 1 if len(b)==1 else len(b)-1)
        xb = b[:i]
        if hasattr(xb[0], 'vars'): return xb[0].vars
        if xb[0].ndim >= 4: return xb[0].shape[-3]
        else: return xb[0].shape[-2]
    @property
    def len(self):
        if len(self.dataset) == 0: return 0
        b = self.one_batch()
        i = getattr(self, 'n_inp', 1 if len(b)==1 else len(b)-1)
        xb = b[:i]
        if hasattr(xb[0], 'len'): return xb[0].len
        if xb[0].ndim >= 4: return xb[0].shape[-2:]
        else: return xb[0].shape[-1]

#|export
_batch_tfms = ('after_item','before_batch','after_batch')

class NumpyDataLoaders(DataLoaders):
    _xblock = NumpyTensorBlock
    _dl_type = NumpyDataLoader
    def __init__(self, *loaders, path='.', device=None):
        create_dir(path, verbose=False)
        self.loaders, self.path = list(loaders), Path(path)
        self.device = ifnone(device, default_device())

    def new_dl(self, X, y=None, bs=64):
        assert X.ndim == 3, "You must pass an X with 3 dimensions [batch_size x n_vars x seq_len]"
        if y is not None and not is_array(y) and not is_listy(y): y = [y]
        new_dloader = self.new(self.dataset.add_dataset(X, y=y), bs=min(bs, len(X)))
        return new_dloader

    @delegates(plt.subplots)
    def show_dist(self, figsize=None, **kwargs): self.loaders[0].show_dist(figsize=figsize, **kwargs)

    def decoder(self, o):
        if isinstance(o, tuple): return self.decode(o)
        if o.ndim <= 1: return self.decodes(o)
        else: return L([self.decodes(oi) for oi in o])

    def decode(self, b):
        return to_cpu(self.after_batch.decode(self._retain_dl(b)))


    @classmethod
    @delegates(DataLoaders.from_dblock)
    def from_numpy(cls, X, y=None, splitter=None, valid_pct=0.2, seed=0, item_tfms=None, batch_tfms=None, **kwargs):
        "Create timeseries dataloaders from arrays (X and y, unless unlabeled)"
        if splitter is None: splitter = RandomSplitter(valid_pct=valid_pct, seed=seed)
        getters = [ItemGetter(0), ItemGetter(1)] if y is not None else [ItemGetter(0)]
        dblock = DataBlock(blocks=(cls._xblock, CategoryBlock),
                           getters=getters,
                           splitter=splitter,
                           item_tfms=item_tfms,
                           batch_tfms=batch_tfms)

        source = itemify(X) if y is None else itemify(X,y)
        return cls.from_dblock(dblock, source, **kwargs)

    @classmethod
    def from_dsets(cls, *ds, path='.', bs=64, num_workers=0, batch_tfms=None, device=None, shuffle_train=True, drop_last=True,
                   weights=None, partial_n=None, sampler=None, sort=False, vocab=None, **kwargs):
        device = ifnone(device, default_device())
        if batch_tfms is not None and not isinstance(batch_tfms, list): batch_tfms = [batch_tfms]
        shuffle_default = (shuffle_train,) + (False,) * (len(ds)-1)
        drop_last_default = (drop_last,) + (False,) * (len(ds)-1)
        defaults = {'shuffle': shuffle_default, 'drop_last': drop_last_default}
        kwargs = merge(defaults, {k: tuplify(v, match=ds) for k,v in kwargs.items()})
        kwargs = [{k: v[i] for k,v in kwargs.items()} for i in range_of(ds)]
        if not is_listy(bs): bs = [bs]
        if len(bs) != len(ds): bs = bs * len(ds)
        if weights is None: weights = [None] * len(ds)
        if not is_listy(partial_n): partial_n = [partial_n]
        if len(partial_n) != len(ds) and len(ds) > 1: partial_n = partial_n + [None] * (len(ds) - len(partial_n))
        if not is_listy(sampler): sampler = [sampler]
        if len(sampler) != len(ds): sampler = sampler * len(ds)
        loaders = [cls._dl_type(d, bs=b, num_workers=num_workers, batch_tfms=batch_tfms, weights=w, partial_n=n, sampler=s, sort=sort, vocab=vocab, **k)\
                   for d,k,b,w,n,s in zip(ds, kwargs, bs, weights, partial_n, sampler)]
        return cls(*loaders, path=path, device=device)


class TSDataLoaders(NumpyDataLoaders):
    _xblock = TSTensorBlock
    _dl_type = TSDataLoader

#|export
class StratifiedSampler:
    "Sampler where batches preserve the percentage of samples for each class"

    def __init__(self,
        y, # The target variable for supervised learning problems. Stratification is done based on the y labels.
        bs : int = 64, # Batch size
        shuffle : bool = False, # Flag to shuffle each class’s samples before splitting into batches.
        drop_last : bool = False # Flag to drop the last incomplete batch.
        ):
        self.n_splits = len(y) // bs if drop_last else int(np.ceil(len(y) / bs))
        self.skf = StratifiedKFold(n_splits=self.n_splits, shuffle=shuffle)
        self.y = y
        self.shuffle = shuffle
        self.n = self.n_splits * bs if drop_last else len(y)

    def __iter__(self):
        if self.shuffle:
            self.skf.random_state = np.random.randint(0, 1e8)
        chunklist = []
        for _,idx in self.skf.split(self.y, self.y):
            chunklist.extend(idx)
        yield chunklist

    def __len__(self):
        return self.n

a = np.concatenate([np.zeros(90), np.ones(10)])
sampler = StratifiedSampler(a, bs=32, shuffle=True, drop_last=True)
idxs = np.array(list(iter(sampler)))
print(idxs[:32])
print(a[idxs][:32])
test_eq(a[idxs][:32].mean(), .1)
# Output:
#   [[ 0  2  8 17 18 21 27 29 34 38 39 43 45 48 52 54 55 60 61 63 66 67 68 69

#     71 73 78 80 81 84 90 92 95 99  1  6 11 12 15 16 20 23 24 28 30 33 36 37

#     40 41 42 44 49 59 62 64 65 74 75 76 77 79 86 87 91 93 96  3  4  5  7  9

#     10 13 14 19 22 25 26 31 32 35 46 47 50 51 53 56 57 58 70 72 82 83 85 88

#     89 94 97 98]]

#   [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.

#     0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.

#     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.

#     0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.

#     0. 1. 1. 1.]]


#|export
def get_c(dls):
    if getattr(dls, 'c', False): return dls.c
    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c
    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c
    vocab = getattr(dls, 'vocab', [])
    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]
    return len(vocab)

#|export
def get_best_dl_params(dl, n_iters=10, num_workers=[0, 1, 2, 4, 8], pin_memory=[True, False], prefetch_factor=[2, 4, 8], return_best=True,
                       verbose=True):

    if not torch.cuda.is_available():
        num_workers = 0
    n_iters = min(n_iters, len(dl))
    if not return_best: verbose = True

    nw = dl.fake_l.num_workers
    pm = dl.fake_l.pin_memory
    pf = dl.fake_l.prefetch_factor

    try:
        best_nw = nw
        best_pm = pm
        best_pf = pf

        # num_workers
        if not num_workers: best_nw = nw
        elif isinstance(num_workers, Integral): best_nw = num_workers
        else:
            best_time = np.inf
            for _nw in num_workers:
                dl.fake_l.num_workers = _nw
                timer.start(False)
                for i, _ in enumerate(dl):
                    if i == n_iters - 1:
                        t = timer.stop() / (i + 1)
                        pv(f'   num_workers: {_nw:2}  pin_memory: {pm!s:^5}  prefetch_factor: {pf:2}  -  time: {1_000 * t/n_iters:8.3f} ms/iter', verbose)
                        if t < best_time:
                            best_nw = _nw
                            best_time = t
                        break
        dl.fake_l.num_workers = best_nw


        # pin_memory
        if not pin_memory: best_pm = pm
        elif isinstance(pin_memory, bool): best_pm = pin_memory
        else:
            best_time = np.inf
            if not pin_memory: pin_memory = [pm]
            for _pm in pin_memory:
                dl.fake_l.pin_memory = _pm
                timer.start(False)
                for i, _ in enumerate(dl):
                    if i == n_iters - 1:
                        t = timer.stop() / (i + 1)
                        pv(f'   num_workers: {best_nw:2}  pin_memory: {_pm!s:^5}  prefetch_factor: {pf:2}  -  time: {1_000 * t/n_iters:8.3f} ms/iter',
                           verbose)
                        if t < best_time:
                            best_pm = _pm
                            best_time = t
                        break
        dl.fake_l.pin_memory = best_pm

        # prefetch_factor
        if best_nw == 0: best_pf = 2
        elif not prefetch_factor: best_pf = pf
        elif isinstance(prefetch_factor, Integral): best_pf = prefetch_factor
        else:
            best_time = np.inf
            if not prefetch_factor: prefetch_factor = [pf]
            for _pf in prefetch_factor:
                dl.fake_l.prefetch_factor = _pf
                timer.start(False)
                for i, _ in enumerate(dl):
                    if i == n_iters - 1:
                        t = timer.stop() / (i + 1)
                        pv(f'   num_workers: {best_nw:2}  pin_memory: {best_pm!s:^5}  prefetch_factor: {_pf:2}  -  time: {1_000 * t/n_iters:8.3f} ms/iter',
                           verbose)
                        if t < best_time:
                            best_pf = _pf
                            best_time = t
                        break
        dl.fake_l.prefetch_factor = best_pf

    except KeyboardInterrupt:
        dl.fake_l.num_workers = best_nw if return_best else nw
        dl.fake_l.pin_memory = best_pm if return_best else pm
        dl.fake_l.prefetch_factor = best_pf if return_best else pf

    if not return_best:
        dl.fake_l.num_workers = nw
        dl.fake_l.pin_memory = pm
        dl.fake_l.prefetch_factor = pf

    if verbose:
        print('\n   best dl params:')
        print(f'       best num_workers    : {best_nw}')
        print(f'       best pin_memory     : {best_pm}')
        print(f'       best prefetch_factor: {best_pf}')
        print(f'       return_best         : {return_best}')
        print('\n')

    return dl

def get_best_dls_params(dls, n_iters=10, num_workers=[0, 1, 2, 4, 8], pin_memory=[True, False], prefetch_factor=[2, 4, 8],
                        return_best=True, verbose=True):

    for i in range(len(dls.loaders)):
        try:
            pv(f'\nDataloader {i}\n', verbose)
            dls.loaders[i] = get_best_dl_params(dls.loaders[i], n_iters=n_iters, num_workers=num_workers, pin_memory=pin_memory,
                                            prefetch_factor=prefetch_factor, return_best=return_best, verbose=verbose)
        except KeyboardInterrupt: pass
    return dls

#|export
def _check_splits(X, splits):
    if splits is None:
        _dtype = smallest_dtype(len(X))
        if len(X) < 1e6:
            splits = (L(np.arange(len(X), dtype=_dtype).tolist()), L())
        else:
            _dtype = smallest_dtype(len(X))
            splits = (np.arange(len(X), dtype=_dtype), L())
    elif isinstance(splits, (tuple, list, L, np.ndarray)):
        if not isinstance(splits[0], (tuple, list, L, np.ndarray)):
            splits = (splits, L())
        elif len(splits) == 1:
            splits = (splits[0], L())
        elif len(splits) >= 2 and splits[1] is None:
            splits = (splits[0], L())
    assert len(splits) >= 2, 'splits must be a tuple or list of length >=2'
    assert len(splits[0]) > 0, 'splits[0] must be a non-empty list'
    return splits

def get_ts_dls(X, y=None, splits=None, sel_vars=None, sel_steps=None, tfms=None, inplace=True,
               path='.', bs=64, batch_tfms=None, num_workers=0, device=None, shuffle_train=True, drop_last=True,
               weights=None, partial_n=None, sampler=None, sort=False, **kwargs):
    splits = _check_splits(X, splits)
    create_dir(path, verbose=False)
    dsets = TSDatasets(X, y, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace)
    dsets = [dsets.subset(i) for i in range(len(splits))]
    if weights is not None:
        assert len(X) == len(weights), 'len(X) != len(weights)'
        weights = [weights[split] if i == 0 else None for i,split in enumerate(splits)] # weights only applied to train set
    dls   = TSDataLoaders.from_dsets(*dsets, path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers,
                                     device=device, shuffle_train=shuffle_train, drop_last=drop_last, weights=weights,
                                     partial_n=partial_n, sampler=sampler, sort=sort, **kwargs)
    return dls

get_tsimage_dls = get_ts_dls

# Tests
a = np.arange(10)

for s in [None, np.arange(10), np.arange(10).tolist(), L(np.arange(10).tolist()), (np.arange(10).tolist(), None), (np.arange(10).tolist(), L())]:
    test_eq(_check_splits(a, s), (L(np.arange(10).tolist()), L()))

#|export
def _check_split(X, split):
    if split is None:
        _dtype = smallest_dtype(len(X))
        if len(X) < 1e6:
            split = L(np.arange(len(X), dtype=_dtype).tolist())
        else:
            _dtype = smallest_dtype(len(X))
            split = np.arange(len(X), dtype=_dtype)
    return (split, L())

def get_ts_dl(X, y=None, split=None, sel_vars=None, sel_steps=None, tfms=None, inplace=True,
              path='.', bs=64, batch_tfms=None, num_workers=0, device=None, shuffle_train=True, drop_last=True, weights=None,
              partial_n=None, sampler=None, sort=False, **kwargs):
    splits = _check_split(X, split)
    create_dir(path, verbose=False)
    dsets = TSDatasets(X, y, splits=splits, sel_vars=sel_vars, sel_steps=sel_steps, tfms=tfms, inplace=inplace, **kwargs)
    if not is_listy(partial_n): partial_n = [partial_n]
    dls   = TSDataLoaders.from_dsets(dsets.train, path=path, bs=bs, batch_tfms=batch_tfms, num_workers=num_workers,
                                     device=device, shuffle_train=shuffle_train, drop_last=drop_last, weights=weights,
                                     partial_n=partial_n, sampler=sampler, sort=sort, **kwargs)
    return dls.train



def get_subset_dl(dl, idxs): return dl.new(dl.dataset.subset(idxs))

X, y, splits = get_UCR_data(dsid, on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=8)
dls = get_best_dls_params(dls, prefetch_factor=[2, 4, 8, 16])
# Output:
#   

#   Dataloader 0

#   

#      num_workers:  0  pin_memory: True   prefetch_factor:  2  -  time:    1.400 ms/iter

#      num_workers:  0  pin_memory: False  prefetch_factor:  2  -  time:    0.620 ms/iter

#   

#      best dl params:

#          best num_workers    : 0

#          best pin_memory     : False

#          best prefetch_factor: 2

#          return_best         : True

#   

#   

#   

#   Dataloader 1

#   

#      num_workers:  0  pin_memory: True   prefetch_factor:  2  -  time:    0.261 ms/iter

#      num_workers:  0  pin_memory: False  prefetch_factor:  2  -  time:    0.306 ms/iter

#   

#      best dl params:

#          best num_workers    : 0

#          best pin_memory     : True

#          best prefetch_factor: 2

#          return_best         : True

#   

#   


y_int = np.random.randint(0, 4, size=len(X))
dls = get_ts_dls(X, y_int, splits=splits, bs=8)
test_eq(hasattr(dls, "vocab"), False)

dls = get_ts_dls(X, y_int, splits=splits, bs=8, vocab=[0,1,2,3])
test_eq(dls.vocab, [0,1,2,3])
test_eq(dls.c, 4)
test_eq(dls.cat, True)

X, y, splits = get_UCR_data(dsid, on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=8)
b=first(dls.train)
dls.decode(b)
test_eq(X.shape[1], dls.vars)
test_eq(X.shape[-1], dls.len)

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=64, inplace=True)

idxs = random_choice(len(dls.valid_ds), 10, False)
new_dl = get_subset_dl(dls.train, idxs)

idxs = random_choice(len(dls.valid_ds), 10, False)
new_dl = get_subset_dl(dls.valid, idxs)
test_eq(new_dl.one_batch()[0].cpu().numpy(), X[splits[1][idxs]])

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
weights = np.random.rand(len(X))
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=64, inplace=True, weights=weights)
weights2 = weights[splits[0]] / weights[splits[0]].sum()
test_eq(dls.train.weights, weights2)
test_eq(dls.valid.weights, None)

partial_n = 12
X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, splits=splits, tfms=[None, TSClassification()], bs=64, inplace=True, partial_n=partial_n)
test_eq(len(dls.train.one_batch()[0]), partial_n)

partial_n = .1
X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], bs=64, inplace=True, partial_n=partial_n)
test_eq(len(dls.train.one_batch()[0]), int(round(len(dls.train.dataset) * partial_n)))

"""
You'll now be able to pass a sampler to a `tsai` dataloader.

You should use a sampler for the train set and a sampler for the validation set. You'll need to pass an object with the same length as each dataset. For example, the splits like in the case below. 

⚠️ Remember to set shuffle=False when using a sampler since they a mutually exclusive. This means that when you use a sampler, you always need to set the shuffle in the dataloader to False. The sampler will control whether the indices are shuffled or not (you can set shuffle to True or False in the sampler). 

drop_last is managed in the dataloder though.
"""

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
train_sampler = torch.utils.data.sampler.RandomSampler(splits[0])
valid_sampler = torch.utils.data.sampler.SequentialSampler(splits[1])
dls = get_ts_dls(X, y, splits=splits, tfms=[None, TSClassification()], bs=8, inplace=True,
                 shuffle=False, drop_last=True, sampler=[train_sampler, valid_sampler])
print('train')
for _ in dls.train:
    print(dls.train.idxs)
print('valid')
for _ in dls.valid:
    print(dls.valid.idxs)
# Output:
#   train

#   [22, 25, 16, 3, 26, 28, 7, 18]

#   [5, 4, 12, 27, 29, 24, 9, 11]

#   [0, 2, 8, 17, 21, 20, 23, 10]

#   valid

#   [0, 1, 2, 3, 4, 5, 6, 7]

#   [8, 9, 10, 11, 12, 13, 14, 15]

#   [16, 17, 18, 19, 20, 21, 22, 23]

#   [24, 25, 26, 27, 28, 29]


X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
train_sampler = torch.utils.data.sampler.SequentialSampler(splits[0])
valid_sampler = torch.utils.data.sampler.SequentialSampler(splits[1])
dls = get_ts_dls(X, y, splits=splits, tfms=[None, TSClassification()], bs=64, inplace=True,
                 shuffle=False, sampler=[train_sampler, valid_sampler])
test_eq(dls.get_idxs(), np.arange(len(splits[0])))
test_eq(dls.train.get_idxs(), np.arange(len(splits[0])))
test_eq(dls.valid.get_idxs(), np.arange(len(splits[1])))
xb = dls.valid.one_batch()[0].cpu().numpy()
test_close(xb, X[dls.valid.split_idxs])

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
train_sampler = torch.utils.data.sampler.RandomSampler(splits[0])
valid_sampler = torch.utils.data.sampler.SequentialSampler(splits[0])
dls = get_ts_dls(X, y, splits=splits, tfms=[None, TSClassification()], bs=32, inplace=True,
                 shuffle=False, drop_last=True, sampler=[train_sampler, valid_sampler])
test_ne(dls.train.get_idxs(), np.arange(len(splits[0])))
test_eq(np.sort(dls.train.get_idxs()), np.arange(len(splits[0])))
test_eq(dls.valid.get_idxs(), np.arange(len(splits[1])))

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=64, inplace=False)

idxs = random_choice(len(dls.valid_ds), 10, False)
new_dl = get_subset_dl(dls.train, idxs)

idxs = random_choice(len(dls.valid_ds), 10, False)
new_dl = get_subset_dl(dls.valid, idxs)
test_eq(new_dl.one_batch()[0].cpu().numpy(), X[splits[1][idxs]])

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSClassification()], splits=splits, bs=8)
b = dls.one_batch()
input_idxs = dls.input_idxs
test_eq(b[0].cpu().numpy(), X[input_idxs])
b = dls.train.one_batch()
input_idxs = dls.train.input_idxs
test_eq(b[0].cpu().numpy(), X[input_idxs])
assert max(input_idxs) < len(splits[0])
b = dls.valid.one_batch()
input_idxs = dls.valid.input_idxs
test_eq(b[0].cpu().numpy(), X[input_idxs])
assert min(input_idxs) >= len(splits[0])

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSCategorize()], splits=splits, bs=8)
b=first(dls.train)
dls.decode(b)
test_eq(X.shape[1], dls.vars)
test_eq(X.shape[-1], dls.len)

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSCategorize()], splits=splits, bs=8, weights=np.random.randint(0, 3, len(y)))
b=first(dls.train)
dls.decode(b)
test_eq(X.shape[1], dls.vars)
test_eq(X.shape[-1], dls.len)

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dsets = TSDatasets(X, y, tfms=[None, TSCategorize()], splits=splits)
ts_dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, device=default_device(), bs=4)
torch.save(ts_dls, 'export/ts_dls.pth')
del ts_dls
ts_dls = torch.load('export/ts_dls.pth')
for xb,yb in ts_dls.train:
    test_eq(tensor(X[ts_dls.train.idxs]), xb.cpu())

X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSCategorize()], splits=splits, bs=4)
for xb,yb in dls.train:
    test_eq(xb.cpu().numpy(), X[dls.train.input_idxs])
for xb,yb in dls.valid:
    test_eq(xb.cpu().numpy(), X[dls.valid.input_idxs])

test_eq((ts_dls.train.shuffle, ts_dls.valid.shuffle, ts_dls.train.drop_last, ts_dls.valid.drop_last), (True, False, True, False))

dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSCategorize()], splits=splits, bs=8, num_workers=0)
xb, yb = first(dls.train)
test_eq(tensor(X[dls.train.idxs]), xb.cpu())

test_eq((dls.train.shuffle, dls.valid.shuffle, dls.train.drop_last, dls.valid.drop_last), (True, False, True, False))

# multiclass
dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, on_disk=True, split_data=False)
dls = get_ts_dls(X, y, tfms=[None, TSCategorize()], splits=splits, inplace=True)
dls.show_dist()
dls.train.show_dist()
xb,yb = first(dls.train)
test_eq((dls.cat, dls.c), (True, 4))
test_ne(dls.cws.cpu().numpy(), None)
dls.decoder((xb, ))
dls.decoder((xb[0], ))
dls.decoder((xb, yb))
dls.decoder((xb[0], yb[0]))
dls.decoder(yb)
dls.decoder(yb[0])
# Output:
#   <Figure size 800x600 with 1 Axes>
#   <Figure size 800x600 with 1 Axes>
#   '1'

new_dl = dls.new_dl(X)
first(new_dl)
# Output:
#   (TSTensor(samples:60, vars:1, len:570, device=cpu, dtype=torch.float32),)

new_dl = dls.new_dl(X, y=y)
first(new_dl)
# Output:
#   (TSTensor(samples:60, vars:1, len:570, device=cpu, dtype=torch.float32),

#    TensorCategory([2, 3, 2, 2, 0, 1, 1, 3, 3, 1, 2, 0, 0, 3, 0, 1, 0, 3, 3, 3, 1,

#                    3, 3, 3, 3, 3, 0, 3, 1, 1, 3, 3, 2, 3, 3, 3, 1, 1, 3, 2, 3, 0,

#                    3, 0, 3, 1, 1, 2, 1, 1, 1, 3, 3, 1, 2, 1, 1, 3, 0, 0]))

dls.train.dataset.split_idxs, dls.train.dataset.splits, dls.valid.split_idxs
# Output:
#   (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,

#           17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], dtype=int8),

#    (#30) [0,1,2,3,4,5,6,7,8,9...],

#    array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,

#           47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], dtype=int8))

# 2d input array and tfms == None return a NoTfmLists object
X, y, splits = get_UCR_data('OliveOil', on_disk=False, split_data=False)
X = X[:, 0]
tfms=[None, TSCategorize()]
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, bs=8)
test_eq(1, dls.vars)
test_eq(X.shape[-1], dls.len)
test_eq(type(dls.tls[0]).__name__, 'NoTfmLists')
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, bs=8, inplace=False)
test_eq(1, dls.vars)
test_eq(X.shape[-1], dls.len)
test_eq(type(dls.tls[0]).__name__, 'NoTfmLists')

# regression
dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, on_disk=True, split_data=False)
dls = get_ts_dls(X, np.random.rand(60, ), tfms=[None, ToNumpyTensor], splits=splits)
dls.show_dist()
dls.train.show_dist()
xb,yb = first(dls.train)
dls.decoder((xb, ))
dls.decoder((xb[0], ))
dls.decoder((xb, yb))
dls.decoder((xb[0], yb[0]))
dls.decoder(yb)
dls.decoder(yb[0])
test_eq((dls.cat, dls.c), (False, 1))
test_eq(dls.cws, None)
# Output:
#   <Figure size 800x600 with 1 Axes>
#   <Figure size 800x600 with 1 Axes>

# regression, multilabel
dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, on_disk=True, split_data=False)
dls = get_ts_dls(X, np.random.rand(60, 3) * 5, tfms=[None, ToNumpyTensor], splits=splits)
dls.show_dist()
dls.train.show_dist()
xb,yb = first(dls.train)
dls.decoder((xb, ))
dls.decoder((xb[0], ))
dls.decoder((xb, yb))
dls.decoder((xb[0], yb[0]))
dls.decoder(yb)
dls.decoder(yb[0])
test_eq((dls.cat, dls.c, dls.d),(False, 1, 3))
test_eq(dls.cws, None)
# Output:
#   <Figure size 800x600 with 1 Axes>
#   <Figure size 800x600 with 1 Axes>

# multiclass, multilabel
dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, on_disk=True, split_data=False)
cm = {
    '1':'A',
    '2':['B', 'C'],
    '3':['B', 'D'] ,
    '4':'E',
    }
keys = cm.keys()
new_cm = {k:v for k,v in zip(keys, [listify(v) for v in cm.values()])}
y_multi = np.array([new_cm[yi] if yi in keys else listify(yi) for yi in y], dtype=object)
dls = get_ts_dls(X, y_multi, tfms=[None, TSMultiLabelClassification()], splits=splits)
dls.show_dist()
dls.train.show_dist()
xb,yb = first(dls.train)
dls.decoder((xb, ))
dls.decoder((xb[0], ))
dls.decoder((xb, yb))
dls.decoder((xb[0], yb[0]))
dls.decoder(yb)
dls.decoder(yb[0])
test_eq((dls.cat, dls.c), (True, 5))
test_ne(dls.cws.cpu().numpy(), None)
# Output:
#   <Figure size 800x600 with 1 Axes>
#   <Figure size 800x600 with 1 Axes>

dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, on_disk=True, split_data=False)
cm = {
    '1':'A',
    '2':['B', 'C'],
    '3':['B', 'D'] ,
    '4':'E',
    }
keys = cm.keys()
new_cm = {k:v for k,v in zip(keys, [listify(v) for v in cm.values()])}
y_multi = np.array([new_cm[yi] if yi in keys else listify(yi) for yi in y], dtype=object)
dls = get_ts_dls(X, y_multi, tfms=[None, TSMultiLabelClassification()], splits=splits)
test_eq(dls.new(X[0]).one_batch().shape, (1, 570))
test_eq(dls.new(X[:15]).one_batch().shape, (15, 1, 570))
test_eq(dls.train.new(X[0]).one_batch().shape, (1, 570))
test_eq(dls.valid.new(X[:15]).one_batch().shape, (15, 1, 570))

bs = 25
dsets = TSDatasets(X, y, tfms=[None, TSCategorize()], splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2], batch_tfms=add(1), num_workers=0)
xb,yb = dls.train.one_batch()
test_eq(xb.cpu().data, tensor(X_on_disk[splits[0]][dls.train.idxs]) + 1)

dsets = TSDatasets(X, y, tfms=[None, TSCategorize()], splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])
xb,yb = dls.train.one_batch()
test_eq(xb.shape, (min(bs, len(splits[0])), X.shape[1], X.shape[-1]))
it = iter(dls.valid)
for xb,yb in it:
    test_close(xb.cpu(), TSTensor(X[splits[1]][dls.valid.idxs]))

bs = 64
dsets = TSDatasets(X, y, tfms=[add(1), TSCategorize()], splits=RandomSplitter(valid_pct=.3)(y_array))
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])
xb,yb = dls.train.one_batch()
test_eq(xb.shape, (min(bs, len(dsets.train)), X_on_disk.shape[1], X_on_disk.shape[-1]))
xb,yb = dls.valid.one_batch()
test_eq(xb.shape, (min(bs*2, len(dsets.valid)), X_on_disk.shape[1], X_on_disk.shape[-1]))

dsets = TSDatasets(X_on_disk, y_array, tfms=[None, TSCategorize()], splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[32, 64])
for i in range(10):
    dl = dls.train if random.random() < .5 else dls.valid
    xb,yb = dl.one_batch()
    torch.equal(xb.cpu(), TSTensor(X_on_disk[dl.input_idxs]))

dsets = TSDatasets(X_on_disk, y_array, tfms=[None, TSCategorize()])
dls   = TSDataLoaders.from_dsets(dsets, bs=32)
for i in range(10):
    xb,yb = dls.one_batch()
    torch.equal(xb.cpu(), TSTensor(X_on_disk[dl.input_idxs]))

dsets = TSDatasets(X_on_disk, tfms=None)
dls   = TSDataLoaders.from_dsets(dsets, bs=32)
for i in range(10):
    xb = dls.one_batch()
    torch.equal(xb[0].cpu(), TSTensor(X_on_disk[dl.input_idxs]))

dsets = TSDatasets(X_on_disk, y_array, tfms=[None, TSCategorize()])
dls   = TSDataLoaders.from_dsets(dsets, bs=32)
test_eq(dls.split_idxs, L(np.arange(len(X_on_disk)).tolist()))

X, y, splits = get_UCR_data('NATOPS', return_split=False)
tfms  = [None, [TSCategorize()]]
dls = get_ts_dls(X, y, tfms=tfms, splits=splits, bs=[64, 128])
dls.show_batch()
dls.show_dist()
# Output:
#   <Figure size 1800x1200 with 9 Axes>
#   <Figure size 800x600 with 1 Axes>

# test passing a list with categories instead of a numpy array
dsid = 'NATOPS'
bs = 64
X2, y2, splits2 = get_UCR_data(dsid, return_split=False)
vocab = sorted(set(y))
tfms = [None, [TSCategorize(vocab=vocab)]]
dsets = TSDatasets(X2, y2, tfms=tfms, splits=splits2)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])
dls.train.one_batch()
# Output:
#   (TSTensor(samples:64, vars:24, len:51, device=cpu, dtype=torch.float32),

#    TensorCategory([0, 3, 0, 5, 0, 0, 5, 3, 3, 1, 2, 0, 0, 2, 5, 2, 2, 4, 5, 3, 2,

#                    4, 2, 1, 1, 0, 1, 2, 0, 4, 4, 4, 4, 2, 0, 0, 3, 3, 0, 5, 4, 3,

#                    2, 5, 5, 2, 2, 4, 3, 0, 2, 4, 4, 5, 5, 0, 5, 3, 2, 1, 0, 3, 4,

#                    2]))

# MultiCategory
bs = 64
n_epochs = 100
tfms = [None, [MultiCategorize()]]
dsets = TSDatasets(X2, y2, tfms=tfms, splits=splits2)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=bs)
dls.train.one_batch()
# Output:
#   (TSTensor(samples:64, vars:24, len:51, device=cpu, dtype=torch.float32),

#    TensorMultiCategory([[7, 0, 1],

#                         [4, 0, 1],

#                         [7, 0, 1],

#                         [5, 0, 1],

#                         [2, 0, 1],

#                         [2, 0, 1],

#                         [2, 0, 1],

#                         [7, 0, 1],

#                         [5, 0, 1],

#                         [3, 0, 1],

#                         [6, 0, 1],

#                         [7, 0, 1],

#                         [3, 0, 1],

#                         [6, 0, 1],

#                         [7, 0, 1],

#                         [7, 0, 1],

#                         [6, 0, 1],

#                         [7, 0, 1],

#                         [5, 0, 1],

#                         [3, 0, 1],

#                         [3, 0, 1],

#                         [7, 0, 1],

#                         [7, 0, 1],

#                         [2, 0, 1],

#                         [4, 0, 1],

#                         [4, 0, 1],

#                         [2, 0, 1],

#                         [4, 0, 1],

#                         [6, 0, 1],

#                         [2, 0, 1],

#                         [2, 0, 1],

#                         [5, 0, 1],

#                         [2, 0, 1],

#                         [5, 0, 1],

#                         [4, 0, 1],

#                         [7, 0, 1],

#                         [2, 0, 1],

#                         [3, 0, 1],

#                         [4, 0, 1],

#                         [6, 0, 1],

#                         [2, 0, 1],

#                         [7, 0, 1],

#                         [2, 0, 1],

#                         [3, 0, 1],

#                         [4, 0, 1],

#                         [5, 0, 1],

#                         [5, 0, 1],

#                         [2, 0, 1],

#                         [5, 0, 1],

#                         [2, 0, 1],

#                         [3, 0, 1],

#                         [5, 0, 1],

#                         [6, 0, 1],

#                         [7, 0, 1],

#                         [5, 0, 1],

#                         [2, 0, 1],

#                         [7, 0, 1],

#                         [4, 0, 1],

#                         [5, 0, 1],

#                         [6, 0, 1],

#                         [7, 0, 1],

#                         [4, 0, 1],

#                         [7, 0, 1],

#                         [3, 0, 1]]))

"""
The combination of splits, sel_vars and sel_steps is very powerful, as it allows you to perform advanced indexing of the array-like X.
"""

from tsai.data.validation import TSSplitter

X = np.arange(16*5*50).reshape(16,5,50)
y = alphabet[np.random.randint(0,3, 16)]
splits = TSSplitter(show_plot=False)(y)
tfms = [None, TSCategorize()]
batch_tfms = None
dls = get_ts_dls(X, y, splits=splits, sel_vars=[0, 1, 3], sel_steps=slice(-10, None), tfms=tfms, batch_tfms=batch_tfms)
xb,yb=dls.train.one_batch()
test_close(X[dls.input_idxs][:, [0, 1, 3]][...,slice(-10, None)], xb.cpu().numpy())
new_dl = dls.train.new_dl(X[:5], y[:5])
print(new_dl.one_batch())
new_empty_dl = dls.new_empty() # when exported
dl = new_empty_dl.new_dl(X[:10], y[:10], bs=64) # after export
dl.one_batch()
# Output:
#   (TSTensor(samples:5, vars:3, len:10, device=cpu, dtype=torch.int64), TensorCategory([2, 2, 2, 2, 2]))

#   (TSTensor(samples:10, vars:3, len:10, device=cpu, dtype=torch.int64),

#    TensorCategory([2, 2, 2, 0, 2, 2, 0, 2, 1, 1]))

#|export
def get_time_per_batch(dl, model=None, n_batches=None):
    try:
        timer.start(False)
        pbar = progress_bar(dl, leave=False)
        for i, (xb, _) in enumerate(pbar):
            if model is not None:
                _ = model(xb)
            if n_batches is not None and i >= n_batches - 1:
                t = timer.stop()
                pbar.on_interrupt()
                break
        if n_batches is None or i < n_batches - 1:
            t = timer.stop()

    except KeyboardInterrupt:
        t = timer.stop()
        pbar.on_interrupt()
    return t / (i+1)

def get_dl_percent_per_epoch(dl, model, n_batches=None):
    dl_time = get_time_per_batch(dl, model=None, n_batches=n_batches)
    model_time = get_time_per_batch(dl, model=model, n_batches=n_batches)
    return f'{min(1, dl_time/model_time):.2%}'

X, y, splits = get_UCR_data('NATOPS', split_data=False)
tfms  = [None, [TSCategorize()]]
dls = get_ts_dls(X, y, tfms=tfms, splits=splits)
train_dl = dls.train
xb, _ = train_dl.one_batch()
model = nn.Linear(xb.shape[-1], 2).to(xb.device)
t = get_dl_percent_per_epoch(train_dl, model, n_batches=10)
print(t)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   93.70%


#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/006_data.core.ipynb saved at 2023-07-02 13:54:50

#   Correct notebook to script conversion! 😃

#   Sunday 02/07/23 13:54:53 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/008_data.metadatasets.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp data.metadatasets

"""
# Metadataset
"""

"""
>A dataset of datasets

This functionality will allow you to create a dataset from data stores in multiple, smaller datasets.

I'd like to thank both **Thomas Capelle** (https://github.com/tcapelle)  and **Xander Dunn** (https://github.com/xanderdunn) for their contributions to make this code possible. 

This functionality allows you to use multiple numpy arrays instead of a single one, which may be very useful in many practical settings. It's been tested it with 10k+ datasets and it works well. 
"""

#|export
from tsai.imports import *
from tsai.utils import *
from tsai.data.validation import *
from tsai.data.core import *

#|export
class TSMetaDataset():
    _type = (TSTensor,)
    " A dataset capable of indexing mutiple datasets at the same time"
    def __init__(self, dataset_list, **kwargs):
        if not is_listy(dataset_list): dataset_list = [dataset_list]
        self.datasets = dataset_list
        self.split = kwargs['split'] if 'split' in kwargs else None            
        self.mapping = self._mapping()
        if hasattr(dataset_list[0], 'loss_func'): 
            self.loss_func =  dataset_list[0].loss_func
        else: 
            self.loss_func = None

    def __len__(self):
        if self.split is not None: 
            return len(self.split)
        else:
            return sum([len(ds) for ds in self.datasets])

    def __getitem__(self, idx):
        if self.datasets:
            if self.split is not None: idx = self.split[idx]
            idx = listify(idx)
            idxs = self.mapping[idx]
            idxs = idxs[idxs[:, 0].argsort()]
            self.mapping_idxs = idxs
            ds = np.unique(idxs[:, 0])
            b = [self.datasets[d][idxs[idxs[:, 0] == d, 1]] for d in ds]
            output = tuple(map(torch.cat, zip(*b)))
            output = self._type[0](output[0]), output[1]
            return output
        else:
            return

    def _mapping(self):
        lengths = [len(ds) for ds in self.datasets]
        idx_pairs = np.zeros((np.sum(lengths), 2)).astype(np.int32)
        start = 0
        for i,length in enumerate(lengths):
            if i > 0: 
                idx_pairs[start:start+length, 0] = i
            idx_pairs[start:start+length, 1] = np.arange(length)
            start += length
        return idx_pairs

    def new_empty(self): 
        new_dset = type(self)(self.datasets, split=self.split)
        new_dset.datasets = None
        return new_dset
    
    @property
    def vars(self):
        s = self.datasets[0][0][0] if not isinstance(self.datasets[0][0][0], tuple) else self.datasets[0][0][0][0]
        return s.shape[-2]
    @property
    def len(self): 
        s = self.datasets[0][0][0] if not isinstance(self.datasets[0][0][0], tuple) else self.datasets[0][0][0][0]
        return s.shape[-1]
    @property
    def vocab(self): 
        return self.datasets[0].vocab
    @property
    def cat(self): return hasattr(self, "vocab")


class TSMetaDatasets(FilteredBase):
    def __init__(self, metadataset, splits):
        store_attr()
        self.mapping = metadataset.mapping
        self.datasets = metadataset.datasets
    def subset(self, i):
        return type(self.metadataset)(self.metadataset.datasets, split=self.splits[i])
    @property
    def train(self): 
        return self.subset(0)
    @property
    def valid(self): 
        return self.subset(1)

"""
Let's create 3 datasets. In this case they will have different sizes.
"""

vocab = alphabet[:10]
dsets = []
for i in range(3):
    size = np.random.randint(50, 150)
    X = torch.rand(size, 5, 50)
    y = vocab[torch.randint(0, 10, (size,))]
    tfms = [None, TSClassification(vocab=vocab)]
    dset = TSDatasets(X, y, tfms=tfms)
    dsets.append(dset)



metadataset = TSMetaDataset(dsets)
splits = TimeSplitter(show_plot=False)(metadataset)
metadatasets = TSMetaDatasets(metadataset, splits=splits)
dls = TSDataLoaders.from_dsets(metadatasets.train, metadatasets.valid)
xb, yb = dls.train.one_batch()
xb, yb
# Output:
#   (TSTensor(samples:64, vars:5, len:50, device=cpu, dtype=torch.float32),

#    TensorCategory([1, 0, 3, 9, 7, 2, 8, 6, 1, 1, 1, 8, 1, 1, 9, 2, 6, 6, 1, 5, 5,

#                    6, 9, 2, 7, 1, 6, 4, 9, 2, 5, 0, 4, 9, 1, 4, 4, 6, 0, 8, 8, 5,

#                    8, 6, 9, 0, 8, 8, 6, 4, 8, 9, 7, 3, 4, 7, 7, 8, 6, 2, 3, 0, 7,

#                    4]))

"""
You can train metadatasets as you would train any other time series model in `tsai`:

```python
learn = ts_learner(dls, arch="TSTPlus")
learn.fit_one_cycle(1)
learn.export("test.pkl")
```
"""

"""
For inference, you should create the new metadatasets using the same method you used when you trained it. The you use fastai's learn.get_preds method to generate predictions: 

```python
vocab = alphabet[:10]
dsets = []
for i in range(3):
    size = np.random.randint(50, 150)
    X = torch.rand(size, 5, 50)
    y = vocab[torch.randint(0, 10, (size,))]
    tfms = [None, TSClassification(vocab=vocab)]
    dset = TSDatasets(X, y, tfms=tfms)
    dsets.append(dset)
metadataset = TSMetaDataset(dsets)
dl = TSDataLoader(metadataset)


learn = load_learner("test.pkl")
learn.get_preds(dl=dl)
```
"""

"""
There also en easy way to map any particular sample in a batch to the original dataset and id: 
"""

dls = TSDataLoaders.from_dsets(metadatasets.train, metadatasets.valid)
xb, yb = first(dls.train)
mappings = dls.train.dataset.mapping_idxs
for i, (xbi, ybi) in enumerate(zip(xb, yb)):
    ds, idx = mappings[i]
    test_close(dsets[ds][idx][0].data.cpu(), xbi.cpu())
    test_close(dsets[ds][idx][1].data.cpu(), ybi.cpu())

"""
For example the 3rd sample in this batch would be: 
"""

dls.train.dataset.mapping_idxs[2]
# Output:
#   array([  0, 112], dtype=int32)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/008_data.metadatasets.ipynb saved at 2023-03-24 11:30:57

#   Correct notebook to script conversion! 😃

#   Friday 24/03/23 11:31:00 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/010_data.transforms.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp data.transforms

"""
# Time Series Data Augmentation
"""

"""
>Functions used to transform TSTensors (Data Augmentation)
"""

#|export
from tsai.imports import *
from scipy.interpolate import CubicSpline
from scipy.ndimage import convolve1d
from fastcore.transform import compose_tfms
from fastai.vision.augment import RandTransform
from tsai.utils import *
from tsai.data.core import *

from tsai.data.core import TSCategorize
from tsai.data.external import get_UCR_data
from tsai.data.preprocessing import TSStandardize

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, return_split=False)
tfms = [None, TSCategorize()]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, tfms=tfms, splits=splits, batch_tfms=batch_tfms, bs=128)
xb, yb = next(iter(dls.train))

#|export
class TSIdentity(RandTransform):
    "Applies the identity tfm to a `TSTensor` batch"
    order = 90
    def __init__(self, magnitude=None, **kwargs):
        self.magnitude = magnitude
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor): return o

test_eq(TSIdentity()(xb, split_idx=0).shape, xb.shape)

#|export
# partial(TSShuffle_HLs, ex=0),
class TSShuffle_HLs(RandTransform):
    "Randomly shuffles HIs/LOs of an OHLC `TSTensor` batch"
    order = 90
    def __init__(self, magnitude=1., ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        timesteps = o.shape[-1] // 4
        pos_rand_list = random_choice(np.arange(timesteps),size=random.randint(1, timesteps),replace=False)
        rand_list = pos_rand_list * 4
        highs = rand_list + 1
        lows = highs + 1
        a = np.vstack([highs, lows]).flatten('F')
        b = np.vstack([lows, highs]).flatten('F')
        output = o.clone()
        output[...,a] = output[...,b]
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSShuffle_HLs()(xb, split_idx=0).shape, xb.shape)

#|export
# partial(TSShuffleSteps, ex=0),
class TSShuffleSteps(RandTransform):
    "Randomly shuffles consecutive sequence datapoints in batch"
    order = 90
    def __init__(self, magnitude=1., ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        odd = 1 - o.shape[-1]%2
        r = np.random.randint(2)
        timesteps = o.shape[-1] // 2
        pos_rand_list = random_choice(np.arange(0, timesteps - r * odd), size=random.randint(1, timesteps - r * odd),replace=False) * 2 + 1 + r
        a = np.vstack([pos_rand_list, pos_rand_list - 1]).flatten('F')
        b = np.vstack([pos_rand_list - 1, pos_rand_list]).flatten('F')
        output = o.clone()
        output[...,a] = output[...,b]
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

t = TSTensor(torch.arange(11).float())
tt_ = []
for _ in range(1000):
    tt = TSShuffleSteps()(t, split_idx=0)
    test_eq(len(set(tt.tolist())), len(t))
    test_ne(tt, t)
    tt_.extend([t for i,t in enumerate(tt) if t!=i])
x, y = np.unique(tt_, return_counts=True) # This is to visualize distribution which should be equal for all and half for first and last items
plt.bar(x, y);
# Output:
#   <Figure size 640x480 with 1 Axes>

#|export
class TSGaussianNoise(RandTransform):
    "Applies additive or multiplicative gaussian noise"
    order = 90
    def __init__(self, magnitude=.5, additive=True, ex=None, **kwargs):
        self.magnitude, self.additive, self.ex = magnitude, additive, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if self.magnitude <= 0: return o
        noise = self.magnitude * torch.randn_like(o)
        if self.ex is None:
            if self.additive: return o + noise
            else: return o * (1 + noise)
        else:
            if self.additive: output = o + noise
            else: output = o * (1 + noise)
        output[..., self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSGaussianNoise(.1, additive=True)(xb, split_idx=0).shape, xb.shape)
test_eq(TSGaussianNoise(.1, additive=False)(xb, split_idx=0).shape, xb.shape)

#|export
class TSMagAddNoise(RandTransform):
    "Applies additive noise on the y-axis for each step of a `TSTensor` batch"
    order = 90
    def __init__(self, magnitude=1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        # output = o + torch.normal(0, o.std() * self.magnitude, o.shape, dtype=o.dtype, device=o.device)
        output = o + torch.normal(0, 1/3, o.shape, dtype=o.dtype, device=o.device) * (o[..., 1:] - o[..., :-1]).std(2, keepdims=True) * self.magnitude
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

class TSMagMulNoise(RandTransform):
    "Applies multiplicative noise on the y-axis for each step of a `TSTensor` batch"
    order = 90
    def __init__(self, magnitude=1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        noise = torch.normal(1, self.magnitude * .025, o.shape, dtype=o.dtype, device=o.device)
        output = o * noise
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSMagAddNoise()(xb, split_idx=0).shape, xb.shape)
test_eq(TSMagMulNoise()(xb, split_idx=0).shape, xb.shape)
test_ne(TSMagAddNoise()(xb, split_idx=0), xb)
test_ne(TSMagMulNoise()(xb, split_idx=0), xb)

#|export
def random_curve_generator(o, magnitude=0.1, order=4, noise=None):
    seq_len = o.shape[-1]
    f = CubicSpline(np.linspace(-seq_len, 2 * seq_len - 1, 3 * (order - 1) + 1, dtype=int),
                    np.random.normal(loc=1.0, scale=magnitude, size=3 * (order - 1) + 1), axis=-1)
    return f(np.arange(seq_len))

def random_cum_curve_generator(o, magnitude=0.1, order=4, noise=None):
    x = random_curve_generator(o, magnitude=magnitude, order=order, noise=noise).cumsum()
    x -= x[0]
    x /= x[-1]
    x = np.clip(x, 0, 1)
    return x * (o.shape[-1] - 1)

def random_cum_noise_generator(o, magnitude=0.1, noise=None):
    seq_len = o.shape[-1]
    x = np.clip(np.ones(seq_len) + np.random.normal(loc=0, scale=magnitude, size=seq_len), 0, 1000).cumsum()
    x -= x[0]
    x /= x[-1]
    return x * (o.shape[-1] - 1)

def random_cum_linear_generator(o, magnitude=0.1):
    seq_len = o.shape[-1]
    win_len = int(round(seq_len * np.random.rand() * magnitude))
    if win_len == seq_len: return np.arange(o.shape[-1])
    start = np.random.randint(0, seq_len - win_len)
    # mult between .5 and 2
    rand = np.random.rand()
    mult = 1 + rand
    if np.random.randint(2): mult = 1 - rand/2
    x = np.ones(seq_len)
    x[start : start + win_len] = mult
    x = x.cumsum()
    x -= x[0]
    x /= x[-1]
    return np.clip(x, 0, 1) * (seq_len - 1)

#|export
class TSTimeNoise(RandTransform):
    "Applies noise to each step in the x-axis of a `TSTensor` batch based on smooth random curve"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)
        output = o.new(f(random_cum_noise_generator(o, magnitude=self.magnitude)))
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSTimeNoise()(xb, split_idx=0).shape, xb.shape)
test_ne(TSTimeNoise()(xb, split_idx=0), xb)

#|export
class TSMagWarp(RandTransform):
    "Applies warping to the y-axis of a `TSTensor` batch based on a smooth random curve"
    order = 90
    def __init__(self, magnitude=0.02, ord=4, ex=None, **kwargs):
        self.magnitude, self.ord, self.ex = magnitude, ord, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if self.magnitude and self.magnitude <= 0: return o
        y_mult = random_curve_generator(o, magnitude=self.magnitude, order=self.ord)
        output = o * o.new(y_mult)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSMagWarp()(xb, split_idx=0).shape, xb.shape)
test_ne(TSMagWarp()(xb, split_idx=0), xb)

#|export
class TSTimeWarp(RandTransform):
    "Applies time warping to the x-axis of a `TSTensor` batch based on a smooth random curve"
    order = 90
    def __init__(self, magnitude=0.1, ord=6, ex=None, **kwargs):
        self.magnitude, self.ord, self.ex = magnitude, ord, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)
        output = o.new(f(random_cum_curve_generator(o, magnitude=self.magnitude, order=self.ord)))
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSTimeWarp()(xb, split_idx=0).shape, xb.shape)
test_ne(TSTimeWarp()(xb, split_idx=0), xb)

#|export
class TSWindowWarp(RandTransform):
    """Applies window slicing to the x-axis of a `TSTensor` batch based on a random linear curve based on
    https://halshs.archives-ouvertes.fr/halshs-01357973/document"""
    order = 90
    def __init__(self, magnitude=0.1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o
        f = CubicSpline(np.arange(o.shape[-1]), o.cpu(), axis=-1)
        output = o.new(f(random_cum_linear_generator(o, magnitude=self.magnitude)))
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSWindowWarp()(xb, split_idx=0).shape, xb.shape)

#|export
class TSMagScale(RandTransform):
    "Applies scaling to the y-axis of a `TSTensor` batch based on a scalar"
    order = 90
    def __init__(self, magnitude=0.5, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        rand = random_half_normal()
        scale = (1 - (rand  * self.magnitude)/2) if random.random() > 1/3 else (1 + (rand  * self.magnitude))
        output = o * scale
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

class TSMagScalePerVar(RandTransform):
    "Applies per_var scaling to the y-axis of a `TSTensor` batch based on a scalar"
    order = 90
    def __init__(self, magnitude=0.5, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        s = [1] * o.ndim
        s[-2] = o.shape[-2]
        rand = random_half_normal_tensor(s, device=o.device)
        scale = (1 - (rand  * self.magnitude)/2) if random.random() > 1/3 else (1 + (rand  * self.magnitude))
        output = o * scale
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

TSMagScaleByVar = TSMagScalePerVar

test_eq(TSMagScale()(xb, split_idx=0).shape, xb.shape)
test_eq(TSMagScalePerVar()(xb, split_idx=0).shape, xb.shape)
test_ne(TSMagScale()(xb, split_idx=0), xb)
test_ne(TSMagScalePerVar()(xb, split_idx=0), xb)

#|export
def test_interpolate(mode="linear"):

    assert mode in ["nearest", "linear", "area"], "Mode must be 'nearest', 'linear' or 'area'."

    # Create a 1D tensor
    tensor = torch.randn(1, 1, 8, device=default_device())

    try:
        # Try to interpolate using linear mode
        result = F.interpolate(tensor, scale_factor=2, mode=mode)
        return True
    except NotImplementedError as e:
        print(f"{mode} interpolation is not supported by {default_device()}. You can try a different mode")
        print("Error:", e)
        return False

# Run the test
test_interpolate('linear')
# Output:
#   linear interpolation is not supported by mps. You can try a different mode

#   Error: The operator 'aten::upsample_linear1d.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.

#   False

test_interpolate('nearest')
# Output:
#   True

#|export
class TSRandomResizedCrop(RandTransform):
    "Randomly amplifies a sequence focusing on a random section of the steps"
    order = 90
    def __init__(self, magnitude=0.1, size=None, scale=None, ex=None, mode='nearest', **kwargs):
        """
        Args:
            size: None, int or float
            scale: None or tuple of 2 floats 0 < float <= 1
            mode:  'nearest' | 'linear' | 'area'

        """

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        if scale is not None:
            assert is_listy(scale) and len(scale) == 2 and min(scale) > 0 and min(scale) <= 1, "scale must be a tuple with 2 floats 0 < float <= 1"
        self.size,self.scale = size,scale
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        if self.size is not None:
            size = self.size if isinstance(self.size, Integral) else int(round(self.size * seq_len))
        else:
            size = seq_len
        if self.scale is not None:
            lambd = np.random.uniform(self.scale[0], self.scale[1])
        else:
            lambd = np.random.beta(self.magnitude, self.magnitude)
            lambd = max(lambd, 1 - lambd)
        win_len = int(round(seq_len * lambd))
        if win_len == seq_len:
            if size == seq_len: return o
            _slice = slice(None)
        else:
            start = np.random.randint(0, seq_len - win_len)
            _slice = slice(start, start + win_len)
        return F.interpolate(o[..., _slice], size=size, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)

TSRandomZoomIn = TSRandomResizedCrop

if test_interpolate('nearest'):
    test_eq(TSRandomResizedCrop(.5)(xb, split_idx=0).shape, xb.shape)
    test_ne(TSRandomResizedCrop(size=.8, scale=(.5, 1))(xb, split_idx=0).shape, xb.shape)
    test_ne(TSRandomResizedCrop(size=20, scale=(.5, 1))(xb, split_idx=0).shape, xb.shape)

#|export
class TSWindowSlicing(RandTransform):
    "Randomly extracts an resize a ts slice based on https://halshs.archives-ouvertes.fr/halshs-01357973/document"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o
        seq_len = o.shape[-1]
        win_len = int(round(seq_len * (1 - self.magnitude)))
        if win_len == seq_len: return o
        start = np.random.randint(0, seq_len - win_len)
        return F.interpolate(o[..., start : start + win_len], size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)

if test_interpolate('nearest'):
    test_eq(TSWindowSlicing()(xb, split_idx=0).shape, xb.shape)
    test_ne(TSWindowSlicing()(xb, split_idx=0), xb)

#|export
class TSRandomZoomOut(RandTransform):
    "Randomly compresses a sequence on the x-axis"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = max(lambd, 1 - lambd)
        win_len = int(round(seq_len * lambd))
        if win_len == seq_len: return o
        start = (seq_len - win_len) // 2
        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)
        interp = F.interpolate(o, size=win_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        output[..., start:start + win_len] = o.new(interp)
        return output

if test_interpolate('nearest'):
    test_eq(TSRandomZoomOut(.5)(xb, split_idx=0).shape, xb.shape)#

#|export
class TSRandomTimeScale(RandTransform):
    "Randomly amplifies/ compresses a sequence on the x-axis keeping the same length"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        if np.random.rand() <= 0.5: return TSRandomZoomIn(magnitude=self.magnitude, ex=self.ex, mode=self.mode)(o, split_idx=0)
        else: return TSRandomZoomOut(magnitude=self.magnitude, ex=self.ex, mode=self.mode)(o, split_idx=0)

if test_interpolate('nearest'):
    test_eq(TSRandomTimeScale(.5)(xb, split_idx=0).shape, xb.shape)

#|export
class TSRandomTimeStep(RandTransform):
    "Compresses a sequence on the x-axis by randomly selecting sequence steps and interpolating to previous size"
    order = 90
    def __init__(self, magnitude=0.02, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        new_seq_len = int(round(seq_len * max(.5, (1 - np.random.rand() * self.magnitude))))
        if  new_seq_len == seq_len: return o
        timesteps = np.sort(random_choice(np.arange(seq_len),new_seq_len, replace=False))
        output = F.interpolate(o[..., timesteps], size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

if test_interpolate('nearest'):
    test_eq(TSRandomTimeStep()(xb, split_idx=0).shape, xb.shape)

#|export

class TSResampleSteps(RandTransform):
    "Transform that randomly selects and sorts sequence steps (with replacement) maintaining the sequence length"

    order = 90
    def __init__(self, step_pct=1., same_seq_len=True, magnitude=None, **kwargs):
        assert step_pct > 0, 'seq_len_pct must be subsample > 0'
        self.step_pct, self.same_seq_len = step_pct, same_seq_len
        super().__init__(**kwargs)

    def encodes(self, o: TSTensor):
        S = o.shape[-1]
        if isinstance(self.step_pct, tuple):
            step_pct = np.random.rand() * (self.step_pct[1] - self.step_pct[0]) + self.step_pct[0]
        else:
            step_pct = self.step_pct
        if step_pct != 1 and self.same_seq_len:
            idxs = np.sort(np.tile(random_choice(S, round(S * step_pct), True), math.ceil(1 / step_pct))[:S])
        else:
            idxs = np.sort(random_choice(S, round(S * step_pct), True))
        return o[..., idxs]

TSSubsampleSteps = TSResampleSteps

test_eq(TSResampleSteps(step_pct=.9, same_seq_len=False)(xb, split_idx=0).shape[-1], round(.9*xb.shape[-1]))
test_eq(TSResampleSteps(step_pct=.9, same_seq_len=True)(xb, split_idx=0).shape[-1], xb.shape[-1])

#|export
class TSBlur(RandTransform):
    "Blurs a sequence applying a filter of type [1, 0, 1]"
    order = 90
    def __init__(self, magnitude=1., ex=None, filt_len=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        if filt_len is None:
            filterargs = [1, 0, 1]
        else:
            filterargs = ([1] * max(1, filt_len // 2) + [0] + [1] * max(1, filt_len // 2))
        self.filterargs = np.array(filterargs)
        self.filterargs = self.filterargs/self.filterargs.sum()
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        output = o.new(convolve1d(o.cpu(), self.filterargs, mode='nearest'))
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSBlur(filt_len=7)(xb, split_idx=0).shape, xb.shape)
test_ne(TSBlur()(xb, split_idx=0), xb)

#|export
class TSSmooth(RandTransform):
    "Smoothens a sequence applying a filter of type [1, 5, 1]"
    order = 90
    def __init__(self, magnitude=1., ex=None, filt_len=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        self.filterargs = np.array([1, 5, 1])
        if filt_len is None:
            filterargs = [1, 5, 1]
        else:
            filterargs = ([1] * max(1, filt_len // 2) + [5] + [1] * max(1, filt_len // 2))
        self.filterargs = np.array(filterargs)
        self.filterargs = self.filterargs/self.filterargs.sum()
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        output = o.new(convolve1d(o.cpu(), self.filterargs, mode='nearest'))
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSSmooth(filt_len=7)(xb, split_idx=0).shape, xb.shape)
test_ne(TSSmooth()(xb, split_idx=0), xb)

#|export
def maddest(d, axis=None):
    #Mean Absolute Deviation
    return np.mean(np.absolute(d - np.mean(d, axis=axis)), axis=axis)

class TSFreqDenoise(RandTransform):
    "Denoises a sequence applying a wavelet decomposition method"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, wavelet='db4', level=2, thr=None, thr_mode='hard', pad_mode='per', **kwargs):
        self.magnitude, self.ex = magnitude, ex
        self.wavelet, self.level, self.thr, self.thr_mode, self.pad_mode = wavelet, level, thr, thr_mode, pad_mode
        super().__init__(**kwargs)
        try:
            import pywt
        except ImportError:
            raise ImportError('You need to install pywt to run TSFreqDenoise')
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        """
        1. Adapted from waveletSmooth function found here:
        http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/
        2. Threshold equation and using hard mode in threshold as mentioned
        in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:
        http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf
        """
        seq_len = o.shape[-1]
        # Decompose to get the wavelet coefficients
        coeff = pywt.wavedec(o.cpu(), self.wavelet, mode=self.pad_mode)
        # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf
        # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation
        sigma = (1/0.6745) * maddest(coeff[-self.level])
        # Calculate the univeral threshold
        uthr = sigma * np.sqrt(2*np.log(seq_len)) * (1 if self.thr is None else self.magnitude)
        coeff[1:] = (pywt.threshold(c, value=uthr, mode=self.thr_mode) for c in coeff[1:])
        # Reconstruct the signal using the thresholded coefficients
        output = o.new(pywt.waverec(coeff, self.wavelet, mode=self.pad_mode)[..., :seq_len])
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

try: import pywt
except ImportError: pass

if 'pywt' in dir():
    test_eq(TSFreqDenoise()(xb, split_idx=0).shape, xb.shape)
    test_ne(TSFreqDenoise()(xb, split_idx=0), xb)

#|export
class TSRandomFreqNoise(RandTransform):
    "Applys random noise using a wavelet decomposition method"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, wavelet='db4', level=2, mode='constant', **kwargs):
        self.magnitude, self.ex = magnitude, ex
        self.wavelet, self.level, self.mode = wavelet, level, mode
        super().__init__(**kwargs)
        try:
            import pywt
        except ImportError:
            raise ImportError('You need to install pywt to run TSRandomFreqNoise')
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        self.level = 1 if self.level is None else self.level
        coeff = pywt.wavedec(o.cpu(), self.wavelet, mode=self.mode, level=self.level)
        coeff[1:] = [c * (1 + 2 * (np.random.rand() - 0.5) * self.magnitude) for c in coeff[1:]]
        output = o.new(pywt.waverec(coeff, self.wavelet, mode=self.mode)[..., :o.shape[-1]])
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

if 'pywt' in dir():
    test_eq(TSRandomFreqNoise()(xb, split_idx=0).shape, xb.shape)

#|export
class TSRandomResizedLookBack(RandTransform):
    "Selects a random number of sequence steps starting from the end and return an output of the same shape"
    order = 90
    def __init__(self, magnitude=0.1, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.mode = magnitude, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = min(lambd, 1 - lambd)
        output = o.clone()[..., int(round(lambd * seq_len)):]
        return F.interpolate(output, size=seq_len, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)

if test_interpolate('nearest'):
    for i in range(100):
        o = TSRandomResizedLookBack()(xb, split_idx=0)
        test_eq(o.shape[-1], xb.shape[-1])

#|export
class TSRandomLookBackOut(RandTransform):
    "Selects a random number of sequence steps starting from the end and set them to zero"
    order = 90
    def __init__(self, magnitude=0.1, **kwargs):
        self.magnitude = magnitude
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = min(lambd, 1 - lambd)
        output = o.clone()
        output[..., :int(round(lambd * seq_len))] = 0
        return output

for i in range(100):
    o = TSRandomLookBackOut()(xb, split_idx=0)
    test_eq(o.shape[-1], xb.shape[-1])

#|export
class TSVarOut(RandTransform):
    "Set the value of a random number of variables to zero"
    order = 90
    def __init__(self, magnitude=0.05, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        in_vars = o.shape[-2]
        if in_vars == 1: return o
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = min(lambd, 1 - lambd)
        p = np.arange(in_vars).cumsum()
        p = p/p[-1]
        p = p / p.sum()
        p = p[::-1]
        out_vars = random_choice(np.arange(in_vars), int(round(lambd * in_vars)), p=p, replace=False)
        if len(out_vars) == 0:  return o
        output = o.clone()
        output[...,out_vars,:] = 0
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSVarOut()(xb, split_idx=0).shape, xb.shape)

#|export
class TSCutOut(RandTransform):
    "Sets a random section of the sequence to zero"
    order = 90
    def __init__(self, magnitude=0.05, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = min(lambd, 1 - lambd)
        win_len = int(round(seq_len * lambd))
        start = np.random.randint(-win_len + 1, seq_len)
        end = start + win_len
        start = max(0, start)
        end = min(end, seq_len)
        output = o.clone()
        output[..., start:end] = 0
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSCutOut()(xb, split_idx=0).shape, xb.shape)

#|export
class TSTimeStepOut(RandTransform):
    "Sets random sequence steps to zero"
    order = 90
    def __init__(self, magnitude=0.05, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        magnitude = min(.5, self.magnitude)
        seq_len = o.shape[-1]
        timesteps = np.sort(random_choice(np.arange(seq_len), int(round(seq_len * magnitude)), replace=False))
        output = o.clone()
        output[..., timesteps] = 0
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSTimeStepOut()(xb, split_idx=0).shape, xb.shape)

#|export
class TSRandomCropPad(RandTransform):
    "Crops a section of the sequence of a random length"
    order = 90
    def __init__(self, magnitude=0.05, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = max(lambd, 1 - lambd)
        win_len = int(round(seq_len * lambd))
        if win_len == seq_len: return o
        start = np.random.randint(0, seq_len - win_len)
        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)
        output[..., start : start + win_len] = o[..., start : start + win_len]
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSRandomCropPad()(xb, split_idx=0).shape, xb.shape)

#|export
class TSMaskOut(RandTransform):
    """Applies a random mask"""
    order = 90
    def __init__(self, magnitude=0.1, compensate:bool=False, ex=None, **kwargs):
        store_attr()
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        mask = torch.rand_like(o) > (1 - self.magnitude)
        if self.compensate: # per sample and feature
            mean_per_seq = (torch.max(torch.ones(1, device=mask.device), torch.sum(mask, dim=-1).unsqueeze(-1)) / mask.shape[-1])
            output = o.masked_fill(mask, 0) / (1 - mean_per_seq)
        else:
            output = o.masked_fill(mask, 0)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSMaskOut()(xb, split_idx=0).shape, xb.shape)
test_ne(TSMaskOut()(xb, split_idx=0), xb)

#|export
class TSInputDropout(RandTransform):
    """Applies input dropout with required_grad=False"""
    order = 90
    def __init__(self, magnitude=0., ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        self.dropout = nn.Dropout(magnitude)
        super().__init__(**kwargs)

    @torch.no_grad()
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        output = self.dropout(o)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSInputDropout(.1)(xb, split_idx=0).shape, xb.shape)
test_ne(TSInputDropout(.1)(xb, split_idx=0), xb)

#|export
class TSTranslateX(RandTransform):
    "Moves a selected sequence window a random number of steps"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        seq_len = o.shape[-1]
        lambd = np.random.beta(self.magnitude, self.magnitude)
        lambd = min(lambd, 1 - lambd)
        shift = int(round(seq_len * lambd))
        if shift == 0 or shift == seq_len: return o
        if np.random.rand() < 0.5: shift = -shift
        new_start = max(0, shift)
        new_end = min(seq_len + shift, seq_len)
        start = max(0, -shift)
        end = min(seq_len - shift, seq_len)
        output = torch.zeros_like(o, dtype=o.dtype, device=o.device)
        output[..., new_start : new_end] = o[..., start : end]
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSTranslateX()(xb, split_idx=0).shape, xb.shape)

#|export
class TSRandomShift(RandTransform):
    "Shifts and splits a sequence"
    order = 90
    def __init__(self, magnitude=0.02, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        pos = int(round(np.random.randint(0, o.shape[-1]) * self.magnitude)) * (random.randint(0, 1)*2-1)
        output = torch.cat((o[..., pos:], o[..., :pos]), dim=-1)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSRandomShift()(xb, split_idx=0).shape, xb.shape)

#|export
class TSHorizontalFlip(RandTransform):
    "Flips the sequence along the x-axis"
    order = 90
    def __init__(self, magnitude=1., ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        output = torch.flip(o, [-1])
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

test_eq(TSHorizontalFlip()(xb, split_idx=0).shape, xb.shape)
test_ne(TSHorizontalFlip()(xb, split_idx=0), xb)

#|export
class TSRandomTrend(RandTransform):
    "Randomly rotates the sequence along the z-axis"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        flat_x = o.reshape(o.shape[0], -1)
        ran = flat_x.max(dim=-1, keepdim=True)[0] - flat_x.min(dim=-1, keepdim=True)[0]
        trend = torch.linspace(0, 1, o.shape[-1], device=o.device) * ran
        t = (1 + self.magnitude * 2 * (np.random.rand() - 0.5) * trend)
        t -= t.mean(-1, keepdim=True)
        if o.ndim == 3: t = t.unsqueeze(1)
        output = o + t
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

TSRandomRotate = TSRandomTrend

test_eq(TSRandomTrend()(xb, split_idx=0).shape, xb.shape)

#|export
class TSVerticalFlip(RandTransform):
    "Applies a negative value to the time sequence"
    order = 90
    def __init__(self, magnitude=1., ex=None, **kwargs):
        self.magnitude, self.ex = magnitude, ex
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        return - o

test_eq(TSVerticalFlip()(xb, split_idx=0).shape, xb.shape)
test_ne(TSVerticalFlip()(xb, split_idx=0), xb)

#|export
class TSResize(RandTransform):
    "Resizes the sequence length of a time series"
    order = 90
    def __init__(self, magnitude=-0.5, size=None, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.size, self.ex, self.mode = magnitude, size, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if self.magnitude == 0: return o
        size = ifnone(self.size, int(round((1 + self.magnitude) * o.shape[-1])))
        output = F.interpolate(o, size=size, mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        return output

if test_interpolate('nearest'):
    for sz in np.linspace(.2, 2, 10): test_eq(TSResize(sz)(xb, split_idx=0).shape[-1], int(round(xb.shape[-1]*(1+sz))))
    test_ne(TSResize(1)(xb, split_idx=0), xb)

#|export
class TSRandomSize(RandTransform):
    "Randomly resizes the sequence length of a time series"
    order = 90
    def __init__(self, magnitude=0.1, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        size_perc = 1 + random_half_normal() * self.magnitude * (-1 if random.random() > .5 else 1)
        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)

if test_interpolate('nearest'):
    seq_len_ = []
    for i in range(100):
        o = TSRandomSize(.5)(xb, split_idx=0)
        seq_len_.append(o.shape[-1])
    test_lt(min(seq_len_), xb.shape[-1])
    test_gt(max(seq_len_), xb.shape[-1])

#|export
class TSRandomLowRes(RandTransform):
    "Randomly resizes the sequence length of a time series to a lower resolution"
    order = 90
    def __init__(self, magnitude=.5, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        size_perc = 1 - (np.random.rand() * (1 - self.magnitude))
        return F.interpolate(o, size=int(size_perc * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)

#|export
class TSDownUpScale(RandTransform):
    "Downscales a time series and upscales it again to previous sequence length"
    order = 90
    def __init__(self, magnitude=0.5, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o
        output = F.interpolate(o, size=int((1 - self.magnitude) * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        output = F.interpolate(output, size=o.shape[-1], mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

if test_interpolate('nearest'):
    test_eq(TSDownUpScale()(xb, split_idx=0).shape, xb.shape)

#|export
class TSRandomDownUpScale(RandTransform):
    "Randomly downscales a time series and upscales it again to previous sequence length"
    order = 90
    def __init__(self, magnitude=.5, ex=None, mode='nearest', **kwargs):
        "mode:  'nearest' | 'linear' | 'area'"

        if not test_interpolate(mode):
            print(f"self.__name__ will not be applied because {mode} interpolation is not supported by {default_device()}. You can try a different mode")
            magnitude = 0

        self.magnitude, self.ex, self.mode = magnitude, ex, mode
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.magnitude >= 1: return o
        scale_factor = 0.5 + 0.5 * np.random.rand()
        output = F.interpolate(o, size=int(scale_factor * o.shape[-1]), mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        output = F.interpolate(output, size=o.shape[-1], mode=self.mode, align_corners=None if self.mode in ['nearest', 'area'] else False)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

if test_interpolate('nearest'):
    test_eq(TSRandomDownUpScale()(xb, split_idx=0).shape, xb.shape)
    test_ne(TSDownUpScale()(xb, split_idx=0), xb)
    test_eq(TSDownUpScale()(xb, split_idx=1), xb)

#|export
class TSRandomConv(RandTransform):
    """Applies a convolution with a random kernel and random weights with required_grad=False"""
    order = 90
    def __init__(self, magnitude=0.05, ex=None, ks=[1, 3, 5, 7], **kwargs):
        self.magnitude, self.ex, self.ks = magnitude, ex, ks
        self.conv = nn.Conv1d(1, 1, 1, bias=False)
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.ks is None: return o
        ks = random_choice(self.ks, 1)[0] if is_listy(self.ks) else self.ks
        c_in = o.shape[1]
        weight = nn.Parameter(torch.zeros(c_in, c_in, ks, device=o.device, requires_grad=False))
        nn.init.kaiming_normal_(weight)
        self.conv.weight = weight
        self.conv.padding = ks // 2
        output = (1 - self.magnitude) * o + self.magnitude * self.conv(o)
        if self.ex is not None: output[...,self.ex,:] = o[...,self.ex,:]
        return output

for i in range(5):
    o = TSRandomConv(magnitude=0.05, ex=None, ks=[1, 3, 5, 7])(xb, split_idx=0)
    test_eq(o.shape, xb.shape)

#| export
class TSRandom2Value(RandTransform):
    "Randomly sets selected variables of type `TSTensor` to predefined value (default: np.nan)"
    order = 90
    def __init__(self, magnitude=0.1, sel_vars=None, sel_steps=None, static=False, value=np.nan, **kwargs):
        assert not (sel_steps is not None and static), "you must choose either static or sel_steps"
        if is_listy(sel_vars) and is_listy(sel_steps):
            sel_vars = np.asarray(sel_vars)[:, None]
        self.sel_vars, self.sel_steps = sel_vars, sel_steps
        if sel_vars is None:
            self._sel_vars = slice(None)
        else:
            self._sel_vars = sel_vars
        if sel_steps is None or static:
            self._sel_steps = slice(None)
        else:
            self._sel_steps = sel_steps
        self.magnitude, self.static, self.value = magnitude , static, value
        super().__init__(**kwargs)

    def encodes(self, o:TSTensor):
        if not self.magnitude or self.magnitude <= 0 or self.magnitude > 1: return o
        if self.static:
            if self.sel_vars is not None:
                if self.magnitude == 1:
                    o[:, self._sel_vars] = o[:, self._sel_vars].fill_(self.value)
                    return o
                else:
                    vals = torch.zeros_like(o)
                    vals[:, self._sel_vars] = torch.rand(*vals[:, self._sel_vars, 0].shape, device=o.device).unsqueeze(-1)
            else:
                if self.magnitude == 1:
                    return o.fill_(self.value)
                else:
                    vals = torch.rand(*o.shape[:-1], device=o.device).unsqueeze(-1)
        elif self.sel_vars is not None or self.sel_steps is not None:
            if self.magnitude == 1:
                o[:, self._sel_vars, self._sel_steps] = o[:, self._sel_vars, self._sel_steps].fill_(self.value)
                return o
            else:
                vals = torch.zeros_like(o)
                vals[:, self._sel_vars, self._sel_steps] = torch.rand(*vals[:, self._sel_vars, self._sel_steps].shape, device=o.device)
        else:
            if self.magnitude == 1:
                return o.fill_(self.value)
            else:
                vals = torch.rand_like(o)
        mask = vals > (1 - self.magnitude)
        return o.masked_fill(mask, self.value)

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=0.5, sel_vars=None, sel_steps=None, static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[0., 0., 1., 0., 1., 1., 0., 1., 1., 0.],

#            [1., 1., 0., 1., 1., 1., 1., 1., 1., 0.],

#            [1., 1., 1., 1., 1., 0., 0., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 0., 1., 1., 0., 1.],

#            [0., 0., 0., 0., 0., 1., 0., 1., 0., 1.],

#            [0., 1., 0., 1., 0., 0., 0., 1., 0., 0.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=0.5, sel_vars=[1], sel_steps=slice(-5, None), static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 0., 1., 0., 0., 0.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 0., 1., 0., 0., 0.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=0.5, sel_vars=[1], sel_steps=None, static=True, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=1, sel_vars=1, sel_steps=None, static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=1, sel_vars=[1,2], sel_steps=None, static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],

#            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=1, sel_vars=1, sel_steps=[1,3,5], static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])

t = TSTensor(torch.ones(2, 3, 10))
TSRandom2Value(magnitude=1, sel_vars=[1,2], sel_steps=[1,3,5], static=False, value=0)(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.]],

#   

#           [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.],

#            [1., 0., 1., 0., 1., 0., 1., 1., 1., 1.]]])

t = TSTensor(torch.ones(2,3,4))
TSRandom2Value(magnitude=.5, sel_vars=[0,2])(t, split_idx=0).data
# Output:
#   tensor([[[1., nan, nan, 1.],

#            [1., 1., 1., 1.],

#            [1., nan, 1., 1.]],

#   

#           [[nan, 1., 1., nan],

#            [1., 1., 1., 1.],

#            [nan, nan, 1., 1.]]])

t = TSTensor(torch.ones(2,3,4))
TSRandom2Value(magnitude=.5, sel_steps=slice(2, None))(t, split_idx=0).data
# Output:
#   tensor([[[1., 1., 1., nan],

#            [1., 1., nan, 1.],

#            [1., 1., nan, nan]],

#   

#           [[1., 1., nan, 1.],

#            [1., 1., nan, nan],

#            [1., 1., nan, 1.]]])

t = TSTensor(torch.ones(2,3,100))
test_gt(np.isnan(TSRandom2Value(magnitude=.5)(t, split_idx=0)).sum().item(), 0)
t = TSTensor(torch.ones(2,3,100))
test_gt(np.isnan(TSRandom2Value(magnitude=.5, sel_vars=[0,2])(t, split_idx=0)[:, [0,2]]).sum().item(), 0)
t = TSTensor(torch.ones(2,3,100))
test_eq(np.isnan(TSRandom2Value(magnitude=.5, sel_vars=[0,2])(t, split_idx=0)[:, 1]).sum().item(), 0)

#|export
class TSMask2Value(RandTransform):
    "Randomly sets selected variables of type `TSTensor` to predefined value (default: np.nan)"
    order = 90
    def __init__(self, mask_fn, value=np.nan, sel_vars=None, **kwargs):
        self.sel_vars = sel_vars
        self.mask_fn = mask_fn
        self.value = value
        super().__init__(**kwargs)

    def encodes(self, o:TSTensor):
        mask = self.mask_fn(o)
        if self.sel_vars is not None:
            mask[:, self.sel_vars] = False
        return o.masked_fill(mask, self.value)

t = TSTensor(torch.ones(2,3,100))
def _mask_fn(o, r=.15, value=np.nan):
    return torch.rand_like(o) > (1-r)
test_gt(np.isnan(TSMask2Value(_mask_fn)(t, split_idx=0)).sum().item(), 0)

#| export
def self_mask(o):
    mask1 = torch.isnan(o)
    mask2 = rotate_axis0(mask1)
    return torch.logical_and(mask2, ~mask1)


class TSSelfDropout(RandTransform):
    """Applies dropout to a tensor with nan values by rotating axis=0 inplace"""
    order = 90
    def encodes(self, o: TSTensor):
        mask = self_mask(o)
        o[mask] = np.nan
        return o

t = TSTensor(torch.ones(2,3,100))
mask = torch.rand_like(t) > .7
t[mask] = np.nan
nan_perc = np.isnan(t).float().mean().item()
t2 = TSSelfDropout()(t, split_idx=0)
test_gt(torch.isnan(t2).float().mean().item(), nan_perc)
nan_perc, torch.isnan(t2).float().mean().item()
# Output:
#   (0.30000001192092896, 0.49000000953674316)

#|export
all_TS_randaugs = [

    TSIdentity,

    # Noise
    (TSMagAddNoise, 0.1, 1.),
    (TSGaussianNoise, .01, 1.),
    (partial(TSMagMulNoise, ex=0), 0.1, 1),
    (partial(TSTimeNoise, ex=0), 0.1, 1.),
    (partial(TSRandomFreqNoise, ex=0), 0.1, 1.),
    partial(TSShuffleSteps, ex=0),
    (TSRandomTimeScale, 0.05, 0.5),
    (TSRandomTimeStep, 0.05, 0.5),
    (partial(TSFreqDenoise, ex=0), 0.1, 1.),
    (TSRandomLowRes, 0.05, 0.5),
    (TSInputDropout, 0.05, .5),

    # Magnitude
    (partial(TSMagWarp, ex=0), 0.02, 0.2),
    (TSMagScale, 0.2, 1.),
    (partial(TSMagScalePerVar, ex=0), 0.2, 1.),
    (partial(TSRandomConv, ex=0), .05, .2),
    partial(TSBlur, ex=0),
    partial(TSSmooth, ex=0),
    partial(TSDownUpScale, ex=0),
    partial(TSRandomDownUpScale, ex=0),
    (TSRandomTrend, 0.1, 0.5),
    TSVerticalFlip,
    (TSVarOut, 0.05, 0.5),
    (TSCutOut, 0.05, 0.5),

    # Time
    (partial(TSTimeWarp, ex=0), 0.02, 0.2),
    (TSWindowWarp, 0.05, 0.5),
    (TSRandomSize, 0.05, 1.),
    TSHorizontalFlip,
    (TSTranslateX, 0.1, 0.5),
    (TSRandomShift, 0.02, 0.2),
    (TSRandomZoomIn, 0.05, 0.5),
    (TSWindowSlicing, 0.05, 0.2),
    (TSRandomZoomOut, 0.05, 0.5),
    (TSRandomLookBackOut, 0.1, 1.),
    (TSRandomResizedLookBack, 0.1, 1.),
    (TSTimeStepOut, 0.01, 0.2),
    (TSRandomCropPad, 0.05, 0.5),
    (TSRandomResizedCrop, 0.05, 0.5),
    (TSMaskOut, 0.01, 0.2),
]

#|export
class RandAugment(RandTransform):
    order = 90
    def __init__(self, tfms:list, N:int=1, M:int=3, **kwargs):
        '''
        tfms   : list of tfm functions (not called)
        N      : number of tfms applied to each batch (usual values 1-3)
        M      : tfm magnitude multiplier (1-10, usually 3-5). Only works if tfms are tuples (tfm, min, max)
        kwargs : RandTransform kwargs
        '''
        super().__init__(**kwargs)
        if not isinstance(tfms, list): tfms = [tfms]
        self.tfms, self.N, self.magnitude = tfms, min(len(tfms), N), M / 10
        self.n_tfms, self.tfms_idxs = len(tfms), np.arange(len(tfms))

    def encodes(self, o:(NumpyTensor, TSTensor)):
        if not self.N or not self.magnitude: return o
        tfms = self.tfms if self.n_tfms==1 else L(self.tfms)[random_choice(np.arange(self.n_tfms), self.N, replace=False)]
        tfms_ = []
        for tfm in tfms:
            if isinstance(tfm, tuple):
                t, min_val, max_val = tfm
                tfms_ += [t(magnitude=self.magnitude * float(max_val - min_val) + min_val)]
            else:  tfms_ += [tfm()]
        output = compose_tfms(o, tfms_, split_idx=self.split_idx)
        return output

test_ne(RandAugment(TSMagAddNoise, N=5, M=10)(xb, split_idx=0), xb)

#|export
class TestTfm(RandTransform):
    "Utility class to test the output of selected tfms during training"
    def __init__(self, tfm, magnitude=1., ex=None, **kwargs):
        self.tfm, self.magnitude, self.ex = tfm, magnitude, ex
        self.tfmd, self.shape = [], []
        super().__init__(**kwargs)
    def encodes(self, o: TSTensor):
        if not self.magnitude or self.magnitude <= 0: return o
        output = self.tfm(o, split_idx=self.split_idx)
        self.tfmd.append(torch.equal(o, output))
        self.shape.append(o.shape)
        return output

#|export
def get_tfm_name(tfm):
    if isinstance(tfm, tuple): tfm = tfm[0]
    if hasattr(tfm, "func"): tfm = tfm.func
    if hasattr(tfm, "__name__"): return tfm.__name__
    elif hasattr(tfm, "__class__") and hasattr(tfm.__class__, "__name__"): return tfm.__class__.__name__
    else: return tfm

test_eq(get_tfm_name(partial(TSMagScale()))==get_tfm_name((partial(TSMagScale()), 0.1, .05))==get_tfm_name(TSMagScale())==get_tfm_name((TSMagScale(), 0.1, .05)), True)

all_TS_randaugs_names = [get_tfm_name(t) for t in all_TS_randaugs]

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/010_data.transforms.ipynb saved at 2024-02-10 21:46:00

#   Correct notebook to script conversion! 😃

#   Saturday 10/02/24 21:46:03 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/015_data.mixed.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp data.mixed

"""
# Mixed data
"""

"""
>DataLoader than can take data from multiple dataloaders with different types of data
"""

#|export
from packaging import version
from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter, _SingleProcessDataLoaderIter, _DatasetKind
from fastai.data.load import _FakeLoader
from fastai.tabular.core import *
from tsai.imports import *

#|export
# This implementation of a mixed dataloader is based on a great implementation created by Zach Mueller in this fastai thread:
# https://forums.fast.ai/t/combining-tabular-images-in-fastai2-and-should-work-with-almost-any-other-type/73197

_loaders = (_MultiProcessingDataLoaderIter, _SingleProcessDataLoaderIter)


class MixedDataLoader():
    def __init__(self, *loaders, path='.', shuffle=False, device=None, bs=None):
        "Accepts any number of `DataLoader` and a device"
        self.path = path
        device = ifnone(device, default_device())
        self.device = device
        self.c = None
        self.d = None
        self.bs = ifnone(bs, min([dl.bs for dl in loaders]))
        for i, dl in enumerate(loaders):  # ensure all dls have the same bs
            if hasattr(dl, 'vars'):
                self.vars = dl.vars
            if hasattr(dl, 'len'):
                self.len = dl.len
            if hasattr(dl, 'split_idxs'):
                self.split_idxs = dl.split_idxs
            dl.bs = self.bs
            if i > 0 and hasattr(dl, 'get_idxs'):
                dl.get_idxs = self.get_idxs_copy
            dl.shuffle_fn = self.shuffle_fn
            if self.c is None and hasattr(dl, "c"):
                self.c = dl.c
            if self.d is None and hasattr(dl, "d"):
                self.d = dl.d
            if i == 0:
                self.dataset = dl.dataset
            dl.to(device=device)
        self.shuffle = shuffle
        if not self.shuffle:
            self.rng = np.arange(len(self.dataset)).tolist()
        self.loaders = loaders
        self.count = 0
        self.fake_l = _FakeLoader(self, False, 0, 0, 0, "") if version.parse(fastai.__version__) >= version.parse("2.7") \
            else _FakeLoader(self, False, 0, 0, 0) if version.parse(fastai.__version__) >= version.parse("2.1") \
            else _FakeLoader(self, False, 0, 0)
        if sum([len(dl.dataset) for dl in loaders]) > 0:
            self._get_idxs()  # Do not apply on an empty dataset

    def new(self, *args, **kwargs):
        loaders = [dl.new(*args, **kwargs) for dl in self.loaders]
        return type(self)(*loaders, path=self.path, device=self.device)

#     def __len__(self): return len(self.loaders[0])
    def __len__(self): return self.loaders[0].__len__()

    def _get_vals(self, x):
        "Checks for duplicates in batches"
        idxs, new_x = [], []
        for i, o in enumerate(x):
            x[i] = o.cpu().numpy().flatten()
        for idx, o in enumerate(x):
            if not self._arrayisin(o, new_x):
                idxs.append(idx)
                new_x.append(o)
        return idxs

    def _get_idxs(self):
        "Get `x` and `y` indices for batches of data"
        self.n_inps = [dl.n_inp for dl in self.loaders]
        self.x_idxs = self._split_idxs(self.n_inps)

        # Identify duplicate targets
        dl_dict = dict(zip(range(0, len(self.loaders)), self.n_inps))
        outs = L([])
        for key, n_inp in dl_dict.items():
            b = next(iter(self.loaders[key]))
            outs += L(b[n_inp:])
        self.y_idxs = self._get_vals(outs)

    def get_idxs_copy(self):
        return self.loaders[0].get_idxs()

    def __iter__(self):
        z = zip(*[_loaders[i.fake_l.num_workers == 0](i.fake_l)
                for i in self.loaders])
        for b in z:
            inps = []
            outs = []
            if self.device is not None:
                b = to_device(b, self.device)
            for batch, dl in zip(b, self.loaders):
                if hasattr(dl, 'idxs'):
                    self.idxs = dl.idxs
                if hasattr(dl, 'input_idxs'):
                    self.input_idxs = dl.input_idxs
                batch = dl.after_batch(batch)
                inps += batch[:dl.n_inp]
                outs += batch[dl.n_inp:]
            inps = tuple([tuple(L(inps)[idx]) if isinstance(idx, list) else inps[idx]
                          for idx in self.x_idxs]) if len(self.x_idxs) > 1 else tuple(L(outs)[self.x_idxs][0])
            # based on issue identified by @Wabinab https://github.com/timeseriesAI/tsai/pull/229
            if len(self.y_idxs) == 0:
                yield tuple((inps,))
            outs = tuple(L(outs)[self.y_idxs]) if len(
                self.y_idxs) > 1 else L(outs)[self.y_idxs][0]
            yield inps, outs

    def one_batch(self):
        "Grab one batch of data"
        with self.fake_l.no_multiproc():
            res = first(self)
        if hasattr(self, 'it'):
            delattr(self, 'it')
        return res

    def shuffle_fn(self, idxs):
        "Generate the same idxs for all dls in each batch when shuffled"
        if self.count == 0:
            self.shuffled_idxs = np.random.permutation(idxs)
        # sort each batch
        for i in range(len(self.shuffled_idxs)//self.bs + 1):
            self.shuffled_idxs[i*self.bs:(i+1)*self.bs] = np.sort(
                self.shuffled_idxs[i*self.bs:(i+1)*self.bs])
        self.count += 1
        if self.count == len(self.loaders):
            self.count = 0
        return self.shuffled_idxs

    def show_batch(self):
        "Show a batch of data"
        for dl in self.loaders:
            dl.show_batch()

    def to(self, device): self.device = device

    def _arrayisin(self, arr, arr_list):
        "Checks if `arr` is in `arr_list`"
        for a in arr_list:
            if np.array_equal(arr, a):
                return True
        return False

    def _split_idxs(self, a):
        a_cum = np.array(a).cumsum().tolist()
        b = np.arange(sum(a)).tolist()
        start = 0
        b_ = []
        for i, idx in enumerate(range(len(a))):
            end = a_cum[i]
            b_.append(b[start:end] if end - start > 1 else b[start])
            start = end
        return b_


class MixedDataLoaders(DataLoaders):
    pass

#|export

def get_mixed_dls(*dls, device=None, shuffle_train=None, shuffle_valid=None, **kwargs):
    _mixed_train_dls = []
    _mixed_valid_dls = []
    for dl in dls:
        _mixed_train_dls.append(dl.train)
        _mixed_valid_dls.append(dl.valid)
        if shuffle_train is None: shuffle_train = dl.train.shuffle
        if shuffle_valid is None: shuffle_valid = dl.valid.shuffle
        if device is None: device = dl.train.device
    mixed_train_dl = MixedDataLoader(*_mixed_train_dls, shuffle=shuffle_train, **kwargs)
    mixed_valid_dl = MixedDataLoader(*_mixed_valid_dls, shuffle=shuffle_valid, **kwargs)
    mixed_dls = MixedDataLoaders(mixed_train_dl, mixed_valid_dl, device=device)
    return mixed_dls

from tsai.data.tabular import *

path = untar_data(URLs.ADULT_SAMPLE)
df = pd.read_csv(path/'adult.csv')
# df['salary'] = np.random.rand(len(df)) # uncomment to simulate a cont dependent variable
target = 'salary'
splits = RandomSplitter()(range_of(df))

cat_names = ['workclass', 'education', 'marital-status']
cont_names = ['age', 'fnlwgt']
dls1 = get_tabular_dls(df, cat_names=cat_names, cont_names=cont_names, y_names=target, splits=splits, bs=512)
dls1.show_batch()

cat_names = None #['occupation', 'relationship', 'race']
cont_names = ['education-num']
dls2 = get_tabular_dls(df, cat_names=cat_names, cont_names=cont_names, y_names=target, splits=splits, bs=128)
dls2.show_batch()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>

dls = get_mixed_dls(dls1, dls2, bs=8)
first(dls.train)
first(dls.valid)
torch.save(dls,'export/mixed_dls.pth')
del dls
dls = torch.load('export/mixed_dls.pth')
dls.train.show_batch()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>

from tsai.data.validation import TimeSplitter
from tsai.data.core import TSRegression, get_ts_dls

X = np.repeat(np.repeat(np.arange(16)[:, None, None], 2, 1), 5, 2).astype(float)
y = np.concatenate([np.arange(len(X)//2)]*2)
alphabet = np.array(list(string.ascii_lowercase))
# y = alphabet[y]
splits = TimeSplitter(.5, show_plot=False)(range_of(X))
tfms = [None, TSRegression()]
dls1 = get_ts_dls(X, y, splits=splits, tfms=tfms, bs=4)
for xb, yb in iter(dls1.train):
    print(xb.data, yb)
# Output:
#   tensor([[[5., 5., 5., 5., 5.],

#            [5., 5., 5., 5., 5.]],

#   

#           [[0., 0., 0., 0., 0.],

#            [0., 0., 0., 0., 0.]],

#   

#           [[4., 4., 4., 4., 4.],

#            [4., 4., 4., 4., 4.]],

#   

#           [[3., 3., 3., 3., 3.],

#            [3., 3., 3., 3., 3.]]], device='mps:0') tensor([5., 0., 4., 3.], device='mps:0')

#   tensor([[[6., 6., 6., 6., 6.],

#            [6., 6., 6., 6., 6.]],

#   

#           [[1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1.]],

#   

#           [[2., 2., 2., 2., 2.],

#            [2., 2., 2., 2., 2.]],

#   

#           [[7., 7., 7., 7., 7.],

#            [7., 7., 7., 7., 7.]]], device='mps:0') tensor([6., 1., 2., 7.], device='mps:0')


data = np.repeat(np.arange(16)[:, None], 3, 1)*np.array([1, 10, 100])
df = pd.DataFrame(data, columns=['cat1', 'cat2', 'cont'])
df['cont'] = df['cont'].astype(float)
df['target'] = y
display(df)
cat_names = ['cat1', 'cat2']
cont_names = ['cont']
target = 'target'
dls2 = get_tabular_dls(df, procs=[Categorify, FillMissing, #Normalize
                                 ], cat_names=cat_names, cont_names=cont_names, y_names=target, splits=splits, bs=4)
for b in iter(dls2.train):
    print(b[0], b[1], b[2])
# Output:
#       cat1  cat2    cont  target

#   0      0     0     0.0       0

#   1      1    10   100.0       1

#   2      2    20   200.0       2

#   3      3    30   300.0       3

#   4      4    40   400.0       4

#   5      5    50   500.0       5

#   6      6    60   600.0       6

#   7      7    70   700.0       7

#   8      8    80   800.0       0

#   9      9    90   900.0       1

#   10    10   100  1000.0       2

#   11    11   110  1100.0       3

#   12    12   120  1200.0       4

#   13    13   130  1300.0       5

#   14    14   140  1400.0       6

#   15    15   150  1500.0       7
#   tensor([[5, 5],

#           [5, 5],

#           [6, 6],

#           [4, 4]], device='mps:0') tensor([[400.],

#           [400.],

#           [500.],

#           [300.]], device='mps:0') tensor([[4],

#           [4],

#           [5],

#           [3]], device='mps:0', dtype=torch.int8)

#   tensor([[4, 4],

#           [7, 7],

#           [2, 2],

#           [1, 1]], device='mps:0') tensor([[300.],

#           [600.],

#           [100.],

#           [  0.]], device='mps:0') tensor([[3],

#           [6],

#           [1],

#           [0]], device='mps:0', dtype=torch.int8)


bs = 8
dls = get_mixed_dls(dls1, dls2, bs=bs)
dl = dls.train
xb, yb = dl.one_batch()
test_eq(len(xb), 2)
test_eq(len(xb[0]), bs)
test_eq(len(xb[1]), 2)
test_eq(len(xb[1][0]), bs)
test_eq(len(xb[1][1]), bs)
test_eq(xb[0].data[:, 0, 0].long(), xb[1][0][:, 0] - 1) # categorical data and ts are in synch
test_eq(xb[0].data[:, 0, 0], (xb[1][1]/100).flatten()) # continuous data and ts are in synch
test_eq(tensor(dl.input_idxs), yb.long().cpu())
dl = dls.valid
xb, yb = dl.one_batch()
test_eq(tensor(y[dl.input_idxs]), yb.long().cpu())

bs = 4
dls = get_mixed_dls(dls1, dls2, bs=bs)
for xb, yb in iter(dls.train):
    print(xb[0].data, xb[1], yb)
# Output:
#   tensor([[[0., 0., 0., 0., 0.],

#            [0., 0., 0., 0., 0.]],

#   

#           [[1., 1., 1., 1., 1.],

#            [1., 1., 1., 1., 1.]],

#   

#           [[2., 2., 2., 2., 2.],

#            [2., 2., 2., 2., 2.]],

#   

#           [[4., 4., 4., 4., 4.],

#            [4., 4., 4., 4., 4.]]], device='mps:0') (tensor([[1, 1],

#           [2, 2],

#           [3, 3],

#           [5, 5]], device='mps:0'), tensor([[  0.],

#           [100.],

#           [200.],

#           [400.]], device='mps:0')) tensor([0., 1., 2., 4.], device='mps:0')

#   tensor([[[3., 3., 3., 3., 3.],

#            [3., 3., 3., 3., 3.]],

#   

#           [[5., 5., 5., 5., 5.],

#            [5., 5., 5., 5., 5.]],

#   

#           [[6., 6., 6., 6., 6.],

#            [6., 6., 6., 6., 6.]],

#   

#           [[7., 7., 7., 7., 7.],

#            [7., 7., 7., 7., 7.]]], device='mps:0') (tensor([[4, 4],

#           [6, 6],

#           [7, 7],

#           [8, 8]], device='mps:0'), tensor([[300.],

#           [500.],

#           [600.],

#           [700.]], device='mps:0')) tensor([3., 5., 6., 7.], device='mps:0')


#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/015_data.mixed.ipynb saved at 2025-01-20 09:51:26

#   Correct notebook to script conversion! 😃

#   Monday 20/01/25 09:51:29 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/016_losses.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp losses

"""
# Losses
"""

"""
>Losses not available in fastai or Pytorch.
"""

#|export
from tsai.imports import *
from fastai.losses import *

#|export
## Available in Pytorch 1.9
class HuberLoss(nn.Module):
    """Huber loss 
    
    Creates a criterion that uses a squared term if the absolute
    element-wise error falls below delta and a delta-scaled L1 term otherwise.
    This loss combines advantages of both :class:`L1Loss` and :class:`MSELoss`; the
    delta-scaled L1 region makes the loss less sensitive to outliers than :class:`MSELoss`,
    while the L2 region provides smoothness over :class:`L1Loss` near 0. See
    `Huber loss <https://en.wikipedia.org/wiki/Huber_loss>`_ for more information.
    This loss is equivalent to nn.SmoothL1Loss when delta == 1.
    """
    def __init__(self, reduction='mean', delta=1.0):
        assert reduction in ['mean', 'sum', 'none'], "You must set reduction to 'mean', 'sum' or 'none'"
        self.reduction, self.delta = reduction, delta
        super().__init__()

    def forward(self, input: Tensor, target: Tensor) -> Tensor:
        diff = input - target
        abs_diff = torch.abs(diff)
        mask = abs_diff < self.delta
        loss = torch.cat([(.5*diff[mask]**2), self.delta * (abs_diff[~mask] - (.5 * self.delta))])
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else: 
            return loss

#|export
class LogCoshLoss(nn.Module):
    def __init__(self, reduction='mean', delta=1.0):
        assert reduction in ['mean', 'sum', 'none'], "You must set reduction to 'mean', 'sum' or 'none'"
        self.reduction, self.delta = reduction, delta
        super().__init__()
        
    def forward(self, input: Tensor, target: Tensor) -> Tensor:
        loss = torch.log(torch.cosh(input - target + 1e-12))
        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else: 
            return loss

inp = torch.rand(8, 3, 10)
targ = torch.randn(8, 3, 10)
test_close(HuberLoss(delta=1)(inp, targ), nn.SmoothL1Loss()(inp, targ))
LogCoshLoss()(inp, targ)
# Output:
#   tensor(0.4588)

#|export
class MaskedLossWrapper(Module):
    def __init__(self, crit):
        self.loss = crit

    def forward(self, inp, targ):
        inp = inp.flatten(1)
        targ = targ.flatten(1)
        mask = torch.isnan(targ)
        inp, targ = inp[~mask], targ[~mask]
        return self.loss(inp, targ)

inp = torch.rand(8, 3, 10)
targ = torch.randn(8, 3, 10)
targ[targ >.8] = np.nan
nn.L1Loss()(inp, targ), MaskedLossWrapper(nn.L1Loss())(inp, targ)
# Output:
#   (tensor(nan), tensor(1.0520))

#|export
class CenterLoss(Module):
    r"""
    Code in Pytorch has been slightly modified from: https://github.com/KaiyangZhou/pytorch-center-loss/blob/master/center_loss.py
    Based on paper: Wen et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.

    Args:
        c_out (int): number of classes.
        logits_dim (int): dim 1 of the logits. By default same as c_out (for one hot encoded logits)
        
    """
    def __init__(self, c_out, logits_dim=None):
        logits_dim = ifnone(logits_dim, c_out)
        self.c_out, self.logits_dim = c_out, logits_dim
        self.centers = nn.Parameter(torch.randn(c_out, logits_dim))
        self.classes = nn.Parameter(torch.arange(c_out).long(), requires_grad=False)

    def forward(self, x, labels):
        """
        Args:
            x: feature matrix with shape (batch_size, logits_dim).
            labels: ground truth labels with shape (batch_size).
        """
        bs = x.shape[0]
        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(bs, self.c_out) + \
                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.c_out, bs).T
        distmat = torch.addmm(distmat, x, self.centers.T, beta=1, alpha=-2)

        labels = labels.unsqueeze(1).expand(bs, self.c_out)
        mask = labels.eq(self.classes.expand(bs, self.c_out))

        dist = distmat * mask.float()
        loss = dist.clamp(min=1e-12, max=1e+12).sum() / bs

        return loss


class CenterPlusLoss(Module):
    
    def __init__(self, loss, c_out, λ=1e-2, logits_dim=None):
        self.loss, self.c_out, self.λ = loss, c_out, λ
        self.centerloss = CenterLoss(c_out, logits_dim)
        
    def forward(self, x, labels):
        return self.loss(x, labels) + self.λ * self.centerloss(x, labels)
    def __repr__(self): return f"CenterPlusLoss(loss={self.loss}, c_out={self.c_out}, λ={self.λ})"

c_in = 10
x = torch.rand(64, c_in).to(device=default_device())
x = F.softmax(x, dim=1)
label = x.max(dim=1).indices
CenterLoss(c_in).to(x.device)(x, label), CenterPlusLoss(LabelSmoothingCrossEntropyFlat(), c_in).to(x.device)(x, label)
# Output:
#   (tensor(9.2481, grad_fn=<DivBackward0>),

#    TensorBase(2.3559, grad_fn=<AliasBackward0>))

CenterPlusLoss(LabelSmoothingCrossEntropyFlat(), c_in)
# Output:
#   CenterPlusLoss(loss=FlattenedLoss of LabelSmoothingCrossEntropy(), c_out=10, λ=0.01)

#|export
class FocalLoss(Module):
    """ Weighted, multiclass focal loss"""

    def __init__(self, alpha:Optional[Tensor]=None, gamma:float=2., reduction:str='mean'):
        """
        Args:
            alpha (Tensor, optional): Weights for each class. Defaults to None.
            gamma (float, optional): A constant, as described in the paper. Defaults to 2.
            reduction (str, optional): 'mean', 'sum' or 'none'. Defaults to 'mean'.
        """
        self.alpha, self.gamma, self.reduction = alpha, gamma, reduction
        self.nll_loss = nn.NLLLoss(weight=alpha, reduction='none')

    def forward(self, x: Tensor, y: Tensor) -> Tensor:

        log_p = F.log_softmax(x, dim=-1)
        pt = log_p[torch.arange(len(x)), y].exp()
        ce = self.nll_loss(log_p, y)
        loss = (1 - pt) ** self.gamma * ce

        if self.reduction == 'mean':
            loss = loss.mean()
        elif self.reduction == 'sum':
            loss = loss.sum()
        return loss

inputs = torch.normal(0, 2, (16, 2)).to(device=default_device())
targets = torch.randint(0, 2, (16,)).to(device=default_device())
FocalLoss()(inputs, targets)
# Output:
#   tensor(0.9829)

#|export
class TweedieLoss(Module):
    def __init__(self, p=1.5, eps=1e-8):
        """
        Tweedie loss as calculated in LightGBM
        Args:
            p: tweedie variance power (1 < p < 2)
            eps: small number to avoid log(zero).
        """
        assert 1 < p < 2, "make sure 1 < p < 2" 
        self.p, self.eps = p, eps

    def forward(self, inp, targ):
        "Poisson and compound Poisson distribution, targ >= 0, inp > 0"
        inp = inp.flatten()
        targ = targ.flatten()
        torch.clamp_min_(inp, self.eps)
        a = targ * torch.exp((1 - self.p) * torch.log(inp)) / (1 - self.p)
        b = torch.exp((2 - self.p) * torch.log(inp)) / (2 - self.p)
        loss = -a + b
        return loss.mean()

c_in = 10
output = torch.rand(64).to(device=default_device())
target = torch.rand(64).to(device=default_device())
TweedieLoss().to(output.device)(output, target)
# Output:
#   tensor(3.0539)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/050_losses.ipynb saved at 2022-11-09 12:52:08

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 12:52:11 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/020_analysis.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp analysis

"""
# Analysis
"""

"""
>fastai Learner extensions useful to perform prediction analysis.
"""

#|export
import inspect

import sklearn.metrics as skm
from fastai.interpret import *
from fastai.learner import *
from sklearn.model_selection import train_test_split

from tsai.data.core import *
from tsai.data.preprocessing import *
from tsai.imports import *
from tsai.inference import *
from tsai.utils import *

#|export
@patch
@delegates(subplots)
def show_probas(self:Learner, figsize=(6,6), ds_idx=1, dl=None, one_batch=False, max_n=None, **kwargs):
    recorder = copy(self.recorder) # This is to avoid loss of recorded values while generating preds
    if dl is None: dl = self.dls[ds_idx]
    if one_batch: dl = [dl.one_batch()]
    probas, targets = self.get_preds(dl=dl)
    if probas.ndim == 2 and probas.min() < 0 or probas.max() > 1: probas = nn.Softmax(-1)(probas)
    if not isinstance(targets[0].item(), Integral): return
    targets = targets.flatten()
    if max_n is not None:
        idxs = random_choice(len(probas), max_n, False)
        probas, targets = probas[idxs], targets[idxs]
    if isinstance(probas, torch.Tensor): probas = probas.detach().cpu().numpy()
    if isinstance(targets, torch.Tensor): targets = targets.detach().cpu().numpy()
    fig = plt.figure(figsize=figsize, **kwargs)
    classes = np.unique(targets)
    nclasses = len(classes)
    vals = np.linspace(.5, .5 + nclasses - 1, nclasses)[::-1]
    plt.vlines(.5, min(vals) - 1, max(vals), color='black', linewidth=.5)
    cm = plt.get_cmap('gist_rainbow')
    color = [cm(1.* c/nclasses) for c in range(1, nclasses + 1)][::-1]
    # class_probas = np.array([probas[i,t] for i,t in enumerate(targets)])
    class_probas = np.array([probas[i][t] for i,t in enumerate(targets)])
    for i, c in enumerate(classes):
        plt.scatter(class_probas[targets == c] if nclasses > 2 or i > 0 else 1 - class_probas[targets == c],
                    targets[targets == c] + .5 * (np.random.rand((targets == c).sum()) - .5), color=color[i], edgecolor='black', alpha=.2, s=100)
        if nclasses > 2: plt.vlines((targets == c).mean(), i - .5, i + .5, color='r', linewidth=.5)
    plt.hlines(vals, 0, 1)
    plt.ylim(min(vals) - 1, max(vals))
    plt.xlim(0,1)
    plt.xticks(np.linspace(0,1,11), fontsize=12)
    plt.yticks(classes, [self.dls.vocab[x] for x in classes], fontsize=12)
    plt.title('Predicted proba per true class' if nclasses > 2 else 'Predicted class 1 proba per true class', fontsize=14)
    plt.xlabel('Probability', fontsize=12)
    plt.ylabel('True class', fontsize=12)
    plt.grid(axis='x', color='gainsboro', linewidth=.2)
    plt.show()
    self.recorder = recorder

#|export
@patch
def plot_confusion_matrix(self:Learner, ds_idx=1, dl=None, thr=.5, normalize=False, title='Confusion matrix', cmap="Blues", norm_dec=2, figsize=(5,5),
                          title_fontsize=12, fontsize=10, plot_txt=True, **kwargs):
        "Plot the confusion matrix, with `title` and using `cmap`."
        # This function is mainly copied from the sklearn docs
        if dl is None: dl = self.dls[ds_idx]
        assert dl.cat
        if dl.c == 2: # binary classification
            probas, preds = self.get_preds(dl=dl)
            y_pred = (probas[:, 1] > thr).numpy().astype(int)
            y_test = preds.numpy()
            if normalize: skm_normalize = 'true'
            else: skm_normalize = None
            cm = skm.confusion_matrix(y_test, y_pred, normalize=skm_normalize)
        else: 
            cm = ClassificationInterpretation.from_learner(self).confusion_matrix()

        if normalize: cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        fig = plt.figure(figsize=figsize, **kwargs)
        plt.imshow(cm, interpolation='nearest', cmap=cmap)
        if self.dls.c == 2:
            plt.title(f"{title} (threshold: {thr})", fontsize=title_fontsize)
        else: 
            plt.title(title, fontsize=title_fontsize)
        tick_marks = np.arange(len(self.dls.vocab))
        plt.xticks(tick_marks, self.dls.vocab, rotation=90, fontsize=fontsize)
        plt.yticks(tick_marks, self.dls.vocab, rotation=0, fontsize=fontsize)

        if plot_txt:
            thresh = cm.max() / 2.
            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
                coeff = f'{cm[i, j]:.{norm_dec}f}' if normalize else f'{cm[i, j]}'
                plt.text(j, i, coeff, horizontalalignment="center", verticalalignment="center", color="white" if cm[i, j] > thresh else "black", fontsize=fontsize)

        ax = fig.gca()
        ax.set_ylim(len(self.dls.vocab)-.5,-.5)

        plt.tight_layout()
        plt.ylabel('Actual', fontsize=fontsize)
        plt.xlabel('Predicted', fontsize=fontsize)
        plt.grid(False)

#|export
@patch
def top_losses(self:Learner,
    X, # array-like object representing the independent variables
    y, # array-like object representing the target
    k:int=9, # Optional. #items to plot
    largest=True, # Flag to show largest or smallest losses
    bs:int=64, # batch size
    ):
    *_, losses = self.get_X_preds(X, y, bs=bs, with_loss=True)
    top_losses, idxs = losses.topk(ifnone(k, len(losses)), largest=largest)
    idxs = idxs.tolist()
    return top_losses, idxs

@patch
def plot_top_losses(self:Learner,
    X, # array-like object representing the independent variables
    y, # array-like object representing the target
    k:int=9, # Optional. #items to plot
    largest=True, # Flag to show largest or smallest losses
    bs:int=64, # batch size
    **kwargs, # show_batch kwargs
    ):
    *_, losses = self.get_X_preds(X, y, bs=bs, with_loss=True)
    idxs = losses.topk(ifnone(k, len(losses)), largest=largest)[1].tolist()
    dl = self.dls.valid.new_dl(X[idxs], y=y[idxs], bs=k)
    b = dl.one_batch()
    dl.show_batch(b, max_n=k, **kwargs)

"""
## Permutation importance
"""

"""
We've also introduced 2 methods to help you better understand how important certain features or certain steps are for your model. Both methods use permutation importance. 

⚠️**The permutation feature or step importance is defined as the decrease in a model score when a single feature or step value is randomly shuffled.**

So if you using accuracy (higher is better), the most important features or steps will be those with a *lower* value on the chart (as randomly shuffling them reduces performance). 

The opposite occurs for metrics like mean squared error (lower is better). In this case, the most important features or steps will be those with a *higher* value on the chart. 

There are 2 issues with step importance: 

* there may be many steps and the analysis could take very long
* steps will likely have a high autocorrelation

For those reasons, we've introduced an argument (n_steps) to group steps. In this way you'll be able to know which part of the time series is the most important. 

Feature importance has been adapted from https://www.kaggle.com/cdeotte/lstm-feature-importance by Chris Deotte (Kaggle GrandMaster).
"""

#|export
@patch
def feature_importance(self:Learner, 
    X=None, # array-like object containing the time series. If None, all data in the validation set will be used.
    y=None, # array-like object containing the targets. If None, all targets in the validation set will be used.
    bs:int=None, # batch size. If None, the default batch size of the dataloader will be used.
    partial_n:(int, float)=None, # # (int) or % (float) of used to measure feature importance. If None, all data will be used.
    method:str='permutation', # Method used to invalidate feature. Use 'permutation' for shuffling or 'ablation' for setting values to np.nan.
    feature_names:list=None, # Optional list of feature names that will be displayed if available. Otherwise var_0, var_1, etc.
    sel_classes:(str, list)=None, # classes for which the analysis will be made
    key_metric_idx:int=0, # Optional position of the metric used. If None or no metric is available, the loss will be used.
    show_chart:bool=True, # Flag to indicate if a chart showing permutation feature importance will be plotted.
    figsize:tuple=None, # Size of the chart.
    title:str=None, # Optional string that will be used as the chart title. If None 'Permutation Feature Importance'.
    return_df:bool=True, # Flag to indicate if the dataframe with feature importance will be returned.
    save_df_path:Path=None, # Path where dataframe containing the permutation feature importance results will be saved.
    random_state:int=23, # Optional int that controls the shuffling applied to the data.
    verbose:bool=True, # Flag that controls verbosity.
    ):
    r"""Calculates feature importance as the drop in the model's validation loss or metric when a feature value is randomly shuffled"""
    
    assert method in ['permutation', 'ablation']

    # X, y
    if X is None:
        X = self.dls.train.dataset.tls[0].items
        if hasattr(self.dls.train.dataset.tls[0], '_splits'): X = X[self.dls.train.dataset.tls[0]._splits]
    if y is None:
        y = self.dls.train.dataset.tls[1].items
    if partial_n is not None:
        _, rand_idxs, *_ = train_test_split(np.arange(len(y)), y, test_size=partial_n, random_state=random_state, stratify=y)
        X = X.oindex[rand_idxs] if hasattr(X, 'oindex') else X[rand_idxs]
        y = y.oindex[rand_idxs] if hasattr(y, 'oindex') else y[rand_idxs]
    else: 
        X, y = X[:], y[:]
    if sel_classes is not None:
        filt = np.isin(y, listify(sel_classes))
        X, y = X[filt], y[filt]
    pv(f'X.shape: {X.shape}', verbose)
    pv(f'y.shape: {y.shape}', verbose)
    if bs is None:
        bs = self.dls.valid.bs

    # Metrics
    metrics = [mn for mn in self.recorder.metric_names if mn not in ['epoch', 'train_loss', 'valid_loss', 'time']]
    if len(metrics) == 0 or key_metric_idx is None:
        metric_name = self.loss_func.__class__.__name__
        key_metric_idx = None
    else:
        metric_name = metrics[key_metric_idx]
        metric = self.recorder.metrics[key_metric_idx].func
        if "sklearn" in inspect.getmodule(metric).__name__:
            sklearn_metric = True
        else:
            sklearn_metric = False
    metric_name = metric_name.replace("train_", "").replace("valid_", "")
    pv(f'Selected metric: {metric_name}', verbose)

    # Selected vars & feature names
    sel_vars = not(isinstance(self.dls.sel_vars, slice) and self.dls.sel_vars == slice(None, None, None))
    if feature_names is None:
        feature_names = L([f"var_{i}" for i in range(X.shape[1])])
        if sel_vars:
            feature_names = feature_names[self.dls.sel_vars]
    else:
        feature_names = listify(feature_names)

    if sel_vars:
        assert len(feature_names) == len(self.dls.sel_vars)
    else:
        assert len(feature_names) == X.shape[1]
    sel_var_idxs = L(np.arange(X.shape[1]).tolist())
    if sel_vars:
        sel_var_idxs = sel_var_idxs[self.dls.sel_vars]
    assert len(feature_names) == len(sel_var_idxs)
    g = list(zip(np.arange(len(sel_var_idxs)+2), [0] + sel_var_idxs))
    
    # Loop
    COLS = ['BASELINE'] + list(feature_names)
    results = []
    pv(f'Computing feature importance ({method} method)...', verbose)
    try:
        if method == 'ablation':
            fs = self.dls.valid.after_batch.fs
            self.dls.valid.after_batch.fs = fs + [TSNan2Value()]
        for i,k in progress_bar(g):
            if i > 0:
                if k not in sel_var_idxs: continue
                save_feat = X[:, k].copy()
                if method == 'permutation':
                    # shuffle along samples & steps
                    X[:, k] = random_shuffle(X[:, k].flatten(), random_state=random_state).reshape(X[:, k].shape)
                elif method == 'ablation':
                    X[:, k] = np.nan
            if key_metric_idx is None:
                value = self.get_X_preds(X, y, with_loss=True, with_decoded=False, bs=bs)[-1].mean().item()
            else:
                output = self.get_X_preds(X, y, with_decoded=False, bs=bs)
                if self.dls.c == 2:
                    try: 
                        if sklearn_metric:
                            value = metric(output[1], output[0][:, 1]).item()
                        else:
                            value = metric(output[0][:, 1], output[1]).item()
                    except: 
                        if sklearn_metric:
                            value = metric(output[1], output[0]).item()
                        else:
                            value = metric(output[0], output[1]).item()
                else:
                    if sklearn_metric:
                        value = metric(output[1], output[0]).item()
                    else:
                        value = metric(output[0], output[1]).item()
                del output
            pv(f"{k:3} feature: {COLS[i]:20} {metric_name}: {value:8.6f}", verbose)
            results.append([COLS[i], value])
            del value; gc.collect()
            if i > 0:
                X[:, k] = save_feat
                del save_feat; gc.collect()
        
        if method == 'ablation':
            self.dls.valid.after_batch.fs = fs

    except KeyboardInterrupt:
        if i > 0:
            X[:, k] = save_feat
            del save_feat; gc.collect()
        if method == 'ablation':
            self.dls.valid.after_batch.fs = fs

    # DataFrame
    df = pd.DataFrame(results, columns=["Feature", metric_name])
    df[f'{metric_name}_change'] = df[metric_name] - df.loc[0, metric_name]
    sign = np.sign(df[f'{metric_name}_change'].mean())
    if sign == 0: sign = 1
    df[f'{metric_name}_change'] = df[f'{metric_name}_change'] * sign

    # Display feature importance
    if show_chart:
        print()
        value_change = df.loc[1:, f'{metric_name}_change'].values
        pos_value_change = value_change.copy()
        neg_value_change = value_change.copy()
        pos_value_change[pos_value_change < 0] = 0
        neg_value_change[neg_value_change > 0] = 0
        if figsize is None:
            figsize=(10, .5*len(value_change))
        plt.figure(figsize=figsize)
        plt.barh(np.arange(len(value_change))[::-1], pos_value_change, color='lime', edgecolor='black')
        plt.barh(np.arange(len(value_change))[::-1], neg_value_change, color='red', edgecolor='black')
        plt.axvline(0, color='black')
        plt.yticks(np.arange(len(value_change))[::-1], df.loc[1:, "Feature"].values)
        if title is None: title = f'Feature Importance ({method} method)'
        plt.title(title, size=16)
        text = 'increase' if sign == 1 else 'decrease'
        plt.xlabel(f"{metric_name} {text} when feature is removed")
        plt.ylim((-1,len(value_change)))
        plt.show()

    # Save feature importance
    df = df.sort_values(metric_name, ascending=sign < 0, kind='stable').reset_index(drop=True)
    if save_df_path:
        if save_df_path.split('.')[-1] != 'csv': save_df_path = f'{save_df_path}.csv'
        df.to_csv(f'{save_df_path}', index=False)
        pv(f'Feature importance df saved to {save_df_path}', verbose)
    if return_df: 
        return df 

#|export
@patch
def step_importance(
    self:Learner, 
    X=None, # array-like object containing the time series. If None, all data in the validation set will be used.
    y=None, # array-like object containing the targets. If None, all targets in the validation set will be used.
    bs:int=None, # batch size used to compute predictions. If None, the batch size used in the validation set will be used.
    partial_n:(int, float)=None, # # (int) or % (float) of used to measure feature importance. If None, all data will be used.
    method:str='permutation', # Method used to invalidate feature. Use 'permutation' for shuffling or 'ablation' for setting values to np.nan.
    step_names:list=None, # Optional list of step names that will be displayed if available. Otherwise 0, 1, 2, etc.
    sel_classes:(str, list)=None, # classes for which the analysis will be made
    n_steps:int=1, # # of steps that will be analyzed at a time. Default is 1.
    key_metric_idx:int=0, # Optional position of the metric used. If None or no metric is available, the loss will be used.
    show_chart:bool=True, # Flag to indicate if a chart showing permutation feature importance will be plotted.
    figsize:tuple=(10, 5), # Size of the chart.
    title:str=None, # Optional string that will be used as the chart title. If None 'Permutation Feature Importance'.
    xlabel=None, # Optional string that will be used as the chart xlabel. If None 'steps'.
    return_df:bool=True, # Flag to indicate if the dataframe with feature importance will be returned.
    save_df_path:Path=None, # Path where dataframe containing the permutation feature importance results will be saved.
    random_state:int=23, # Optional int that controls the shuffling applied to the data.
    verbose:bool=True, # Flag that controls verbosity.
    ):
    r"""Calculates step importance as the drop in the model's validation loss or metric when a step/s value/s is/are randomly shuffled"""
    
    assert method in ['permutation', 'ablation']
    
    # X, y
    if X is None:
        X = self.dls.train.dataset.tls[0].items
        if hasattr(self.dls.train.dataset.tls[0], '_splits'): X = X[self.dls.train.dataset.tls[0]._splits]
    if y is None:
        y = self.dls.train.dataset.tls[1].items
    if partial_n is not None:
        _, rand_idxs, *_ = train_test_split(np.arange(len(y)), y, test_size=partial_n, random_state=random_state, stratify=y)
        X = X.oindex[rand_idxs] if hasattr(X, 'oindex') else X[rand_idxs]
        y = y.oindex[rand_idxs] if hasattr(y, 'oindex') else y[rand_idxs]
    else: 
        X, y = X[:], y[:]
    if sel_classes is not None:
        filt = np.isin(y, listify(sel_classes))
        X, y = X[filt], y[filt]
    pv(f'X.shape: {X.shape}', verbose)
    pv(f'y.shape: {y.shape}', verbose)
    if bs is None:
        bs = self.dls.valid.bs

    # Metrics
    metrics = [mn for mn in self.recorder.metric_names if mn not in ['epoch', 'train_loss', 'valid_loss', 'time']]
    if len(metrics) == 0 or key_metric_idx is None:
        metric_name = self.loss_func.__class__.__name__
        key_metric_idx = None
    else:
        metric_name = metrics[key_metric_idx]
        metric = self.recorder.metrics[key_metric_idx].func
        if "sklearn" in inspect.getmodule(metric).__name__:
            sklearn_metric = True
        else:
            sklearn_metric = False
    metric_name = metric_name.replace("train_", "").replace("valid_", "")
    pv(f'Selected metric: {metric_name}', verbose)
    
    # Selected steps
    sel_step_idxs = L(np.arange(X.shape[-1]).tolist())[self.dls.sel_steps]
    if n_steps != 1:
        sel_step_idxs = [listify(sel_step_idxs[::-1][n:n+n_steps][::-1]) for n in range(0, len(sel_step_idxs), n_steps)][::-1]     
    g = list(zip(np.arange(len(sel_step_idxs)+2), [0] + sel_step_idxs))

    # Loop
    COLS = ['BASELINE'] + sel_step_idxs
    results = []
    _step_names = []
    pv('Computing step importance...', verbose)
    try:
        if method == 'ablation':
            fs = self.dls.valid.after_batch.fs
            self.dls.valid.after_batch.fs = fs + [TSNan2Value()]
        for i,k in progress_bar(g):
            if i > 0:
                if k not in sel_step_idxs: continue
                save_feat = X[..., k].copy()
                if method == 'permutation':
                    # shuffle along samples
                    X[..., k] = shuffle_along_axis(X[..., k], axis=0, random_state=random_state)
                elif method == 'ablation':
                    X[..., k] = np.nan
            if key_metric_idx is None:
                value = self.get_X_preds(X, y, bs=bs, with_loss=True, with_decoded=False)[-1].mean().item()
            else:
                output = self.get_X_preds(X, y, bs=bs, with_decoded=False)
                if self.dls.c == 2:
                    try: 
                        if sklearn_metric:
                            value = metric(output[1], output[0][:, 1]).item()
                        else:
                            value = metric(output[0][:, 1], output[1]).item()
                    except: 
                        if sklearn_metric:
                            value = metric(output[1], output[0]).item()
                        else:
                            value = metric(output[0], output[1]).item()
                else:
                    if sklearn_metric:
                        value = metric(output[1], output[0]).item()
                    else:
                        value = metric(output[0], output[1]).item()
                del output
            
            # Step names
            if i == 0 or step_names is None:
                if i > 0 and n_steps != 1:
                    step_name = f"{str(COLS[i][0])} to {str(COLS[i][-1])}"
                else: step_name = str(COLS[i])
            else:
                step_name = step_names[i - 1]
            if i > 0: _step_names.append(step_name)
                
            pv(f"{i:3} step: {step_name:20} {metric_name}: {value:8.6f}", verbose)
            results.append([step_name, value])
            del value; gc.collect()
            if i > 0:
                X[..., k] = save_feat
                del save_feat; gc.collect()
        
        if method == 'ablation':
            self.dls.valid.after_batch.fs = fs

    except KeyboardInterrupt:
        if i > 0:
            X[..., k] = save_feat
            del save_feat; gc.collect()
        if method == 'ablation':
            self.dls.valid.after_batch.fs = fs

    # DataFrame
    df = pd.DataFrame(results, columns=["Step", metric_name])
    df[f'{metric_name}_change'] = df[metric_name] - df.loc[0, metric_name]
    sign = np.sign(df[f'{metric_name}_change'].mean())
    if sign == 0: sign = 1
    df[f'{metric_name}_change'] = df[f'{metric_name}_change'] * sign
    
    # Display step importance
    if show_chart:
        print()
        value_change = df.loc[1:, f'{metric_name}_change'].values
        pos_value_change = value_change.copy()
        neg_value_change = value_change.copy()
        pos_value_change[pos_value_change < 0] = 0
        neg_value_change[neg_value_change > 0] = 0
        plt.figure(figsize=figsize)
        plt.bar(np.arange(len(value_change)), pos_value_change, color='lime', edgecolor='black')
        plt.bar(np.arange(len(value_change)), neg_value_change, color='red', edgecolor='black')
        plt.axhline(0, color='black')
        plt.xticks(np.arange(len(value_change)), _step_names, rotation=90)
        if title is None: title = f'Step Importance ({method} method)'
        plt.title(title, size=16)
        text = 'increase' if sign == 1 else 'decrease'
        if xlabel is None: xlabel = 'steps'
        plt.xlabel(xlabel)
        plt.ylabel(f"{metric_name} {text} when removed")
        plt.xlim((-1,len(value_change)))
        plt.show()

    # Save step importance
    df = df.sort_values(metric_name, ascending=sign < 0, kind='stable').reset_index(drop=True)
    if save_df_path:
        if save_df_path.split('.')[-1] != 'csv': save_df_path = f'{save_df_path}.csv'
        df.to_csv(f'{save_df_path}', index=False)
        pv(f'Step importance df saved to {save_df_path}', verbose)
    if return_df: 
        return df

from tsai.data.external import get_UCR_data
from tsai.data.preprocessing import TSRobustScale, TSStandardize
from tsai.learner import ts_learner
from tsai.models.FCNPlus import FCNPlus
from tsai.metrics import accuracy

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, split_data=False)
tfms  = [None, [TSClassification()]]
batch_tfms = TSRobustScale()
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, splits=splits, sel_vars=[0, 3, 5, 8, 10], sel_steps=slice(-30, None), tfms=tfms, batch_tfms=batch_tfms)
learn = ts_learner(dls, FCNPlus, metrics=accuracy, train_metrics=True)
learn.fit_one_cycle(2)
learn.plot_metrics()
learn.show_probas()
learn.plot_confusion_matrix()
learn.plot_top_losses(X[splits[1]], y[splits[1]], largest=True)
learn.top_losses(X[splits[1]], y[splits[1]], largest=True)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1300x400 with 2 Axes>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 600x600 with 1 Axes>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([2.3713, 2.3146, 2.2843, 2.2581, 2.2408, 2.2264, 2.2254, 2.2237,

#                2.2230]),

#    [9, 56, 128, 25, 104, 116, 57, 72, 108])
#   <Figure size 500x500 with 1 Axes>
#   <Figure size 1800x1200 with 9 Axes>

learn.feature_importance()
# Output:
#   X.shape: (180, 24, 51)

#   y.shape: (180,)

#   Selected metric: accuracy

#   Computing feature importance (permutation method)...

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     0 feature: BASELINE             accuracy: 0.277778

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     0 feature: var_0                accuracy: 0.238889

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     3 feature: var_3                accuracy: 0.172222

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     5 feature: var_5                accuracy: 0.261111

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     8 feature: var_8                accuracy: 0.250000

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#    10 feature: var_10               accuracy: 0.266667

#   

#   <Figure size 1000x250 with 1 Axes>
#       Feature  accuracy  accuracy_change

#   0     var_3  0.172222         0.105556

#   1     var_0  0.238889         0.038889

#   2     var_8  0.250000         0.027778

#   3     var_5  0.261111         0.016667

#   4    var_10  0.266667         0.011111

#   5  BASELINE  0.277778        -0.000000

learn.step_importance(n_steps=5);
# Output:
#   X.shape: (180, 24, 51)

#   y.shape: (180,)

#   Selected metric: accuracy

#   Computing step importance...

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     0 step: BASELINE             accuracy: 0.277778

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     1 step: 21 to 25             accuracy: 0.288889

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     2 step: 26 to 30             accuracy: 0.255556

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     3 step: 31 to 35             accuracy: 0.194444

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     4 step: 36 to 40             accuracy: 0.216667

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     5 step: 41 to 45             accuracy: 0.272222

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#     6 step: 46 to 50             accuracy: 0.283333

#   

#   <Figure size 1000x500 with 1 Axes>

"""
You may pass an X and y if you want to analyze a particular group of samples: 

```bash
learn.feature_importance(X=X[splits[1]], y=y[splits[1]])
```
"""

"""
If you have a large validation dataset, you may also use the partial_n argument to select a fixed amount of samples (integer) or a percentage of the validation dataset (float):

```bash
learn.feature_importance(partial_n=.1)
```

```bash
learn.feature_importance(partial_n=100)
```
"""

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/020_analysis.ipynb couldn't be saved automatically. You should save it manually 👋

#   Correct notebook to script conversion! 😃

#   Monday 19/06/23 09:53:06 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/024_callback.core.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp callback.core

"""
# Callback
"""

"""
>Miscellaneous callbacks for timeseriesAI.
"""

#|export 
from fastai.callback.all import *
from tsai.imports import *
from tsai.utils import *
from tsai.data.preprocessing import *
from tsai.data.transforms import *
from tsai.models.layers import *

#|export
import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')

"""
## Events
"""

"""
A callback can implement actions on the following events:
* before_fit: called before doing anything, ideal for initial setup.
* before_epoch: called at the beginning of each epoch, useful for any behavior you need to reset at each epoch.
* before_train: called at the beginning of the training part of an epoch.
* before_batch: called at the beginning of each batch, just after drawing said batch. It can be used to do any setup necessary for the batch (like hyper-parameter scheduling) or to change the input/target before it goes in the model (change of the input with techniques like mixup for instance).
* after_pred: called after computing the output of the model on the batch. It can be used to change that output before it's fed to the loss.
* after_loss: called after the loss has been computed, but before the backward pass. It can be used to add any penalty to the loss (AR or TAR in RNN training for instance).
* before_backward: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)
* after_backward: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).
* after_step: called after the step and before the gradients are zeroed.
* after_batch: called at the end of a batch, for any clean-up before the next one.
* after_train: called at the end of the training phase of an epoch.
* before_validate: called at the beginning of the validation phase of an epoch, useful for any setup needed specifically for validation.
* after_validate: called at the end of the validation part of an epoch.
* after_epoch: called at the end of an epoch, for any clean-up before the next one.
* after_fit: called at the end of training, for final clean-up.
"""

"""
## Learner attributes
"""

"""
When writing a callback, the following attributes of Learner are available:

* **model**: the model used for training/validation
* **data**: the underlying DataLoaders
* **loss_func**: the loss function used
* **opt**: the optimizer used to udpate the model parameters
* **opt_func**: the function used to create the optimizer
* **cbs**: the list containing all Callbacks
* **dl**: current DataLoader used for iteration
* **x/xb**: last input drawn from self.dl (potentially modified by callbacks). xb is always a tuple (potentially with one element) and x is detuplified. You can only assign to xb.
* **y/yb**: last target drawn from self.dl (potentially modified by callbacks). yb is always a tuple (potentially with one element) and y is detuplified. You can only assign to yb.
* **pred**: last predictions from self.model (potentially modified by callbacks)
* **loss**: last computed loss (potentially modified by callbacks)
* **n_epoch**: the number of epochs in this training
* **n_iter**: the number of iterations in the current self.dl
* **epoch**: the current epoch index (from 0 to n_epoch-1)
* **iter**: the current iteration index in self.dl (from 0 to n_iter-1)

The following attributes are added by TrainEvalCallback and should be available unless you went out of your way to remove that callback:
* **train_iter**: the number of training iterations done since the beginning of this training
* **pct_train**: from 0. to 1., the percentage of training iterations completed
* **training**: flag to indicate if we're in training mode or not

The following attribute is added by Recorder and should be available unless you went out of your way to remove that callback:
* **smooth_loss**: an exponentially-averaged version of the training loss
"""

"""
## Transform scheduler
"""

#|export
class TransformScheduler(Callback):
    "A callback to schedule batch transforms during training based on a function (sched_lin, sched_exp, sched_cos (default), etc)"
    def __init__(self, schedule_func:callable, show_plot:bool=False): 
        self.schedule_func,self.show_plot = schedule_func,show_plot
        self.mult = []

    def before_fit(self):
        for pct in np.linspace(0, 1, len(self.dls.train) * self.n_epoch): self.mult.append(self.schedule_func(pct))
        # get initial magnitude values and update initial value
        self.mag = []
        self.mag_tfms = []
        for t in self.dls.after_batch: 
            if hasattr(t, 'magnitude'):
                self.mag.append(t.magnitude)
                t.magnitude *= self.mult[0]
                self.mag_tfms.append(t)

    def after_batch(self):
        if self.training and len(self.mag_tfms)>0 and self.train_iter < len(self.mult):
            # set values for next batch
            for t,m in zip(self.mag_tfms, self.mag): 
                t.magnitude = m * self.mult[self.train_iter]
                
    def after_fit(self):
        if self.show_plot and self.mult != [] and len(self.mag_tfms)>0: 
            print()
            plt.plot(self.mult)
            plt.title('Scheduled tfms')
            plt.show()
            print()
            self.show_plot = False
        # set values to initial values
        for t,m in zip(self.mag_tfms, self.mag): t.magnitude = m
    
    def __repr__(self):
        return f'{self.__class__.__name__}({self.schedule_func})'

TransformScheduler(SchedCos(1, 0))
# Output:
#   TransformScheduler(<fastai.callback.schedule._Annealer object>)

p = torch.linspace(0.,1,100)
f = combine_scheds([0.3, 0.4, 0.3], [SchedLin(1.,1.), SchedCos(1.,0.), SchedLin(0.,.0), ])
plt.plot(p, [f(o) for o in p]);
# Output:
#   <Figure size 640x480 with 1 Axes>

p = torch.linspace(0.,1,100)
f = combine_scheds([0.3, 0.7], [SchedCos(0.,1.), SchedCos(1.,0.)])
plt.plot(p, [f(o) for o in p]);
# Output:
#   <Figure size 640x480 with 1 Axes>

"""
## ShowGraph
"""

#|export
class ShowGraph(Callback):
    "(Modified) Update a graph of training and validation loss"
    order,run_valid=65,False
    names = ['train', 'valid']
    def __init__(self, plot_metrics:bool=True, final_losses:bool=True, perc:float=.5):
        store_attr()

    def before_fit(self):
        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, "gather_preds")
        if not(self.run): return
        self.nb_batches = []
        self.learn.recorder.loss_idxs = [i for i,n in enumerate(self.learn.recorder.metric_names[1:-1]) if 'loss' in n]
        _metrics_info = [(i,n) for i,n in enumerate(self.learn.recorder.metric_names[1:-1]) if 'loss' not in n]
        if len(_metrics_info) > 0: 
            self.metrics_idxs, self.metrics_names = list(zip(*_metrics_info))
        else: 
            self.metrics_idxs, self.metrics_names = None, None

    def after_train(self): self.nb_batches.append(self.train_iter - 1)

    def after_epoch(self):
        "Plot validation loss in the pbar graph"
        if not self.nb_batches: return
        rec = self.learn.recorder
        if self.epoch == 0:
            self.rec_start = len(rec.losses)
        iters = range_of(rec.losses)
        all_losses = rec.losses if self.epoch == 0 else rec.losses[self.rec_start-1:]
        val_losses = np.stack(rec.values)[:, self.learn.recorder.loss_idxs[-1]].tolist()
        if rec.valid_metrics and val_losses[0] is not None:
            all_losses = all_losses + val_losses
        else:
            val_losses = [None] * len(iters)
        y_min, y_max = min(all_losses), max(all_losses)
        margin = (y_max - y_min) * .05
        x_bounds = (0, len(rec.losses) - 1)
        y_bounds = (y_min - margin, y_max + margin)
        self.update_graph([(iters, rec.losses), (self.nb_batches, val_losses)], x_bounds, y_bounds)

    def after_fit(self):
        if hasattr(self, 'graph_ax'):
            plt.close(self.graph_ax.figure)
        if self.plot_metrics: 
            self.learn.plot_metrics(final_losses=self.final_losses, perc=self.perc)

    def update_graph(self, graphs, x_bounds=None, y_bounds=None, figsize=(6,4)):
        if not hasattr(self, 'graph_fig'):
            self.graph_fig, self.graph_ax = plt.subplots(1, figsize=figsize)
            self.graph_out = display(self.graph_ax.figure, display_id=True)
        self.graph_ax.clear()
        if len(self.names) < len(graphs): self.names += [''] * (len(graphs) - len(self.names))
        for g,n in zip(graphs,self.names): 
            if (g[1] == [None] * len(g[1])): continue
            self.graph_ax.plot(*g, label=n)
        self.graph_ax.legend(loc='upper right')
        self.graph_ax.grid(color='gainsboro', linewidth=.5)
        if x_bounds is not None: self.graph_ax.set_xlim(*x_bounds)
        if y_bounds is not None: self.graph_ax.set_ylim(*y_bounds)
        self.graph_ax.set_title(f'Losses\nepoch: {self.epoch +1}/{self.n_epoch}')
        self.graph_out.update(self.graph_ax.figure)
        
ShowGraphCallback2 = ShowGraph

"""
## SaveModel
"""

#|export
class SaveModel(TrackerCallback):
    "A `TrackerCallback` that saves the model's best during training and loads it at the end with a verbose option."
    _only_train_loop,order = True,TrackerCallback.order+1
    def __init__(self, monitor='valid_loss', comp=None, min_delta=0., fname='model', every_epoch=False, at_end=False,
                 with_opt=False, reset_on_fit=True, verbose=False):
        super().__init__(monitor=monitor, comp=comp, min_delta=min_delta, reset_on_fit=reset_on_fit)
        assert not (every_epoch and at_end), "every_epoch and at_end cannot both be set to True"
        # keep track of file path for loggers
        self.last_saved_path = None
        store_attr('fname,every_epoch,at_end,with_opt,verbose')

    def _save(self, name): self.last_saved_path = self.learn.save(name, with_opt=self.with_opt)

    def after_epoch(self):
        "Compare the value monitored to its best score and save if best."
        if self.every_epoch:
            if (self.epoch%self.every_epoch) == 0: self._save(f'{self.fname}_{self.epoch}')
        else: #every improvement
            super().after_epoch()
            if self.new_best:
                pv(f'Better model found at epoch {self.epoch} with {self.monitor} value: {self.best}.', self.verbose)
                self._save(f'{self.fname}')

    def after_fit(self, **kwargs):
        "Load the best model."
        if self.at_end: self._save(f'{self.fname}')
        elif not self.every_epoch: self.learn.load(f'{self.fname}', with_opt=self.with_opt)

"""
# Weight per sample loss
"""

"""
This process shows an example of how the weights could be calculated. This particular regression method was published in: 

Yang, Y., Zha, K., Chen, Y. C., Wang, H., & Katabi, D. (2021). Delving into Deep Imbalanced Regression. arXiv preprint arXiv:2102.09554.    
(https://arxiv.org/pdf/2102.09554.pdf)
"""

#|export
from scipy.ndimage import gaussian_filter1d
from scipy.signal.windows import triang
from scipy.ndimage import convolve1d


def get_lds_kernel_window(lds_kernel="gaussian", lds_ks=9, lds_sigma=1):
    r"""Function to determine the label distribution smoothing kernel window

    lds_kernel (str): LDS kernel type
    lds_ks (int): LDS kernel size (should be an odd number).
    lds_sigma (float): LDS gaussian/laplace kernel sigma
    """

    assert lds_kernel in ['gaussian', 'triang', 'laplace']
    half_ks = (lds_ks - 1) // 2

    if lds_kernel == 'gaussian':
        base_kernel = [0.] * half_ks + [1.] + [0.] * half_ks
        kernel_window = gaussian_filter1d(
            base_kernel, sigma=lds_sigma) / max(gaussian_filter1d(base_kernel, sigma=lds_sigma))
    elif lds_kernel == 'triang':
        kernel_window = triang(lds_ks)
    else:
        def laplace(x): return np.exp(-abs(x) / lds_sigma) / (2. * lds_sigma)
        kernel_window = list(map(laplace, np.arange(-half_ks, half_ks + 1))) / \
            max(map(laplace, np.arange(-half_ks, half_ks + 1)))

    return kernel_window


def prepare_LDS_weights(labels, n_bins=None, label_range=None, reweight='inv', lds_kernel='gaussian', lds_ks=9, lds_sigma=1, 
                        max_rel_weight=None, show_plot=True):
    
    assert reweight in {'inv', 'sqrt_inv'}
    labels_shape = labels.shape
    if n_bins is None:
        labels = labels.astype(int)
        n_bins = np.max(labels) - np.min(labels)
    num_per_label, bin_edges = np.histogram(labels, bins=n_bins, range=label_range)
    new_labels = np.searchsorted(bin_edges, labels, side='left')
    new_labels[new_labels == 0] = 1
    if reweight == 'sqrt_inv':
        num_per_label = np.sqrt(num_per_label)
    lds_kernel_window = get_lds_kernel_window(lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma)
    smoothed_value = convolve1d(num_per_label, weights=lds_kernel_window, mode='constant')
    if show_plot:
        plt.bar(bin_edges[:-1], num_per_label / num_per_label.sum(), width=(bin_edges[1]-bin_edges[0]), color='lime', edgecolor='black', label='original')
        plt.plot(bin_edges[:-1], smoothed_value / smoothed_value.sum(), color='red', label='smoothed')
        plt.title(f"Label distribution by bin (reweight={reweight})")
        plt.legend(loc='best')
        plt.show()
    num_per_label = smoothed_value[new_labels.flatten() - 1].reshape(*labels_shape)
    weights = 1 / num_per_label
    weights[num_per_label == 0] = 0
    if max_rel_weight is not None: 
        weights = np.clip(weights, None, np.min(weights) * max_rel_weight)
    weights = weights / weights.sum() * len(labels)
    return torch.Tensor(weights)

labels = np.concatenate([np.random.normal(-20, 1, 10), np.random.normal(0, 2, 100), np.random.normal(12, 2, 300)], -1)
labels[(-1<labels) & (labels<1)] = 0   # This is done to create some 'gaps' for demo purposes
labels[(10<labels) & (labels<12)] = 0  # This is done to create some 'gaps' for demo purposes

n_bins = 50
label_range=None
reweight = 'inv'
lds_kernel='gaussian'
lds_ks=5
lds_sigma=2

weights_per_sample = prepare_LDS_weights(labels, n_bins, label_range=label_range, reweight=reweight, 
                                         lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma, show_plot=True)

n_bins = 50
label_range=None
reweight = 'sqrt_inv'
lds_kernel='gaussian'
lds_ks=5
lds_sigma=2

weights_per_sample = prepare_LDS_weights(labels, n_bins, label_range=label_range, reweight=reweight, 
                                         lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma, show_plot=True)

n_bins = None
label_range=None
reweight = 'sqrt_inv'
lds_kernel='triang'
lds_ks=9
lds_sigma=1

weights_per_sample = prepare_LDS_weights(labels, n_bins, label_range=label_range, reweight=reweight, 
                                         lds_kernel=lds_kernel, lds_ks=lds_ks, lds_sigma=lds_sigma, show_plot=True)
# Output:
#   <Figure size 640x480 with 1 Axes>
#   <Figure size 640x480 with 1 Axes>
#   <Figure size 640x480 with 1 Axes>

#|export
class WeightedPerSampleLoss(Callback):
    order = 65

    r"""Loss wrapper than applies a weight per sample during training

    Weights are not applied to the validation loss.

    Args:
        instance_weights:   weights that will be applied. Weights will be normalized to 1.
                            You can pass weights for the entire dataset or just for the training set.
    """

    def __init__(self, instance_weights):
        store_attr()

    def before_fit(self):
        self.old_loss = self.learn.loss_func
        self.reduction = getattr(self.learn.loss_func, 'reduction', None)
        self.learn.loss_func = _PerInstanceLoss(crit=self.learn.loss_func)
        if len(self.instance_weights) == len(self.learn.dls.train.dataset):
            self.instance_weights = torch.cat([self.instance_weights, torch.zeros(len(self.learn.dls.valid.dataset))])
        assert len(self.instance_weights) == len(self.learn.dls.train.dataset) + len(self.learn.dls.valid.dataset)
        self.instance_weights = self.instance_weights / torch.sum(self.instance_weights) * len(self.instance_weights)
        self.instance_weights = torch.as_tensor(self.instance_weights, device=self.learn.dls.device)

    def before_batch(self):
        self.learn.loss_func.training = self.training
        if self.training:
            input_idxs = self.learn.dls.train.input_idxs
            self.learn.loss_func.weights = self.instance_weights[input_idxs]

    def after_fit(self):
        self.learn.loss_func = self.old_loss
        if self.reduction is not None: self.learn.loss_func.reduction = self.reduction
            

class _PerInstanceLoss(Module):
    def __init__(self, crit):
        self.crit = crit
        self.crit.reduction = 'none'
        self.weights = None
        self.training = False

    def forward(self, input, target):
        if not self.training:
            return self.crit(input, target).mean()
        else:
            return ((self.crit(input, target) * self.weights)).mean()

"""
# BatchSubsampler
"""

#|export
class BatchSubsampler(Callback):
    """ Callback that selects a percentage of samples and/ or sequence steps with replacement from each training batch

    Args:
    ====

    sample_pct:     percentage of random samples (or instances) that will be drawn. If 1. the output batch will contain the same number of samples
                    as the input batch.
    step_pct:       percentage of random sequence steps that will be drawn. If 1. the output batch will contain the same number of sequence steps
                    as the input batch. If used with models that don't use a pooling layer, this must be set to 1 to keep the same dimensions.
                    With CNNs, this value may be different.
    same_seq_len:   If True, it ensures that the output has the same shape as the input, even if the step_pct chosen is < 1. Defaults to True.
    update_y:       used with step_pct. If True, it applies the same random indices to y. It can only be used with sequential targets.
    """

    def __init__(self, sample_pct:Optional[float]=None, step_pct:Optional[float]=None, same_seq_len:bool=True, update_y:bool=False):
        store_attr()

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if not(self.run): return

    def before_batch(self):
        if not self.training: return

        if self.sample_pct is not None:
            B = self.x.shape[0]
            if isinstance(self.sample_pct, tuple):
                sample_pct = np.random.rand() * (self.sample_pct[1] - self.sample_pct[0]) + self.sample_pct[0]
            else:
                sample_pct = self.sample_pct
            idxs = random_choice(B, round(B * sample_pct), True)
            self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)
            self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)

        if self.step_pct is not None:
            S = self.x.shape[-1]
            if isinstance(self.step_pct, tuple):
                step_pct = np.random.rand() * (self.step_pct[1] - self.step_pct[0]) + self.step_pct[0]
            else:
                step_pct = self.step_pct
            if self.step_pct != 1 and self.same_seq_len:
                idxs = np.sort(np.tile(random_choice(S, round(S * step_pct), True), math.ceil(1 / step_pct))[:S])
            else:
                idxs = np.sort(random_choice(S, round(S * step_pct), True))
            self.learn.xb = tuple(xbi[...,idxs] for xbi in self.learn.xb)
            if self.update_y:
                self.learn.yb = tuple(ybi[...,idxs] for ybi in self.learn.yb)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/024_callback.core.ipynb saved at 2023-02-21 13:46:35

#   Correct notebook to script conversion! 😃

#   Tuesday 21/02/23 13:46:38 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/025_callback.experimental.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp callback.experimental

"""
# Experimental Callbacks
"""

"""
>Miscellaneous experimental callbacks for timeseriesAI.
"""

#|export
import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')

#|export 
from fastai.callback.all import *
from tsai.imports import *
from tsai.utils import *
from tsai.data.preprocessing import *
from tsai.data.transforms import *
from tsai.models.layers import *
from tsai.callback.MVP import *

"""
## Gambler's loss: noisy labels
"""

#|export
class GamblersCallback(Callback):
    "A callback to use metrics with gambler's loss"
    def after_loss(self): self.learn.pred = self.learn.pred[..., :-1]
        

def gambler_loss(reward=2):
    def _gambler_loss(model_output, targets):
        outputs = torch.nn.functional.softmax(model_output, dim=1)
        outputs, reservation = outputs[:, :-1], outputs[:, -1]
        gain = torch.gather(outputs, dim=1, index=targets.unsqueeze(1)).squeeze()
        doubling_rate = (gain + reservation / reward).log()
        return - doubling_rate.mean()
    return 

from tsai.data.external import *
from tsai.data.core import *
from tsai.models.InceptionTime import *
from tsai.models.layers import *
from tsai.learner import *
from fastai.metrics import *
from tsai.metrics import *

X, y, splits = get_UCR_data('NATOPS', return_split=False)
tfms = [None, TSCategorize()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128])
loss_func = gambler_loss()
learn = ts_learner(dls, InceptionTime(dls.vars, dls.c + 1), loss_func=loss_func, cbs=GamblersCallback, metrics=[accuracy])
learn.fit_one_cycle(1)
# Output:
#   <IPython.core.display.HTML object>

"""
## Uncertainty-based data augmentation
"""

#|export
class UBDAug(Callback):
    r"""A callback to implement the uncertainty-based data augmentation."""
    
    def __init__(self, batch_tfms:list, N:int=2, C:int=4, S:int=1): 
        r'''
        Args:
            batch_tfms:   list of available transforms applied to the combined batch. They will be applied in addition to the dl tfms.
            N:            # composition steps (# transforms randomly applied to each sample)
            C:            # augmented data per input data (# times N transforms are applied)
            S:            # selected data points used for training (# augmented samples in the final batch from each original sample)
        '''
        
        self.C, self.S = C, min(S, C)
        self.batch_tfms = L(batch_tfms)
        self.n_tfms = len(self.batch_tfms)
        self.N = min(N, self.n_tfms)
        
    def before_fit(self):
        assert hasattr(self.loss_func, 'reduction'), "You need to pass a loss_function with a 'reduction' attribute"
        self.red = self.loss_func.reduction
    
    def before_batch(self):
        if self.training:
            with torch.no_grad():
                setattr(self.loss_func, 'reduction', 'none')
                for i in range(self.C):
                    idxs = random_choice(self.n_tfms, self.N, False)
                    x_tfm = compose_tfms(self.x, self.batch_tfms[idxs], split_idx=0)
                    loss = self.loss_func(self.learn.model(x_tfm), self.y).reshape(-1,1)
                    if i == 0:
                        x2 = x_tfm.unsqueeze(1)
                        max_loss = loss
                    else: 
                        losses = torch.cat((max_loss, loss), dim=1)
                        x2 = torch.cat((x2, x_tfm.unsqueeze(1)), dim=1)
                        x2 = x2[np.arange(x2.shape[0]).reshape(-1,1), losses.argsort(1)[:, -self.S:]]
                        max_loss = losses.max(1)[0].reshape(-1,1)
                setattr(self.loss_func, 'reduction', self.red)
            x2 = x2.reshape(-1, self.x.shape[-2], self.x.shape[-1])
            if self.S > 1: self.learn.yb = (torch_tile(self.y, 2),)
            self.learn.xb = (x2,)

    def __repr__(self): return f'UBDAug({[get_tfm_name(t) for t in self.batch_tfms]})'

from tsai.models.utils import *

X, y, splits = get_UCR_data('NATOPS', return_split=False)
tfms = [None, TSCategorize()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, batch_tfms=[TSStandardize()])
model = build_ts_model(InceptionTime, dls=dls)
TS_tfms = [TSMagScale(.75, p=.5), TSMagWarp(.1, p=0.5),  TSWindowWarp(.25, p=.5), 
           TSSmooth(p=0.5), TSRandomResizedCrop(.1, p=.5), 
           TSRandomCropPad(.3, p=0.5), 
           TSMagAddNoise(.5, p=.5)]

ubda_cb = UBDAug(TS_tfms, N=2, C=4, S=2)
learn = ts_learner(dls, model, cbs=ubda_cb, metrics=accuracy)
learn.fit_one_cycle(1)
# Output:
#   <IPython.core.display.HTML object>

"""
# BatchLossFilter
"""

#|export
class BatchLossFilter(Callback):
    """ Callback that selects the hardest samples in every batch representing a percentage of the total loss"""

    def __init__(self, loss_perc=1., schedule_func:Optional[callable]=None):
        store_attr()

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if not(self.run): return
        self.crit = self.learn.loss_func
        if hasattr(self.crit, 'reduction'): self.red = self.crit.reduction

    def before_batch(self):
        if not self.training: return
        if self.schedule_func is None: loss_perc = self.loss_perc
        else: loss_perc = self.loss_perc * self.schedule_func(self.pct_train)
        if loss_perc == 1.: return
        with torch.no_grad():
            if hasattr(self.crit, 'reduction'):  setattr(self.crit, 'reduction', 'none')
            losses = self.crit(self.learn.model(self.x), self.y)
            if losses.ndim == 2: losses = losses.mean(-1)
            if hasattr(self.crit, 'reduction'):  setattr(self.crit, 'reduction', self.red)
            losses /= losses.sum()
            idxs = torch.argsort(losses, descending=True)
            cut_idx = max(1, torch.argmax((losses[idxs].cumsum(0) > loss_perc).float()))
            idxs = idxs[:cut_idx]
            self.learn.xb = tuple(xbi[idxs] for xbi in self.learn.xb)
            self.learn.yb = tuple(ybi[idxs] for ybi in self.learn.yb)

    def after_fit(self):
        if hasattr(self.learn.loss_func, 'reduction'):  setattr(self.learn.loss_func, 'reduction', self.red)

"""
# RandomWeightLossWrapper
"""

#|export

class RandomWeightLossWrapper(Callback):

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if not(self.run): return
        self.crit = self.learn.loss_func
        if hasattr(self.crit, 'reduction'): self.red = self.crit.reduction
        self.learn.loss_func = self._random_weight_loss

    def _random_weight_loss(self, input: Tensor, target: Tensor) -> Tensor:
        if self.training:
            setattr(self.crit, 'reduction', 'none')
            loss = self.crit(input, target)
            setattr(self.crit, 'reduction', self.red)
            rw = torch.rand(input.shape[0], device=input.device)
            rw /= rw.sum()
            non_red_loss = loss * rw
            return non_red_loss.sum()
        else:
            return self.crit(input, target)

    def after_fit(self):
        if hasattr(self.crit, 'reduction'): setattr(self.crit, 'reduction', self.red)
        self.learn.loss_func = self.crit

"""
# BatchMasker
"""

#|export

class BatchMasker(Callback):
    """ Callback that applies a random mask to each sample in a training batch

    Args:
    ====
    r:                  probability of masking.
    subsequence_mask:   apply a mask to random subsequences.
    lm:                 average mask len when using stateful (geometric) masking.
    stateful:           geometric distribution is applied so that average mask length is lm.
    sync:               all variables have the same masking.
    variable_mask:      apply a mask to random variables. Only applicable to multivariate time series.
    future_mask:        used to train a forecasting model.
    schedule_func:      if a scheduler is passed, it will modify the probability of masking during training.
    """

    def __init__(self, r:float=.15, lm:int=3, stateful:bool=True, sync:bool=False, subsequence_mask:bool=True, 
                 variable_mask:bool=False, future_mask:bool=False, schedule_func:Optional[callable]=None):
        store_attr()

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if not(self.run): return

    def before_batch(self):
        if not self.training: return
        r = self.r * self.schedule_func(self.pct_train) if self.schedule_func is not None else self.r
        mask = create_mask(self.x,  r=r, lm=self.lm, stateful=self.stateful, sync=self.sync, 
                        subsequence_mask=self.subsequence_mask, variable_mask=self.variable_mask, future_mask=self.future_mask)
        self.learn.xb = (self.xb[0].masked_fill(mask, 0),)
        # In my tests, mask-based compensation doesn't seem to be important. ??
        # mean_per_seq = (torch.max(torch.ones(1, device=mask.device), torch.sum(mask, dim=-1).unsqueeze(-1)) / mask.shape[-1])
        # self.learn.xb = (self.xb[0].masked_fill(mask, 0) / (1 - mean_per_seq), )

"""
# SamplerWithReplacement
"""

#|export

class SamplerWithReplacement(Callback):
    """ Callback that modify the sampler to select a percentage of samples and/ or sequence steps with replacement from each training batch"""

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if not(self.run): return

        self.old_get_idxs = self.learn.dls.train.get_idxs
        self.learn.dls.train.get_idxs = self._get_idxs

    def _get_idxs(self):
        dl = self.learn.dls.train
        if dl.n==0: return []
        if dl.weights is not None:
            return random_choice(dl.n, dl.n, p=dl.weights)
        idxs = Inf.count if dl.indexed else Inf.nones
        if dl.n is not None: idxs = random_choice(dl.n,dl.n,True)
        if dl.shuffle: idxs = dl.shuffle_fn(idxs)
        return idxs

    def after_fit(self):
        self.learn.dls.train.get_idxs = self.old_get_idxs

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/060_callback.experimental.ipynb saved at 2022-11-09 12:56:03

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 12:56:06 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/026_callback.noisy_student.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp callback.noisy_student

"""
# Noisy student
"""

"""
Callback to apply noisy student self-training (a semi-supervised learning approach) based on: 

Xie, Q., Luong, M. T., Hovy, E., & Le, Q. V. (2020). 
<span style="color:dodgerblue">Self-training with noisy student improves imagenet classification</span>. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10687-10698).
"""

#|export
import torch.multiprocessing
torch.multiprocessing.set_sharing_strategy('file_system')

#|export
from tsai.imports import *
from tsai.utils import *
from tsai.data.preprocessing import *
from tsai.data.transforms import *
from tsai.models.layers import *
from fastai.callback.all import *

#|export

# This is an unofficial implementation of noisy student based on:
# Xie, Q., Luong, M. T., Hovy, E., & Le, Q. V. (2020). Self-training with noisy student improves imagenet classification.
# In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10687-10698).
# Official tensorflow implementation available in https://github.com/google-research/noisystudent


class NoisyStudent(Callback):
    """A callback to implement the Noisy Student approach. In the original paper this was used in combination with noise:
        - stochastic depth: .8
        - RandAugment: N=2, M=27
        - dropout: .5

    Steps:
        1. Build the dl you will use as a teacher
        2. Create dl2 with the pseudolabels (either soft or hard preds)
        3. Pass any required batch_tfms to the callback

    """

    def __init__(self, dl2:DataLoader, bs:Optional[int]=None, l2pl_ratio:int=1, batch_tfms:Optional[list]=None, do_setup:bool=True,
                 pseudolabel_sample_weight:float=1., verbose=False):
        r'''
        Args:
            dl2:                       dataloader with the pseudolabels
            bs:                        batch size of the new, combined dataloader. If None, it will pick the bs from the labeled dataloader.
            l2pl_ratio:                ratio between labels and pseudolabels in the combined batch
            batch_tfms:                transforms applied to the combined batch. If None, it will pick the batch_tfms from the labeled dataloader (if any)
            do_setup:                  perform a transform setup on the labeled dataset.
            pseudolabel_sample_weight: weight of each pseudolabel sample relative to the labeled one of the loss.
        '''

        self.dl2, self.bs, self.l2pl_ratio, self.batch_tfms, self.do_setup, self.verbose = dl2, bs, l2pl_ratio, batch_tfms, do_setup, verbose
        self.pl_sw = pseudolabel_sample_weight

    def before_fit(self):
        if self.batch_tfms is None: self.batch_tfms = self.dls.train.after_batch
        self.old_bt = self.dls.train.after_batch # Remove and store dl.train.batch_tfms
        self.old_bs = self.dls.train.bs
        self.dls.train.after_batch = noop

        if self.do_setup and self.batch_tfms:
            for bt in self.batch_tfms:
                bt.setup(self.dls.train)

        if self.bs is None: self.bs = self.dls.train.bs
        self.dl2.to(self.dls.device)
        self.dl2.bs = min(len(self.dl2.dataset), int(self.bs / (1 + self.l2pl_ratio)))
        self.dls.train.bs = self.bs - self.dl2.bs
        pv(f'labels / pseudolabels per training batch              : {self.dls.train.bs} / {self.dl2.bs}', self.verbose)
        rel_weight = (self.dls.train.bs/self.dl2.bs) * (len(self.dl2.dataset)/len(self.dls.train.dataset))
        pv(f'relative labeled/ pseudolabel sample weight in dataset: {rel_weight:.1f}', self.verbose)

        self.dl2iter = iter(self.dl2)

        self.old_loss_func = self.learn.loss_func
        self.learn.loss_func = self.loss

    def before_batch(self):
        if self.training:
            X, y = self.x, self.y
            try: X2, y2 = next(self.dl2iter)
            except StopIteration:
                self.dl2iter = iter(self.dl2)
                X2, y2 = next(self.dl2iter)
            if y.ndim == 1 and y2.ndim == 2: y = torch.eye(self.learn.dls.c, device=y.device)[y]

            X_comb, y_comb = concat(X, X2), concat(y, y2)

            if self.batch_tfms is not None:
                X_comb = compose_tfms(X_comb, self.batch_tfms, split_idx=0)
                y_comb = compose_tfms(y_comb, self.batch_tfms, split_idx=0)
            self.learn.xb = (X_comb,)
            self.learn.yb = (y_comb,)
            pv(f'\nX: {X.shape}  X2: {X2.shape}  X_comb: {X_comb.shape}', self.verbose)
            pv(f'y: {y.shape}  y2: {y2.shape}  y_comb: {y_comb.shape}', self.verbose)

    def loss(self, output, target):
        if target.ndim == 2: _, target = target.max(dim=1)
        if self.training and self.pl_sw != 1:
            loss = (1 - self.pl_sw) * self.old_loss_func(output[:self.dls.train.bs], target[:self.dls.train.bs])
            loss += self.pl_sw * self.old_loss_func(output[self.dls.train.bs:], target[self.dls.train.bs:])
            return loss
        else:
            return self.old_loss_func(output, target)

    def after_fit(self):
        self.dls.train.after_batch = self.old_bt
        self.learn.loss_func = self.old_loss_func
        self.dls.train.bs = self.old_bs
        self.dls.bs = self.old_bs

from tsai.data.all import *
from tsai.models.all import *
from tsai.tslearner import *

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, return_split=False)
X = X.astype(np.float32)

pseudolabeled_data = X
soft_preds = True

pseudolabels = ToNumpyCategory()(y) if soft_preds else OneHot()(y)
dsets2 = TSDatasets(pseudolabeled_data, pseudolabels)
dl2 = TSDataLoader(dsets2, num_workers=0)
noisy_student_cb = NoisyStudent(dl2, bs=256, l2pl_ratio=2, verbose=True)
tfms = [None, TSClassification]
learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=[TSStandardize(), TSRandomSize(.5)], cbs=noisy_student_cb)
learn.fit_one_cycle(1)
# Output:
#   labels / pseudolabels per training batch              : 171 / 85

#   relative labeled/ pseudolabel sample weight in dataset: 4.0

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   X: torch.Size([171, 24, 51])  X2: torch.Size([85, 24, 51])  X_comb: torch.Size([256, 24, 41])

#   y: torch.Size([171])  y2: torch.Size([85])  y_comb: torch.Size([256])


pseudolabeled_data = X
soft_preds = False

pseudolabels = ToNumpyCategory()(y) if soft_preds else OneHot()(y)
pseudolabels = pseudolabels.astype(np.float32)
dsets2 = TSDatasets(pseudolabeled_data, pseudolabels)
dl2 = TSDataLoader(dsets2, num_workers=0)
noisy_student_cb = NoisyStudent(dl2, bs=256, l2pl_ratio=2, verbose=True)
tfms = [None, TSClassification]
learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=[TSStandardize(), TSRandomSize(.5)], cbs=noisy_student_cb)
learn.fit_one_cycle(1)
# Output:
#   labels / pseudolabels per training batch              : 171 / 85

#   relative labeled/ pseudolabel sample weight in dataset: 4.0

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   X: torch.Size([171, 24, 51])  X2: torch.Size([85, 24, 51])  X_comb: torch.Size([256, 24, 51])

#   y: torch.Size([171, 6])  y2: torch.Size([85, 6])  y_comb: torch.Size([256, 6])


#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/026_callback.noisy_student.ipynb saved at 2024-02-10 21:53:24

#   Correct notebook to script conversion! 😃

#   Saturday 10/02/24 21:53:27 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/027_callback.MVP.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp callback.MVP

"""
# MVP (aka TSBERT)
"""

"""
>Self-Supervised Pretraining of Time Series Models

Masked Value Predictor callback used to predict time series step values after a binary mask has been applied.
"""

#|export
from torch.distributions.geometric import Geometric
from torch.distributions.binomial import Binomial
from tsai.imports import *
from fastai.callback.all import *
from tsai.utils import *
from tsai.models.utils import *
from tsai.models.layers import *

#|export
def create_subsequence_mask(o, r=.15, lm=3, stateful=True, sync=False):
    if r <= 0: return torch.zeros_like(o).bool()
    device = o.device
    if o.ndim == 2: o = o[None]
    n_masks, mask_dims, mask_len = o.shape
    if sync == 'random': sync = random.random() > .5
    dims = 1 if sync else mask_dims
    if stateful: 
        numels = n_masks * dims * mask_len
        pm = torch.tensor([1 / lm], device=device)
        pu = torch.clip(pm * (r / max(1e-6, 1 - r)), 1e-3, 1)
        zot, proba_a, proba_b = (torch.as_tensor([False, True], device=device), pu, pm) if random.random() > pm else \
        (torch.as_tensor([True, False], device=device), pm, pu)
        max_len = max(1, 2 * torch.div(numels, (1/pm + 1/pu), rounding_mode='floor').long().item())
        for i in range(10):
            _dist_a = (Geometric(probs=proba_a).sample([max_len])+1).long()
            _dist_b = (Geometric(probs=proba_b).sample([max_len])+1).long()
            dist_a = _dist_a if i == 0 else torch.cat((dist_a, _dist_a), dim=0)
            dist_b = _dist_b if i == 0 else torch.cat((dist_b, _dist_b), dim=0)
            add = torch.add(dist_a, dist_b)
            if torch.gt(torch.sum(add), numels): break
        dist_len = torch.argmax((torch.cumsum(add, 0) >= numels).float()) + 1
        if dist_len%2: dist_len += 1
        repeats = torch.cat((dist_a[:dist_len], dist_b[:dist_len]), -1).flatten()
        zot = zot.repeat(dist_len)
        mask = torch.repeat_interleave(zot, repeats)[:numels].reshape(n_masks, dims, mask_len)
    else: 
        probs = torch.tensor(r, device=device)
        mask = Binomial(1, probs).sample((n_masks, dims, mask_len)).bool()
    if sync: mask = mask.repeat(1, mask_dims, 1)
    return mask

def create_variable_mask(o, r=.15):
    if r <= 0: return torch.zeros_like(o).bool()
    device = o.device
    n_masks, mask_dims, mask_len = o.shape
    _mask = torch.zeros((n_masks * mask_dims, mask_len), device=device)
    if int(mask_dims * r) > 0:
        n_masked_vars = int(n_masks * mask_dims * r)
        p = torch.tensor([1./(n_masks * mask_dims)], device=device).repeat([n_masks * mask_dims])
        sel_dims = p.multinomial(num_samples=n_masked_vars, replacement=False)
        _mask[sel_dims] = 1
    mask = _mask.reshape(*o.shape).bool()
    return mask

def create_future_mask(o, r=.15, sync=False):
    if r <= 0: return torch.zeros_like(o).bool()
    if o.ndim == 2: o = o[None]
    n_masks, mask_dims, mask_len = o.shape
    if sync == 'random': sync = random.random() > .5
    dims = 1 if sync else mask_dims
    probs = torch.tensor(r, device=o.device)
    mask = Binomial(1, probs).sample((n_masks, dims, mask_len))
    if sync: mask = mask.repeat(1, mask_dims, 1)
    mask = torch.sort(mask,dim=-1, descending=False)[0].bool()
    return mask

def self_mask(o): 
    mask1 = torch.isnan(o)
    mask2 = rotate_axis0(mask1)
    return torch.logical_and(mask2, ~mask1)

t = torch.rand(16, 3, 100)
mask = create_subsequence_mask(t, sync=False)
test_eq(mask.shape, t.shape)
mask = create_subsequence_mask(t, sync=True)
test_eq(mask.shape, t.shape)
mask = create_variable_mask(t)
test_eq(mask.shape, t.shape)
mask = create_future_mask(t)
test_eq(mask.shape, t.shape)

o = torch.randn(2, 3, 4)
o[o>.5] = np.nan
test_eq(torch.isnan(self_mask(o)).sum(), 0)

t = torch.rand(16, 30, 100)
mask = create_subsequence_mask(t, r=.15) # default settings
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'sample 0 subsequence mask (sync=False) - default mean: {mask[0].float().mean().item():.3f}')
plt.show()
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[1], cmap='cool')
plt.title(f'sample 1 subsequence mask (sync=False) - default mean: {mask[1].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(16, 30, 100)
mask = create_subsequence_mask(t, r=.5) # 50% of values masked
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'sample 0 subsequence mask (r=.5) mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(16, 30, 100)
mask = create_subsequence_mask(t, lm=5) # average length of mask = 5 
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'sample 0 subsequence mask (lm=5) mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(16, 30, 100)
mask = create_subsequence_mask(t, stateful=False) # individual time steps masked 
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'per sample subsequence mask (stateful=False) mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(1, 30, 100)
mask = create_subsequence_mask(t, sync=True) # all time steps masked simultaneously
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'per sample subsequence mask (sync=True) mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(1, 30, 100)
mask = create_variable_mask(t) # masked variables
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'per sample variable mask mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(1, 30, 100)
mask = create_future_mask(t, r=.15, sync=True) # masked steps
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'future mask mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

t = torch.rand(1, 30, 100)
mask = create_future_mask(t, r=.15, sync=False) # masked steps
mask = create_future_mask(t, r=.15, sync=True) # masked steps
test_eq(mask.dtype, torch.bool)
plt.figure(figsize=(10, 3))
plt.pcolormesh(mask[0], cmap='cool')
plt.title(f'future mask mean: {mask[0].float().mean().item():.3f}')
plt.show()
# Output:
#   <Figure size 1000x300 with 1 Axes>

#|export
def create_mask(o,  r=.15, lm=3, stateful=True, sync=False, subsequence_mask=True, variable_mask=False, future_mask=False):
    if r <= 0 or r >=1: return torch.zeros_like(o).bool()
    if int(r * o.shape[1]) == 0:
        variable_mask = False 
    if subsequence_mask and variable_mask:
        random_thr = 1/3 if sync == 'random' else 1/2
        if random.random() > random_thr: 
            variable_mask = False
        else:
            subsequence_mask = False 
    elif future_mask:
        return create_future_mask(o, r=r)
    elif subsequence_mask:
        return create_subsequence_mask(o, r=r, lm=lm, stateful=stateful, sync=sync)
    elif variable_mask:
        return create_variable_mask(o, r=r)
    else:
        raise ValueError('You need to set subsequence_mask, variable_mask or future_mask to True or pass a custom mask.')

#|export
import matplotlib.colors as mcolors


class MVP(Callback):
    order = 60

    def __init__(self, r: float = .15, subsequence_mask: bool = True, lm: float = 3., stateful: bool = True, sync: bool = False, variable_mask: bool = False,
                 future_mask: bool = False, custom_mask: Optional = None, sel_vars: Optional[list] = None, nan_to_num: int = 0, 
                 window_size: Optional[tuple] = None, dropout: float = .1, crit: callable = None, weights_path: Optional[str] = None, 
                 target_dir: str = './models/MVP', fname: str = 'model', save_best: bool = True,
                 verbose: bool = False):
        r"""
        Callback used to perform the pretext task of reconstruct the original data after a binary mask has been applied.

        Args:
            r:                proba of masking.
            subsequence_mask: apply a mask to random subsequences.
            lm:               average mask len when using stateful (geometric) masking.
            stateful:         geometric distribution is applied so that average mask length is lm.
            sync:             all variables have the same masking.
            variable_mask:    apply a mask to random variables. Only applicable to multivariate time series.
            future_mask:      used to train a forecasting model.
            custom_mask:      allows to pass any type of mask with input tensor and output tensor. Values to mask should be set to True.
            sel_vars:         allows to pass a list of variables to mask. If None, all variables will be masked.
            nan_to_num:       integer used to fill masked values
            window_size:      allows you to pass a fixed window size or tuple of window sizes to train MVP with on sequences of different length. 
                              You may pass int(s) or float(s).
            dropout:          dropout applied to the head of the model during pretraining.
            crit:             loss function that will be used. If None MSELossFlat().
            weights_path:     indicates the path to pretrained weights. This is useful when you want to continue training from a checkpoint. It will load the
                              pretrained weights to the model with the MVP head.
            target_dir :      directory where trained model will be stored.
            fname :           file name that will be used to save the pretrained model.
            save_best:        saves best model weights
    """
        assert subsequence_mask or variable_mask or future_mask or custom_mask, \
            'you must set (subsequence_mask and/or variable_mask) or future_mask to True or use a custom_mask'
        if custom_mask is not None and (future_mask or subsequence_mask or variable_mask):
            warnings.warn("Only custom_mask will be used")
        elif future_mask and (subsequence_mask or variable_mask):
            warnings.warn("Only future_mask will be used")
        store_attr("subsequence_mask,variable_mask,future_mask,custom_mask,dropout,r,lm,stateful,sync,crit,weights_path,fname,save_best,verbose,nan_to_num")
        self.PATH = Path(f'{target_dir}/{self.fname}')
        if not os.path.exists(self.PATH.parent):
            os.makedirs(self.PATH.parent)
        self.path_text = f"pretrained weights_path='{self.PATH}.pth'"
        self.window_size = window_size
        self.sel_vars = sel_vars

    def before_fit(self):
        self.run = not hasattr(self, "gather_preds")
        if 'SaveModelCallback' in [cb.__class__.__name__ for cb in self.learn.cbs]:
            self.save_best =  False # avoid saving if SaveModelCallback is being used
        if not(self.run): return

        # prepare to save best model
        self.best = float('inf')

        # modify loss for denoising task
        self.old_loss_func = self.learn.loss_func
        self.learn.loss_func = self._loss
        if self.crit is None: 
            self.crit = MSELossFlat()
        self.learn.MVP = self
        self.learn.TSBERT = self

        # remove and store metrics
        self.learn.metrics = L([])
        
        device = self.learn.dls.device
        
        if self.sel_vars is not None:
            self.sel_vars = torch.Tensor(listify(self.sel_vars)).long().to(device=device)

        # change head with conv layer (equivalent to linear layer applied to dim=1)
        assert hasattr(self.learn.model, "head"), "model must have a head attribute to be trained with MVP"
        self.learn.model.head = nn.Sequential(nn.Dropout(self.dropout),
                                              nn.Conv1d(self.learn.model.head_nf, self.learn.dls.vars, 1)
                                             ).to(device=device)
        if self.weights_path is not None:
            transfer_weights(self.learn.model, self.weights_path, device=device, exclude_head=False)

        with torch.no_grad():
            xb = torch.zeros(2, self.learn.dls.vars, self.learn.dls.len).to(device=device)
            assert xb.shape == self.learn.model(xb).shape, f'the model cannot reproduce the input shape {xb.shape}, {self.learn.model(xb).shape}'
            
        if self.window_size:
            if isinstance(self.window_size, float) or self.window_size == 1: 
                self.window_size = int(round(self.window_size * self.learn.dls.len))
            elif is_listy(self.window_size): 
                self.window_size = list(self.window_size)
                for i in range(len(self.window_size)):
                    if isinstance(self.window_size[i], float) or self.window_size[i] == 1: 
                        self.window_size[i] = int(round(self.window_size[i] * self.learn.dls.len))
        
    def before_batch(self):
        original_mask = torch.isnan(self.x)
        if self.custom_mask is not None:
            new_mask = self.custom_mask(self.x)
        else:
            new_mask = create_mask(self.x, r=self.r, lm=self.lm, stateful=self.stateful, sync=self.sync, subsequence_mask=self.subsequence_mask,
                                   variable_mask=self.variable_mask, future_mask=self.future_mask).bool()
        if original_mask.any(): 
            self.mask = torch.logical_and(new_mask, ~original_mask)
        else: 
            self.mask = new_mask
        
        if self.sel_vars is not None:
            self.mask[:, ~self.sel_vars] = 0
            
#         self.learn.yb = (torch.nan_to_num(self.x, self.nan_to_num),) # Only available in Pytorch 1.8
        self.learn.yb = (torch_nan_to_num(self.x, self.nan_to_num),)
        self.learn.xb = (self.yb[0].masked_fill(self.mask, self.nan_to_num), )
        if self.window_size:
            if is_listy(self.window_size): ws = np.random.randint(*self.window_size)
            else: ws = self.window_size
            w_start = np.random.randint(0, self.x.shape[-1] - ws)
            self.learn.xb = (self.learn.xb[0][..., w_start:w_start+ws], )
            self.learn.yb = (self.learn.yb[0][..., w_start:w_start+ws], )
            self.mask = self.mask[..., w_start:w_start+ws]

    def after_epoch(self):
        val = self.learn.recorder.values[-1][-1]
        if self.save_best:
            if np.less(val, self.best):
                self.best = val
                self.best_epoch = self.epoch
                torch.save(self.learn.model.state_dict(), f'{self.PATH}.pth')
                pv(f"best epoch: {self.best_epoch:3}  val_loss: {self.best:8.6f} - {self.path_text}", self.verbose or (self.epoch == self.n_epoch - 1))
            elif self.epoch == self.n_epoch - 1:
                print(f"\nepochs: {self.n_epoch} best epoch: {self.best_epoch:3}  val_loss: {self.best:8.6f} - {self.path_text}\n")

    def after_fit(self):
        self.run = True

    def _loss(self, preds, target):
        return self.crit(preds[self.mask], target[self.mask])

    def show_preds(self, max_n=9, nrows=3, ncols=3, figsize=None, sharex=True, **kwargs):
        b = self.learn.dls.valid.one_batch()
        self.learn._split(b)
        self.learn('before_batch')
        xb = self.xb[0].detach().cpu().numpy()
        bs, nvars, seq_len = xb.shape
        masked_pred = torch.where(self.mask, self.learn.model(*self.learn.xb), tensor([np.nan], device=self.learn.x.device))
        masked_pred = masked_pred.detach().cpu().numpy()
        ncols = min(ncols, math.ceil(bs / ncols))
        nrows = min(nrows, math.ceil(bs / ncols))
        max_n = min(max_n, bs, nrows*ncols)
        if figsize is None:
            figsize = (ncols*6, math.ceil(max_n/ncols)*4)
        fig, ax = plt.subplots(nrows=nrows, ncols=ncols,
                               figsize=figsize, sharex=sharex, **kwargs)
        idxs = np.random.permutation(np.arange(bs))
        colors = list(mcolors.TABLEAU_COLORS.keys()) + \
            random_shuffle(list(mcolors.CSS4_COLORS.keys()))
        i = 0
        for row in ax:
            for col in row:
                color_iter = iter(colors)
                for j in range(nvars):
                    try:
                        color = next(color_iter)
                    except:
                        color_iter = iter(colors)
                        color = next(color_iter)
                    col.plot(xb[idxs[i]][j], alpha=.5, color=color)
                    col.plot(masked_pred[idxs[i]][j],
                             marker='o', markersize=4, linestyle='None', color=color)
                i += 1
        plt.tight_layout()
        plt.show()
        
TSBERT = MVP

"""
# Experiments
"""

from tsai.data.external import get_UCR_data, check_data
from tsai.data.preprocessing import TSStandardize, TSNan2Value
from tsai.data.core import TSCategorize, get_ts_dls
from tsai.learner import ts_learner
from tsai.models.InceptionTimePlus import InceptionTimePlus

dsid = 'MoteStrain'
X, y, splits = get_UCR_data(dsid, split_data=False)
check_data(X, y, splits, False)
X[X<-1] = np.nan # This is to test the model works well even if nan values are passed through the dataloaders.
# Output:
#   X      - shape: [1272 samples x 1 features x 84 timesteps]  type: memmap  dtype:float32  isnan: 0

#   y      - shape: (1272,)  type: memmap  dtype:<U1  n_classes: 2 (636 samples per class) ['1', '2']  isnan: False

#   splits - n_splits: 2 shape: [20, 1252]  overlap: False


# Pre-train
tfms  = [None, [TSCategorize()]]
batch_tfms = [TSStandardize(by_var=True)]
unlabeled_dls = get_ts_dls(X, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
learn = ts_learner(unlabeled_dls, InceptionTimePlus, cbs=[MVP(fname=f'{dsid}', window_size=(.5, 1))]) # trained on variable window size
learn.fit_one_cycle(1, 3e-3)
# Output:
#   <IPython.core.display.HTML object>

learn = ts_learner(unlabeled_dls, InceptionTimePlus, cbs=[MVP(weights_path=f'models/MVP/{dsid}.pth')])
learn.fit_one_cycle(1, 3e-3)
# Output:
#   <IPython.core.display.HTML object>

learn.MVP.show_preds(sharey=True) # these preds are highly inaccurate as the model's been trained for just 1 epoch for testing purposes
# Output:
#   <Figure size 1800x1200 with 9 Axes>

# Fine-tune
tfms  = [None, [TSCategorize()]]
batch_tfms = [TSStandardize(by_var=True), TSNan2Value()]
labeled_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=64)
learn = ts_learner(labeled_dls, InceptionTimePlus, pretrained=True, weights_path=f'models/MVP/{dsid}.pth', metrics=accuracy)
learn.fit_one_cycle(1)
# Output:
#   <IPython.core.display.HTML object>

tfms  = [None, [TSCategorize()]]
batch_tfms = [TSStandardize(by_var=True), TSNan2Value()]
unlabeled_dls = get_ts_dls(X, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=64)
fname = f'{dsid}_test'
mvp = MVP(subsequence_mask=True, sync='random', variable_mask=True, future_mask=True, fname=fname)
learn = ts_learner(unlabeled_dls, InceptionTimePlus, metrics=accuracy, cbs=mvp) # Metrics will not be used!
# Output:
#   /Users/nacho/opt/anaconda3/envs/py37torch113/lib/python3.7/site-packages/ipykernel_launcher.py:42: UserWarning: Only future_mask will be used


tfms  = [None, [TSCategorize()]]
batch_tfms = [TSStandardize(by_var=True)]
unlabeled_dls = get_ts_dls(X, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=64)
fname = f'{dsid}_test'
mvp = MVP(subsequence_mask=True, sync='random', variable_mask=True, future_mask=True, custom_mask=partial(create_future_mask, r=.15),
                fname=fname)
learn = ts_learner(unlabeled_dls, InceptionTimePlus, metrics=accuracy, cbs=mvp) # Metrics will not be used!
# Output:
#   /Users/nacho/opt/anaconda3/envs/py37torch113/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Only custom_mask will be used


try: os.remove("models/MVP/MoteStrain.pth")
except OSError: pass
try: os.remove("models/MVP/model.pth")
except OSError: pass

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/027_callback.MVP.ipynb saved at 2023-02-17 19:39:04

#   Correct notebook to script conversion! 😃

#   Friday 17/02/23 19:39:07 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/029_models.layers.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.layers

"""
# Layers
"""

"""
>Helper functions used to build PyTorch timeseries models.
"""

#|export
from torch.jit import TracerWarning
import warnings
from torch.nn.utils import weight_norm, spectral_norm
from torch.nn.init import normal_
from fastcore.basics import snake2camel
from fastcore.test import test_eq
from fastai.layers import *
from fastai.losses import *
from tsai.imports import *
from tsai.utils import *

warnings.filterwarnings("ignore", category=TracerWarning)

#|export
def test_module_to_torchscript(
    m:torch.nn.Module, # The PyTorch module to be tested.
    inputs:Tensor, # A tensor or tuple of tensors representing the inputs to the model.
    trace:bool=True, #  If `True`, attempts to trace the model. Defaults to `True`.
    script:bool=True, # If `True`, attempts to script the model. Defaults to `True`.
    serialize:bool=True, # If `True`, saves and loads the traced/scripted module to ensure it can be serialized. Defaults to `True`.
    verbose:bool=True, # If `True`, prints detailed information about the tracing and scripting process. Defaults to `True`.
):
    "Tests if a PyTorch module can be correctly traced or scripted and serialized"

    m = m.eval()
    m_name = m.__class__.__name__

    # Ensure inputs are in a tuple or list format
    inp_is_tuple = isinstance(inputs, (tuple, list))

    # Get the model's output
    output = m(*inputs) if inp_is_tuple else m(inputs)
    output_shapes = output.shape if not isinstance(output, (tuple, list)) else [o.shape for o in output]
    if verbose:
        print(f"output.shape: {output_shapes}")

    # Try tracing the model
    if trace:
        if verbose:
            print("Tracing...")
        try:
            traced_m = torch.jit.trace(m, inputs)
            if serialize:
                file_path = Path(f"test_traced_{m_name}.pt")
                torch.jit.save(traced_m, file_path)
                traced_mod = torch.jit.load(file_path)
                file_path.unlink()
            traced_output = traced_m(*inputs) if inp_is_tuple else traced_m(inputs)
            torch.testing.assert_close(traced_output, output)
            if verbose:
                print(f"...{m_name} has been successfully traced 😃\n")
            return True
        except Exception as e:
            if verbose:
                print(f"{m_name} cannot be traced 😔")
                print(e)
                print("\n")

    # Try scripting the model
    if script:
        if verbose:
            print("Scripting...")
        try:
            scripted_m = torch.jit.script(m)
            if serialize:
                file_path = Path(f"test_scripted_{m_name}.pt")
                torch.jit.save(scripted_m, file_path)
                scripted_mod = torch.jit.load(file_path)
                file_path.unlink()
            scripted_output = scripted_m(*inputs) if inp_is_tuple else scripted_m(inputs)
            torch.testing.assert_close(scripted_output, output)
            if verbose:
                print(f"...{m_name} has been successfully scripted 😃\n")
            return True
        except Exception as e:
            if verbose:
                print(f"{m_name} cannot be scripted 😔")
                print(e)

    return False

m = nn.Linear(10, 2)
inp = torch.randn(3, 10)
test_module_to_torchscript(m, inp, trace=True, script=True, serialize=True, verbose=True)
# Output:
#   output.shape: torch.Size([3, 2])

#   Tracing...

#   ...Linear has been successfully traced 😃

#   

#   True

#|export
def init_lin_zero(m):
    if isinstance(m, (nn.Linear)):
        if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)
        nn.init.constant_(m.weight, 0)
    for l in m.children(): init_lin_zero(l)

lin_zero_init = init_lin_zero

#|export
class SwishBeta(Module):
    def __multiinit__(self, beta=1.):
        self.sigmoid = torch.sigmoid
        self.beta = nn.Parameter(torch.Tensor(1).fill_(beta))
    def forward(self, x): return x.mul(self.sigmoid(x*self.beta))

#|export
class SmeLU(nn.Module):
    "Smooth ReLU activation function based on https://arxiv.org/pdf/2202.06499.pdf"

    def __init__(self,
        beta: float = 2. # Beta value
        ) -> None:
        super().__init__()
        self.beta = abs(beta)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return torch.where(torch.abs(x) <= self.beta, ((x + self.beta) ** 2) / (4. * self.beta), F.relu(x))

#|export
class Chomp1d(nn.Module):
    def __init__(self, chomp_size):
        super(Chomp1d, self).__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        return x[:, :, :-self.chomp_size].contiguous()

#|export
def same_padding1d(seq_len, ks, stride=1, dilation=1):
    "Same padding formula as used in Tensorflow"
    p = (seq_len - 1) * stride + (ks - 1) * dilation + 1 - seq_len
    return p // 2, p - p // 2


class Pad1d(nn.ConstantPad1d):
    def __init__(self, padding, value=0.):
        super().__init__(padding, value)


# @delegates(nn.Conv1d.__init__)
class SameConv1d(Module):
    "Conv1d with padding='same'"
    def __init__(self, ni, nf, ks=3, stride=1, dilation=1, **kwargs):
        self.ks, self.stride, self.dilation = ks, stride, dilation
        self.conv1d_same = nn.Conv1d(ni, nf, ks, stride=stride, dilation=dilation, **kwargs)
        self.weight = self.conv1d_same.weight
        self.bias = self.conv1d_same.bias
        self.pad = Pad1d

    def forward(self, x):
        self.padding = same_padding1d(x.shape[-1], self.ks, dilation=self.dilation) #stride=self.stride not used in padding calculation!
        return self.conv1d_same(self.pad(self.padding)(x))

#|export
def same_padding2d(H, W, ks, stride=(1, 1), dilation=(1, 1)):
    "Same padding formula as used in Tensorflow"
    if isinstance(ks, Integral): ks = (ks, ks)
    if ks[0] == 1:  p_h = 0
    else:  p_h = (H - 1) * stride[0] + (ks[0] - 1) * dilation[0] + 1 - H
    if ks[1] == 1:  p_w = 0
    else:  p_w = (W - 1) * stride[1] + (ks[1] - 1) * dilation[1] + 1 - W
    return (p_w // 2, p_w - p_w // 2, p_h // 2, p_h - p_h // 2)


class Pad2d(nn.ConstantPad2d):
    def __init__(self, padding, value=0.):
        super().__init__(padding, value)


# @delegates(nn.Conv2d.__init__)
class Conv2dSame(Module):
    "Conv2d with padding='same'"
    def __init__(self, ni, nf, ks=(3, 3), stride=(1, 1), dilation=(1, 1), **kwargs):
        if isinstance(ks, Integral): ks = (ks, ks)
        if isinstance(stride, Integral): stride = (stride, stride)
        if isinstance(dilation, Integral): dilation = (dilation, dilation)
        self.ks, self.stride, self.dilation = ks, stride, dilation
        self.conv2d_same = nn.Conv2d(ni, nf, ks, stride=stride, dilation=dilation, **kwargs)
        self.weight = self.conv2d_same.weight
        self.bias = self.conv2d_same.bias
        self.pad = Pad2d

    def forward(self, x):
        self.padding = same_padding2d(x.shape[-2], x.shape[-1], self.ks, dilation=self.dilation) #stride=self.stride not used in padding calculation!
        return self.conv2d_same(self.pad(self.padding)(x))


# @delegates(nn.Conv2d.__init__)
def Conv2d(ni, nf, kernel_size=None, ks=None, stride=1, padding='same', dilation=1, init='auto', bias_std=0.01, **kwargs):
    "conv1d layer with padding='same', 'valid', or any integer (defaults to 'same')"
    assert not (kernel_size and ks), 'use kernel_size or ks but not both simultaneously'
    assert kernel_size is not None or ks is not None, 'you need to pass a ks'
    kernel_size = kernel_size or ks
    if padding == 'same':
        conv = Conv2dSame(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)
    elif padding == 'valid': conv = nn.Conv2d(ni, nf, kernel_size, stride=stride, padding=0, dilation=dilation, **kwargs)
    else: conv = nn.Conv2d(ni, nf, kernel_size, stride=stride, padding=padding, dilation=dilation, **kwargs)
    init_linear(conv, None, init=init, bias_std=bias_std)
    return conv

bs = 2
c_in = 3
c_out = 5
h = 16
w = 20
t = torch.rand(bs, c_in, h, w)
test_eq(Conv2dSame(c_in, c_out, ks=3, stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))
test_eq(Conv2dSame(c_in, c_out, ks=(3, 1), stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))
test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(1, 1), dilation=(2, 2), bias=False)(t).shape, (bs, c_out, h, w))
test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(2, 2), dilation=(1, 1), bias=False)(t).shape, (bs, c_out, h//2, w//2))
test_eq(Conv2dSame(c_in, c_out, ks=3, stride=(2, 2), dilation=(2, 2), bias=False)(t).shape, (bs, c_out, h//2, w//2))
test_eq(Conv2d(c_in, c_out, ks=3, padding='same', stride=1, dilation=1, bias=False)(t).shape, (bs, c_out, h, w))

#|export
class CausalConv1d(torch.nn.Conv1d):
    def __init__(self, ni, nf, ks, stride=1, dilation=1, groups=1, bias=True):
        super(CausalConv1d, self).__init__(ni, nf, kernel_size=ks, stride=stride, padding=0, dilation=dilation, groups=groups, bias=bias)
        self.__padding = (ks - 1) * dilation
    def forward(self, input):
        return super(CausalConv1d, self).forward(F.pad(input, (self.__padding, 0)))

#|export
# @delegates(nn.Conv1d.__init__)
def Conv1d(ni, nf, kernel_size=None, ks=None, stride=1, padding='same', dilation=1, init='auto', bias_std=0.01, **kwargs):
    "conv1d layer with padding='same', 'causal', 'valid', or any integer (defaults to 'same')"
    assert not (kernel_size and ks), 'use kernel_size or ks but not both simultaneously'
    assert kernel_size is not None or ks is not None, 'you need to pass a ks'
    kernel_size = kernel_size or ks
    if padding == 'same':
        if kernel_size%2==1:
            conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=kernel_size//2 * dilation, dilation=dilation, **kwargs)
        else:
            conv = SameConv1d(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)
    elif padding == 'causal': conv = CausalConv1d(ni, nf, kernel_size, stride=stride, dilation=dilation, **kwargs)
    elif padding == 'valid': conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=0, dilation=dilation, **kwargs)
    else: conv = nn.Conv1d(ni, nf, kernel_size, stride=stride, padding=padding, dilation=dilation, **kwargs)
    init_linear(conv, None, init=init, bias_std=bias_std)
    return conv

bs = 2
c_in = 3
c_out = 5
seq_len = 512
t = torch.rand(bs, c_in, seq_len)
dilation = 1
test_eq(CausalConv1d(c_in, c_out, ks=3, dilation=dilation)(t).shape, Conv1d(c_in, c_out, ks=3, padding="same", dilation=dilation)(t).shape)
dilation = 2
test_eq(CausalConv1d(c_in, c_out, ks=3, dilation=dilation)(t).shape, Conv1d(c_in, c_out, ks=3, padding="same", dilation=dilation)(t).shape)

bs = 2
ni = 3
nf = 5
seq_len = 6
ks = 3
t = torch.rand(bs, c_in, seq_len)
test_eq(Conv1d(ni, nf, ks, padding=0)(t).shape, (bs, c_out, seq_len - (2 * (ks//2))))
test_eq(Conv1d(ni, nf, ks, padding='valid')(t).shape, (bs, c_out, seq_len - (2 * (ks//2))))
test_eq(Conv1d(ni, nf, ks, padding='same')(t).shape, (bs, c_out, seq_len))
test_eq(Conv1d(ni, nf, ks, padding='causal')(t).shape, (bs, c_out, seq_len))
test_error('use kernel_size or ks but not both simultaneously', Conv1d, ni, nf, kernel_size=3, ks=3)
test_error('you need to pass a ks', Conv1d, ni, nf)

conv = Conv1d(ni, nf, ks, padding='same')
init_linear(conv, None, init='auto', bias_std=.01)
conv
# Output:
#   Conv1d(3, 5, kernel_size=(3,), stride=(1,), padding=(1,))

conv = Conv1d(ni, nf, ks, padding='causal')
init_linear(conv, None, init='auto', bias_std=.01)
conv
# Output:
#   CausalConv1d(3, 5, kernel_size=(3,), stride=(1,))

conv = Conv1d(ni, nf, ks, padding='valid')
init_linear(conv, None, init='auto', bias_std=.01)
weight_norm(conv)
conv
# Output:
#   Conv1d(3, 5, kernel_size=(3,), stride=(1,))

conv = Conv1d(ni, nf, ks, padding=0)
init_linear(conv, None, init='auto', bias_std=.01)
weight_norm(conv)
conv
# Output:
#   Conv1d(3, 5, kernel_size=(3,), stride=(1,))

#|export
class SeparableConv1d(Module):
    def __init__(self, ni, nf, ks, stride=1, padding='same', dilation=1, bias=True, bias_std=0.01):
        self.depthwise_conv = Conv1d(ni, ni, ks, stride=stride, padding=padding, dilation=dilation, groups=ni, bias=bias)
        self.pointwise_conv = nn.Conv1d(ni, nf, 1, stride=1, padding=0, dilation=1, groups=1, bias=bias)
        if bias:
            if bias_std != 0:
                normal_(self.depthwise_conv.bias, 0, bias_std)
                normal_(self.pointwise_conv.bias, 0, bias_std)
            else:
                self.depthwise_conv.bias.data.zero_()
                self.pointwise_conv.bias.data.zero_()

    def forward(self, x):
        x = self.depthwise_conv(x)
        x = self.pointwise_conv(x)
        return x

bs = 64
c_in = 6
c_out = 5
seq_len = 512
t = torch.rand(bs, c_in, seq_len)
test_eq(SeparableConv1d(c_in, c_out, 3)(t).shape, (bs, c_out, seq_len))

#|export
class AddCoords1d(Module):
    """Add coordinates to ease position identification without modifying mean and std"""
    def forward(self, x):
        bs, _, seq_len = x.shape
        cc = torch.linspace(-1,1,x.shape[-1], device=x.device).repeat(bs, 1, 1)
        cc = (cc - cc.mean()) / cc.std()
        x = torch.cat([x, cc], dim=1)
        return x

bs = 2
c_in = 3
c_out = 5
seq_len = 50

t = torch.rand(bs, c_in, seq_len)
t = (t - t.mean()) / t.std()
test_eq(AddCoords1d()(t).shape, (bs, c_in + 1, seq_len))
new_t = AddCoords1d()(t)
test_close(new_t.mean(),0, 1e-2)
test_close(new_t.std(), 1, 1e-2)

#|export
class ConvBlock(nn.Sequential):
    "Create a sequence of conv1d (`ni` to `nf`), activation (if `act_cls`) and `norm_type` layers."
    def __init__(self, ni, nf, kernel_size=None, ks=3, stride=1, padding='same', bias=None, bias_std=0.01, norm='Batch', zero_norm=False, bn_1st=True,
                 act=nn.ReLU, act_kwargs={}, init='auto', dropout=0., xtra=None, coord=False, separable=False,  **kwargs):
        kernel_size = kernel_size or ks
        ndim = 1
        layers = [AddCoords1d()] if coord else []
        norm_type = getattr(NormType,f"{snake2camel(norm)}{'Zero' if zero_norm else ''}") if norm is not None else None
        bn = norm_type in (NormType.Batch, NormType.BatchZero)
        inn = norm_type in (NormType.Instance, NormType.InstanceZero)
        if bias is None: bias = not (bn or inn)
        if separable: conv = SeparableConv1d(ni + coord, nf, ks=kernel_size, bias=bias, stride=stride, padding=padding, **kwargs)
        else: conv = Conv1d(ni + coord, nf, ks=kernel_size, bias=bias, stride=stride, padding=padding, **kwargs)
        act = None if act is None else act(**act_kwargs)
        if not separable: init_linear(conv, act, init=init, bias_std=bias_std)
        if   norm_type==NormType.Weight:   conv = weight_norm(conv)
        elif norm_type==NormType.Spectral: conv = spectral_norm(conv)
        layers += [conv]
        act_bn = []
        if act is not None: act_bn.append(act)
        if bn: act_bn.append(BatchNorm(nf, norm_type=norm_type, ndim=ndim))
        if inn: act_bn.append(InstanceNorm(nf, norm_type=norm_type, ndim=ndim))
        if bn_1st: act_bn.reverse()
        if dropout: layers += [nn.Dropout(dropout)]
        layers += act_bn
        if xtra: layers.append(xtra)
        super().__init__(*layers)

Conv = named_partial('Conv', ConvBlock, norm=None, act=None)
ConvBN = named_partial('ConvBN', ConvBlock, norm='Batch', act=None)
CoordConv = named_partial('CoordConv', ConvBlock, norm=None, act=None, coord=True)
SepConv = named_partial('SepConv', ConvBlock, norm=None, act=None, separable=True)

#|export
class ResBlock1dPlus(Module):
    "Resnet block from `ni` to `nh` with `stride`"
#     @delegates(ConvLayer.__init__)
    def __init__(self, expansion, ni, nf, coord=False, stride=1, groups=1, reduction=None, nh1=None, nh2=None, dw=False, g2=1,
                 sa=False, sym=False, norm='Batch', zero_norm=True, act_cls=defaults.activation, ks=3,
                 pool=AvgPool, pool_first=True, **kwargs):
        if nh2 is None: nh2 = nf
        if nh1 is None: nh1 = nh2
        nf,ni = nf*expansion,ni*expansion
        k0 = dict(norm=norm, zero_norm=False, act=act_cls, **kwargs)
        k1 = dict(norm=norm, zero_norm=zero_norm, act=None, **kwargs)
        convpath  = [ConvBlock(ni,  nh2, ks, coord=coord, stride=stride, groups=ni if dw else groups, **k0),
                     ConvBlock(nh2,  nf, ks, coord=coord, groups=g2, **k1)
        ] if expansion == 1 else [
                     ConvBlock(ni,  nh1, 1, coord=coord, **k0),
                     ConvBlock(nh1, nh2, ks, coord=coord, stride=stride, groups=nh1 if dw else groups, **k0),
                     ConvBlock(nh2,  nf, 1, coord=coord, groups=g2, **k1)]
        if reduction: convpath.append(SEModule(nf, reduction=reduction, act_cls=act_cls))
        if sa: convpath.append(SimpleSelfAttention(nf,ks=1,sym=sym))
        self.convpath = nn.Sequential(*convpath)
        idpath = []
        if ni!=nf: idpath.append(ConvBlock(ni, nf, 1, coord=coord, act=None, **kwargs))
        if stride!=1: idpath.insert((1,0)[pool_first], pool(stride, ndim=1, ceil_mode=True))
        self.idpath = nn.Sequential(*idpath)
        self.act = defaults.activation(inplace=True) if act_cls is defaults.activation else act_cls()

    def forward(self, x): return self.act(self.convpath(x) + self.idpath(x))

#|export
def SEModule1d(ni, reduction=16, act=nn.ReLU, act_kwargs={}):
    "Squeeze and excitation module for 1d"
    nf = math.ceil(ni//reduction/8)*8
    assert nf != 0, 'nf cannot be 0'
    return SequentialEx(nn.AdaptiveAvgPool1d(1),
                        ConvBlock(ni, nf, ks=1, norm=None, act=act, act_kwargs=act_kwargs),
                        ConvBlock(nf, ni, ks=1, norm=None, act=nn.Sigmoid), ProdLayer())

t = torch.rand(8, 32, 12)
test_eq(SEModule1d(t.shape[1], 16, act=nn.ReLU, act_kwargs={})(t).shape, t.shape)

#|export
def Norm(nf, ndim=1, norm='Batch', zero_norm=False, init=True, **kwargs):
    "Norm layer with `nf` features and `ndim` with auto init."
    assert 1 <= ndim <= 3
    nl = getattr(nn, f"{snake2camel(norm)}Norm{ndim}d")(nf, **kwargs)
    if nl.affine and init:
        nl.bias.data.fill_(1e-3)
        nl.weight.data.fill_(0. if zero_norm else 1.)
    return nl

BN1d = partial(Norm, ndim=1, norm='Batch')
IN1d = partial(Norm, ndim=1, norm='Instance')

bs = 2
ni = 3
nf = 5
sl = 4
ks = 5

t = torch.rand(bs, ni, sl)
test_eq(ConvBlock(ni, nf, ks)(t).shape, (bs, nf, sl))
test_eq(ConvBlock(ni, nf, ks, padding='causal')(t).shape, (bs, nf, sl))
test_eq(ConvBlock(ni, nf, ks, coord=True)(t).shape, (bs, nf, sl))

test_eq(BN1d(ni)(t).shape, (bs, ni, sl))
test_eq(BN1d(ni).weight.data.mean().item(), 1.)
test_eq(BN1d(ni, zero_norm=True).weight.data.mean().item(), 0.)

test_eq(ConvBlock(ni, nf, ks, norm='batch', zero_norm=True)[1].weight.data.unique().item(), 0)
test_ne(ConvBlock(ni, nf, ks, norm='batch', zero_norm=False)[1].weight.data.unique().item(), 0)
test_eq(ConvBlock(ni, nf, ks, bias=False)[0].bias, None)
ConvBlock(ni, nf, ks, act=Swish, coord=True)
# Output:
#   ConvBlock(

#     (0): AddCoords1d()

#     (1): Conv1d(4, 5, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)

#     (2): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (3): SiLU()

#   )

#|export
class LinLnDrop(nn.Sequential):
    "Module grouping `LayerNorm1d`, `Dropout` and `Linear` layers"
    def __init__(self, n_in, n_out, ln=True, p=0., act=None, lin_first=False):
        layers = [nn.LayerNorm(n_out if lin_first else n_in)] if ln else []
        if p != 0: layers.append(nn.Dropout(p))
        lin = [nn.Linear(n_in, n_out, bias=not ln)]
        if act is not None: lin.append(act)
        layers = lin+layers if lin_first else layers+lin
        super().__init__(*layers)

LinLnDrop(2, 3, p=.5)
# Output:
#   LinLnDrop(

#     (0): LayerNorm((2,), eps=1e-05, elementwise_affine=True)

#     (1): Dropout(p=0.5, inplace=False)

#     (2): Linear(in_features=2, out_features=3, bias=False)

#   )

#|export
class LambdaPlus(Module):
    def __init__(self, func, *args, **kwargs): self.func,self.args,self.kwargs=func,args,kwargs
    def forward(self, x): return self.func(x, *self.args, **self.kwargs)

#|export
class Squeeze(Module):
    def __init__(self, dim=-1): self.dim = dim
    def forward(self, x): return x.squeeze(dim=self.dim)
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class Unsqueeze(Module):
    def __init__(self, dim=-1): self.dim = dim
    def forward(self, x): return x.unsqueeze(dim=self.dim)
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class Add(Module):
    def forward(self, x, y): return x.add(y)
    def __repr__(self): return f'{self.__class__.__name__}'


class Concat(Module):
    def __init__(self, dim=1): self.dim = dim
    def forward(self, *x): return torch.cat(*x, dim=self.dim)
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class Unfold(Module):
    def __init__(self, dim, size, step=1): self.dim, self.size, self.step =  dim, size, step
    def forward(self, x:Tensor) -> Tensor: return x.unfold(dimension=self.dim, size=self.size, step=self.step)
    def __repr__(self): return f"{self.__class__.__name__}(dim={self.dim}, size={self.size}, step={self.step})"


class Permute(Module):
    def __init__(self, *dims): self.dims = dims
    def forward(self, x:Tensor) -> Tensor: return x.permute(self.dims)
    def __repr__(self): return f"{self.__class__.__name__}(dims={', '.join([str(d) for d in self.dims])})"


class Transpose(Module):
    def __init__(self, *dims, contiguous=True): self.dims, self.contiguous = dims, contiguous
    def forward(self, x):
        x = x.contiguous()
        if self.contiguous: return x.transpose(*self.dims).contiguous()
        else: return x.transpose(*self.dims)
    def __repr__(self):
        if self.contiguous: return f"{self.__class__.__name__}(dims={', '.join([str(d) for d in self.dims])}).contiguous()"
        else: return f"{self.__class__.__name__}({', '.join([str(d) for d in self.dims])})"


class View(Module):
    def __init__(self, *shape): self.shape = shape
    def forward(self, x):
        return x.view(x.shape[0], -1).contiguous() if not self.shape else x.view(-1).contiguous() if self.shape == (-1,) else \
            x.view(x.shape[0], *self.shape).contiguous()
    def __repr__(self): return f"{self.__class__.__name__}({', '.join(['bs'] + [str(s) for s in self.shape])})"


class Reshape(Module):
    def __init__(self, *shape): self.shape = shape
    def forward(self, x):
        return x.contiguous().reshape(x.shape[0], -1) if not self.shape else x.contiguous().reshape(-1) if self.shape == (-1,) else x.contiguous().reshape(x.shape[0], *self.shape)
    def __repr__(self): return f"{self.__class__.__name__}({', '.join(['bs'] + [str(s) for s in self.shape])})"


class Max(Module):
    def __init__(self, dim=None, keepdim=False): self.dim, self.keepdim = dim, keepdim
    def forward(self, x): return x.max(self.dim, keepdim=self.keepdim)[0]
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim}, keepdim={self.keepdim})'


class LastStep(Module):
    def forward(self, x): return x[..., -1]
    def __repr__(self): return f'{self.__class__.__name__}()'


class SoftMax(Module):
    "SoftMax layer"
    def __init__(self, dim=-1):
        self.dim = dim
    def forward(self, x):
        return F.softmax(x, dim=self.dim)
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class Clamp(Module):
    def __init__(self, min=None, max=None):
        self.min, self.max = min, max
    def forward(self, x):
        return x.clamp(min=self.min, max=self.max)
    def __repr__(self): return f'{self.__class__.__name__}(min={self.min}, max={self.max})'


class Clip(Module):
    def __init__(self, min=None, max=None):
        self.min, self.max = min, max

    def forward(self, x):
        if self.min is not None:
            x = torch.maximum(x, self.min)
        if self.max is not None:
            x = torch.minimum(x, self.max)
        return x
    def __repr__(self): return f'{self.__class__.__name__}()'


class ReZero(Module):
    def __init__(self, module):
        self.module = module
        self.alpha = nn.Parameter(torch.zeros(1))
    def forward(self, x):
        return x + self.alpha * self.module(x)


Noop = nn.Sequential()

bs = 2
nf = 5
sl = 4

t = torch.rand(bs, nf, sl)
test_eq(Permute(0,2,1)(t).shape, (bs, sl, nf))
test_eq(Max(1)(t).shape, (bs, sl))
test_eq(Transpose(1,2)(t).shape, (bs, sl, nf))
test_eq(Transpose(1,2, contiguous=True)(t).shape, (bs, sl, nf))
test_eq(View(-1, 2, 10)(t).shape, (bs, 1, 2, 10))
test_eq(Reshape(-1, 2, 10)(t).shape, (bs, 1, 2, 10))
test_eq(Reshape()(t).shape, (2, 20))
test_eq(Reshape(-1)(t).shape, (40,))
Transpose(1,2), Permute(0,2,1), View(-1, 2, 10), Transpose(1,2, contiguous=True), Reshape(-1, 2, 10), Noop
# Output:
#   (Transpose(dims=1, 2).contiguous(),

#    Permute(dims=0, 2, 1),

#    View(bs, -1, 2, 10),

#    Transpose(dims=1, 2).contiguous(),

#    Reshape(bs, -1, 2, 10),

#    Sequential())

#|export
class DropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).

    It's similar to Dropout but it drops individual connections instead of nodes.
    Original code in https://github.com/rwightman/pytorch-image-models (timm library)
    """

    def __init__(self, p=None):
        super().__init__()
        self.p = p

    def forward(self, x):
        if self.p == 0. or not self.training: return x
        keep_prob = 1 - self.p
        shape = (x.shape[0],) + (1,) * (x.ndim - 1)
        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
        random_tensor.floor_()
        output = x.div(keep_prob) * random_tensor
#         output = x.div(random_tensor.mean()) * random_tensor # divide by the actual mean to mantain the input mean?
        return output

t = torch.ones(100,2,3)
test_eq(DropPath(0.)(t), t)
assert DropPath(0.5)(t).max() >= 1

#|export
class Sharpen(Module):
    "This is used to increase confidence in predictions - MixMatch paper"
    def __init__(self, T=.5): self.T = T
    def forward(self, x):
        x = x**(1. / self.T)
        return x / x.sum(dim=1, keepdims=True)

n_samples = 1000
n_classes = 3

t = (torch.rand(n_samples, n_classes) - .5) * 10
probas = F.softmax(t, -1)
sharpened_probas = Sharpen()(probas)
plt.plot(probas.flatten().sort().values, color='r')
plt.plot(sharpened_probas.flatten().sort().values, color='b')
plt.show()
test_gt(sharpened_probas[n_samples//2:].max(-1).values.sum().item(), probas[n_samples//2:].max(-1).values.sum().item())
# Output:
#   <Figure size 640x480 with 1 Axes>

#|export
class Sequential(nn.Sequential):
    """Class that allows you to pass one or multiple inputs"""
    def forward(self, *x):
        for i, module in enumerate(self._modules.values()):
            x = module(*x) if isinstance(x, (list, tuple, L)) else module(x)
        return x

#|export
class TimeDistributed(nn.Module):
    def __init__(self, module, batch_first=False):
        super(TimeDistributed, self).__init__()
        self.module = module
        self.batch_first = batch_first

    def forward(self, x):

        if len(x.size()) <= 2:
            return self.module(x)

        # Squash samples and timesteps into a single axis
        x_reshape = x.contiguous().reshape(-1, x.size(-1))  # (samples * timesteps, input_size)

        y = self.module(x_reshape)

        # We have to reshape Y
        if self.batch_first:
            y = y.contiguous().reshape(x.size(0), -1, y.size(-1))  # (samples, timesteps, output_size)
        else:
            y = y.reshape(-1, x.size(1), y.size(-1))  # (timesteps, samples, output_size)

        return y

#|export
class Temp_Scale(Module):
    "Used to perform Temperature Scaling (dirichlet=False) or Single-parameter Dirichlet calibration (dirichlet=True)"
    def __init__(self, temp=1., dirichlet=False):
        self.weight = nn.Parameter(tensor(temp))
        self.bias = None
        self.log_softmax = dirichlet

    def forward(self, x):
        if self.log_softmax: x = F.log_softmax(x, dim=-1)
        return x.div(self.weight)


class Vector_Scale(Module):
    "Used to perform Vector Scaling (dirichlet=False) or Diagonal Dirichlet calibration (dirichlet=True)"
    def __init__(self, n_classes=1, dirichlet=False):
        self.weight = nn.Parameter(torch.ones(n_classes))
        self.bias = nn.Parameter(torch.zeros(n_classes))
        self.log_softmax = dirichlet

    def forward(self, x):
        if self.log_softmax: x = F.log_softmax(x, dim=-1)
        return x.mul(self.weight).add(self.bias)


class Matrix_Scale(Module):
    "Used to perform Matrix Scaling (dirichlet=False) or Dirichlet calibration (dirichlet=True)"
    def __init__(self, n_classes=1, dirichlet=False):
        self.ms = nn.Linear(n_classes, n_classes)
        self.ms.weight.data = nn.Parameter(torch.eye(n_classes))
        nn.init.constant_(self.ms.bias.data, 0.)
        self.weight = self.ms.weight
        self.bias = self.ms.bias
        self.log_softmax = dirichlet

    def forward(self, x):
        if self.log_softmax: x = F.log_softmax(x, dim=-1)
        return self.ms(x)


def get_calibrator(calibrator=None, n_classes=1, **kwargs):
    if calibrator is None or not calibrator: return noop
    elif calibrator.lower() == 'temp': return Temp_Scale(dirichlet=False, **kwargs)
    elif calibrator.lower() == 'vector': return Vector_Scale(n_classes=n_classes, dirichlet=False, **kwargs)
    elif calibrator.lower() == 'matrix': return Matrix_Scale(n_classes=n_classes, dirichlet=False, **kwargs)
    elif calibrator.lower() == 'dtemp': return Temp_Scale(dirichlet=True, **kwargs)
    elif calibrator.lower() == 'dvector': return Vector_Scale(n_classes=n_classes, dirichlet=True, **kwargs)
    elif calibrator.lower() == 'dmatrix': return Matrix_Scale(n_classes=n_classes, dirichlet=True, **kwargs)
    else: assert False, f'please, select a correct calibrator instead of {calibrator}'

bs = 2
c_out = 3

t = torch.rand(bs, c_out)
for calibrator, cal_name in zip(['temp', 'vector', 'matrix'], ['Temp_Scale', 'Vector_Scale', 'Matrix_Scale']):
    cal = get_calibrator(calibrator, n_classes=c_out)
#     print(calibrator)
#     print(cal.weight, cal.bias, '\n')
    test_eq(cal(t), t)
    test_eq(cal.__class__.__name__, cal_name)
for calibrator, cal_name in zip(['dtemp', 'dvector', 'dmatrix'], ['Temp_Scale', 'Vector_Scale', 'Matrix_Scale']):
    cal = get_calibrator(calibrator, n_classes=c_out)
#     print(calibrator)
#     print(cal.weight, cal.bias, '\n')
    test_eq(cal(t), F.log_softmax(t, dim=1))
    test_eq(cal.__class__.__name__, cal_name)

bs = 2
c_out = 3

t = torch.rand(bs, c_out)

test_eq(Temp_Scale()(t).shape, t.shape)
test_eq(Vector_Scale(c_out)(t).shape, t.shape)
test_eq(Matrix_Scale(c_out)(t).shape, t.shape)
test_eq(Temp_Scale(dirichlet=True)(t).shape, t.shape)
test_eq(Vector_Scale(c_out, dirichlet=True)(t).shape, t.shape)
test_eq(Matrix_Scale(c_out, dirichlet=True)(t).shape, t.shape)

test_eq(Temp_Scale()(t), t)
test_eq(Vector_Scale(c_out)(t), t)
test_eq(Matrix_Scale(c_out)(t), t)

bs = 2
c_out = 5

t = torch.rand(bs, c_out)
test_eq(Vector_Scale(c_out)(t), t)
test_eq(Vector_Scale(c_out).weight.data, torch.ones(c_out))
test_eq(Vector_Scale(c_out).weight.requires_grad, True)
test_eq(type(Vector_Scale(c_out).weight), torch.nn.parameter.Parameter)

bs = 2
c_out = 3
weight = 2
bias = 1

t = torch.rand(bs, c_out)
test_eq(Matrix_Scale(c_out)(t).shape, t.shape)
test_eq(Matrix_Scale(c_out).weight.requires_grad, True)
test_eq(type(Matrix_Scale(c_out).weight), torch.nn.parameter.Parameter)

#|export
class LogitAdjustmentLayer(Module):
    "Logit Adjustment for imbalanced datasets"
    def __init__(self, class_priors):
        self.class_priors = class_priors
    def forward(self, x):
        return x.add(self.class_priors)

LogitAdjLayer = LogitAdjustmentLayer

bs, n_classes = 16, 3
class_priors = torch.rand(n_classes)
logits = torch.randn(bs, n_classes) * 2
test_eq(LogitAdjLayer(class_priors)(logits), logits + class_priors)

#|export
class PPV(Module):
    def __init__(self, dim=-1):
        self.dim = dim
    def forward(self, x):
        return torch.gt(x, 0).sum(dim=self.dim).float() / x.shape[self.dim]
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class PPAuc(Module):
    def __init__(self, dim=-1):
        self.dim = dim
    def forward(self, x):
        x = F.relu(x).sum(self.dim) / (abs(x).sum(self.dim) + 1e-8)
        return x
    def __repr__(self): return f'{self.__class__.__name__}(dim={self.dim})'


class MaxPPVPool1d(Module):
    "Drop-in replacement for AdaptiveConcatPool1d - multiplies nf by 2"
    def forward(self, x):
        _max = x.max(dim=-1).values
        _ppv = torch.gt(x, 0).sum(dim=-1).float() / x.shape[-1]
        return torch.cat((_max, _ppv), dim=-1).unsqueeze(2)

bs = 2
nf = 5
sl = 4

t = torch.rand(bs, nf, sl)
test_eq(MaxPPVPool1d()(t).shape, (bs, nf*2, 1))
test_eq(MaxPPVPool1d()(t).shape, AdaptiveConcatPool1d(1)(t).shape)

#|export
class AdaptiveWeightedAvgPool1d(Module):
    '''Global Pooling layer that performs a weighted average along the temporal axis

    It can be considered as a channel-wise form of local temporal attention. Inspired by the paper:
    Hyun, J., Seong, H., & Kim, E. (2019). Universal Pooling--A New Pooling Method for Convolutional Neural Networks. arXiv preprint arXiv:1907.11440.'''

    def __init__(self, n_in, seq_len, mult=2, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=True):
        layers = nn.ModuleList()
        for i in range(n_layers):
            inp_mult = mult if i > 0 else 1
            out_mult = mult if i < n_layers -1 else 1
            p = dropout[i] if is_listy(dropout) else dropout
            layers.append(LinLnDrop(seq_len * inp_mult, seq_len * out_mult, ln=False, p=p,
                                    act=act if i < n_layers-1 and n_layers > 1 else None))
        self.layers = layers
        self.softmax = SoftMax(-1)
        if zero_init: init_lin_zero(self)

    def forward(self, x):
        wap = x
        for l in self.layers: wap = l(wap)
        wap = self.softmax(wap)
        return torch.mul(x, wap).sum(-1)

#|export
class GAP1d(Module):
    "Global Adaptive Pooling + Flatten"
    def __init__(self, output_size=1):
        self.gap = nn.AdaptiveAvgPool1d(output_size)
        self.flatten = Reshape()
    def forward(self, x):
        return self.flatten(self.gap(x))


class GACP1d(Module):
    "Global AdaptiveConcatPool + Flatten"
    def __init__(self, output_size=1):
        self.gacp = AdaptiveConcatPool1d(output_size)
        self.flatten = Reshape()
    def forward(self, x):
        return self.flatten(self.gacp(x))


class GAWP1d(Module):
    "Global AdaptiveWeightedAvgPool1d + Flatten"
    def __init__(self, n_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False):
        self.gacp = AdaptiveWeightedAvgPool1d(n_in, seq_len, n_layers=n_layers, ln=ln, dropout=dropout, act=act, zero_init=zero_init)
        self.flatten = Reshape()
    def forward(self, x):
        return self.flatten(self.gacp(x))

#|export
class GlobalWeightedAveragePool1d(Module):
    """ Global Weighted Average Pooling layer

    Inspired by Building Efficient CNN Architecture for Offline Handwritten Chinese Character Recognition
    https://arxiv.org/pdf/1804.01259.pdf
    """

    def __init__(self, n_in, seq_len):
        self.weight = nn.Parameter(torch.ones(1, n_in, seq_len))
        self.bias = nn.Parameter(torch.zeros(1, n_in, seq_len))

    def forward(self, x):
        α = F.softmax(torch.sigmoid(x * self.weight + self.bias), dim=-1)
        return (x * α).sum(-1)

GWAP1d = GlobalWeightedAveragePool1d

def gwa_pool_head(n_in, c_out, seq_len, bn=True, fc_dropout=0.):
    return nn.Sequential(GlobalWeightedAveragePool1d(n_in, seq_len), Reshape(), LinBnDrop(n_in, c_out, p=fc_dropout, bn=bn))

t = torch.randn(16, 64, 50)
head = gwa_pool_head(64, 5, 50)
test_eq(head(t).shape, (16, 5))

#|export
class AttentionalPool1d(Module):
    """Global Adaptive Pooling layer inspired by Attentional Pooling for Action Recognition https://arxiv.org/abs/1711.01467"""
    def __init__(self, n_in, c_out, bn=False):
        store_attr()
        self.bn = nn.BatchNorm1d(n_in) if bn else None
        self.conv1 = Conv1d(n_in, 1, 1)
        self.conv2 = Conv1d(n_in, c_out, 1)

    def forward(self, x):
        if self.bn is not None: x = self.bn(x)
        return (self.conv1(x) @ self.conv2(x).transpose(1,2)).transpose(1,2)

class GAttP1d(nn.Sequential):
    def __init__(self, n_in, c_out, bn=False):
        super().__init__(AttentionalPool1d(n_in, c_out, bn=bn), Reshape())

def attentional_pool_head(n_in, c_out, seq_len=None, bn=True, **kwargs):
    return nn.Sequential(AttentionalPool1d(n_in, c_out, bn=bn, **kwargs), Reshape())

bs, c_in, seq_len = 16, 1, 50
c_out = 3
t = torch.rand(bs, c_in, seq_len)
test_eq(GAP1d()(t).shape, (bs, c_in))
test_eq(GACP1d()(t).shape, (bs, c_in*2))
bs, c_in, seq_len = 16, 4, 50
t = torch.rand(bs, c_in, seq_len)
test_eq(GAP1d()(t).shape, (bs, c_in))
test_eq(GACP1d()(t).shape, (bs, c_in*2))
test_eq(GAWP1d(c_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False)(t).shape, (bs, c_in))
test_eq(GAWP1d(c_in, seq_len, n_layers=2, ln=False, dropout=0.5, act=nn.ReLU(), zero_init=False)(t).shape, (bs, c_in))
test_eq(GAWP1d(c_in, seq_len, n_layers=1, ln=False, dropout=0.5, zero_init=False)(t).shape, (bs, c_in))
test_eq(GAWP1d(c_in, seq_len, n_layers=1, ln=False, dropout=0.5, zero_init=True)(t).shape, (bs, c_in))
test_eq(AttentionalPool1d(c_in, c_out)(t).shape, (bs, c_out, 1))

bs, c_in, seq_len = 16, 128, 50
c_out = 14
t = torch.rand(bs, c_in, seq_len)
attp = attentional_pool_head(c_in, c_out)
test_eq(attp(t).shape, (bs, c_out))

#|export
class PoolingLayer(Module):
    def __init__(self, method='cls', seq_len=None, token=True, seq_last=True):
        method = method.lower()
        assert method in ['cls', 'max', 'mean', 'max-mean', 'linear', 'conv1d', 'flatten']
        if method == 'cls': assert token, 'you can only choose method=cls if a token exists'
        self.method = method
        self.token = token
        self.seq_last = seq_last
        if method == 'linear' or method == 'conv1d':
            self.linear = nn.Linear(seq_len - token, 1)

    def forward(self, x):
        if self.method == 'cls':
            return x[..., 0] if self.seq_last else x[:, 0]
        if self.token:
            x = x[..., 1:] if self.seq_last else x[:, 1:]
        if self.method == 'max':
            return torch.max(x, -1)[0] if self.seq_last else torch.max(x, 1)[0]
        elif self.method == 'mean':
            return torch.mean(x, -1) if self.seq_last else torch.mean(x, 1)
        elif self.method == 'max-mean':
            return torch.cat([torch.max(x, -1)[0] if self.seq_last else torch.max(x, 1)[0],
                              torch.mean(x, -1) if self.seq_last else torch.mean(x, 1)], 1)
        elif self.method == 'flatten':
            return x.flatten(1)
        elif self.method == 'linear' or self.method == 'conv1d':
            return self.linear(x)[...,0] if self.seq_last else self.linear(x.transpose(1,2))[...,0]

    def __repr__(self): return f"{self.__class__.__name__}(method={self.method}, token={self.token}, seq_last={self.seq_last})"

t = torch.arange(24).reshape(2, 3, 4).float()
test_eq(PoolingLayer('cls', token=True, seq_last=True)(t), tensor([[ 0.,  4.,  8.], [12., 16., 20.]]))
test_eq(PoolingLayer('max', token=True, seq_last=True)(t), tensor([[ 3.,  7., 11.], [15., 19., 23.]]))
test_close(PoolingLayer('mean', token=True, seq_last=True)(t), tensor([[ 2.,  6., 10.], [14., 18., 22.]]))
test_close(PoolingLayer('max-mean', token=True, seq_last=True)(t), tensor([[ 3.,  7., 11.,  2.,  6., 10.],
                                                                           [15., 19., 23., 14., 18., 22.]]))
test_close(PoolingLayer('flatten', token=True, seq_last=True)(t), tensor([[ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],
                                                                          [13., 14., 15., 17., 18., 19., 21., 22., 23.]]))
test_eq(PoolingLayer('linear', seq_len=4, token=True, seq_last=True)(t).shape, (2, 3))
test_eq(PoolingLayer('max', token=False, seq_last=True)(t), tensor([[ 3.,  7., 11.], [15., 19., 23.]]))
test_close(PoolingLayer('mean', token=False, seq_last=True)(t), tensor([[ 1.5000,  5.5000,  9.5000],
                                                                        [13.5000, 17.5000, 21.5000]]))
test_close(PoolingLayer('max-mean', token=False, seq_last=True)(t), tensor([[ 3.,  7., 11.,  1.5000,  5.5000,  9.5000],
                                                                            [15., 19., 23., 13.5000, 17.5000, 21.5000]]))
test_close(PoolingLayer('flatten', token=False, seq_last=True)(t), tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.],
                                                                           [12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.]]))
test_eq(PoolingLayer('linear', seq_len=4, token=False, seq_last=True)(t).shape, (2, 3))

t = torch.arange(24).reshape(2, 3, 4).swapaxes(1,2).float()
test_eq(PoolingLayer('cls', token=True, seq_last=False)(t), tensor([[ 0.,  4.,  8.], [12., 16., 20.]]))
test_eq(PoolingLayer('max', token=True, seq_last=False)(t), tensor([[ 3.,  7., 11.], [15., 19., 23.]]))
test_close(PoolingLayer('mean', token=True, seq_last=False)(t), tensor([[ 2.,  6., 10.], [14., 18., 22.]]))
test_close(PoolingLayer('max-mean', token=True, seq_last=False)(t), tensor([[ 3.,  7., 11.,  2.,  6., 10.],
                                                                           [15., 19., 23., 14., 18., 22.]]))
test_close(PoolingLayer('flatten', token=True, seq_last=False)(t), tensor([[ 1.,  5.,  9.,  2.,  6., 10.,  3.,  7., 11.],
                                                                           [13., 17., 21., 14., 18., 22., 15., 19., 23.]]))
t = torch.arange(24).reshape(2, 3, 4).swapaxes(1,2).float()
test_eq(PoolingLayer('conv1d', seq_len=4, token=False, seq_last=False)(t).shape, (2, 3))
test_eq(PoolingLayer('max', token=False, seq_last=False)(t), tensor([[ 3.,  7., 11.], [15., 19., 23.]]))
test_close(PoolingLayer('mean', token=False, seq_last=False)(t), tensor([[ 1.5000,  5.5000,  9.5000],
                                                                        [13.5000, 17.5000, 21.5000]]))
test_close(PoolingLayer('max-mean', token=False, seq_last=False)(t), tensor([[ 3.,  7., 11.,  1.5000,  5.5000,  9.5000],
                                                                            [15., 19., 23., 13.5000, 17.5000, 21.5000]]))
test_close(PoolingLayer('flatten', token=False, seq_last=False)(t), tensor([[ 0.,  4.,  8.,  1.,  5.,  9.,  2.,  6., 10.,  3.,  7., 11.],
                                                                            [12., 16., 20., 13., 17., 21., 14., 18., 22., 15., 19., 23.]]))
test_eq(PoolingLayer('conv1d', seq_len=4, token=False, seq_last=False)(t).shape, (2, 3))

#|export
class GEGLU(Module):
    def forward(self, x):
        x, gates = x.chunk(2, dim=-1)
        return x * F.gelu(gates)

class ReGLU(Module):
    def forward(self, x):
        x, gates = x.chunk(2, dim=-1)
        return x * F.relu(gates)

#|export
pytorch_acts = [nn.ELU, nn.LeakyReLU, nn.PReLU, nn.ReLU, nn.ReLU6, nn.SELU, nn.CELU, nn.GELU, nn.Sigmoid, Mish, nn.Softplus,
nn.Tanh, nn.Softmax, GEGLU, ReGLU, SmeLU]
pytorch_act_names = [a.__name__.lower() for a in pytorch_acts]

def get_act_fn(act, **act_kwargs):
    if act is None: return
    elif isinstance(act, nn.Module): return act
    elif callable(act): return act(**act_kwargs)
    idx = pytorch_act_names.index(act.lower())
    return pytorch_acts[idx](**act_kwargs)

test_eq(get_act_fn(nn.ReLU).__repr__(), "ReLU()")
test_eq(get_act_fn(nn.ReLU()).__repr__(), "ReLU()")
test_eq(get_act_fn(nn.LeakyReLU, negative_slope=0.05).__repr__(), "LeakyReLU(negative_slope=0.05)")
test_eq(get_act_fn('reglu').__repr__(), "ReGLU()")
test_eq(get_act_fn('leakyrelu', negative_slope=0.05).__repr__(), "LeakyReLU(negative_slope=0.05)")

#|export
class RevIN(nn.Module):
    """ Reversible Instance Normalization layer adapted from

        Kim, T., Kim, J., Tae, Y., Park, C., Choi, J. H., & Choo, J. (2021, September).
        Reversible instance normalization for accurate time-series forecasting against distribution shift.
        In International Conference on Learning Representations.
        Original code: https://github.com/ts-kim/RevIN
    """

    def __init__(self,
         c_in:int,    # #features (aka variables or channels)
         affine:bool=True,  # flag to incidate if RevIN has learnable weight and bias
         subtract_last:bool=False,
         dim:int=2,   # int or tuple of dimensions used to calculate mean and std
         eps:float=1e-5  # epsilon - parameter added for numerical stability
         ):
        super().__init__()
        self.c_in, self.affine, self.subtract_last, self.dim, self.eps = c_in, affine, subtract_last, dim, eps
        if self.affine:
            self.weight = nn.Parameter(torch.ones(1, c_in, 1))
            self.bias = nn.Parameter(torch.zeros(1, c_in, 1))

    def forward(self, x:Tensor, mode:Tensor):
        """Args:

            x: rank 3 tensor with shape [batch size x c_in x sequence length]
            mode: torch.tensor(True) to normalize data and torch.tensor(False) to reverse normalization
        """

        # Normalize
        if mode: return self.normalize(x)

        # Denormalize
        else: return self.denormalize(x)

    def normalize(self, x):
        if self.subtract_last:
            self.sub = x[..., -1].unsqueeze(-1).detach()
        else:
            self.sub = torch.mean(x, dim=-1, keepdim=True).detach()
        self.std = torch.std(x, dim=-1, keepdim=True, unbiased=False).detach() + self.eps
        if self.affine:
            x = x.sub(self.sub)
            x = x.div(self.std)
            x = x.mul(self.weight)
            x = x.add(self.bias)
            return x
        else:
            x = x.sub(self.sub)
            x = x.div(self.std)
            return x

    def denormalize(self, x):
        if self.affine:
            x = x.sub(self.bias)
            x = x.div(self.weight)
            x = x.mul(self.std)
            x = x.add(self.sub)
            return x
        else:
            x = x.mul(self.std)
            x = x.add(self.sub)
            return x

#|export
class RevIN(nn.Module):
    """ Reversible Instance Normalization layer adapted from

        Kim, T., Kim, J., Tae, Y., Park, C., Choi, J. H., & Choo, J. (2021, September).
        Reversible instance normalization for accurate time-series forecasting against distribution shift.
        In International Conference on Learning Representations.
        Original code: https://github.com/ts-kim/RevIN
    """

    def __init__(self,
         c_in:int,    # #features (aka variables or channels)
         affine:bool=True,  # flag to incidate if RevIN has learnable weight and bias
         subtract_last:bool=False,
         dim:int=2,   # int or tuple of dimensions used to calculate mean and std
         eps:float=1e-5  # epsilon - parameter added for numerical stability
         ):
        super().__init__()
        self.c_in, self.affine, self.subtract_last, self.dim, self.eps = c_in, affine, subtract_last, dim, eps
        self.weight = nn.Parameter(torch.ones(1, c_in, 1))
        self.bias = nn.Parameter(torch.zeros(1, c_in, 1))
        self.sub, self.std, self.mul, self.add = torch.zeros(1), torch.ones(1), torch.ones(1), torch.zeros(1)

    def forward(self, x:Tensor, mode:Tensor):
        """Args:

            x: rank 3 tensor with shape [batch size x c_in x sequence length]
            mode: torch.tensor(True) to normalize data and torch.tensor(False) to reverse normalization
        """

        # Normalize
        if mode:
            if self.subtract_last:
                self.sub = x[..., -1].unsqueeze(-1).detach()
            else:
                self.sub = torch.mean(x, dim=-1, keepdim=True).detach()
            self.std = torch.std(x, dim=-1, keepdim=True, unbiased=False).detach() + self.eps
            if self.affine:
                x = x.sub(self.sub)
                x = x.div(self.std)
                x = x.mul(self.weight)
                x = x.add(self.bias)
                return x
            else:
                x = x.sub(self.sub)
                x = x.div(self.std)
                return x

        # Denormalize
        else:
            if self.affine:
                x = x.sub(self.bias)
                x = x.div(self.weight)
                x = x.mul(self.std)
                x = x.add(self.sub)
                return x
            else:
                x = x.mul(self.std)
                x = x.add(self.sub)
                return x

t = ((torch.rand(16, 5, 100) - .25) * torch.Tensor([.01, .1, 1, 10, 100]).reshape(1, -1, 1)).cumsum(-1)
t_clone = t.clone()
l = RevIN(5)
t_norm = l(t, torch.tensor(True))
t_denorm = l(t_norm, torch.tensor(False))
test_close(t_clone, t_denorm, eps=1e-3)

model = RevIN(5, affine=True)
try:
    scripted_model = torch.jit.script(model)
    file_path = f"test_scripted_model.pt"
    torch.jit.save(scripted_model, file_path)
    scripted_model = torch.jit.load(file_path)

    inp = ((torch.rand(16, 5, 100) - .25) * torch.Tensor([.01, .1, 1, 10, 100]).reshape(1, -1, 1)).cumsum(-1)
    normed_output = model(inp, torch.tensor(True))
    demormed_output = model(normed_output, torch.tensor(False))
    scripted_normed_output = scripted_model(inp, torch.tensor(True))
    scripted_denormed_output = scripted_model(scripted_normed_output, torch.tensor(False))
    test_close(normed_output, scripted_normed_output)
    test_close(demormed_output, scripted_denormed_output)
    os.remove(file_path)
    del scripted_model
    gc.collect()
    print('scripting ok')
except Exception as e:
    print(f'scripting failed: {e}')
# Output:
#   scripting ok


#|export
def create_pool_head(n_in, c_out, seq_len=None, concat_pool=False, fc_dropout=0., bn=False, y_range=None, **kwargs):
    if kwargs: print(f'{kwargs}  not being used')
    if concat_pool: n_in*=2
    layers = [GACP1d(1) if concat_pool else GAP1d(1)]
    layers += [LinBnDrop(n_in, c_out, bn=bn, p=fc_dropout)]
    if y_range: layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

pool_head = create_pool_head
average_pool_head = partial(pool_head, concat_pool=False)
setattr(average_pool_head, "__name__", "average_pool_head")
concat_pool_head = partial(pool_head, concat_pool=True)
setattr(concat_pool_head, "__name__", "concat_pool_head")

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_pool_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))
test_eq(create_pool_head(nf, c_out, seq_len, concat_pool=True, fc_dropout=0.5)(t).shape, (bs, c_out))
create_pool_head(nf, c_out, seq_len, concat_pool=True, bn=True, fc_dropout=.5)
# Output:
#   Sequential(

#     (0): GACP1d(

#       (gacp): AdaptiveConcatPool1d(

#         (ap): AdaptiveAvgPool1d(output_size=1)

#         (mp): AdaptiveMaxPool1d(output_size=1)

#       )

#       (flatten): Reshape(bs)

#     )

#     (1): LinBnDrop(

#       (0): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (1): Dropout(p=0.5, inplace=False)

#       (2): Linear(in_features=24, out_features=2, bias=False)

#     )

#   )

#|export
def max_pool_head(n_in, c_out, seq_len, fc_dropout=0., bn=False, y_range=None, **kwargs):
    if kwargs: print(f'{kwargs}  not being used')
    layers = [nn.MaxPool1d(seq_len, **kwargs), Reshape()]
    layers += [LinBnDrop(n_in, c_out, bn=bn, p=fc_dropout)]
    if y_range: layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(max_pool_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))

#|export
def create_pool_plus_head(*args, lin_ftrs=None, fc_dropout=0., concat_pool=True, bn_final=False, lin_first=False, y_range=None):
    nf = args[0]
    c_out = args[1]
    if concat_pool: nf = nf * 2
    lin_ftrs = [nf, 512, c_out] if lin_ftrs is None else [nf] + lin_ftrs + [c_out]
    ps = L(fc_dropout)
    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps
    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]
    pool = AdaptiveConcatPool1d() if concat_pool else nn.AdaptiveAvgPool1d(1)
    layers = [pool, Reshape()]
    if lin_first: layers.append(nn.Dropout(ps.pop(0)))
    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):
        layers += LinBnDrop(ni, no, bn=True, p=p, act=actn, lin_first=lin_first)
    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], c_out))
    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))
    if y_range is not None: layers.append(SigmoidRange(*y_range))
    return nn.Sequential(*layers)

pool_plus_head = create_pool_plus_head

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_pool_plus_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))
test_eq(create_pool_plus_head(nf, c_out, concat_pool=True, fc_dropout=0.5)(t).shape, (bs, c_out))
create_pool_plus_head(nf, c_out, seq_len, fc_dropout=0.5)
# Output:
#   Sequential(

#     (0): AdaptiveConcatPool1d(

#       (ap): AdaptiveAvgPool1d(output_size=1)

#       (mp): AdaptiveMaxPool1d(output_size=1)

#     )

#     (1): Reshape(bs)

#     (2): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (3): Dropout(p=0.25, inplace=False)

#     (4): Linear(in_features=24, out_features=512, bias=False)

#     (5): ReLU(inplace=True)

#     (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (7): Dropout(p=0.5, inplace=False)

#     (8): Linear(in_features=512, out_features=2, bias=False)

#   )

#|export
def create_conv_head(*args, adaptive_size=None, y_range=None):
    nf = args[0]
    c_out = args[1]
    layers = [nn.AdaptiveAvgPool1d(adaptive_size)] if adaptive_size is not None else []
    for i in range(2):
        if nf > 1:
            layers += [ConvBlock(nf, nf // 2, 1)]
            nf = nf//2
        else: break
    layers += [ConvBlock(nf, c_out, 1), GAP1d(1)]
    if y_range: layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

conv_head = create_conv_head

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_conv_head(nf, c_out, seq_len)(t).shape, (bs, c_out))
test_eq(create_conv_head(nf, c_out, adaptive_size=50)(t).shape, (bs, c_out))
create_conv_head(nf, c_out, 50)
# Output:
#   Sequential(

#     (0): ConvBlock(

#       (0): Conv1d(12, 6, kernel_size=(1,), stride=(1,), bias=False)

#       (1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (1): ConvBlock(

#       (0): Conv1d(6, 3, kernel_size=(1,), stride=(1,), bias=False)

#       (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (2): ConvBlock(

#       (0): Conv1d(3, 2, kernel_size=(1,), stride=(1,), bias=False)

#       (1): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (3): GAP1d(

#       (gap): AdaptiveAvgPool1d(output_size=1)

#       (flatten): Reshape(bs)

#     )

#   )

#|export
def create_mlp_head(nf, c_out, seq_len=None, flatten=True, fc_dropout=0., bn=False, lin_first=False, y_range=None):
    if flatten: nf *= seq_len
    layers = [Reshape()] if flatten else []
    layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout, lin_first=lin_first)]
    if y_range: layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

mlp_head = create_mlp_head

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_mlp_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))
t = torch.rand(bs, nf, seq_len)
create_mlp_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)
# Output:
#   Sequential(

#     (0): Reshape(bs)

#     (1): LinBnDrop(

#       (0): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (1): Dropout(p=0.5, inplace=False)

#       (2): Linear(in_features=240, out_features=2, bias=False)

#     )

#   )

#|export
def create_fc_head(nf, c_out, seq_len=None, flatten=True, lin_ftrs=None, y_range=None, fc_dropout=0., bn=False, bn_final=False, act=nn.ReLU(inplace=True)):
    if flatten: nf *= seq_len
    layers = [Reshape()] if flatten else []
    lin_ftrs = [nf, 512, c_out] if lin_ftrs is None else [nf] + lin_ftrs + [c_out]
    if not is_listy(fc_dropout): fc_dropout = [fc_dropout]*(len(lin_ftrs) - 1)
    actns = [act for _ in range(len(lin_ftrs) - 2)] + [None]
    layers += [LinBnDrop(lin_ftrs[i], lin_ftrs[i+1], bn=bn and (i!=len(actns)-1 or bn_final), p=p, act=a) for i,(p,a) in enumerate(zip(fc_dropout+[0.], actns))]
    if y_range is not None: layers.append(SigmoidRange(*y_range))
    return nn.Sequential(*layers)

fc_head = create_fc_head

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_fc_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))
create_mlp_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)
# Output:
#   Sequential(

#     (0): Reshape(bs)

#     (1): LinBnDrop(

#       (0): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (1): Dropout(p=0.5, inplace=False)

#       (2): Linear(in_features=240, out_features=2, bias=False)

#     )

#   )

#|export
def create_rnn_head(*args, fc_dropout=0., bn=False, y_range=None):
    nf = args[0]
    c_out = args[1]
    layers = [LastStep()]
    layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]
    if y_range: layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

rnn_head = create_rnn_head

bs = 16
nf = 12
c_out = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
test_eq(create_rnn_head(nf, c_out, seq_len, fc_dropout=0.5)(t).shape, (bs, c_out))
create_rnn_head(nf, c_out, seq_len, bn=True, fc_dropout=.5)
# Output:
#   Sequential(

#     (0): LastStep()

#     (1): LinBnDrop(

#       (0): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (1): Dropout(p=0.5, inplace=False)

#       (2): Linear(in_features=12, out_features=2, bias=False)

#     )

#   )

#|export
def imputation_head(c_in, c_out, seq_len=None, ks=1, y_range=None, fc_dropout=0.):
    layers = [nn.Dropout(fc_dropout), nn.Conv1d(c_in, c_out, ks)]
    if y_range is not None:
        y_range = (tensor(y_range[0]), tensor(y_range[1]))
        layers += [SigmoidRange(*y_range)]
    return nn.Sequential(*layers)

bs = 16
nf = 12
ni = 2
seq_len = 20
t = torch.rand(bs, nf, seq_len)
head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=None, fc_dropout=0.)
test_eq(head(t).shape, (bs, ni, seq_len))
head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=(.3,.7), fc_dropout=0.)
test_ge(head(t).min(), .3)
test_le(head(t).max(), .7)
y_range = (tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.2000, 0.2000, 0.2000, 0.3000,
                   0.3000, 0.3000, 0.3000]),
           tensor([0.6000, 0.6000, 0.6000, 0.6000, 0.7000, 0.7000, 0.7000, 0.7000, 0.8000,
                   0.8000, 0.8000, 0.8000]))
test_ge(head(t).min(), .1)
test_le(head(t).max(), .9)
head = imputation_head(nf, ni, seq_len=None, ks=1, y_range=y_range, fc_dropout=0.)
head
# Output:
#   Sequential(

#     (0): Dropout(p=0.0, inplace=False)

#     (1): Conv1d(12, 2, kernel_size=(1,), stride=(1,))

#     (2): fastai.layers.SigmoidRange(low=tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.2000, 0.2000, 0.2000, 0.2000, 0.3000,

#             0.3000, 0.3000, 0.3000]), high=tensor([0.6000, 0.6000, 0.6000, 0.6000, 0.7000, 0.7000, 0.7000, 0.7000, 0.8000,

#             0.8000, 0.8000, 0.8000]))

#   )

#|export
class create_conv_lin_nd_head(nn.Sequential):
    "Module to create a nd output head"

    def __init__(self, n_in, n_out, seq_len, d, conv_first=True, conv_bn=False, lin_bn=False, fc_dropout=0., **kwargs):

        assert d, "you cannot use an nd head when d is None or 0"
        if is_listy(d):
            fd = 1
            shape = []
            for _d in d:
                fd *= _d
                shape.append(_d)
            if n_out > 1: shape.append(n_out)
        else:
            fd = d
            shape = [d, n_out] if n_out > 1 else [d]

        conv = [BatchNorm(n_in, ndim=1)] if conv_bn else []
        conv.append(Conv1d(n_in, n_out, 1, padding=0, bias=not conv_bn, **kwargs))
        l = [Transpose(-1, -2), BatchNorm(seq_len, ndim=1), Transpose(-1, -2)] if lin_bn else []
        if fc_dropout != 0: l.append(nn.Dropout(fc_dropout))
        lin = [nn.Linear(seq_len, fd, bias=not lin_bn)]
        lin_layers = l+lin
        layers = conv + lin_layers if conv_first else lin_layers + conv
        layers += [Transpose(-1,-2)]
        layers += [Reshape(*shape)]

        super().__init__(*layers)

conv_lin_nd_head = create_conv_lin_nd_head
conv_lin_3d_head = create_conv_lin_nd_head # included for compatibility
create_conv_lin_3d_head = create_conv_lin_nd_head # included for compatibility

bs = 16
nf = 32
c = 5
seq_len = 10
d = 2
targ = torch.randint(0, c, (bs,d))
t = torch.randn(bs, nf, seq_len)
head = conv_lin_nd_head(nf, c, seq_len, d, conv_first=True, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, (bs, d, c))
loss = CrossEntropyLossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(1.7252, grad_fn=<AliasBackward0>),

#    create_conv_lin_nd_head(

#      (0): Conv1d(32, 5, kernel_size=(1,), stride=(1,))

#      (1): Dropout(p=0.5, inplace=False)

#      (2): Linear(in_features=10, out_features=2, bias=True)

#      (3): Transpose(dims=-1, -2).contiguous()

#      (4): Reshape(bs, 2, 5)

#    ))

bs = 16
nf = 32
c = 5
seq_len = 10
d = [2, 8]
targ = torch.randint(0, c, [bs]+d)
t = torch.randn(bs, nf, seq_len)
head = conv_lin_nd_head(nf, c, seq_len, d, conv_first=False, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, [bs]+d+[c])
loss = CrossEntropyLossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(1.6647, grad_fn=<AliasBackward0>),

#    create_conv_lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Linear(in_features=10, out_features=16, bias=True)

#      (2): Conv1d(32, 5, kernel_size=(1,), stride=(1,))

#      (3): Transpose(dims=-1, -2).contiguous()

#      (4): Reshape(bs, 2, 8, 5)

#    ))

bs = 16
nf = 32
c = 1
seq_len = 10
d = 2
targ = torch.rand(bs, d)
t = torch.randn(bs, nf, seq_len)
head = conv_lin_nd_head(nf, c, seq_len, d, conv_first=False, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, (bs, d))
loss = L1LossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(0.7063, grad_fn=<AliasBackward0>),

#    create_conv_lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Linear(in_features=10, out_features=2, bias=True)

#      (2): Conv1d(32, 1, kernel_size=(1,), stride=(1,))

#      (3): Transpose(dims=-1, -2).contiguous()

#      (4): Reshape(bs, 2)

#    ))

bs = 16
nf = 32
c = 1
seq_len = 10
d = [2,3]
targ = torch.rand(bs, *d)
t = torch.randn(bs, nf, seq_len)
head = conv_lin_nd_head(nf, c, seq_len, d, conv_first=False, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, [bs]+d)
loss = L1LossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(0.6203, grad_fn=<AliasBackward0>),

#    create_conv_lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Linear(in_features=10, out_features=6, bias=True)

#      (2): Conv1d(32, 1, kernel_size=(1,), stride=(1,))

#      (3): Transpose(dims=-1, -2).contiguous()

#      (4): Reshape(bs, 2, 3)

#    ))

#|export
class lin_nd_head(nn.Sequential):
    "Module to create a nd output head with linear layers"

    def __init__(self, n_in, n_out, seq_len=None, d=None, flatten=False, use_bn=False, fc_dropout=0.):

        if seq_len is None:
            seq_len = 1
        if d is None:
            fd = 1
            shape = [n_out]
        elif is_listy(d):
            fd = 1
            shape = []
            for _d in d:
                fd *= _d
                shape.append(_d)
            if n_out > 1: shape.append(n_out)
        else:
            fd = d
            shape = [d, n_out] if n_out > 1 else [d]

        layers = []
        if use_bn:
            layers += [nn.BatchNorm1d(n_in)]
        if fc_dropout:
            layers += [nn.Dropout(fc_dropout)]
        if d is None:
            if not flatten or seq_len == 1:
                layers += [nn.AdaptiveAvgPool1d(1), Squeeze(-1), nn.Linear(n_in, n_out)]
                if n_out == 1:
                    layers += [Squeeze(-1)]
            else:
                layers += [Reshape(), nn.Linear(n_in * seq_len, n_out * fd)]
                if n_out * fd== 1:
                    layers += [Squeeze(-1)]
        else:
            if seq_len == 1:
                layers += [nn.AdaptiveAvgPool1d(1)]
            if not flatten and fd == seq_len:
                layers += [Transpose(1,2), nn.Linear(n_in, n_out)]
            else:
                layers += [Reshape(), nn.Linear(n_in * seq_len, n_out * fd)]
            layers += [Reshape(*shape)]

        super().__init__(*layers)

create_lin_nd_head = lin_nd_head
lin_3d_head = lin_nd_head # included for backwards compatiblity
create_lin_3d_head = lin_nd_head # included for backwards compatiblity

bs = 16
nf = 32
seq_len = 50
x = torch.normal(0, 1, (bs, nf, seq_len))

for use_bn in [False, True]:
    for fc_dropout in [0, 0.2]:
        for flatten in [False, True]:
            for c in [1, 3]:
                for d in [None, (50,), (50,10), (30,5), (50,2,3), (30,2,3)]:
                    for q_len in [1, seq_len]:
                        head = lin_nd_head(nf, c, q_len, d, flatten=flatten, use_bn=use_bn, fc_dropout=fc_dropout)
                        test_eq(head(x).shape, (bs, ) + (d if d is not None else ()) + ((c,) if c != 1 else ()))

bs = 16
nf = 32
c = 5
seq_len = 10
d = 2
targ = torch.randint(0, c, (bs,d))
t = torch.randn(bs, nf, seq_len)
head = lin_nd_head(nf, c, seq_len, d, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, (bs, d, c))
loss = CrossEntropyLossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(1.7711, grad_fn=<AliasBackward0>),

#    lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Reshape(bs)

#      (2): Linear(in_features=320, out_features=10, bias=True)

#      (3): Reshape(bs, 2, 5)

#    ))

bs = 16
nf = 32
c = 5
seq_len = 10
d = [2, 8]
targ = torch.randint(0, c, [bs]+d)
t = torch.randn(bs, nf, seq_len)
head = lin_nd_head(nf, c, seq_len, d, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, [bs]+d+[c])
loss = CrossEntropyLossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(1.8884, grad_fn=<AliasBackward0>),

#    lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Reshape(bs)

#      (2): Linear(in_features=320, out_features=80, bias=True)

#      (3): Reshape(bs, 2, 8, 5)

#    ))

bs = 16
nf = 32
c = 1
seq_len = 10
d = 2
targ = torch.rand(bs, d)
t = torch.randn(bs, nf, seq_len)
head = lin_nd_head(nf, c, seq_len, d, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, (bs, d))
loss = L1LossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(0.7737, grad_fn=<AliasBackward0>),

#    lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Reshape(bs)

#      (2): Linear(in_features=320, out_features=2, bias=True)

#      (3): Reshape(bs, 2)

#    ))

bs = 16
nf = 32
c = 1
seq_len = 10
d = [2,3]
targ = torch.rand(bs, *d)
t = torch.randn(bs, nf, seq_len)
head = lin_nd_head(nf, c, seq_len, d, fc_dropout=.5)
inp = head(t)
test_eq(inp.shape, [bs]+d)
loss = L1LossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(0.8873, grad_fn=<AliasBackward0>),

#    lin_nd_head(

#      (0): Dropout(p=0.5, inplace=False)

#      (1): Reshape(bs)

#      (2): Linear(in_features=320, out_features=6, bias=True)

#      (3): Reshape(bs, 2, 3)

#    ))

#|export
class rocket_nd_head(nn.Sequential):
    "Module to create a nd output head with linear layers for the rocket family of models"

    def __init__(self, n_in, n_out, seq_len=None, d=None, use_bn=False, fc_dropout=0., zero_init=True):

        if d is None:
            fd = 1
            shape = [n_out]
        elif is_listy(d):
            fd = 1
            shape = []
            for _d in d:
                fd *= _d
                shape.append(_d)
            if n_out > 1: shape.append(n_out)
        else:
            fd = d
            shape = [d, n_out] if n_out > 1 else [d]

        layers = [nn.Flatten()]
        if use_bn:
            layers += [nn.BatchNorm1d(n_in)]
        if fc_dropout:
            layers += [nn.Dropout(fc_dropout)]
        linear = nn.Linear(n_in, fd * n_out)
        if zero_init:
            nn.init.constant_(linear.weight.data, 0)
            nn.init.constant_(linear.bias.data, 0)
        layers += [linear]
        if d is None and n_out == 1:
            layers += [Squeeze(-1)]
        if d is not None:
            layers += [Reshape(*shape)]

        super().__init__(*layers)

bs = 16
nf = 99
seq_len = 1
x = torch.normal(0, 1, (bs, nf, seq_len))

for use_bn in [False, True]:
    for fc_dropout in [0, 0.2]:
        for c in [1, 3]:
            for d in [None, (50,), (50,10), (30,5), (50,2,3), (30,2,3)]:
                head = rocket_nd_head(nf, c, 1, d, use_bn=use_bn, fc_dropout=fc_dropout)
                test_eq(head(x).shape, (bs, ) + (d if d is not None else ()) + ((c,) if c != 1 else ()))

#|export
class xresnet1d_nd_head(nn.Sequential):
    "Module to create a nd output head with linear layers for the xresnet family of models"

    def __init__(self, n_in, n_out, seq_len=None, d=None, use_bn=False, fc_dropout=0., zero_init=True):

        if d is None:
            fd = 1
            shape = [n_out]
        elif is_listy(d):
            fd = 1
            shape = []
            for _d in d:
                fd *= _d
                shape.append(_d)
            if n_out > 1: shape.append(n_out)
        else:
            fd = d
            shape = [d, n_out] if n_out > 1 else [d]

        layers = [nn.AdaptiveAvgPool1d(1), nn.Flatten()]
        if use_bn:
            layers += [nn.BatchNorm1d(n_in)]
        if fc_dropout:
            layers += [nn.Dropout(fc_dropout)]
        linear = nn.Linear(n_in, fd * n_out)
        if zero_init:
            nn.init.constant_(linear.weight.data, 0)
            nn.init.constant_(linear.bias.data, 0)
        layers += [linear]
        if d is None and n_out == 1:
            layers += [Squeeze(-1)]
        if d is not None:
            layers += [Reshape(*shape)]

        super().__init__(*layers)

bs = 16
nf = 99
seq_len = 2
x = torch.normal(0, 1, (bs, nf, seq_len))

for use_bn in [False, True]:
    for fc_dropout in [0, 0.2]:
        for c in [1, 3]:
            for d in [None, (50,), (50,10), (30,5), (50,2,3), (30,2,3)]:
                head = xresnet1d_nd_head(nf, c, 1, d, use_bn=use_bn, fc_dropout=fc_dropout)
                test_eq(head(x).shape, (bs, ) + (d if d is not None else ()) + ((c,) if c != 1 else ()))

#|export
class create_conv_3d_head(nn.Sequential):
    "Module to create a nd output head with a convolutional layer"
    def __init__(self, n_in, n_out, seq_len, d, use_bn=False, **kwargs):
        assert d, "you cannot use an 3d head when d is None or 0"
        assert d == seq_len, 'You can only use this head when learn.dls.len == learn.dls.d'
        layers = [nn.BatchNorm1d(n_in)] if use_bn else []
        layers += [Conv(n_in, n_out, 1, **kwargs), Transpose(-1,-2)]
        if n_out == 1: layers += [Squeeze(-1)]
        super().__init__(*layers)

conv_3d_head = create_conv_3d_head

bs = 16
nf = 32
c = 5
seq_len = 10
d = 10
targ = torch.randint(0, c, (bs,d))
t = torch.randn(bs, nf, seq_len)
head = conv_3d_head(nf, c, seq_len, d)
inp = head(t)
test_eq(inp.shape, (bs, d, c))
loss = CrossEntropyLossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(1.8352, grad_fn=<AliasBackward0>),

#    create_conv_3d_head(

#      (0): ConvBlock(

#        (0): Conv1d(32, 5, kernel_size=(1,), stride=(1,))

#      )

#      (1): Transpose(dims=-1, -2).contiguous()

#    ))

bs = 16
nf = 32
c = 1
seq_len = 10
d = 10
targ = torch.rand(bs, d)
t = torch.randn(bs, nf, seq_len)
head = conv_3d_head(nf, c, seq_len, d)
inp = head(t)
test_eq(inp.shape, (bs, d))
loss = L1LossFlat()(inp, targ)
loss, head
# Output:
#   (TensorBase(0.6711, grad_fn=<AliasBackward0>),

#    create_conv_3d_head(

#      (0): ConvBlock(

#        (0): Conv1d(32, 1, kernel_size=(1,), stride=(1,))

#      )

#      (1): Transpose(dims=-1, -2).contiguous()

#      (2): Squeeze(dim=-1)

#    ))

#|export
def universal_pool_head(n_in, c_out, seq_len, mult=2, pool_n_layers=2, pool_ln=True, pool_dropout=0.5, pool_act=nn.ReLU(),
                        zero_init=True, bn=True, fc_dropout=0.):
    return nn.Sequential(AdaptiveWeightedAvgPool1d(n_in, seq_len, n_layers=pool_n_layers, mult=mult, ln=pool_ln, dropout=pool_dropout, act=pool_act),
                         Reshape(), LinBnDrop(n_in, c_out, p=fc_dropout, bn=bn))

bs, c_in, seq_len = 16, 128, 50
c_out = 14
t = torch.rand(bs, c_in, seq_len)
uph = universal_pool_head(c_in, c_out, seq_len)
test_eq(uph(t).shape, (bs, c_out))
uph = universal_pool_head(c_in, c_out, seq_len, 2)
test_eq(uph(t).shape, (bs, c_out))

#|export
heads = [mlp_head, fc_head, average_pool_head, max_pool_head, concat_pool_head, pool_plus_head, conv_head, rnn_head,
         conv_lin_nd_head, lin_nd_head, conv_3d_head, attentional_pool_head, universal_pool_head, gwa_pool_head]

bs, c_in, seq_len = 16, 128, 50
c_out = 14
d = 5
t = torch.rand(bs, c_in, seq_len)
for head in heads:
    print(head.__name__)
    if head.__name__ == "create_conv_3d_head":
        h = head(c_in, c_out, seq_len, seq_len)
        test_eq(h(t).shape, (bs, seq_len, c_out))
    elif 'nd' in head.__name__:
        h = head(c_in, c_out, seq_len, d)
        test_eq(h(t).shape, (bs, d, c_out))
    else:
        h = head(c_in, c_out, seq_len)
        test_eq(h(t).shape, (bs, c_out))
# Output:
#   create_mlp_head

#   create_fc_head

#   average_pool_head

#   max_pool_head

#   concat_pool_head

#   create_pool_plus_head

#   create_conv_head

#   create_rnn_head

#   create_conv_lin_nd_head

#   lin_nd_head

#   create_conv_3d_head

#   attentional_pool_head

#   universal_pool_head

#   gwa_pool_head


#|export
class SqueezeExciteBlock(Module):
    def __init__(self, ni, reduction=16):
        self.avg_pool = GAP1d(1)
        self.fc = nn.Sequential(nn.Linear(ni, ni // reduction, bias=False), nn.ReLU(),  nn.Linear(ni // reduction, ni, bias=False), nn.Sigmoid())

    def forward(self, x):
        y = self.avg_pool(x)
        y = self.fc(y).unsqueeze(2)
        return x * y.expand_as(x)

bs = 2
ni = 32
sl = 4
t = torch.rand(bs, ni, sl)
test_eq(SqueezeExciteBlock(ni)(t).shape, (bs, ni, sl))

#|export
class GaussianNoise(Module):
    """Gaussian noise regularizer.

    Args:
        sigma (float, optional): relative standard deviation used to generate the
            noise. Relative means that it will be multiplied by the magnitude of
            the value your are adding the noise to. This means that sigma can be
            the same regardless of the scale of the vector.
        is_relative_detach (bool, optional): whether to detach the variable before
            computing the scale of the noise. If `False` then the scale of the noise
            won't be seen as a constant but something to optimize: this will bias the
            network to generate vectors with smaller values.
    """

    def __init__(self, sigma=0.1, is_relative_detach=True):
        self.sigma, self.is_relative_detach = sigma, is_relative_detach

    def forward(self, x):
        if self.training and self.sigma not in [0, None]:
            scale = self.sigma * (x.detach() if self.is_relative_detach else x)
            sampled_noise = torch.empty(x.size(), device=x.device).normal_() * scale
            x = x + sampled_noise
        return x

t = torch.ones(2,3,4)
test_ne(GaussianNoise()(t), t)
test_eq(GaussianNoise()(t).shape, t.shape)
t = torch.ones(2,3)
test_ne(GaussianNoise()(t), t)
test_eq(GaussianNoise()(t).shape, t.shape)
t = torch.ones(2)
test_ne(GaussianNoise()(t), t)
test_eq(GaussianNoise()(t).shape, t.shape)

#|eval: false
#|hide
import numpy as np
from scipy.stats import ttest_ind, ttest_ind_from_stats
from scipy.special import stdtr

#|eval: false
#|hide
# https://stackoverflow.com/questions/22611446/perform-2-sample-t-test
np.random.seed(1)

# Create sample data.
a = np.random.randn(40)
b = 4*np.random.randn(50)

# Use scipy.stats.ttest_ind.
t, p = ttest_ind(a, b, equal_var=False)
print("ttest_ind:            t = %g  p = %g" % (t, p))

# Compute the descriptive statistics of a and b.
abar = a.mean()
avar = a.var(ddof=1)
na = a.size
adof = na - 1

bbar = b.mean()
bvar = b.var(ddof=1)
nb = b.size
bdof = nb - 1

# Use scipy.stats.ttest_ind_from_stats.
t2, p2 = ttest_ind_from_stats(abar, np.sqrt(avar), na,
                              bbar, np.sqrt(bvar), nb,
                              equal_var=False)
print("ttest_ind_from_stats: t = %g  p = %g" % (t2, p2))

# Use the formulas directly.
tf = (abar - bbar) / np.sqrt(avar/na + bvar/nb)
dof = (avar/na + bvar/nb)**2 / (avar**2/(na**2*adof) + bvar**2/(nb**2*bdof))
pf = 2*stdtr(dof, -np.abs(tf))

print("formula:              t = %g  p = %g" % (tf, pf))

a = torch.tensor(a)
b = torch.tensor(b)
tf = (a.mean() - b.mean()) / torch.sqrt(a.var()/a.size(0) + b.var()/b.size(0))
print("formula:              t = %g" % (tf))
# Output:
#   ttest_ind:            t = -1.5827  p = 0.118873

#   ttest_ind_from_stats: t = -1.5827  p = 0.118873

#   formula:              t = -1.5827  p = 0.118873

#   formula:              t = -1.5827


#|export
class PositionwiseFeedForward(nn.Sequential):
    def __init__(self, dim, dropout=0., act='reglu', mlp_ratio=1):
        act_mult = 2 if act.lower() in ["geglu", "reglu"] else 1
        super().__init__(nn.Linear(dim, dim * mlp_ratio * act_mult),
                         get_act_fn(act),
                         nn.Dropout(dropout),
                         nn.Linear(dim * mlp_ratio, dim),
                         nn.Dropout(dropout))

class TokenLayer(Module):
    def __init__(self, token=True): self.token = token
    def forward(self, x): return x[..., 0] if self.token is not None else x.mean(-1)
    def __repr__(self): return f"{self.__class__.__name__}()"

t = torch.randn(2,3,10)
m = PositionwiseFeedForward(10, dropout=0., act='reglu', mlp_ratio=1)
test_eq(m(t).shape, t.shape)
m = PositionwiseFeedForward(10, dropout=0., act='smelu', mlp_ratio=1)
test_eq(m(t).shape, t.shape)

#|export
class ScaledDotProductAttention(Module):
    r"""Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer
    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets
    by Lee et al, 2021)"""

    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):
        self.attn_dropout = nn.Dropout(attn_dropout)
        self.res_attention = res_attention
        head_dim = d_model // n_heads
        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)
        self.lsa = lsa

    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):
        '''
        Input shape:
            q               : [bs x n_heads x max_q_len x d_k]
            k               : [bs x n_heads x d_k x seq_len]
            v               : [bs x n_heads x seq_len x d_v]
            prev            : [bs x n_heads x q_len x seq_len]
            key_padding_mask: [bs x seq_len]
            attn_mask       : [1 x seq_len x seq_len]

        Output shape:
            output:  [bs x n_heads x q_len x d_v]
            attn   : [bs x n_heads x q_len x seq_len]
            scores : [bs x n_heads x q_len x seq_len]
        '''

        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]

        # Add pre-softmax attention scores from the previous layer (optional)
        if prev is not None: attn_scores = attn_scores + prev

        # Attention mask (optional)
        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len
            if attn_mask.dtype == torch.bool:
                attn_scores.masked_fill_(attn_mask, -np.inf)
            else:
                attn_scores += attn_mask

        # Key padding mask (optional)
        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)
            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)

        # normalize the attention weights
        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]
        attn_weights = self.attn_dropout(attn_weights)

        # compute the new values given the attention weights
        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]

        if self.res_attention: return output, attn_weights, attn_scores
        else: return output, attn_weights

B = 16
C = 10
M = 1500 # seq_len

n_heads = 1
D = 128 # model dimension
N = 512 # max_seq_len - latent's index dimension
d_k = D // n_heads

xb = torch.randn(B, C, M)
xb = (xb - xb.mean()) / xb.std()

# Attention
# input (Q)
lin = nn.Linear(M, N, bias=False)
Q = lin(xb).transpose(1,2)
test_eq(Q.shape, (B, N, C))

# q
to_q = nn.Linear(C, D, bias=False)
q = to_q(Q)
q = nn.LayerNorm(D)(q)

# k, v
context = xb.transpose(1,2)
to_kv = nn.Linear(C, D * 2, bias=False)
k, v = to_kv(context).chunk(2, dim = -1)
k = k.transpose(-1, -2)
k = nn.LayerNorm(M)(k)
v = nn.LayerNorm(D)(v)

test_eq(q.shape, (B, N, D))
test_eq(k.shape, (B, D, M))
test_eq(v.shape, (B, M, D))

output, attn, scores = ScaledDotProductAttention(D, n_heads, res_attention=True)(q.unsqueeze(1), k.unsqueeze(1), v.unsqueeze(1))
test_eq(output.shape, (B, 1, N, D))
test_eq(attn.shape, (B, 1, N, M))
test_eq(scores.shape, (B, 1, N, M))
scores.mean(), scores.std()
# Output:
#   (tensor(-2.3159e-10, grad_fn=<MeanBackward0>),

#    tensor(0.9743, grad_fn=<StdBackward0>))

#|export
class MultiheadAttention(Module):
    def __init__(self, d_model, n_heads, d_k=None, d_v=None, res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):
        """Multi Head Attention Layer

        Input shape:
            Q:       [batch_size (bs) x max_q_len x d_model]
            K, V:    [batch_size (bs) x q_len x d_model]
            mask:    [q_len x q_len]
        """

        d_k = ifnone(d_k, d_model // n_heads)
        d_v = ifnone(d_v, d_model // n_heads)

        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v

        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)
        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)
        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)

        # Scaled Dot-Product Attention (multiple heads)
        self.res_attention = res_attention
        self.sdp_attn = ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout, res_attention=self.res_attention, lsa=lsa)

        # Poject output
        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))


    def forward(self, Q:Tensor, K:Optional[Tensor]=None, V:Optional[Tensor]=None, prev:Optional[Tensor]=None,
                key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):

        bs = Q.size(0)
        if K is None: K = Q
        if V is None: V = Q

        # Linear (+ split in multiple heads)
        q_s = self.W_Q(Q).reshape(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]
        k_s = self.W_K(K).reshape(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)
        v_s = self.W_V(V).reshape(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]

        # Apply Scaled Dot-Product Attention (multiple heads)
        if self.res_attention:
            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
        else:
            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]

        # back to the original inputs dimensions
        output = output.transpose(1, 2).contiguous().reshape(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]
        output = self.to_out(output)

        if self.res_attention: return output, attn_weights, attn_scores
        else: return output, attn_weights

q = torch.rand([16, 3, 50, 8])
k = torch.rand([16, 3, 50, 8]).transpose(-1, -2)
v = torch.rand([16, 3, 50, 6])
attn_mask = torch.triu(torch.ones(50, 50)) # shape: q_len x q_len
key_padding_mask = torch.zeros(16, 50)
key_padding_mask[[1, 3, 6, 15], -10:] = 1
key_padding_mask = key_padding_mask.bool()
print('attn_mask', attn_mask.shape, 'key_padding_mask', key_padding_mask.shape)
output, attn = ScaledDotProductAttention(24, 3, attn_dropout=.1)(q, k, v, attn_mask=attn_mask, key_padding_mask=key_padding_mask)
output.shape, attn.shape
# Output:
#   attn_mask torch.Size([50, 50]) key_padding_mask torch.Size([16, 50])

#   (torch.Size([16, 3, 50, 6]), torch.Size([16, 3, 50, 50]))

t = torch.rand(16, 50, 128)
output, attn = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)(t, t, t, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
output.shape, attn.shape
# Output:
#   (torch.Size([16, 50, 128]), torch.Size([16, 3, 50, 50]))

"""
Test multi-head attention with self-locality attention
"""

# lsa (locality self-sttention)
t = torch.rand(16, 50, 128)
attn_mask = torch.eye(50).reshape(1, 1, 50, 50).bool()
output, attn = MultiheadAttention(d_model=128, n_heads=8, lsa=True)(t, t, t, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
output.shape, attn.shape
# Output:
#   (torch.Size([16, 50, 128]), torch.Size([16, 8, 50, 50]))

t = torch.rand(16, 50, 128)
att_mask = (torch.rand((50, 50)) > .85).float()
att_mask[att_mask == 1] = -np.inf

mha = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)
output, attn = mha(t, t, t, attn_mask=att_mask)
test_eq(torch.isnan(output).sum().item(), 0)
test_eq(torch.isnan(attn).sum().item(), 0)
loss = output[:2, :].sum()
test_eq(torch.isnan(loss).sum().item(), 0)
loss.backward()
for n, p in mha.named_parameters():
    if p.grad is not None:
        test_eq(torch.isnan(p.grad).sum().item(), 0)

t = torch.rand(16, 50, 128)
attn_mask = (torch.rand((50, 50)) > .85)

# True values will be masked
mha = MultiheadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)
output, attn = mha(t, t, t, attn_mask=att_mask)
test_eq(torch.isnan(output).sum().item(), 0)
test_eq(torch.isnan(attn).sum().item(), 0)
loss = output[:2, :].sum()
test_eq(torch.isnan(loss).sum().item(), 0)
loss.backward()
for n, p in mha.named_parameters():
    if p.grad is not None:
        test_eq(torch.isnan(p.grad).sum().item(), 0)

#|export
class MultiConv1d(Module):
    """Module that applies multiple convolutions with different kernel sizes"""

    def __init__(self, ni, nf=None, kss=[1,3,5,7], keep_original=False, separable=False, dim=1, **kwargs):
        kss = listify(kss)
        n_layers = len(kss)
        if ni == nf: keep_original = False
        if nf is None: nf = ni * (keep_original + n_layers)
        nfs = [(nf - ni*keep_original) // n_layers] * n_layers
        while np.sum(nfs) + ni * keep_original < nf:
            for i in range(len(nfs)):
                nfs[i] += 1
                if np.sum(nfs) + ni * keep_original == nf: break

        _conv = SeparableConv1d if separable else Conv1d
        self.layers = nn.ModuleList()
        for nfi,ksi in zip(nfs, kss):
            self.layers.append(_conv(ni, nfi, ksi, **kwargs))
        self.keep_original, self.dim = keep_original, dim

    def forward(self, x):
        output = [x] if self.keep_original else []
        for l in self.layers:
            output.append(l(x))
        x = torch.cat(output, dim=self.dim)
        return x

t = torch.rand(16, 6, 37)
test_eq(MultiConv1d(6, None, kss=[1,3,5], keep_original=True)(t).shape, [16, 24, 37])
test_eq(MultiConv1d(6, 36, kss=[1,3,5], keep_original=False)(t).shape, [16, 36, 37])
test_eq(MultiConv1d(6, None, kss=[1,3,5], keep_original=True, dim=-1)(t).shape, [16, 6, 37*4])
test_eq(MultiConv1d(6, 60, kss=[1,3,5], keep_original=True)(t).shape, [16, 60, 37])
test_eq(MultiConv1d(6, 60, kss=[1,3,5], separable=True)(t).shape, [16, 60, 37])

#|export
class LSTMOutput(Module):
    def forward(self, x): return x[0]
    def __repr__(self): return f'{self.__class__.__name__}()'

t = ([1], [2], [3])
test_eq(LSTMOutput()(t), [1])

#|export
def emb_sz_rule(n_cat):
    "Rule of thumb to pick embedding size corresponding to `n_cat` (original from fastai)"
    return min(600, round(1.6 * n_cat**0.56))

test_eq(emb_sz_rule(7), 5)

#|export
class TSEmbedding(nn.Embedding):
    "Embedding layer with truncated normal initialization adapted from fastai"
    def __init__(self, ni, nf, std=0.01, padding_idx=None):
        super().__init__(ni, nf)
        trunc_normal_(self.weight.data, std=std)
        if padding_idx is not None:
            nn.init.zeros_(self.weight.data[padding_idx])

#|export
class MultiEmbedding(Module):
    def __init__(self, c_in, n_cat_embeds, cat_embed_dims=None, cat_pos=None, std=0.01, cat_padding_idxs=None):
        cat_n_embeds = listify(n_cat_embeds)
        if cat_padding_idxs is None: cat_padding_idxs = [None]
        else: cat_padding_idxs = listify(cat_padding_idxs)
        if len(cat_padding_idxs) == 1 and len(cat_padding_idxs) < len(cat_n_embeds):
            cat_padding_idxs = cat_padding_idxs * len(cat_n_embeds)
        assert len(cat_n_embeds) == len(cat_padding_idxs)
        if cat_embed_dims is None:
            cat_embed_dims = [emb_sz_rule(s) for s in cat_n_embeds]
        else:
            cat_embed_dims = listify(cat_embed_dims)
            if len(cat_embed_dims) == 1: cat_embed_dims = cat_embed_dims * len(cat_n_embeds)
            assert len(cat_embed_dims) == len(cat_n_embeds)
        if cat_pos:
            cat_pos = torch.as_tensor(listify(cat_pos))
        else:
            cat_pos = torch.arange(len(cat_n_embeds))
        self.register_buffer("cat_pos", cat_pos)
        cont_pos = torch.tensor([p for p in torch.arange(c_in) if p not in self.cat_pos])
        self.register_buffer("cont_pos", cont_pos)
        self.cat_embed = nn.ModuleList([TSEmbedding(n,d,std=std, padding_idx=p) for n,d,p in zip(cat_n_embeds, cat_embed_dims, cat_padding_idxs)])

    def forward(self, x):
        if isinstance(x, tuple): x_cat, x_cont, *_ = x
        else: x_cat, x_cont = x[:, self.cat_pos], x[:, self.cont_pos]
        x_cat = torch.cat([e(torch.round(x_cat[:,i]).long()).transpose(1,2) for i,e in enumerate(self.cat_embed)],1)
        return torch.cat([x_cat, x_cont], 1)

a = alphabet[np.random.randint(0,3,40)]
b = ALPHABET[np.random.randint(6,10,40)]
c = np.random.rand(40).reshape(4,1,10)
map_a = {k:v for v,k in enumerate(np.unique(a))}
map_b = {k:v for v,k in enumerate(np.unique(b))}
n_embeds = [len(m.keys()) for m in [map_a, map_b]]
szs = [emb_sz_rule(n) for n in n_embeds]
a = np.asarray(a.map(map_a)).reshape(4,1,10)
b = np.asarray(b.map(map_b)).reshape(4,1,10)
inp = torch.from_numpy(np.concatenate((c,a,b), 1)).float()
memb = MultiEmbedding(3, n_embeds, cat_pos=[1,2])
# registered buffers are part of the state_dict() but not module.parameters()
assert all([(k in memb.state_dict().keys()) for k in ['cat_pos', 'cont_pos']])
embeddings = memb(inp)
print(n_embeds, szs, inp.shape, embeddings.shape)
test_eq(embeddings.shape, (inp.shape[0],sum(szs)+1,inp.shape[-1]))
# Output:
#   [3, 4] [3, 3] torch.Size([4, 3, 10]) torch.Size([4, 7, 10])


me = MultiEmbedding(3, 4, cat_pos=2)
test_eq(me.cat_embed[0].weight.shape, (4,3))
test_eq(me.cat_pos.cpu().item(), 2)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/029_models.layers.ipynb saved at 2025-01-22 18:40:22

#   Correct notebook to script conversion! 😃

#   Wednesday 22/01/25 18:40:25 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/030_models.utils.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.utils

"""
# Model utilities
"""

"""
>Utility functions used to build PyTorch timeseries models.
"""

#|export
from tsai.imports import *
from copy import deepcopy
from fastai.layers import flatten_model, params, apply_init
from fastai.learner import Learner
from fastai.data.transforms import get_c
from fastai.tabular.model import *
from fastai.callback.schedule import *
from fastai.vision.models.xresnet import *
from tsai.models.layers import *

#|export
def apply_idxs(o, idxs):
    "Function to apply indices to zarr, dask and numpy arrays"
    if is_zarr(o): return o.oindex[idxs]
    elif is_dask(o): return o[idxs].compute()
    else: return o[idxs]

#|export
def SeqTokenizer(c_in, embed_dim, token_size=60, norm=False):
    "Generates non-overlapping tokens from sub-sequences within a sequence by applying a sliding window"
    return ConvBlock(c_in, embed_dim, token_size, stride=token_size, padding=0, act=None,
                     norm='Batch' if norm else None, bias=norm is None)

SeqEmbed = SeqTokenizer

#|export
def get_embed_size(n_cat, rule='log2'):
    if rule == 'log2':
        return int(np.ceil(np.log2(n_cat)))
    elif rule == 'thumb':
        return min(600, round(1.6 * n_cat**0.56)) # fastai's

test_eq(get_embed_size(35), 6)

#|export
def get_layers(model, cond=noop, full=True):
    if isinstance(model, Learner): model=model.model
    if full: return [m for m in flatten_model(model) if any([c(m) for c in L(cond)])]
    else: return [m for m in model if any([c(m) for c in L(cond)])]

def is_layer(*args):
    def _is_layer(l, cond=args):
        return isinstance(l, cond)
    return partial(_is_layer, cond=args)

def is_linear(l):
    return isinstance(l, nn.Linear)

def is_bn(l):
    types = (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)
    return isinstance(l, types)

def is_conv_linear(l):
    types = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear)
    return isinstance(l, types)

def is_affine_layer(l):
    return has_bias(l) or has_weight(l)

def is_conv(l):
    types = (nn.Conv1d, nn.Conv2d, nn.Conv3d)
    return isinstance(l, types)

def has_bias(l):
    return (hasattr(l, 'bias') and l.bias is not None)

def has_weight(l):
    return (hasattr(l, 'weight'))

def has_weight_or_bias(l):
    return any((has_weight(l), has_bias(l)))

#|export
def check_bias(m, cond=noop, verbose=False):
    mean, std = [], []
    for i,l in enumerate(get_layers(m, cond=cond)):
        if hasattr(l, 'bias') and l.bias is not None:
            b = l.bias.data
            mean.append(b.mean())
            std.append(b.std())
            pv(f'{i:3} {l.__class__.__name__:15} shape: {str(list(b.shape)):15}  mean: {b.mean():+6.3f}  std: {b.std():+6.3f}', verbose)
    return np.array(mean), np.array(std)

def check_weight(m, cond=noop, verbose=False):
    mean, std = [], []
    for i,l in enumerate(get_layers(m, cond=cond)):
        if hasattr(l, 'weight') and l.weight is not None:
            w = l.weight.data
            mean.append(w.mean())
            std.append(w.std())
            pv(f'{i:3} {l.__class__.__name__:15} shape: {str(list(w.shape)):15}  mean: {w.mean():+6.3f}  std: {w.std():+6.3f}', verbose)
    return np.array(mean), np.array(std)

#|export
def get_nf(m):
    "Get nf from model's first linear layer in head"
    return get_layers(m[-1], is_linear)[0].in_features

#|export
def ts_splitter(m):
    "Split of a model between body and head"
    return L(m.backbone, m.head).map(params)

#|export
def transfer_weights(model, weights_path:Path, device:torch.device=None, exclude_head:bool=True):
    """Utility function that allows to easily transfer weights between models.
    Taken from the great self-supervised repository created by Kerem Turgutlu.
    https://github.com/KeremTurgutlu/self_supervised/blob/d87ebd9b4961c7da0efd6073c42782bbc61aaa2e/self_supervised/utils.py"""

    device = ifnone(device, default_device())
    state_dict = model.state_dict()
    new_state_dict = torch.load(weights_path, map_location=device)
    matched_layers = 0
    unmatched_layers = []
    for name, param in state_dict.items():
        if exclude_head and 'head' in name: continue
        if name in new_state_dict:
            matched_layers += 1
            input_param = new_state_dict[name]
            if input_param.shape == param.shape: param.copy_(input_param)
            else: unmatched_layers.append(name)
        else:
            unmatched_layers.append(name)
            pass # these are weights that weren't in the original model, such as a new head
    if matched_layers == 0: raise Exception("No shared weight names were found between the models")
    else:
        if len(unmatched_layers) > 0:
            print(f'check unmatched_layers: {unmatched_layers}')
        else:
            print(f"weights from {weights_path} successfully transferred!\n")

#|export
def build_ts_model(arch, c_in=None, c_out=None, seq_len=None, d=None, dls=None, device=None, verbose=False,
                   s_cat_idxs=None, s_cat_embeddings=None, s_cat_embedding_dims=None, s_cont_idxs=None,
                   o_cat_idxs=None, o_cat_embeddings=None, o_cat_embedding_dims=None, o_cont_idxs=None,
                   patch_len=None, patch_stride=None, fusion_layers=128, fusion_act='relu', fusion_dropout=0., fusion_use_bn=True,
                   pretrained=False, weights_path=None, exclude_head=True, cut=-1, init=None, arch_config={}, **kwargs):

    device = ifnone(device, default_device())
    if dls is not None:
        c_in = ifnone(c_in, dls.vars)
        c_out = ifnone(c_out, dls.c)
        seq_len = ifnone(seq_len, dls.len)
        d = ifnone(d, dls.d)

    if s_cat_idxs or s_cat_embeddings or s_cat_embedding_dims or s_cont_idxs or o_cat_idxs or o_cat_embeddings or o_cat_embedding_dims or o_cont_idxs:
        from tsai.models.multimodal import MultInputWrapper
        model = MultInputWrapper(arch, c_in=c_in, c_out=c_out, seq_len=seq_len, d=d,
                                 s_cat_idxs=s_cat_idxs, s_cat_embeddings=s_cat_embeddings, s_cat_embedding_dims=s_cat_embedding_dims, s_cont_idxs=s_cont_idxs,
                                 o_cat_idxs=o_cat_idxs, o_cat_embeddings=o_cat_embeddings, o_cat_embedding_dims=o_cat_embedding_dims, o_cont_idxs=o_cont_idxs,
                                 patch_len=patch_len, patch_stride=patch_stride,
                                 fusion_layers=fusion_layers, fusion_act=fusion_act, fusion_dropout=fusion_dropout, fusion_use_bn=fusion_use_bn,**arch_config,
                                 **kwargs)
    else:
        if d and arch.__name__ not in ["PatchTST", "PatchTSTPlus", 'TransformerRNNPlus', 'TransformerLSTMPlus', 'TransformerGRUPlus',
        "RNN_FCNPlus", "LSTM_FCNPlus", "GRU_FCNPlus", "MRNN_FCNPlus", "MLSTM_FCNPlus", "MGRU_FCNPlus",
        "RNNAttentionPlus", "LSTMAttentionPlus", "GRUAttentionPlus", "ConvTran", "ConvTranPlus"]:
            if 'custom_head' not in kwargs.keys():
                if "rocket" in arch.__name__.lower() or 'hydra' in arch.__name__.lower():
                    kwargs['custom_head'] = partial(rocket_nd_head, d=d)
                elif "xresnet1d" in arch.__name__.lower():
                    kwargs["custom_head"] = partial(xresnet1d_nd_head, d=d)
                else:
                    kwargs['custom_head'] = partial(lin_nd_head, d=d)
            elif not isinstance(kwargs['custom_head'], nn.Module):
                kwargs['custom_head'] = partial(kwargs['custom_head'], d=d)
        if 'ltsf_' in arch.__name__.lower() or 'patchtst' in arch.__name__.lower():
            pv(f'arch: {arch.__name__}(c_in={c_in} c_out={c_out} seq_len={seq_len} pred_dim={d} arch_config={arch_config}, kwargs={kwargs})', verbose)
            model = (arch(c_in=c_in, c_out=c_out, seq_len=seq_len, pred_dim=d, **arch_config, **kwargs)).to(device=device)
        elif arch.__name__ in ['TransformerRNNPlus', 'TransformerLSTMPlus', 'TransformerGRUPlus', "RNN_FCNPlus", "LSTM_FCNPlus", "GRU_FCNPlus", "MRNN_FCNPlus",
        "MLSTM_FCNPlus", "MGRU_FCNPlus", "RNNAttentionPlus", "LSTMAttentionPlus", "GRUAttentionPlus", "ConvTran", "ConvTranPlus", 'mWDNPlus']:
            pv(f'arch: {arch.__name__}(c_in={c_in} c_out={c_out} seq_len={seq_len} d={d} arch_config={arch_config}, kwargs={kwargs})', verbose)
            model = (arch(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, **arch_config, **kwargs)).to(device=device)
        elif sum([1 for v in ['RNN_FCN', 'LSTM_FCN', 'RNNPlus', 'LSTMPlus', 'GRUPlus', 'InceptionTime', 'TSiT', 'Sequencer', 'XceptionTimePlus',
                            'GRU_FCN', 'OmniScaleCNN', 'mWDN', 'TST', 'XCM', 'MLP', 'MiniRocket', 'InceptionRocket', 'ResNetPlus',
                            'RNNAttention', 'LSTMAttention', 'GRUAttention', 'MultiRocket', 'MultiRocketPlus', 'Hydra', 'HydraPlus',
                            'HydraMultiRocket', 'HydraMultiRocketPlus']
                if v in arch.__name__]):
            pv(f'arch: {arch.__name__}(c_in={c_in} c_out={c_out} seq_len={seq_len} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = arch(c_in, c_out, seq_len=seq_len, **arch_config, **kwargs).to(device=device)
        elif 'xresnet' in arch.__name__ and not '1d' in arch.__name__:
            pv(f'arch: {arch.__name__}(c_in={c_in} n_out={c_out} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = (arch(c_in=c_in, n_out=c_out, **arch_config, **kwargs)).to(device=device)
        elif 'xresnet1d' in arch.__name__.lower():
            pv(f'arch: {arch.__name__}(c_in={c_in} c_out={c_out} seq_len={seq_len} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = (arch(c_in=c_in, c_out=c_out, seq_len=seq_len, **arch_config, **kwargs)).to(device=device)
        elif 'minirockethead' in arch.__name__.lower():
            pv(f'arch: {arch.__name__}(c_in={c_in} seq_len={seq_len} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = (arch(c_in, c_out, seq_len=1, **arch_config, **kwargs)).to(device=device)
        elif 'rocket' in arch.__name__.lower():
            pv(f'arch: {arch.__name__}(c_in={c_in} seq_len={seq_len} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = (arch(c_in=c_in, seq_len=seq_len, **arch_config, **kwargs)).to(device=device)
        else:
            pv(f'arch: {arch.__name__}(c_in={c_in} c_out={c_out} arch_config={arch_config} kwargs={kwargs})', verbose)
            model = arch(c_in, c_out, **arch_config, **kwargs).to(device=device)

    try:
        model[0], model[1]
        subscriptable = True
    except:
        subscriptable = False
    if hasattr(model, "head_nf"):  head_nf = model.head_nf
    else:
        try: head_nf = get_nf(model)
        except: head_nf = None

    if not subscriptable and 'Plus' in arch.__name__:
        model = nn.Sequential(*model.children())
        model.backbone = model[:cut]
        model.head = model[cut:]

    if pretrained and not ('xresnet' in arch.__name__ and not '1d' in arch.__name__):
        assert weights_path is not None, "you need to pass a valid weights_path to use a pre-trained model"
        transfer_weights(model, weights_path, exclude_head=exclude_head, device=device)

    if init is not None:
        apply_init(model[1] if pretrained else model, init)

    setattr(model, "head_nf", head_nf)
    setattr(model, "__name__", arch.__name__)

    return model

build_model = build_ts_model
create_model = build_ts_model

from tsai.data.core import get_ts_dls, TSClassification
from tsai.models.TSiTPlus import TSiTPlus
from fastai.losses import CrossEntropyLossFlat

X = np.random.rand(16, 3, 128)
y = np.random.randint(0, 2, (16, 3))
tfms = [None, [TSClassification()]]
dls = get_ts_dls(X, y, splits=RandomSplitter()(range_of(X)), tfms=tfms)
model = build_ts_model(TSiTPlus, dls=dls, pretrained=False, verbose=True)
xb, yb = dls.one_batch()
output = model(xb)
print(output.shape)
loss = CrossEntropyLossFlat()(output, yb)
print(loss)
assert output.shape == (dls.bs, dls.d, dls.c)
# Output:
#   arch: TSiTPlus(c_in=3 c_out=2 seq_len=128 arch_config={} kwargs={'custom_head': functools.partial(<class 'tsai.models.layers.lin_nd_head'>, d=3)})

#   torch.Size([13, 3, 2])

#   TensorBase(0.8796, grad_fn=<AliasBackward0>)


#|export
def count_parameters(model, trainable=True):
    if trainable: return sum(p.numel() for p in model.parameters() if p.requires_grad)
    else: return sum(p.numel() for p in model.parameters())

#|export
# @delegates(XResNet.__init__)
def build_tsimage_model(arch, c_in=None, c_out=None, dls=None, pretrained=False, device=None, verbose=False, init=None, arch_config={}, **kwargs):
    device = ifnone(device, default_device())
    if dls is not None:
        c_in = ifnone(c_in, dls.vars)
        c_out = ifnone(c_out, dls.c)

    model = arch(pretrained=pretrained, c_in=c_in, n_out=c_out, **arch_config, **kwargs).to(device=device)
    setattr(model, "__name__", arch.__name__)
    if init is not None:
        apply_init(model[1] if pretrained else model, init)
    return model

#|export
# @delegates(TabularModel.__init__)
def build_tabular_model(arch, dls, layers=None, emb_szs=None, n_out=None, y_range=None, device=None, arch_config={}, **kwargs):
    if device is None: device = default_device()
    if layers is None: layers = [200,100]
    emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)
    if n_out is None: n_out = get_c(dls)
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"
    if y_range is None and 'y_range' in kwargs: y_range = kwargs.pop('y_range')
    model = arch(emb_szs, len(dls.cont_names), n_out, layers, y_range=y_range, **arch_config, **kwargs).to(device=device)

    if hasattr(model, "head_nf"):  head_nf = model.head_nf
    else: head_nf = get_nf(model)
    setattr(model, "__name__", arch.__name__)
    if head_nf is not None: setattr(model, "head_nf", head_nf)
    return model

create_tabular_model = build_tabular_model

from tsai.data.external import get_UCR_data
from tsai.data.core import TSCategorize, get_ts_dls
from tsai.data.preprocessing import TSStandardize
from tsai.models.InceptionTime import *

X, y, splits = get_UCR_data('NATOPS', split_data=False)
tfms = [None, TSCategorize()]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(InceptionTime, dls=dls)
test_eq(count_parameters(model), 460038)

#|export
def get_clones(module, N):
    return nn.ModuleList([deepcopy(module) for i in range(N)])

m = nn.Conv1d(3,4,3)
get_clones(m, 3)
# Output:
#   ModuleList(

#     (0-2): 3 x Conv1d(3, 4, kernel_size=(3,), stride=(1,))

#   )

#|export
def split_model(m): return m.backbone, m.head

#|export
@torch.no_grad()
def output_size_calculator(mod, c_in, seq_len=None):
    assert isinstance(mod, nn.Module)
    return_q_len = True
    if seq_len is None:
        seq_len = 50
        return_q_len = False
    try:
        params_0 = list(mod.parameters())[0]
        xb = torch.rand(1, c_in, seq_len, device=params_0.device, dtype=params_0.dtype)
    except:
        xb = torch.rand(1, c_in, seq_len)
    training = mod.training
    mod.eval()
    output_shape = tuple(mod.to(xb.device)(xb).shape)
    if len(output_shape) == 2:
        c_out, q_len = output_shape[1], None
    else:
        c_out, q_len = output_shape[1:]
    mod.training = training
    if return_q_len:
        return c_out, q_len
    else:
        return c_out, None

c_in = 3
seq_len = 30
m = nn.Conv1d(3, 12, kernel_size=3, stride=2)
new_c_in, new_seq_len = output_size_calculator(m, c_in, seq_len)
test_eq((new_c_in, new_seq_len), (12, 14))

#|export
def change_model_head(model, custom_head, **kwargs):
    r"""Replaces a model's head by a custom head as long as the model has a head, head_nf, c_out and seq_len attributes"""
    model.head = custom_head(model.head_nf, model.c_out, model.seq_len, **kwargs)
    return model

#|export
def naive_forecaster(o, split, horizon=1):
    if is_listy(horizon):
        _f = []
        for h in horizon:
            _f.append(o[np.asarray(split)-h])
        return np.stack(_f)
    return o[np.asarray(split) - horizon]

def true_forecaster(o, split, horizon=1):
    o_true = o[split]
    if is_listy(horizon):
        o_true = o_true[np.newaxis].repeat(len(horizon), 0)
    return o_true

a = np.random.rand(20).cumsum()
split = np.arange(10, 20)
a, naive_forecaster(a, split, 1), true_forecaster(a, split, 1)
# Output:
#   (array([0.99029138, 1.68463991, 2.21744589, 2.65448222, 2.85159354,

#           3.26171729, 3.67986707, 4.04343956, 4.3077458 , 4.44585435,

#           4.76876866, 4.85844441, 4.93256093, 5.52415845, 6.10704489,

#           6.74848957, 7.31920741, 8.20198208, 8.78954283, 9.0402    ]),

#    array([4.44585435, 4.76876866, 4.85844441, 4.93256093, 5.52415845,

#           6.10704489, 6.74848957, 7.31920741, 8.20198208, 8.78954283]),

#    array([4.76876866, 4.85844441, 4.93256093, 5.52415845, 6.10704489,

#           6.74848957, 7.31920741, 8.20198208, 8.78954283, 9.0402    ]))

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/030_models.utils.ipynb saved at 2025-01-22 18:23:18

#   Correct notebook to script conversion! 😃

#   Wednesday 22/01/25 18:23:21 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/036_models.InceptionTimePlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.InceptionTimePlus

"""
# InceptionTimePlus
"""

"""
>This is an unofficial PyTorch implementation of InceptionTime (Fawaz, 2019) created by Ignacio Oguiza.
"""

"""
**References:**
* Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2020). [Inceptiontime: Finding alexnet for time series classification. Data Mining and Knowledge Discovery, 34(6), 1936-1962.](https://arxiv.org/pdf/1909.04939)
* Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime
"""

#|export
from tsai.imports import *
from collections import OrderedDict
from fastai.layers import *
from tsai.utils import *
from tsai.models.layers import *
from tsai.models.utils import *

#|export
# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@timeseriesAI.co modified from:

# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). 
# InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.
# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime

    
class InceptionModulePlus(Module):
    def __init__(self, ni, nf, ks=40, bottleneck=True, padding='same', coord=False, separable=False, dilation=1, stride=1, conv_dropout=0., sa=False, se=None,
                 norm='Batch', zero_norm=False, bn_1st=True, act=nn.ReLU, act_kwargs={}):
        
        if not (is_listy(ks) and len(ks) == 3):
            if isinstance(ks, Integral): ks = [ks // (2**i) for i in range(3)]
            ks = [ksi if ksi % 2 != 0 else ksi - 1 for ksi in ks]  # ensure odd ks for padding='same'

        bottleneck = False if ni == nf else bottleneck
        self.bottleneck = Conv(ni, nf, 1, coord=coord, bias=False) if bottleneck else noop # 
        self.convs = nn.ModuleList()
        for i in range(len(ks)): self.convs.append(Conv(nf if bottleneck else ni, nf, ks[i], padding=padding, coord=coord, separable=separable,
                                                         dilation=dilation**i, stride=stride, bias=False))
        self.mp_conv = nn.Sequential(*[nn.MaxPool1d(3, stride=1, padding=1), Conv(ni, nf, 1, coord=coord, bias=False)])
        self.concat = Concat()
        self.norm = Norm(nf * 4, norm=norm, zero_norm=zero_norm)
        self.conv_dropout = nn.Dropout(conv_dropout) if conv_dropout else noop
        self.sa = SimpleSelfAttention(nf * 4) if sa else noop
        self.act = act(**act_kwargs) if act else noop
        self.se = nn.Sequential(SqueezeExciteBlock(nf * 4, reduction=se), BN1d(nf * 4)) if se else noop
        
        self._init_cnn(self)
    
    def _init_cnn(self, m):
        if getattr(self, 'bias', None) is not None: nn.init.constant_(self.bias, 0)
        if isinstance(self, (nn.Conv1d,nn.Conv2d,nn.Conv3d,nn.Linear)): nn.init.kaiming_normal_(self.weight)
        for l in m.children(): self._init_cnn(l)

    def forward(self, x):
        input_tensor = x
        x = self.bottleneck(x)
        x = self.concat([l(x) for l in self.convs] + [self.mp_conv(input_tensor)])
        x = self.norm(x)
        x = self.conv_dropout(x)
        x = self.sa(x)
        x = self.act(x)
        x = self.se(x)
        return x


@delegates(InceptionModulePlus.__init__)
class InceptionBlockPlus(Module):
    def __init__(self, ni, nf, residual=True, depth=6, coord=False, norm='Batch', zero_norm=False, act=nn.ReLU, act_kwargs={}, sa=False, se=None, 
                 stoch_depth=1., **kwargs):
        self.residual, self.depth = residual, depth
        self.inception, self.shortcut, self.act = nn.ModuleList(), nn.ModuleList(), nn.ModuleList()
        for d in range(depth):
            self.inception.append(InceptionModulePlus(ni if d == 0 else nf * 4, nf, coord=coord, norm=norm, 
                                                      zero_norm=zero_norm if d % 3 == 2 else False,
                                                      act=act if d % 3 != 2 else None, act_kwargs=act_kwargs, 
                                                      sa=sa if d % 3 == 2 else False,
                                                      se=se if d % 3 != 2 else None,
                                                      **kwargs))
            if self.residual and d % 3 == 2:
                n_in, n_out = ni if d == 2 else nf * 4, nf * 4
                self.shortcut.append(Norm(n_in, norm=norm) if n_in == n_out else ConvBlock(n_in, n_out, 1, coord=coord, bias=False, norm=norm, act=None))
                self.act.append(act(**act_kwargs))
        self.add = Add()
        if stoch_depth != 0: keep_prob = np.linspace(1, stoch_depth, depth)
        else: keep_prob = np.array([1] * depth)
        self.keep_prob = keep_prob

    def forward(self, x):
        res = x
        for i in range(self.depth):
            if self.keep_prob[i] > random.random() or not self.training:
                x = self.inception[i](x)
            if self.residual and i % 3 == 2: 
                res = x = self.act[i//3](self.add(x, self.shortcut[i//3](res)))
        return x

#|export
@delegates(InceptionModulePlus.__init__)
class InceptionTimePlus(nn.Sequential):
    def __init__(self, c_in, c_out, seq_len=None, nf=32, nb_filters=None,
                 flatten=False, concat_pool=False, fc_dropout=0., bn=False, y_range=None, custom_head=None, **kwargs):
        
        if nb_filters is not None: nf = nb_filters
        else: nf = ifnone(nf, nb_filters) # for compatibility
        backbone = InceptionBlockPlus(c_in, nf, **kwargs)
        
        #head
        self.head_nf = nf * 4
        self.c_out = c_out
        self.seq_len = seq_len
        if custom_head is not None: 
            if isinstance(custom_head, nn.Module): head = custom_head
            else: head = custom_head(self.head_nf, c_out, seq_len)
        else: head = self.create_head(self.head_nf, c_out, seq_len, flatten=flatten, concat_pool=concat_pool, 
                                      fc_dropout=fc_dropout, bn=bn, y_range=y_range)
            
        layers = OrderedDict([('backbone', nn.Sequential(backbone)), ('head', nn.Sequential(head))])
        super().__init__(layers)
        
    def create_head(self, nf, c_out, seq_len, flatten=False, concat_pool=False, fc_dropout=0., bn=False, y_range=None):
        if flatten: 
            nf *= seq_len
            layers = [Flatten()]
        else: 
            if concat_pool: nf *= 2
            layers = [GACP1d(1) if concat_pool else GAP1d(1)]
        layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]
        if y_range: layers += [SigmoidRange(*y_range)]
        return nn.Sequential(*layers)

#|export
class InCoordTime(InceptionTimePlus):
    def __init__(self, *args, coord=True, zero_norm=True, **kwargs):
        super().__init__(*args, coord=coord, zero_norm=zero_norm, **kwargs)


class XCoordTime(InceptionTimePlus):
    def __init__(self, *args, coord=True, separable=True, zero_norm=True, **kwargs):
        super().__init__(*args, coord=coord, separable=separable, zero_norm=zero_norm, **kwargs)
        
InceptionTimePlus17x17 = named_partial('InceptionTimePlus17x17', InceptionTimePlus, nf=17, depth=3)
InceptionTimePlus32x32 = named_partial('InceptionTimePlus32x32', InceptionTimePlus)
InceptionTimePlus47x47 = named_partial('InceptionTimePlus47x47', InceptionTimePlus, nf=47, depth=9)
InceptionTimePlus62x62 = named_partial('InceptionTimePlus62x62', InceptionTimePlus, nf=62, depth=9)
InceptionTimeXLPlus = named_partial('InceptionTimeXLPlus', InceptionTimePlus, nf=64, depth=12)

from tsai.data.core import TSCategorize
from tsai.models.utils import count_parameters

bs = 16
n_vars = 3
seq_len = 51
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)

test_eq(InceptionTimePlus(n_vars,c_out)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out,concat_pool=True)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, bottleneck=False)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, residual=False)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, conv_dropout=.5)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, stoch_depth=.5)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars, c_out, seq_len=seq_len, zero_norm=True, flatten=True)(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, coord=True, separable=True, 
                          norm='Instance', zero_norm=True, bn_1st=False, fc_dropout=.5, sa=True, se=True, act=nn.PReLU, act_kwargs={})(xb).shape, [bs, c_out])
test_eq(InceptionTimePlus(n_vars,c_out, coord=True, separable=True,
                          norm='Instance', zero_norm=True, bn_1st=False, act=nn.PReLU, act_kwargs={})(xb).shape, [bs, c_out])
test_eq(count_parameters(InceptionTimePlus(3, 2)), 455490)
test_eq(count_parameters(InceptionTimePlus(6, 2, **{'coord': True, 'separable': True, 'zero_norm': True})), 77204)
test_eq(count_parameters(InceptionTimePlus(3, 2, ks=40)), count_parameters(InceptionTimePlus(3, 2, ks=[9, 19, 39])))

bs = 16
n_vars = 3
seq_len = 51
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)

model = InceptionTimePlus(n_vars, c_out)
model(xb).shape
test_eq(model[0](xb), model.backbone(xb))
test_eq(model[1](model[0](xb)), model.head(model[0](xb)))
test_eq(model[1].state_dict().keys(), model.head.state_dict().keys())
test_eq(len(ts_splitter(model)), 2)

test_eq(check_bias(InceptionTimePlus(2,3, zero_norm=True), is_conv)[0].sum(), 0)
test_eq(check_weight(InceptionTimePlus(2,3, zero_norm=True), is_bn)[0].sum(), 6)
test_eq(check_weight(InceptionTimePlus(2,3), is_bn)[0], np.array([1., 1., 1., 1., 1., 1., 1., 1.]))

for i in range(10): InceptionTimePlus(n_vars,c_out,stoch_depth=0.8,depth=9,zero_norm=True)(xb)

net = InceptionTimePlus(2,3,**{'coord': True, 'separable': True, 'zero_norm': True})
test_eq(check_weight(net, is_bn)[0], np.array([1., 1., 0., 1., 1., 0., 1., 1.]))
net
# Output:
#   InceptionTimePlus(

#     (backbone): Sequential(

#       (0): InceptionBlockPlus(

#         (inception): ModuleList(

#           (0): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(3, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#             (act): ReLU()

#           )

#           (1): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#             (act): ReLU()

#           )

#           (2): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#           )

#           (3): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#             (act): ReLU()

#           )

#           (4): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#             (act): ReLU()

#           )

#           (5): InceptionModulePlus(

#             (bottleneck): ConvBlock(

#               (0): AddCoords1d()

#               (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#             )

#             (convs): ModuleList(

#               (0): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(39,), stride=(1,), padding=(19,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(19,), stride=(1,), padding=(9,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#               (2): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): SeparableConv1d(

#                   (depthwise_conv): Conv1d(33, 33, kernel_size=(9,), stride=(1,), padding=(4,), groups=33, bias=False)

#                   (pointwise_conv): Conv1d(33, 32, kernel_size=(1,), stride=(1,), bias=False)

#                 )

#               )

#             )

#             (mp_conv): Sequential(

#               (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)

#               (1): ConvBlock(

#                 (0): AddCoords1d()

#                 (1): Conv1d(129, 32, kernel_size=(1,), stride=(1,), bias=False)

#               )

#             )

#             (concat): Concat(dim=1)

#             (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#           )

#         )

#         (shortcut): ModuleList(

#           (0): ConvBlock(

#             (0): AddCoords1d()

#             (1): Conv1d(3, 128, kernel_size=(1,), stride=(1,), bias=False)

#             (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#           )

#           (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#         )

#         (act): ModuleList(

#           (0): ReLU()

#           (1): ReLU()

#         )

#         (add): Add

#       )

#     )

#     (head): Sequential(

#       (0): Sequential(

#         (0): GAP1d(

#           (gap): AdaptiveAvgPool1d(output_size=1)

#           (flatten): Reshape(bs)

#         )

#         (1): LinBnDrop(

#           (0): Linear(in_features=128, out_features=3, bias=True)

#         )

#       )

#     )

#   )

#|export
@delegates(InceptionTimePlus.__init__)
class MultiInceptionTimePlus(nn.Sequential):
    """Class that allows you to create a model with multiple branches of InceptionTimePlus."""
    _arch = InceptionTimePlus
    def __init__(self, feat_list, c_out, seq_len=None, nf=32, nb_filters=None, depth=6, stoch_depth=1., 
                flatten=False, concat_pool=False, fc_dropout=0., bn=False, y_range=None, custom_head=None, **kwargs):
        """
        Args:
            feat_list: list with number of features that will be passed to each body.
        """
        self.feat_list = [feat_list] if isinstance(feat_list, int) else feat_list 
        
        # Backbone
        branches = nn.ModuleList()
        self.head_nf = 0
        for feat in self.feat_list:
            if is_listy(feat): feat = len(feat)
            m = build_ts_model(self._arch, c_in=feat, c_out=c_out, seq_len=seq_len, nf=nf, nb_filters=nb_filters, 
                               depth=depth, stoch_depth=stoch_depth, **kwargs)
            self.head_nf += output_size_calculator(m[0], feat, ifnone(seq_len, 10))[0]
            branches.append(m.backbone)
        backbone = _Splitter(self.feat_list, branches)
        
        # Head
        self.c_out = c_out
        self.seq_len = seq_len
        if custom_head is None:
            head = self._arch.create_head(self, self.head_nf, c_out, seq_len, flatten=flatten, concat_pool=concat_pool, 
                                          fc_dropout=fc_dropout, bn=bn, y_range=y_range)
        else: 
            head = custom_head(self.head_nf, c_out, seq_len)
        
        layers = OrderedDict([('backbone', nn.Sequential(backbone)), ('head', nn.Sequential(head))])
        super().__init__(layers)

#|exporti
class _Splitter(Module):
    def __init__(self, feat_list, branches):
        self.feat_list, self.branches = feat_list, branches
    def forward(self, x):
        if is_listy(self.feat_list[0]): 
            x = [x[:, feat] for feat in self.feat_list]
        else: 
            x = torch.split(x, self.feat_list, dim=1)
        _out = []
        for xi, branch in zip(x, self.branches): _out.append(branch(xi))
        output = torch.cat(_out, dim=1)
        return output

bs = 16
n_vars = 3
seq_len = 51
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)

test_eq(count_parameters(MultiInceptionTimePlus([1,1,1], c_out)) > count_parameters(MultiInceptionTimePlus(3, c_out)), True)
test_eq(MultiInceptionTimePlus([1,1,1], c_out).to(xb.device)(xb).shape, MultiInceptionTimePlus(3, c_out).to(xb.device)(xb).shape)
# Output:
#   [W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.


bs = 16
n_vars = 3
seq_len = 12
c_out = 10
xb = torch.rand(bs, n_vars, seq_len)
new_head = partial(conv_lin_nd_head, d=(5,2))
net = MultiInceptionTimePlus(n_vars, c_out, seq_len, custom_head=new_head)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([16, 5, 2, 10])

#   Sequential(

#     (0): create_conv_lin_nd_head(

#       (0): Conv1d(128, 10, kernel_size=(1,), stride=(1,))

#       (1): Linear(in_features=12, out_features=10, bias=True)

#       (2): Transpose(-1, -2)

#       (3): Reshape(bs, 5, 2, 10)

#     )

#   )

bs = 16
n_vars = 6
seq_len = 12
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)
net = MultiInceptionTimePlus([1,2,3], c_out, seq_len)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([16, 2])

#   Sequential(

#     (0): Sequential(

#       (0): GAP1d(

#         (gap): AdaptiveAvgPool1d(output_size=1)

#         (flatten): Reshape(bs)

#       )

#       (1): LinBnDrop(

#         (0): Linear(in_features=384, out_features=2, bias=True)

#       )

#     )

#   )

bs = 8
c_in = 7  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 10
xb2 = torch.randn(bs, c_in, seq_len)
model1 = MultiInceptionTimePlus([2, 5], c_out, seq_len)
model2 = MultiInceptionTimePlus([[0,2,5], [0,1,3,4,6]], c_out, seq_len)
test_eq(model1.to(xb2.device)(xb2).shape, (bs, c_out))
test_eq(model1.to(xb2.device)(xb2).shape, model2.to(xb2.device)(xb2).shape)

from tsai.data.external import *
from tsai.data.core import *
from tsai.data.preprocessing import *

X, y, splits = get_UCR_data('NATOPS', split_data=False)
tfms  = [None, [TSCategorize()]]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = InceptionTimePlus(dls.vars, dls.c, dls.len)
xb,yb=first(dls.train)
test_eq(model.to(xb.device)(xb).shape, (dls.bs, dls.c))
test_eq(count_parameters(model), 460038)

X, y, splits = get_UCR_data('NATOPS', split_data=False)
tfms  = [None, [TSCategorize()]]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = MultiInceptionTimePlus([4, 15, 5], dls.c, dls.len)
xb,yb=first(dls.train)
test_eq(model.to(xb.device)(xb).shape, (dls.bs, dls.c))
test_eq(count_parameters(model), 1370886)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/036_models.InceptionTimePlus.ipynb saved at 2023-03-19 14:18:56

#   Correct notebook to script conversion! 😃

#   Sunday 19/03/23 14:18:59 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/037_models.MLP.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.MLP

"""
# MLP
"""

"""
This is an unofficial PyTorch implementation created by Ignacio Oguiza (oguiza@timeseriesAI.co) based on:

Fawaz, H. I., Forestier, G., Weber, J., Idoumghar, L., & Muller, P. A.
(2019). <span style="color:dodgerblue">**Deep learning for time series classification: a review**</span>. Data Mining and
Knowledge Discovery, 33(4), 917-963. 

Official MLP TensorFlow implementation:
https://github.com/hfawaz/dl-4-tsc/blob/master/classifiers/mlp.py
"""

#|export
from tsai.imports import *
from fastai.layers import *
from tsai.models.layers import *

#|export
class MLP(Module):
    def __init__(self, c_in, c_out, seq_len, layers=[500,500,500], ps=[0.1, 0.2, 0.2], act=nn.ReLU(inplace=True),
                 use_bn=False, bn_final=False, lin_first=False, fc_dropout=0., y_range=None):
        layers, ps = L(layers), L(ps)
        if len(ps) <= 1: ps = ps * len(layers)
        assert len(layers) == len(ps), '#layers and #ps must match'
        self.flatten = Reshape()
        nf = [c_in * seq_len] + layers
        self.mlp = nn.ModuleList()
        for i in range(len(layers)): self.mlp.append(LinBnDrop(nf[i], nf[i+1], bn=use_bn, p=ps[i], act=get_act_fn(act), lin_first=lin_first))
        _head = [LinBnDrop(nf[-1], c_out, bn=bn_final, p=fc_dropout)]
        if y_range is not None: _head.append(SigmoidRange(*y_range))
        self.head = nn.Sequential(*_head)

    def forward(self, x):
        x = self.flatten(x)
        for mlp in self.mlp: x = mlp(x)
        return self.head(x)

bs = 16
nvars = 3
seq_len = 128
c_out = 2
xb = torch.rand(bs, nvars, seq_len)
model = MLP(nvars, c_out, seq_len)
test_eq(model(xb).shape, (bs, c_out))
model
# Output:
#   MLP(

#     (flatten): Reshape(bs)

#     (mlp): ModuleList(

#       (0): LinBnDrop(

#         (0): Dropout(p=0.1, inplace=False)

#         (1): Linear(in_features=384, out_features=500, bias=True)

#         (2): ReLU(inplace=True)

#       )

#       (1): LinBnDrop(

#         (0): Dropout(p=0.2, inplace=False)

#         (1): Linear(in_features=500, out_features=500, bias=True)

#         (2): ReLU(inplace=True)

#       )

#       (2): LinBnDrop(

#         (0): Dropout(p=0.2, inplace=False)

#         (1): Linear(in_features=500, out_features=500, bias=True)

#         (2): ReLU(inplace=True)

#       )

#     )

#     (head): Sequential(

#       (0): LinBnDrop(

#         (0): Linear(in_features=500, out_features=2, bias=True)

#       )

#     )

#   )

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/037_models.MLP.ipynb saved at 2023-03-15 11:58:07

#   Correct notebook to script conversion! 😃

#   Wednesday 15/03/23 11:58:09 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/039_models.FCNPlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.FCNPlus

"""
# FCNPlus
"""

"""
>This is an unofficial PyTorch implementation created by Ignacio Oguiza - oguiza@timeseriesAI.co
"""

#|export
from tsai.imports import *
from fastai.layers import *
from tsai.models.layers import *

#|export
class FCNPlus(nn.Sequential):
    def __init__(self, c_in, c_out, layers=[128, 256, 128], kss=[7, 5, 3], coord=False, separable=False, use_bn=False, fc_dropout=0.,
                 zero_norm=False, act=nn.ReLU, act_kwargs={}, residual=False, custom_head=None):
        assert len(layers) == len(kss)
        backbone = _FCNBlockPlus(c_in, layers=layers, kss=kss, coord=coord, separable=separable,
                                 zero_norm=zero_norm, act=act, act_kwargs=act_kwargs, residual=residual)
        self.head_nf = layers[2]
        head_layers = [nn.AdaptiveAvgPool1d(1), Squeeze(-1)]
        if use_bn: head_layers += [nn.BatchNorm1d(layers[-1])]
        if fc_dropout != 0: head_layers += [nn.Dropout(fc_dropout)]
        head_layers += [nn.Linear(layers[-1], c_out)]
        if custom_head: head = custom_head(self.head_nf, c_out) # custom head passed as a partial func with all its kwargs
        else: head = nn.Sequential(*head_layers)
        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))


class _FCNBlockPlus(Module):
    def __init__(self, c_in, layers=[128, 256, 128], kss=[7, 5, 3], coord=False, separable=False,
                 zero_norm=False, act=nn.ReLU, act_kwargs={}, residual=False):
        self.residual = residual
        self.convblock1 = ConvBlock(
            c_in, layers[0], kss[0], coord=coord, separable=separable, act=act, act_kwargs=act_kwargs)
        self.convblock2 = ConvBlock(
            layers[0], layers[1], kss[1], coord=coord, separable=separable, act=act, act_kwargs=act_kwargs)
        self.convblock3 = ConvBlock(layers[1], layers[2], kss[2], coord=coord, separable=separable, zero_norm=zero_norm if residual else False,
                                    act=None if residual else act, act_kwargs=act_kwargs)
        if residual:
            self.shortcut = BN1d(layers[2]) if c_in == layers[2] else ConvBlock(
                c_in, layers[2], 1, coord=coord, act=None)
        self.add = Add() if residual else Noop

    def forward(self, x):
        if self.residual:
            res = x
        x = self.convblock1(x)
        x = self.convblock2(x)
        x = self.convblock3(x)
        if self.residual:
            x = self.add(x, self.shortcut(res))
        return x

xb = torch.rand(16, 3, 10)
test_eq(FCNPlus(3, 2)(xb).shape, [xb.shape[0], 2])
test_eq(FCNPlus(3, 2, coord=True, separable=True, act=Swish, residual=True)(xb).shape, [xb.shape[0], 2])
test_eq(nn.Sequential(*FCNPlus(3, 2).children())(xb).shape, [xb.shape[0], 2])
test_eq(FCNPlus(3, 2, custom_head=partial(mlp_head, seq_len=10))(xb).shape, [xb.shape[0], 2])

from tsai.models.utils import *

model = build_ts_model(FCNPlus, 2, 3)
model[-1]
# Output:
#   Sequential(

#     (0): AdaptiveAvgPool1d(output_size=1)

#     (1): Squeeze(dim=-1)

#     (2): Linear(in_features=128, out_features=3, bias=True)

#   )

from tsai.models.FCN import *

test_eq(count_parameters(FCN(3,2)), count_parameters(FCNPlus(3,2)))

FCNPlus(3,2)
# Output:
#   FCNPlus(

#     (backbone): _FCNBlockPlus(

#       (convblock1): ConvBlock(

#         (0): Conv1d(3, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)

#         (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#         (2): ReLU()

#       )

#       (convblock2): ConvBlock(

#         (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)

#         (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#         (2): ReLU()

#       )

#       (convblock3): ConvBlock(

#         (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)

#         (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#         (2): ReLU()

#       )

#       (add): Sequential()

#     )

#     (head): Sequential(

#       (0): AdaptiveAvgPool1d(output_size=1)

#       (1): Squeeze(dim=-1)

#       (2): Linear(in_features=128, out_features=2, bias=True)

#     )

#   )

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/103c_models.FCNPlus.ipynb saved at 2022-11-21 13:16:09

#   Correct notebook to script conversion! 😃

#   Monday 21/11/22 13:16:11 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/046_models.RNN_FCN.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.RNN_FCN

"""
# RNN_FCN
"""

"""
>This is an unofficial PyTorch implementation created by Ignacio Oguiza - oguiza@timeseriesAI.co
"""

#|export
from tsai.imports import *
from tsai.models.layers import *

#|export
class _RNN_FCN_Base(Module):
    def __init__(self, c_in, c_out, seq_len=None, hidden_size=100, rnn_layers=1, bias=True, cell_dropout=0, rnn_dropout=0.8, bidirectional=False, shuffle=True, 
                 fc_dropout=0., conv_layers=[128, 256, 128], kss=[7, 5, 3], se=0):
        
        if shuffle: assert seq_len is not None, 'need seq_len if shuffle=True'
            
        # RNN
        self.rnn = self._cell(seq_len if shuffle else c_in, hidden_size, num_layers=rnn_layers, bias=bias, batch_first=True, 
                              dropout=cell_dropout, bidirectional=bidirectional)
        self.rnn_dropout = nn.Dropout(rnn_dropout) if rnn_dropout else noop
        self.shuffle = Permute(0,2,1) if not shuffle else noop # You would normally permute x. Authors did the opposite.
        
        # FCN
        assert len(conv_layers) == len(kss)
        self.convblock1 = ConvBlock(c_in, conv_layers[0], kss[0])
        self.se1 = SqueezeExciteBlock(conv_layers[0], se) if se != 0 else noop
        self.convblock2 = ConvBlock(conv_layers[0], conv_layers[1], kss[1])
        self.se2 = SqueezeExciteBlock(conv_layers[1], se) if se != 0 else noop
        self.convblock3 = ConvBlock(conv_layers[1], conv_layers[2], kss[2])
        self.gap = GAP1d(1)
        
        # Common
        self.concat = Concat()
        self.fc_dropout = nn.Dropout(fc_dropout) if fc_dropout else noop
        self.fc = nn.Linear(hidden_size * (1 + bidirectional) + conv_layers[-1], c_out)
        

    def forward(self, x):  
        # RNN
        rnn_input = self.shuffle(x) # permute --> (batch_size, seq_len, n_vars) when batch_first=True
        output, _ = self.rnn(rnn_input)
        last_out = output[:, -1] # output of last sequence step (many-to-one)
        last_out = self.rnn_dropout(last_out)
        
        # FCN
        x = self.convblock1(x)
        x = self.se1(x)
        x = self.convblock2(x)
        x = self.se2(x)
        x = self.convblock3(x)
        x = self.gap(x)

        # Concat
        x = self.concat([last_out, x])
        x = self.fc_dropout(x)
        x = self.fc(x)
        return x
            

class RNN_FCN(_RNN_FCN_Base):
    _cell = nn.RNN
    
class LSTM_FCN(_RNN_FCN_Base):
    _cell = nn.LSTM
    
class GRU_FCN(_RNN_FCN_Base):
    _cell = nn.GRU
    
class MRNN_FCN(_RNN_FCN_Base):
    _cell = nn.RNN
    def __init__(self, *args, se=16, **kwargs):
        super().__init__(*args, se=se, **kwargs)
    
class MLSTM_FCN(_RNN_FCN_Base):
    _cell = nn.LSTM
    def __init__(self, *args, se=16, **kwargs):
        super().__init__(*args, se=se, **kwargs)
    
class MGRU_FCN(_RNN_FCN_Base):
    _cell = nn.GRU
    def __init__(self, *args, se=16, **kwargs):
        super().__init__(*args, se=se, **kwargs)

bs = 16
n_vars = 3
seq_len = 12
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)
test_eq(RNN_FCN(n_vars, c_out, seq_len)(xb).shape, [bs, c_out])
test_eq(LSTM_FCN(n_vars, c_out, seq_len)(xb).shape, [bs, c_out])
test_eq(MLSTM_FCN(n_vars, c_out, seq_len)(xb).shape, [bs, c_out])
test_eq(GRU_FCN(n_vars, c_out, shuffle=False)(xb).shape, [bs, c_out])
test_eq(GRU_FCN(n_vars, c_out, seq_len, shuffle=False)(xb).shape, [bs, c_out])

LSTM_FCN(n_vars, seq_len, c_out, se=8)
# Output:
#   LSTM_FCN(

#     (rnn): LSTM(2, 100, batch_first=True)

#     (rnn_dropout): Dropout(p=0.8, inplace=False)

#     (convblock1): ConvBlock(

#       (0): Conv1d(3, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)

#       (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (se1): SqueezeExciteBlock(

#       (avg_pool): GAP1d(

#         (gap): AdaptiveAvgPool1d(output_size=1)

#         (flatten): Flatten(full=False)

#       )

#       (fc): Sequential(

#         (0): Linear(in_features=128, out_features=16, bias=False)

#         (1): ReLU()

#         (2): Linear(in_features=16, out_features=128, bias=False)

#         (3): Sigmoid()

#       )

#     )

#     (convblock2): ConvBlock(

#       (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)

#       (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (se2): SqueezeExciteBlock(

#       (avg_pool): GAP1d(

#         (gap): AdaptiveAvgPool1d(output_size=1)

#         (flatten): Flatten(full=False)

#       )

#       (fc): Sequential(

#         (0): Linear(in_features=256, out_features=32, bias=False)

#         (1): ReLU()

#         (2): Linear(in_features=32, out_features=256, bias=False)

#         (3): Sigmoid()

#       )

#     )

#     (convblock3): ConvBlock(

#       (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)

#       (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (gap): GAP1d(

#       (gap): AdaptiveAvgPool1d(output_size=1)

#       (flatten): Flatten(full=False)

#     )

#     (concat): Concat(dim=1)

#     (fc): Linear(in_features=228, out_features=12, bias=True)

#   )

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/107_models.RNN_FCN.ipynb saved at 2022-11-09 13:05:09

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:05:11 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/049_models.TST.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TST

"""
# TST
"""

"""
This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@timeseriesAI.co based on:
* George Zerveas et al. A Transformer-based Framework for Multivariate Time Series Representation Learning, in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21), August 14--18, 2021. ArXiV version: https://arxiv.org/abs/2010.02803
* Official implementation: https://github.com/gzerveas/mvts_transformer

```bash
@inproceedings{10.1145/3447548.3467401,
author = {Zerveas, George and Jayaraman, Srideepika and Patel, Dhaval and Bhamidipaty, Anuradha and Eickhoff, Carsten},
title = {A Transformer-Based Framework for Multivariate Time Series Representation Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467401},
doi = {10.1145/3447548.3467401},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2114–2124},
numpages = {11},
keywords = {regression, framework, multivariate time series, classification, transformer, deep learning, self-supervised learning, unsupervised learning, imputation},
location = {Virtual Event, Singapore},
series = {KDD '21}
}
```


This paper uses 'Attention is all you need' as a major reference:
* Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). **Attention is all you need**. In Advances in neural information processing systems (pp. 5998-6008).

This implementation is adapted to work with the rest of the `tsai` library, and contain some hyperparameters that are not available in the original implementation. They are included to experiment with them. 
"""

"""
## TST arguments
"""

"""
Usual values are the ones that appear in the "Attention is all you need" and "A Transformer-based Framework for Multivariate Time Series Representation Learning" papers. 

The default values are the ones selected as a default configuration in the latter.

* c_in: the number of features (aka variables, dimensions, channels) in the time series dataset. dls.var
* c_out: the number of target classes. dls.c
* seq_len: number of time steps in the time series. dls.len
* max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues. Default. None.
* d_model: total dimension of the model (number of features created by the model). Usual values: 128-1024. Default: 128.
* n_heads:  parallel attention heads. Usual values: 8-16. Default: 16.
* d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
* d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
* d_ff: the dimension of the feedforward network model. Usual values: 256-4096. Default: 256.
* dropout: amount of residual dropout applied in the encoder. Usual values: 0.-0.3. Default: 0.1.
* activation: the activation function of intermediate layer, relu or gelu. Default: 'gelu'.
* n_layers: the number of sub-encoder-layers in the encoder. Usual values: 2-8. Default: 3.
* fc_dropout: dropout applied to the final fully connected layer. Usual values: 0.-0.8. Default: 0.
* y_range: range of possible y values (used in regression tasks). Default: None
* kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.
"""

"""
## Imports
"""

#|export
from tsai.imports import *
from tsai.utils import *
from tsai.models.layers import *
from tsai.models.utils import *

"""
## TST
"""

#|exporti
class _ScaledDotProductAttention(Module):
    def __init__(self, d_k:int): self.d_k = d_k
    def forward(self, q:Tensor, k:Tensor, v:Tensor, mask:Optional[Tensor]=None):

        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        scores = torch.matmul(q, k)                                         # scores : [bs x n_heads x q_len x q_len]
        
        # Scale
        scores = scores / (self.d_k ** 0.5)
        
        # Mask (optional)
        if mask is not None: scores.masked_fill_(mask, -1e9)
        
        # SoftMax
        attn = F.softmax(scores, dim=-1)                                    # attn   : [bs x n_heads x q_len x q_len]
        
        # MatMul (attn, v)
        context = torch.matmul(attn, v)                                     # context: [bs x n_heads x q_len x d_v]
        
        return context, attn

#|exporti
class _MultiHeadAttention(Module):
    def __init__(self, d_model:int, n_heads:int, d_k:int, d_v:int):
        r"""
        Input shape:  Q, K, V:[batch_size (bs) x q_len x d_model], mask:[q_len x q_len]
        """
        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v
        
        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)
        
        self.W_O = nn.Linear(n_heads * d_v, d_model, bias=False)

    def forward(self, Q:Tensor, K:Tensor, V:Tensor, mask:Optional[Tensor]=None):
        
        bs = Q.size(0)

        # Linear (+ split in multiple heads)
        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x q_len x d_k]
        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)
        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]

        # Scaled Dot-Product Attention (multiple heads)
        context, attn = _ScaledDotProductAttention(self.d_k)(q_s, k_s, v_s)          # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]

        # Concat
        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # context: [bs x q_len x n_heads * d_v]

        # Linear
        output = self.W_O(context)                                                  # context: [bs x q_len x d_model]
        
        return output, attn

t = torch.rand(16, 50, 128)
output, attn = _MultiHeadAttention(d_model=128, n_heads=3, d_k=8, d_v=6)(t, t, t)
output.shape, attn.shape
# Output:
#   (torch.Size([16, 50, 128]), torch.Size([16, 3, 50, 50]))

#|exporti
def get_activation_fn(activation):
    if activation == "relu": return nn.ReLU()
    elif activation == "gelu": return nn.GELU()
    else: return activation()
#         raise ValueError(f'{activation} is not available. You can use "relu" or "gelu"')

class _TSTEncoderLayer(Module):
    def __init__(self, q_len:int, d_model:int, n_heads:int, d_k:Optional[int]=None, d_v:Optional[int]=None, d_ff:int=256, dropout:float=0.1, 
                 activation:str="gelu"):

        assert d_model // n_heads, f"d_model ({d_model}) must be divisible by n_heads ({n_heads})"
        d_k = ifnone(d_k, d_model // n_heads)
        d_v = ifnone(d_v, d_model // n_heads)

        # Multi-Head attention
        self.self_attn = _MultiHeadAttention(d_model, n_heads, d_k, d_v)

        # Add & Norm
        self.dropout_attn = nn.Dropout(dropout)
        self.batchnorm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))

        # Position-wise Feed-Forward
        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), 
                                get_activation_fn(activation), 
                                nn.Dropout(dropout), 
                                nn.Linear(d_ff, d_model))

        # Add & Norm
        self.dropout_ffn = nn.Dropout(dropout)
        self.batchnorm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))

    def forward(self, src:Tensor, mask:Optional[Tensor]=None) -> Tensor:

        # Multi-Head attention sublayer
        ## Multi-Head attention
        src2, attn = self.self_attn(src, src, src, mask=mask)
        ## Add & Norm
        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout
        src = self.batchnorm_attn(src)      # Norm: batchnorm 

        # Feed-forward sublayer
        ## Position-wise Feed-Forward
        src2 = self.ff(src)
        ## Add & Norm
        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout
        src = self.batchnorm_ffn(src) # Norm: batchnorm

        return src

t = torch.rand(16, 50, 128)
output = _TSTEncoderLayer(q_len=50, d_model=128, n_heads=3, d_k=None, d_v=None, d_ff=512, dropout=0.1, activation='gelu')(t)
output.shape
# Output:
#   torch.Size([16, 50, 128])

#|exporti
class _TSTEncoder(Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, dropout=0.1, activation='gelu', n_layers=1):
        
        self.layers = nn.ModuleList([_TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, 
                                                            activation=activation) for i in range(n_layers)])

    def forward(self, src):
        output = src
        for mod in self.layers: output = mod(output)
        return output

#|export
class TST(Module):
    def __init__(self, c_in:int, c_out:int, seq_len:int, max_seq_len:Optional[int]=None, 
                 n_layers:int=3, d_model:int=128, n_heads:int=16, d_k:Optional[int]=None, d_v:Optional[int]=None,  
                 d_ff:int=256, dropout:float=0.1, act:str="gelu", fc_dropout:float=0., 
                 y_range:Optional[tuple]=None, verbose:bool=False, **kwargs):
        r"""TST (Time Series Transformer) is a Transformer that takes continuous time series as inputs.
        As mentioned in the paper, the input must be standardized by_var based on the entire training set.
        Args:
            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset.
            c_out: the number of target classes.
            seq_len: number of time steps in the time series.
            max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues.
            d_model: total dimension of the model (number of features created by the model)
            n_heads:  parallel attention heads.
            d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
            d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
            d_ff: the dimension of the feedforward network model.
            dropout: amount of residual dropout applied in the encoder.
            act: the activation function of intermediate layer, relu or gelu.
            n_layers: the number of sub-encoder-layers in the encoder.
            fc_dropout: dropout applied to the final fully connected layer.
            y_range: range of possible y values (used in regression tasks).
            kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.

        Input shape:
            bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)
        """
        self.c_out, self.seq_len = c_out, seq_len
        
        # Input encoding
        q_len = seq_len
        self.new_q_len = False
        if max_seq_len is not None and seq_len > max_seq_len: # Control temporal resolution
            self.new_q_len = True
            q_len = max_seq_len
            tr_factor = math.ceil(seq_len / q_len)
            total_padding = (tr_factor * q_len - seq_len)
            padding = (total_padding // 2, total_padding - total_padding // 2)
            self.W_P = nn.Sequential(Pad1d(padding), Conv1d(c_in, d_model, kernel_size=tr_factor, padding=0, stride=tr_factor))
            pv(f'temporal resolution modified: {seq_len} --> {q_len} time steps: kernel_size={tr_factor}, stride={tr_factor}, padding={padding}.\n', verbose)
        elif kwargs:
            self.new_q_len = True
            t = torch.rand(1, 1, seq_len)
            q_len = nn.Conv1d(1, 1, **kwargs)(t).shape[-1]
            self.W_P = nn.Conv1d(c_in, d_model, **kwargs) # Eq 2
            pv(f'Conv1d with kwargs={kwargs} applied to input to create input encodings\n', verbose)
        else:
            self.W_P = nn.Linear(c_in, d_model) # Eq 1: projection of feature vectors onto a d-dim vector space

        # Positional encoding
        W_pos = torch.empty((q_len, d_model), device=default_device())
        nn.init.uniform_(W_pos, -0.02, 0.02)
        self.W_pos = nn.Parameter(W_pos, requires_grad=True)

        # Residual dropout
        self.dropout = nn.Dropout(dropout)

        # Encoder
        self.encoder = _TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=act, n_layers=n_layers)
        self.flatten = Flatten()
        
        # Head
        self.head_nf = q_len * d_model
        self.head = self.create_head(self.head_nf, c_out, act=act, fc_dropout=fc_dropout, y_range=y_range)

    def create_head(self, nf, c_out, act="gelu", fc_dropout=0., y_range=None, **kwargs):
        layers = [get_activation_fn(act), Flatten()]
        if fc_dropout: layers += [nn.Dropout(fc_dropout)]
        layers += [nn.Linear(nf, c_out)]
        if y_range: layers += [SigmoidRange(*y_range)]
        return nn.Sequential(*layers)    
        

    def forward(self, x:Tensor, mask:Optional[Tensor]=None) -> Tensor:  # x: [bs x nvars x q_len]

        # Input encoding
        if self.new_q_len: u = self.W_P(x).transpose(2,1) # Eq 2        # u: [bs x d_model x q_len] transposed to [bs x q_len x d_model]
        else: u = self.W_P(x.transpose(2,1)) # Eq 1                     # u: [bs x q_len x nvars] converted to [bs x q_len x d_model]

        # Positional encoding
        u = self.dropout(u + self.W_pos)

        # Encoder
        z = self.encoder(u)                                             # z: [bs x q_len x d_model]
        z = z.transpose(2,1).contiguous()                               # z: [bs x d_model x q_len]

        # Classification/ Regression head
        return self.head(z)                                             # output: [bs x c_out]

bs = 32
c_in = 9  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 5000

xb = torch.randn(bs, c_in, seq_len)

# standardize by channel by_var based on the training set
xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)

# Settings
max_seq_len = 256
d_model = 128
n_heads = 16
d_k = d_v = None # if None --> d_model // n_heads
d_ff = 256
dropout = 0.1
activation = "gelu"
n_layers = 3
fc_dropout = 0.1
kwargs = {}

model = TST(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
            d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=activation, n_layers=n_layers,
            fc_dropout=fc_dropout, **kwargs)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 517378


bs = 32
c_in = 9  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 60

xb = torch.randn(bs, c_in, seq_len)

# standardize by channel by_var based on the training set
xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)

# Settings
max_seq_len = 120
d_model = 128
n_heads = 16
d_k = d_v = None # if None --> d_model // n_heads
d_ff = 256
dropout = 0.1
act = "gelu"
n_layers = 3
fc_dropout = 0.1
kwargs = {}
# kwargs = dict(kernel_size=5, padding=2)

model = TST(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
            d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, act=act, n_layers=n_layers,
            fc_dropout=fc_dropout, **kwargs)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 420226


#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/108b_models.TST.ipynb saved at 2022-11-09 13:05:31

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:05:34 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/050_models.TSTPlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TSTPlus

"""
# TSTPlus
"""

"""
This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@timeseriesAI.co based on:

* George Zerveas et al. A Transformer-based Framework for Multivariate Time Series Representation Learning, in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21), August 14--18, 2021. ArXiV version: https://arxiv.org/abs/2010.02803
* Official implementation: https://github.com/gzerveas/mvts_transformer

```bash
@inproceedings{10.1145/3447548.3467401,
author = {Zerveas, George and Jayaraman, Srideepika and Patel, Dhaval and Bhamidipaty, Anuradha and Eickhoff, Carsten},
title = {A Transformer-Based Framework for Multivariate Time Series Representation Learning},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467401},
doi = {10.1145/3447548.3467401},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {2114–2124},
numpages = {11},
keywords = {regression, framework, multivariate time series, classification, transformer, deep learning, self-supervised learning, unsupervised learning, imputation},
location = {Virtual Event, Singapore},
series = {KDD '21}
}
```

* Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). [Attention is all you need. In Advances in neural information processing systems (pp. 5998-6008).](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)

* He, R., Ravula, A., Kanagal, B., & Ainslie, J. (2020). Realformer: Transformer Likes Informed Attention. arXiv preprint arXiv:2012.11747.

This implementation is adapted to work with the rest of the `tsai` library, and contain some hyperparameters that are not available in the original implementation. I included them for experimenting.
"""

"""
## Imports
"""

#|export
from typing import Callable
from tsai.imports import *
from tsai.utils import *
from tsai.models.layers import *
from tsai.models.utils import *
from tsai.models.positional_encoders import *
from tsai.data.core import *

"""
## TST
"""

#|exporti    
class _TSTEncoderLayer(Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=256, store_attn=False,
                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation="gelu", res_attention=False, pre_norm=False):

        assert not d_model%n_heads, f"d_model ({d_model}) must be divisible by n_heads ({n_heads})"
        d_k = ifnone(d_k, d_model // n_heads)
        d_v = ifnone(d_v, d_model // n_heads)

        # Multi-Head attention
        self.res_attention = res_attention
        self.self_attn = MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout, proj_dropout=dropout, res_attention=res_attention)

        # Add & Norm
        self.dropout_attn = nn.Dropout(dropout)
        if "batch" in norm.lower():
            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))
        else: 
            self.norm_attn = nn.LayerNorm(d_model)

        # Position-wise Feed-Forward
        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias), 
                                get_act_fn(activation), 
                                nn.Dropout(dropout), 
                                nn.Linear(d_ff, d_model, bias=bias))

        # Add & Norm
        self.dropout_ffn = nn.Dropout(dropout)
        if "batch" in norm.lower():
            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))
        else: 
            self.norm_ffn = nn.LayerNorm(d_model)
        
        self.pre_norm = pre_norm
        self.store_attn = store_attn

    def forward(self, src:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None) -> Tensor:

        # Multi-Head attention sublayer
        if self.pre_norm:
            src = self.norm_attn(src)
        ## Multi-Head attention
        if self.res_attention:
            src2, attn, scores = self.self_attn(src, src, src, prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
        else:
            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
        if self.store_attn: 
            self.attn = attn
        ## Add & Norm
        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout
        if not self.pre_norm:
            src = self.norm_attn(src)

        # Feed-forward sublayer
        if self.pre_norm:
            src = self.norm_ffn(src)
        ## Position-wise Feed-Forward
        src2 = self.ff(src)
        ## Add & Norm
        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout
        if not self.pre_norm:
            src = self.norm_ffn(src)

        if self.res_attention:
            return src, scores
        else:
            return src

t = torch.rand(16, 50, 128)
attn_mask = torch.triu(torch.ones(50, 50)) # shape: q_len x q_len
key_padding_mask = torch.zeros(16, 50)
key_padding_mask[[1, 3, 6, 15], -10:] = 1
key_padding_mask = key_padding_mask.bool()
print('attn_mask', attn_mask.shape, 'key_padding_mask', key_padding_mask.shape)
encoder = _TSTEncoderLayer(q_len=50, d_model=128, n_heads=8, d_k=None, d_v=None, d_ff=512, attn_dropout=0., dropout=0.1, store_attn=True, activation='gelu')
output = encoder(t, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
output.shape
# Output:
#   attn_mask torch.Size([50, 50]) key_padding_mask torch.Size([16, 50])

#   torch.Size([16, 50, 128])

cmap='viridis'
figsize=(6,5)
plt.figure(figsize=figsize)
plt.pcolormesh(encoder.attn[0][0].detach().cpu().numpy(), cmap=cmap)
plt.title('Self-attention map')
plt.colorbar()
plt.show()
# Output:
#   <Figure size 600x500 with 2 Axes>

#|exporti
class _TSTEncoder(Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu', 
                 res_attention=False, n_layers=1, pre_norm=False, store_attn=False):
        self.layers = nn.ModuleList([_TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, 
                                                      attn_dropout=attn_dropout, dropout=dropout, 
                                                      activation=activation, res_attention=res_attention, 
                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])
        self.res_attention = res_attention

    def forward(self, src:Tensor, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):
        output = src
        scores = None
        if self.res_attention:
            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
            return output
        else:
            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)
            return output

#|exporti
class _TSTBackbone(Module):
    def __init__(self, c_in, seq_len, max_seq_len=512,
                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,
                 d_ff=256, norm='BatchNorm', attn_dropout=0., dropout=0., act="gelu", store_attn=False,
                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,
                 pe='zeros', learn_pe=True, verbose=False, **kwargs):

        # Input encoding
        q_len = seq_len
        self.new_q_len = False
        if max_seq_len is not None and seq_len > max_seq_len: # Control temporal resolution
            self.new_q_len = True
            q_len = max_seq_len
            tr_factor = math.ceil(seq_len / q_len)
            total_padding = (tr_factor * q_len - seq_len)
            padding = (total_padding // 2, total_padding - total_padding // 2)
            self.W_P = nn.Sequential(Pad1d(padding), Conv1d(c_in, d_model, kernel_size=tr_factor, padding=0, stride=tr_factor))
            pv(f'temporal resolution modified: {seq_len} --> {q_len} time steps: kernel_size={tr_factor}, stride={tr_factor}, padding={padding}.\n', verbose)
        elif kwargs:
            self.new_q_len = True
            t = torch.rand(1, 1, seq_len)
            q_len = Conv1d(1, 1, **kwargs)(t).shape[-1]
            self.W_P = Conv1d(c_in, d_model, **kwargs) # Eq 2
            pv(f'Conv1d with kwargs={kwargs} applied to input to create input encodings\n', verbose)
        else:
            self.W_P = nn.Linear(c_in, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space
        self.seq_len = q_len

        # Positional encoding
        self.W_pos = self._positional_encoding(pe, learn_pe, q_len, d_model)

        # Residual dropout
        self.dropout = nn.Dropout(dropout)

        # Encoder
        self.encoder = _TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout, 
                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)
        self.transpose = Transpose(-1, -2, contiguous=True)
        self.key_padding_mask, self.padding_var, self.attn_mask = key_padding_mask, padding_var, attn_mask

    def forward(self, inp) -> Tensor:  
        r"""Pass the input through the TST backbone.
        Args:
            inp: input (optionally with padding mask. 1s (meaning padded) in padding mask will be ignored while 0s (non-padded) will be unchanged.)
        Shape:
            There are 3 options: 
            1. inp: Tensor containing just time series data [bs x nvars x q_len] 
            2. inp: Tensor containing time series data plus a padding feature in the last channel [bs x (nvars + 1) x q_len]
            3. inp: tuple containing a tensor with time series data plus a padding mask per batch ([bs x nvars x q_len] , [bs x q_len] )
        """

        # x and padding mask
        if isinstance(inp, tuple): x, key_padding_mask = inp
        elif self.key_padding_mask == 'auto': x, key_padding_mask = self._key_padding_mask(inp) # automatically identify padding mask
        elif self.key_padding_mask == -1: x, key_padding_mask = inp[:, :-1], inp[:, -1]         # padding mask is the last channel
        else: x, key_padding_mask = inp, None

        # Input encoding
        if self.new_q_len: u = self.W_P(x).transpose(2,1) # Eq 2        # u: [bs x d_model x q_len] transposed to [bs x q_len x d_model]
        else: u = self.W_P(x.transpose(2,1))              # Eq 1        # u: [bs x q_len x nvars] converted to [bs x q_len x d_model]

        # Positional encoding
        u = self.dropout(u + self.W_pos)

        # Encoder
        z = self.encoder(u, key_padding_mask=key_padding_mask, attn_mask=self.attn_mask)    # z: [bs x q_len x d_model]
        z = self.transpose(z)                                                               # z: [bs x d_model x q_len]
        if key_padding_mask is not None: 
            z = z * torch.logical_not(key_padding_mask.unsqueeze(1))  # zero-out padding embeddings
        return z

    def _positional_encoding(self, pe, learn_pe, q_len, d_model):
        # Positional encoding
        if pe == None:
            W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe
            nn.init.uniform_(W_pos, -0.02, 0.02)
            learn_pe = False
        elif pe == 'zero': 
            W_pos = torch.empty((q_len, 1))
            nn.init.uniform_(W_pos, -0.02, 0.02)
        elif pe == 'zeros': 
            W_pos = torch.empty((q_len, d_model))
            nn.init.uniform_(W_pos, -0.02, 0.02)
        elif pe == 'normal' or pe == 'gauss':
            W_pos = torch.zeros((q_len, 1))
            torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)
        elif pe == 'uniform':
            W_pos = torch.zeros((q_len, 1))
            nn.init.uniform_(W_pos, a=0.0, b=0.1)
        elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)
        elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)
        elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)
        elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)
        elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)
        else: raise ValueError(f"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \
            'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)")
        return nn.Parameter(W_pos, requires_grad=learn_pe)

    def _key_padding_mask(self, x):
        if self.padding_var is not None:
            mask = TSMaskTensor(x[:, self.padding_var] == 1)            # key_padding_mask: [bs x q_len]
            return x, mask
        else:
            mask = torch.isnan(x)
            x[mask] = 0
            if mask.any():
                mask = TSMaskTensor((mask.float().mean(1)==1).bool())   # key_padding_mask: [bs x q_len]
                return x, mask
            else:
                return x, None

#|export
class TSTPlus(nn.Sequential):
    """TST (Time Series Transformer) is a Transformer that takes continuous time series as inputs"""
    def __init__(self, c_in:int, c_out:int, seq_len:int, max_seq_len:Optional[int]=512,
                 n_layers:int=3, d_model:int=128, n_heads:int=16, d_k:Optional[int]=None, d_v:Optional[int]=None,
                 d_ff:int=256, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0., act:str="gelu", key_padding_mask:bool='auto', 
                 padding_var:Optional[int]=None, attn_mask:Optional[Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,
                 pe:str='zeros', learn_pe:bool=True, flatten:bool=True, fc_dropout:float=0.,
                 concat_pool:bool=False, bn:bool=False, custom_head:Optional[Callable]=None,
                 y_range:Optional[tuple]=None, verbose:bool=False, **kwargs):
        """
        Args:
            c_in: the number of features (aka variables, dimensions, channels) in the time series dataset.
            c_out: the number of target classes.
            seq_len: number of time steps in the time series.
            max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues. Default=512.
            d_model: total dimension of the model (number of features created by the model). Default: 128 (range(64-512))
            n_heads:  parallel attention heads. Default:16 (range(8-16)).
            d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
            d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
            d_ff: the dimension of the feedforward network model. Default: 512 (range(256-512))
            norm: flag to indicate whether BatchNorm (default) or LayerNorm is used in the encoder layers.
            attn_dropout: dropout applied to the attention scores
            dropout: amount of dropout applied to all linear layers except q,k&v projections in the encoder.
            act: the activation function of intermediate layer, relu or gelu.
            key_padding_mask:   a boolean padding mask will be applied to attention if 'auto' a mask to those steps in a sample where all features are nan.
                                Other options include: True -->tuple (x, key_padding_mask), -1 --> key_padding_mask is the last channel, False: no mask.
            padding_var: (optional) an int indicating the variable that contains the padded steps (0: non-padded, 1: padded). 
            attn_mask: a boolean mask will be applied to attention if a tensor of shape [min(seq_len, max_seq_len) x min(seq_len, max_seq_len)] if provided.
            res_attention: if True Residual MultiheadAttention is applied.
            pre_norm: if True normalization will be applied as the first step in the sublayers. Defaults to False
            store_attn: can be used to visualize attention weights. Default: False.
            n_layers: number of layers (or blocks) in the encoder. Default: 3 (range(1-4))
            pe: type of positional encoder.
                Available types (for experimenting): None, 'exp1d', 'lin1d', 'exp2d', 'lin2d', 'sincos', 'gauss' or 'normal',
                'uniform', 'zero', 'zeros' (default, as in the paper).
            learn_pe: learned positional encoder (True, default) or fixed positional encoder.
            flatten: this will flatten the encoder output to be able to apply an mlp type of head (default=False)
            fc_dropout: dropout applied to the final fully connected layer.
            concat_pool: indicates if global adaptive concat pooling will be used instead of global adaptive pooling.
            bn: indicates if batchnorm will be applied to the head.
            custom_head: custom head that will be applied to the network. It must contain all kwargs (pass a partial function)
            y_range: range of possible y values (used in regression tasks).
            kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.
        Input shape:
            x: bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)
            attn_mask: q_len x q_len
            As mentioned in the paper, the input must be standardized by_var based on the entire training set.
        """
        # Backbone
        backbone = _TSTBackbone(c_in, seq_len=seq_len, max_seq_len=max_seq_len,
                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, 
                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,
                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn, 
                                pe=pe, learn_pe=learn_pe, verbose=verbose, **kwargs)

        # Head
        self.head_nf = d_model
        self.c_out = c_out
        self.seq_len = backbone.seq_len
        if custom_head is not None:
            if isinstance(custom_head, nn.Module): head = custom_head
            else: head = custom_head(self.head_nf, c_out, seq_len)
        else: head = self.create_head(self.head_nf, c_out, self.seq_len, act=act, flatten=flatten, concat_pool=concat_pool,
                                           fc_dropout=fc_dropout, bn=bn, y_range=y_range)
        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))


    def create_head(self, nf, c_out, seq_len, flatten=True, concat_pool=False, act="gelu", fc_dropout=0., bn=False, y_range=None):
        layers = [get_act_fn(act)]
        if flatten:
            nf *= seq_len
            layers += [Flatten()]
        else:
            if concat_pool: nf *= 2
            layers = [GACP1d(1) if concat_pool else GAP1d(1)]
        layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]
        if y_range: layers += [SigmoidRange(*y_range)]
        return nn.Sequential(*layers)


    def show_pe(self, cmap='viridis', figsize=None):
        plt.figure(figsize=figsize)
        plt.pcolormesh(self.backbone.W_pos.detach().cpu().T, cmap=cmap)
        plt.title('Positional Encoding')
        plt.colorbar()
        plt.show()
        plt.figure(figsize=figsize)
        plt.title('Positional Encoding - value along time axis')
        plt.plot(F.relu(self.backbone.W_pos.data).mean(1).cpu())
        plt.plot(-F.relu(-self.backbone.W_pos.data).mean(1).cpu())
        plt.show()

from tsai.models.utils import build_ts_model

bs = 8
c_in = 9  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 1_500

xb = torch.randn(bs, c_in, seq_len).to(device)

# standardize by channel by_var based on the training set
xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)

# Settings
max_seq_len = 256
d_model = 128
n_heads = 16
d_k = d_v = None  # if None --> d_model // n_heads
d_ff = 256
norm = "BatchNorm"
dropout = 0.1
activation = "gelu"
n_layers = 3
fc_dropout = 0.1
pe = None
learn_pe = True
kwargs = {}

model = TSTPlus(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
                d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, dropout=dropout, activation=activation, n_layers=n_layers,
                fc_dropout=fc_dropout, pe=pe, learn_pe=learn_pe, **kwargs).to(device)
test_eq(model(xb).shape, [bs, c_out])
test_eq(model[0], model.backbone)
test_eq(model[1], model.head)
model2 = build_ts_model(TSTPlus, c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
                           d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, dropout=dropout, activation=activation, n_layers=n_layers,
                           fc_dropout=fc_dropout, pe=pe, learn_pe=learn_pe, **kwargs).to(device)
test_eq(model2(xb).shape, [bs, c_out])
test_eq(model2[0], model2.backbone)
test_eq(model2[1], model2.head)
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 470018


key_padding_mask = torch.sort(torch.randint(0, 2, (bs, max_seq_len))).values.bool().to(device)
key_padding_mask[0]
# Output:
#   tensor([False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False, False,

#           False, False, False, False, False, False, False, False, False,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True,  True,  True,  True,  True,

#            True,  True,  True,  True,  True,  True])

model2.key_padding_mask = True
model2.to(device)((xb, key_padding_mask)).shape
# Output:
#   torch.Size([8, 2])

model.head
# Output:
#   Sequential(

#     (0): GELU(approximate='none')

#     (1): fastai.layers.Flatten(full=False)

#     (2): LinBnDrop(

#       (0): Dropout(p=0.1, inplace=False)

#       (1): Linear(in_features=32768, out_features=2, bias=True)

#     )

#   )

model = TSTPlus(c_in, c_out, seq_len, pre_norm=True)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])

bs = 8
c_in = 9  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 5000

xb = torch.randn(bs, c_in, seq_len)

# standardize by channel by_var based on the training set
xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)

model = TSTPlus(c_in, c_out, seq_len, res_attention=True)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 605698


custom_head = partial(create_pool_head, concat_pool=True)
model = TSTPlus(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
            d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=activation, n_layers=n_layers,
            fc_dropout=fc_dropout, pe=pe, learn_pe=learn_pe, flatten=False, custom_head=custom_head, **kwargs)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 421122


custom_head = partial(create_pool_plus_head, concat_pool=True)
model = TSTPlus(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
            d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, activation=activation, n_layers=n_layers,
            fc_dropout=fc_dropout, pe=pe, learn_pe=learn_pe, flatten=False, custom_head=custom_head, **kwargs)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
# Output:
#   model parameters: 554240


bs = 8
c_in = 9  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 60

xb = torch.randn(bs, c_in, seq_len)

# standardize by channel by_var based on the training set
xb = (xb - xb.mean((0, 2), keepdim=True)) / xb.std((0, 2), keepdim=True)

# Settings
max_seq_len = 120
d_model = 128
n_heads = 16
d_k = d_v = None # if None --> d_model // n_heads
d_ff = 256
dropout = 0.1
act = "gelu"
n_layers = 3
fc_dropout = 0.1
pe='zeros'
learn_pe=True
kwargs = {}
# kwargs = dict(kernel_size=5, padding=2)

model = TSTPlus(c_in, c_out, seq_len, max_seq_len=max_seq_len, d_model=d_model, n_heads=n_heads,
            d_k=d_k, d_v=d_v, d_ff=d_ff, dropout=dropout, act=act, n_layers=n_layers,
            fc_dropout=fc_dropout, pe=pe, learn_pe=learn_pe, **kwargs)
test_eq(model.to(xb.device)(xb).shape, [bs, c_out])
print(f'model parameters: {count_parameters(model)}')
body, head = model[0], model[1]
test_eq(body.to(xb.device)(xb).ndim, 3)
test_eq(head.to(xb.device)(body.to(xb.device)(xb)).ndim, 2)
head
# Output:
#   model parameters: 421762

#   Sequential(

#     (0): GELU(approximate='none')

#     (1): fastai.layers.Flatten(full=False)

#     (2): LinBnDrop(

#       (0): Dropout(p=0.1, inplace=False)

#       (1): Linear(in_features=7680, out_features=2, bias=True)

#     )

#   )

model.show_pe()
# Output:
#   <Figure size 640x480 with 2 Axes>
#   <Figure size 640x480 with 1 Axes>

model = TSTPlus(3, 2, 10)
xb = torch.randn(4, 3, 10)
yb = torch.randint(0, 2, (4,))
test_eq(model.backbone._key_padding_mask(xb)[1], None)
random_idxs = random_choice(len(xb), 2, False)
xb[random_idxs, :, -5:] = np.nan
xb[random_idxs, 0, 1] = np.nan
test_eq(model.backbone._key_padding_mask(xb.clone())[1].data, (torch.isnan(xb).float().mean(1)==1).bool())
test_eq(model.backbone._key_padding_mask(xb.clone())[1].data.shape, (4,10))
print(torch.isnan(xb).sum())
pred = model.to(xb.device)(xb.clone())
loss = CrossEntropyLossFlat()(pred, yb)
loss.backward()
model.to(xb.device).backbone._key_padding_mask(xb)[1].data.shape
# Output:
#   tensor(32)

#   torch.Size([4, 10])

bs = 4
c_in = 3
seq_len = 10
c_out = 2
xb = torch.randn(bs, c_in, seq_len)
xb[:, -1] = torch.randint(0, 2, (bs, seq_len)).sort()[0]
model = TSTPlus(c_in, c_out, seq_len).to(xb.device)
test_eq(model.backbone._key_padding_mask(xb)[1], None)
model = TSTPlus(c_in, c_out, seq_len, padding_var=-1).to(xb.device)
test_eq(model.backbone._key_padding_mask(xb)[1], (xb[:, -1]==1))
model = TSTPlus(c_in, c_out, seq_len, padding_var=2).to(xb.device)
test_eq(model.backbone._key_padding_mask(xb)[1], (xb[:, -1]==1))
test_eq(model(xb).shape, (bs, c_out))

bs = 4
c_in = 3
seq_len = 10
c_out = 2
xb = torch.randn(bs, c_in, seq_len)
model = TSTPlus(c_in, c_out, seq_len, act='smelu')

#|export
@delegates(TSTPlus.__init__)
class MultiTSTPlus(nn.Sequential):
    _arch = TSTPlus
    def __init__(self, feat_list, c_out, seq_len, max_seq_len:Optional[int]=512, custom_head=None, **kwargs):
        r"""
        MultiTST is a class that allows you to create a model with multiple branches of TST.
        
        Args:
            * feat_list: list with number of features that will be passed to each body, or list of list with feature indices.
        """
        self.feat_list = [feat_list] if isinstance(feat_list, int) else feat_list 
        self.device = ifnone(device, default_device())
        
        # Backbone
        branches = nn.ModuleList()
        self.head_nf = 0
        for feat in self.feat_list:
            if is_listy(feat): feat = len(feat)
            m = build_ts_model(self._arch, c_in=feat, c_out=c_out, seq_len=seq_len, max_seq_len=max_seq_len, **kwargs)
            with torch.no_grad(): 
                self.head_nf += m[0](torch.randn(1, feat, ifnone(seq_len, 10)).to(self.device)).shape[1]
            branches.append(m.backbone)
        backbone = _Splitter(self.feat_list, branches)
        
        # Head
        self.c_out = c_out
        q_len = min(seq_len, max_seq_len)
        self.seq_len = q_len 
        if custom_head is None:
            head = self._arch.create_head(self, self.head_nf, c_out, q_len)
        else: 
            head = custom_head(self.head_nf, c_out, q_len)
    
        layers = OrderedDict([('backbone', nn.Sequential(backbone)), ('head', nn.Sequential(head))])
        super().__init__(layers)
        self.to(self.device)

#|exporti
class _Splitter(Module):
    def __init__(self, feat_list, branches):
        self.feat_list, self.branches = feat_list, branches
    def forward(self, x):
        if is_listy(self.feat_list[0]): 
            x = [x[:, feat] for feat in self.feat_list]
        else: 
            x = torch.split(x, self.feat_list, dim=1)
        _out = []
        for xi, branch in zip(x, self.branches): _out.append(branch(xi))
        output = torch.cat(_out, dim=1)
        return output

bs = 8
c_in = 7  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 10
xb2 = torch.randn(bs, c_in, seq_len)
model1 = MultiTSTPlus([2, 5], c_out, seq_len)
model2 = MultiTSTPlus(7, c_out, seq_len)
test_eq(model1.to(xb2.device)(xb2).shape, (bs, c_out))
test_eq(model1.to(xb2.device)(xb2).shape, model2.to(xb2.device)(xb2).shape)
test_eq(count_parameters(model1) > count_parameters(model2), True)

bs = 8
c_in = 7  # aka channels, features, variables, dimensions
c_out = 2
seq_len = 10
xb2 = torch.randn(bs, c_in, seq_len)
model1 = MultiTSTPlus([2, 5], c_out, seq_len, )
model2 = MultiTSTPlus([[0,2,5], [0,1,3,4,6]], c_out, seq_len)
test_eq(model1.to(xb2.device)(xb2).shape, (bs, c_out))
test_eq(model1.to(xb2.device)(xb2).shape, model2.to(xb2.device)(xb2).shape)

model1 = MultiTSTPlus([2, 5], c_out, seq_len, y_range=(0.5, 5.5))
body, head = split_model(model1)
test_eq(body.to(xb2.device)(xb2).ndim, 3)
test_eq(head.to(xb2.device)(body.to(xb2.device)(xb2)).ndim, 2)
head
# Output:
#   Sequential(

#     (0): Sequential(

#       (0): GELU(approximate='none')

#       (1): fastai.layers.Flatten(full=False)

#       (2): LinBnDrop(

#         (0): Linear(in_features=2560, out_features=2, bias=True)

#       )

#     )

#   )

model = MultiTSTPlus([2, 5], c_out, seq_len, pre_norm=True)

bs = 8
n_vars = 3
seq_len = 12
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)
net = MultiTSTPlus(n_vars, c_out, seq_len)
change_model_head(net, create_pool_plus_head, concat_pool=False)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([8, 2])

#   Sequential(

#     (0): AdaptiveAvgPool1d(output_size=1)

#     (1): Reshape(bs)

#     (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (3): Linear(in_features=128, out_features=512, bias=False)

#     (4): ReLU(inplace=True)

#     (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (6): Linear(in_features=512, out_features=2, bias=False)

#   )

bs = 8
n_vars = 3
seq_len = 12
c_out = 10
xb = torch.rand(bs, n_vars, seq_len)
new_head = partial(conv_lin_nd_head, d=(5 ,2))
net = MultiTSTPlus(n_vars, c_out, seq_len, custom_head=new_head)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([8, 5, 2, 10])

#   Sequential(

#     (0): create_conv_lin_nd_head(

#       (0): Conv1d(128, 10, kernel_size=(1,), stride=(1,))

#       (1): Linear(in_features=12, out_features=10, bias=True)

#       (2): Transpose(-1, -2)

#       (3): Reshape(bs, 5, 2, 10)

#     )

#   )

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/050_models.TSTPlus.ipynb saved at 2023-03-19 14:21:07

#   Correct notebook to script conversion! 😃

#   Sunday 19/03/23 14:21:10 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/053_models.ROCKET.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.ROCKET

"""
# ROCKET
"""

"""
>ROCKET (RandOm Convolutional KErnel Transform) functions for univariate and multivariate time series.
"""

#|export
import sklearn
from sklearn.linear_model import RidgeClassifierCV, RidgeCV
from sklearn.metrics import make_scorer
from sklearn.preprocessing import StandardScaler

from tsai.data.external import *
from tsai.imports import *
from tsai.models.layers import *

#|export
class RocketClassifier(sklearn.pipeline.Pipeline):
    """Time series classification using ROCKET features and a linear classifier"""
    
    def __init__(self, num_kernels=10_000, normalize_input=True, random_state=None, 
                 alphas=np.logspace(-3, 3, 7), normalize_features=True, memory=None, verbose=False, scoring=None, class_weight=None, **kwargs):
        """
        RocketClassifier is recommended for up to 10k time series. 
        For a larger dataset, you can use ROCKET (in Pytorch).
        scoring = None --> defaults to accuracy.
        
        Rocket args:            
            num_kernels     : int, number of random convolutional kernels (default 10,000)
            normalize_input : boolean, whether or not to normalise the input time series per instance (default True)
            random_state    : Optional random seed (default None)

        """
        try: 
            import sktime
            from sktime.transformations.panel.rocket import Rocket
        except ImportError:
            raise("You need to install sktime to be able to use RocketClassifier")
            
        self.steps = [('rocket', Rocket(num_kernels=num_kernels, normalise=normalize_input, random_state=random_state))]
        if normalize_features:
            self.steps += [('scalar', StandardScaler(with_mean=False))]
        self.steps += [('ridgeclassifiercv', RidgeClassifierCV(alphas=alphas, scoring=scoring, class_weight=class_weight, **kwargs))]
        store_attr()
        self._validate_steps()

    def __repr__(self):  
        return f'Pipeline(steps={self.steps.copy()})'

    def save(self, fname='Rocket', path='./models'):
        path = Path(path)
        filename = path/fname
        with open(f'{filename}.pkl', 'wb') as output:
            pickle.dump(self, output, pickle.HIGHEST_PROTOCOL)

#|export
def load_rocket(fname='Rocket', path='./models'):
    path = Path(path)
    filename = path/fname
    with open(f'{filename}.pkl', 'rb') as input:
        output = pickle.load(input)
    return output

#|export
class RocketRegressor(sklearn.pipeline.Pipeline):
    """Time series regression using ROCKET features and a linear regressor"""
    
    def __init__(self, num_kernels=10_000, normalize_input=True, random_state=None, 
                 alphas=np.logspace(-3, 3, 7), normalize_features=True, memory=None, verbose=False, scoring=None, **kwargs):
        """
        RocketRegressor is recommended for up to 10k time series. 
        For a larger dataset, you can use ROCKET (in Pytorch).
        scoring = None --> defaults to r2.
        
        Args:            
            num_kernels     : int, number of random convolutional kernels (default 10,000)
            normalize_input : boolean, whether or not to normalise the input time series per instance (default True)
            random_state    : Optional random seed (default None)
        """
        try: 
            import sktime
            from sktime.transformations.panel.rocket import Rocket
        except ImportError:
            raise("You need to install sktime to be able to use RocketRegressor")
            
        self.steps = [('rocket', Rocket(num_kernels=num_kernels, normalise=normalize_input, random_state=random_state))]
        if normalize_features:
            self.steps += [('scalar', StandardScaler(with_mean=False))]
        self.steps += [('ridgecv', RidgeCV(alphas=alphas, scoring=scoring, **kwargs))]
        store_attr()
        self._validate_steps()


    def __repr__(self):  
        return f'Pipeline(steps={self.steps.copy()})'

    def save(self, fname='Rocket', path='./models'):
        path = Path(path)
        filename = path/fname
        with open(f'{filename}.pkl', 'wb') as output:
            pickle.dump(self, output, pickle.HIGHEST_PROTOCOL)

#|extras
# Univariate classification with sklearn-type API
dsid = 'OliveOil'
fname = 'RocketClassifier'
X_train, y_train, X_test, y_test = get_UCR_data(dsid, Xdtype='float64')
cls = RocketClassifier()
cls.fit(X_train, y_train)
cls.save(fname)
del cls
cls = load_rocket(fname)
print(cls.score(X_test, y_test))
# Output:
#   OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.

#   0.9


#|extras
# Multivariate classification with sklearn-type API
dsid = 'NATOPS'
fname = 'RocketClassifier'
X_train, y_train, X_test, y_test = get_UCR_data(dsid, Xdtype='float64')
cls = RocketClassifier()
cls.fit(X_train, y_train)
cls.save(fname)
del cls
cls = load_rocket(fname)
print(cls.score(X_test, y_test))
# Output:
#   0.8666666666666667


from sklearn.metrics import mean_squared_error

#|extras
# Univariate regression with sklearn-type API
dsid = 'Covid3Month'
fname = 'RocketRegressor'
X_train, y_train, X_test, y_test = get_Monash_regression_data(dsid, Xdtype='float64')
if X_train is not None: 
    rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
    reg = RocketRegressor(scoring=rmse_scorer)
    reg.fit(X_train, y_train)
    reg.save(fname)
    del reg
    reg = load_rocket(fname)
    y_pred = reg.predict(X_test)
    print(mean_squared_error(y_test, y_pred, squared=False))
# Output:
#   0.03908714523468997


#|extras
# Multivariate regression with sklearn-type API
dsid = 'AppliancesEnergy'
fname = 'RocketRegressor'
X_train, y_train, X_test, y_test = get_Monash_regression_data(dsid, Xdtype='float64')
if X_train is not None: 
    rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
    reg = RocketRegressor(scoring=rmse_scorer)
    reg.fit(X_train, y_train)
    reg.save(fname)
    del reg
    reg = load_rocket(fname)
    y_pred = reg.predict(X_test)
    print(mean_squared_error(y_test, y_pred, squared=False))
# Output:
#   2.287302226812576


#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/053_models.ROCKET.ipynb saved at 2023-04-01 19:54:02

#   Correct notebook to script conversion! 😃

#   Saturday 01/04/23 19:54:04 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/056_models.MINIROCKET_Pytorch.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.MINIROCKET_Pytorch

"""
# MINIROCKET Pytorch
"""

"""
>A Very Fast (Almost) Deterministic Transform for Time Series Classification.

This is a Pytorch implementation of MiniRocket developed by Malcolm McLean and Ignacio Oguiza based on:

Dempster, A., Schmidt, D. F., & Webb, G. I. (2020). MINIROCKET: A Very Fast (Almost) Deterministic Transform for Time Series Classification. arXiv preprint arXiv:2012.08791.

Original paper: https://arxiv.org/abs/2012.08791

Original code:  https://github.com/angus924/minirocket
"""

#|export
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from collections import OrderedDict

#|export
class MiniRocketFeatures(nn.Module):
    """This is a Pytorch implementation of MiniRocket developed by Malcolm McLean and Ignacio Oguiza
    
    MiniRocket paper citation:
    @article{dempster_etal_2020,
      author  = {Dempster, Angus and Schmidt, Daniel F and Webb, Geoffrey I},
      title   = {{MINIROCKET}: A Very Fast (Almost) Deterministic Transform for Time Series Classification},
      year    = {2020},
      journal = {arXiv:2012.08791}
    }
    Original paper: https://arxiv.org/abs/2012.08791
    Original code:  https://github.com/angus924/minirocket"""

    kernel_size, num_kernels, fitting = 9, 84, False

    def __init__(self, c_in, seq_len, num_features=10_000, max_dilations_per_kernel=32, random_state=None):
        super(MiniRocketFeatures, self).__init__()
        self.c_in, self.seq_len = c_in, seq_len
        self.num_features = num_features // self.num_kernels * self.num_kernels
        self.max_dilations_per_kernel  = max_dilations_per_kernel
        self.random_state = random_state

        # Convolution
        indices = torch.combinations(torch.arange(self.kernel_size), 3).unsqueeze(1)
        kernels = (-torch.ones(self.num_kernels, 1, self.kernel_size)).scatter_(2, indices, 2)
        self.kernels = nn.Parameter(kernels.repeat(c_in, 1, 1), requires_grad=False)

        # Dilations & padding
        self._set_dilations(seq_len)

        # Channel combinations (multivariate)
        if c_in > 1:
            self._set_channel_combinations(c_in)

        # Bias
        for i in range(self.num_dilations):
            self.register_buffer(f'biases_{i}', torch.empty((self.num_kernels, self.num_features_per_dilation[i])))
        self.register_buffer('prefit', torch.BoolTensor([False]))
        
    def fit(self, X, chunksize=None):
        num_samples = X.shape[0]
        if chunksize is None:
            chunksize = min(num_samples, self.num_dilations * self.num_kernels)
        else: 
            chunksize = min(num_samples, chunksize)
        np.random.seed(self.random_state)
        idxs = np.random.choice(num_samples, chunksize, False)
        self.fitting = True
        if isinstance(X, np.ndarray): 
            self(torch.from_numpy(X[idxs]).to(self.kernels.device))
        else:
            self(X[idxs].to(self.kernels.device))
        self.fitting = False
    
    def forward(self, x):
        _features = []
        for i, (dilation, padding) in enumerate(zip(self.dilations, self.padding)):
            _padding1 = i%2
            
            # Convolution
            C = F.conv1d(x, self.kernels, padding=padding, dilation=dilation, groups=self.c_in)
            if self.c_in > 1: # multivariate
                C = C.reshape(x.shape[0], self.c_in, self.num_kernels, -1)
                channel_combination = getattr(self, f'channel_combinations_{i}')
                C = torch.mul(C, channel_combination)
                C = C.sum(1)

            # Bias
            if not self.prefit or self.fitting:
                num_features_this_dilation = self.num_features_per_dilation[i]
                bias_this_dilation = self._get_bias(C, num_features_this_dilation)
                setattr(self, f'biases_{i}', bias_this_dilation)        
                if self.fitting:
                    if i < self.num_dilations - 1:
                        continue
                    else:
                        self.prefit = torch.BoolTensor([True])
                        return
                elif i == self.num_dilations - 1:
                    self.prefit = torch.BoolTensor([True])
            else:
                bias_this_dilation = getattr(self, f'biases_{i}')
            
            # Features
            _features.append(self._get_PPVs(C[:, _padding1::2], bias_this_dilation[_padding1::2]))
            _features.append(self._get_PPVs(C[:, 1-_padding1::2, padding:-padding], bias_this_dilation[1-_padding1::2]))
        return torch.cat(_features, dim=1)           

    def _get_PPVs(self, C, bias):
        C = C.unsqueeze(-1)
        bias = bias.view(1, bias.shape[0], 1, bias.shape[1])
        return (C > bias).float().mean(2).flatten(1)

    def _set_dilations(self, input_length):
        num_features_per_kernel = self.num_features // self.num_kernels
        true_max_dilations_per_kernel = min(num_features_per_kernel, self.max_dilations_per_kernel)
        multiplier = num_features_per_kernel / true_max_dilations_per_kernel
        max_exponent = np.log2((input_length - 1) / (9 - 1))
        dilations, num_features_per_dilation = \
        np.unique(np.logspace(0, max_exponent, true_max_dilations_per_kernel, base = 2).astype(np.int32), return_counts = True)
        num_features_per_dilation = (num_features_per_dilation * multiplier).astype(np.int32)
        remainder = num_features_per_kernel - num_features_per_dilation.sum()
        i = 0
        while remainder > 0:
            num_features_per_dilation[i] += 1
            remainder -= 1
            i = (i + 1) % len(num_features_per_dilation)
        self.num_features_per_dilation = num_features_per_dilation
        self.num_dilations = len(dilations)
        self.dilations = dilations
        self.padding = []
        for i, dilation in enumerate(dilations): 
            self.padding.append((((self.kernel_size - 1) * dilation) // 2))

    def _set_channel_combinations(self, num_channels):
        num_combinations = self.num_kernels * self.num_dilations
        max_num_channels = min(num_channels, 9)
        max_exponent_channels = np.log2(max_num_channels + 1)
        np.random.seed(self.random_state)
        num_channels_per_combination = (2 ** np.random.uniform(0, max_exponent_channels, num_combinations)).astype(np.int32)
        channel_combinations = torch.zeros((1, num_channels, num_combinations, 1))
        for i in range(num_combinations):
            channel_combinations[:, np.random.choice(num_channels, num_channels_per_combination[i], False), i] = 1
        channel_combinations = torch.split(channel_combinations, self.num_kernels, 2) # split by dilation
        for i, channel_combination in enumerate(channel_combinations): 
            self.register_buffer(f'channel_combinations_{i}', channel_combination) # per dilation

    def _get_quantiles(self, n):
        return torch.tensor([(_ * ((np.sqrt(5) + 1) / 2)) % 1 for _ in range(1, n + 1)]).float()

    def _get_bias(self, C, num_features_this_dilation):
        np.random.seed(self.random_state)
        idxs = np.random.choice(C.shape[0], self.num_kernels)
        samples = C[idxs].diagonal().T 
        biases = torch.quantile(samples, self._get_quantiles(num_features_this_dilation).to(C.device), dim=1).T
        return biases

MRF = MiniRocketFeatures

#|export 
def get_minirocket_features(o, model, chunksize=1024, use_cuda=None, to_np=True):
    """Function used to split a large dataset into chunks, avoiding OOM error."""
    use = torch.cuda.is_available() if use_cuda is None else use_cuda
    device = torch.device(torch.cuda.current_device()) if use else torch.device('cpu')
    model = model.to(device)
    if isinstance(o, np.ndarray): o = torch.from_numpy(o).to(device)
    _features = []
    for oi in torch.split(o, chunksize): 
        _features.append(model(oi))
    features = torch.cat(_features).unsqueeze(-1)
    if to_np: return features.cpu().numpy()
    else: return features

#|export
class MiniRocketHead(nn.Sequential):
    def __init__(self, c_in, c_out, seq_len=1, bn=True, fc_dropout=0.):
        layers = [nn.Flatten()]
        if bn:
            layers += [nn.BatchNorm1d(c_in)]
        if fc_dropout:
            layers += [nn.Dropout(fc_dropout)]
        linear = nn.Linear(c_in, c_out)
        nn.init.constant_(linear.weight.data, 0)
        nn.init.constant_(linear.bias.data, 0)
        layers += [linear]
        head = nn.Sequential(*layers)
        super().__init__(OrderedDict(
            [('backbone', nn.Sequential()), ('head', head)]))

#|export
class MiniRocket(nn.Sequential):
    def __init__(self, c_in, c_out, seq_len, num_features=10_000, max_dilations_per_kernel=32, random_state=None, bn=True, fc_dropout=0):
        
        # Backbone
        backbone =  MiniRocketFeatures(c_in, seq_len, num_features=num_features, max_dilations_per_kernel=max_dilations_per_kernel, 
                                       random_state=random_state)
        num_features = backbone.num_features

        # Head
        self.head_nf = num_features
        layers = [nn.Flatten()]
        if bn: layers += [nn.BatchNorm1d(num_features)]
        if fc_dropout: layers += [nn.Dropout(fc_dropout)]   
        linear = nn.Linear(num_features, c_out)
        nn.init.constant_(linear.weight.data, 0)
        nn.init.constant_(linear.bias.data, 0) 
        layers += [linear]
        head = nn.Sequential(*layers)

        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))

    def fit(self, X, chunksize=None):
        self.backbone.fit(X, chunksize=chunksize)

from tsai.imports import default_device
from fastai.metrics import accuracy
from fastai.callback.tracker import ReduceLROnPlateau
from tsai.data.all import *
from tsai.learner import *

# Offline feature calculation
dsid = 'ECGFiveDays'
X, y, splits = get_UCR_data(dsid, split_data=False)
mrf = MiniRocketFeatures(c_in=X.shape[1], seq_len=X.shape[2]).to(default_device())
X_train = X[splits[0]]  # X_train may either be a np.ndarray or a torch.Tensor
mrf.fit(X_train)
X_tfm = get_minirocket_features(X, mrf)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_var=True)
dls = get_ts_dls(X_tfm, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=256)
learn = ts_learner(dls, MiniRocketHead, metrics=accuracy)
learn.fit(1, 1e-4, cbs=ReduceLROnPlateau(factor=0.5, min_lr=1e-8, patience=10))
# Output:
#   <IPython.core.display.HTML object>

# Online feature calculation
dsid = 'ECGFiveDays'
X, y, splits = get_UCR_data(dsid, split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=256)
learn = ts_learner(dls, MiniRocket, metrics=accuracy)
learn.fit_one_cycle(1, 1e-2)
# Output:
#   <IPython.core.display.HTML object>

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/056_models.MINIROCKET_Pytorch.ipynb saved at 2023-02-19 20:57:08

#   Correct notebook to script conversion! 😃

#   Sunday 19/02/23 20:57:10 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/058_models.XResNet1d.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.XResNet1d

"""
# XResNet1d
"""

"""
>This is a modified version of fastai's XResNet model in github
"""

#|export
from fastai.vision.models.xresnet import *
from tsai.imports import *
from tsai.models.layers import *
from tsai.models.utils import *

#|export
@delegates(ResBlock)
def xresnet1d18 (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet18(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d34 (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet34(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d50 (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet50(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d101 (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet101(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d152 (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet152(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d18_deep (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet18_deep(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d34_deep (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet34_deep(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d50_deep (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet50_deep(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d18_deeper (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet18_deeper(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d34_deeper (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet34_deeper(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)
@delegates(ResBlock)
def xresnet1d50_deeper (c_in, c_out, act=nn.ReLU, **kwargs): return xresnet50_deeper(c_in=c_in, n_out=c_out, act_cls=act, ndim=1, **kwargs)

bs, c_in, seq_len = 2, 4, 32
c_out = 2
x = torch.rand(bs, c_in, seq_len)
archs = [
    xresnet1d18, xresnet1d34, xresnet1d50, 
    xresnet1d18_deep, xresnet1d34_deep, xresnet1d50_deep, xresnet1d18_deeper,
    xresnet1d34_deeper, xresnet1d50_deeper
#     # Long test
#     xresnet1d101, xresnet1d152,
]
for i, arch in enumerate(archs):
    print(i, arch.__name__)
    test_eq(arch(c_in, c_out, sa=True, act=Mish)(x).shape, (bs, c_out))
# Output:
#   0 xresnet1d18

#   1 xresnet1d34

#   2 xresnet1d50

#   3 xresnet1d18_deep

#   4 xresnet1d34_deep

#   5 xresnet1d50_deep

#   6 xresnet1d18_deeper

#   7 xresnet1d34_deeper

#   8 xresnet1d50_deeper


m = xresnet1d34(4, 2, act=Mish)
test_eq(len(get_layers(m, is_bn)), 38)
test_eq(check_weight(m, is_bn)[0].sum(), 22)

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/112_models.XResNet1d.ipynb saved at 2022-11-09 13:08:29

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:08:32 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/061_models.XCM.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.XCM

"""
# XCM
"""

"""
> An Explainable Convolutional Neural Network for Multivariate Time Series Classification

This is an unofficial PyTorch implementation of XCM created by Ignacio Oguiza (oguiza@timeseriesAI.co)
"""

#|export
from tsai.imports import *
from tsai.utils import *
from tsai.models.layers import *
from tsai.models.utils import *
from tsai.models.explainability import *

#|export
# This is an unofficial PyTorch implementation of XVM created by Ignacio Oguiza - timeseriesAU@gmail.com based on:

# Fauvel, K., Lin, T., Masson, V., Fromont, É., & Termier, A. (2020). XCM: An Explainable Convolutional Neural Network 
# https://hal.inria.fr/hal-03469487/document
# Official tensorflow implementation available at: https://github.com/XAIseries/XCM
# No official XCM PyTorch implementation available as of Dec 11, 2021

class XCM(Module):
    def __init__(self, c_in:int, c_out:int, seq_len:Optional[int]=None, nf:int=128, window_perc:float=1., flatten:bool=False, custom_head:callable=None, 
                 concat_pool:bool=False, fc_dropout:float=0., bn:bool=False, y_range:tuple=None, **kwargs):
        
        window_size = int(round(seq_len * window_perc, 0))
        self.conv2dblock = nn.Sequential(*[Unsqueeze(1), Conv2d(1, nf, kernel_size=(1, window_size), padding='same'), BatchNorm(nf), nn.ReLU()])
        self.conv2d1x1block = nn.Sequential(*[nn.Conv2d(nf, 1, kernel_size=1), nn.ReLU(), Squeeze(1)])
        self.conv1dblock = nn.Sequential(*[Conv1d(c_in, nf, kernel_size=window_size, padding='same'), BatchNorm(nf, ndim=1), nn.ReLU()])
        self.conv1d1x1block = nn.Sequential(*[nn.Conv1d(nf, 1, kernel_size=1), nn.ReLU()])
        self.concat = Concat()
        self.conv1d = nn.Sequential(*[Conv1d(c_in + 1, nf, kernel_size=window_size, padding='same'), BatchNorm(nf, ndim=1), nn.ReLU()])
            
        self.head_nf = nf
        self.c_out = c_out
        self.seq_len = seq_len
        if custom_head: self.head = custom_head(self.head_nf, c_out, seq_len, **kwargs)
        else: self.head = self.create_head(self.head_nf, c_out, seq_len, flatten=flatten, concat_pool=concat_pool, 
                                           fc_dropout=fc_dropout, bn=bn, y_range=y_range)

            
    def forward(self, x):
        x1 = self.conv2dblock(x)
        x1 = self.conv2d1x1block(x1)
        x2 = self.conv1dblock(x)
        x2 = self.conv1d1x1block(x2)
        out = self.concat((x2, x1))
        out = self.conv1d(out)
        out = self.head(out)
        return out
    

    def create_head(self, nf, c_out, seq_len=None, flatten=False, concat_pool=False, fc_dropout=0., bn=False, y_range=None):
        if flatten: 
            nf *= seq_len
            layers = [Reshape()]
        else: 
            if concat_pool: nf *= 2
            layers = [GACP1d(1) if concat_pool else GAP1d(1)]
        layers += [LinBnDrop(nf, c_out, bn=bn, p=fc_dropout)]
        if y_range: layers += [SigmoidRange(*y_range)]
        return nn.Sequential(*layers)
    
    
    def show_gradcam(self, x, y=None, detach=True, cpu=True, apply_relu=True, cmap='inferno', figsize=None, **kwargs):

        att_maps = get_attribution_map(self, [self.conv2dblock, self.conv1dblock], x, y=y, detach=detach, cpu=cpu, apply_relu=apply_relu)
        att_maps[0] = (att_maps[0] - att_maps[0].min()) / (att_maps[0].max() - att_maps[0].min())
        att_maps[1] = (att_maps[1] - att_maps[1].min()) / (att_maps[1].max() - att_maps[1].min())

        figsize = ifnone(figsize, (10, 10))
        fig = plt.figure(figsize=figsize, **kwargs)
        ax = plt.axes()
        plt.title('Observed variables')
        if att_maps[0].ndim == 3:
            att_maps[0] = att_maps[0].mean(0)
        im = ax.imshow(att_maps[0], cmap=cmap)
        cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])
        plt.colorbar(im, cax=cax)
        plt.show()

        fig = plt.figure(figsize=figsize, **kwargs)
        ax = plt.axes()
        plt.title('Time')
        if att_maps[1].ndim == 3:
            att_maps[1] = att_maps[1].mean(0)
        im = ax.imshow(att_maps[1], cmap=cmap)
        cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])
        plt.colorbar(im, cax=cax)
        plt.show()

from tsai.data.basics import *
from tsai.learner import *

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, split_data=False)
tfms = [None, TSCategorize()]
dls = get_ts_dls(X, y, splits=splits, tfms=tfms)
model =  XCM(dls.vars, dls.c, dls.len)
learn = ts_learner(dls, model, metrics=accuracy)
xb, yb = dls.one_batch()

bs, c_in, seq_len = xb.shape
c_out = len(np.unique(yb.cpu().numpy()))

model = XCM(c_in, c_out, seq_len, fc_dropout=.5)
test_eq(model.to(xb.device)(xb).shape, (bs, c_out))
model = XCM(c_in, c_out, seq_len, concat_pool=True)
test_eq(model.to(xb.device)(xb).shape, (bs, c_out))
model = XCM(c_in, c_out, seq_len)
test_eq(model.to(xb.device)(xb).shape, (bs, c_out))
model
# Output:
#   XCM(

#     (conv2dblock): Sequential(

#       (0): Unsqueeze(dim=1)

#       (1): Conv2dSame(

#         (conv2d_same): Conv2d(1, 128, kernel_size=(1, 51), stride=(1, 1))

#       )

#       (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (3): ReLU()

#     )

#     (conv2d1x1block): Sequential(

#       (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))

#       (1): ReLU()

#       (2): Squeeze(dim=1)

#     )

#     (conv1dblock): Sequential(

#       (0): Conv1d(24, 128, kernel_size=(51,), stride=(1,), padding=(25,))

#       (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (conv1d1x1block): Sequential(

#       (0): Conv1d(128, 1, kernel_size=(1,), stride=(1,))

#       (1): ReLU()

#     )

#     (concat): Concat(dim=1)

#     (conv1d): Sequential(

#       (0): Conv1d(25, 128, kernel_size=(51,), stride=(1,), padding=(25,))

#       (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): ReLU()

#     )

#     (head): Sequential(

#       (0): GAP1d(

#         (gap): AdaptiveAvgPool1d(output_size=1)

#         (flatten): Reshape(bs)

#       )

#       (1): LinBnDrop(

#         (0): Linear(in_features=128, out_features=6, bias=True)

#       )

#     )

#   )

model.show_gradcam(xb, yb)
# Output:
#   <Figure size 1000x1000 with 2 Axes>
#   <Figure size 1000x1000 with 2 Axes>

model.show_gradcam(xb[0], yb[0])
# Output:
#   [W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.

#   <Figure size 1000x1000 with 2 Axes>
#   <Figure size 1000x1000 with 2 Axes>

bs = 16
n_vars = 3
seq_len = 12
c_out = 10
xb = torch.rand(bs, n_vars, seq_len)
new_head = partial(conv_lin_nd_head, d=(5, 2))
net = XCM(n_vars, c_out, seq_len, custom_head=new_head)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([16, 5, 2, 10])

#   create_conv_lin_nd_head(

#     (0): Conv1d(128, 10, kernel_size=(1,), stride=(1,))

#     (1): Linear(in_features=12, out_features=10, bias=True)

#     (2): Transpose(-1, -2)

#     (3): Reshape(bs, 5, 2, 10)

#   )

bs = 16
n_vars = 3
seq_len = 12
c_out = 2
xb = torch.rand(bs, n_vars, seq_len)
net = XCM(n_vars, c_out, seq_len)
change_model_head(net, create_pool_plus_head, concat_pool=False)
print(net.to(xb.device)(xb).shape)
net.head
# Output:
#   torch.Size([16, 2])

#   Sequential(

#     (0): AdaptiveAvgPool1d(output_size=1)

#     (1): Reshape(bs)

#     (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (3): Linear(in_features=128, out_features=512, bias=False)

#     (4): ReLU(inplace=True)

#     (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (6): Linear(in_features=512, out_features=2, bias=False)

#   )

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/061_models.XCM.ipynb saved at 2023-03-16 12:38:29

#   Correct notebook to script conversion! 😃

#   Thursday 16/03/23 12:38:32 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/064_models.TabTransformer.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TabTransformer

"""
# TabTransformer
"""

"""
This is an unofficial TabTransformer Pytorch implementation created by Ignacio Oguiza (oguiza@timeseriesAI.co)

Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z. (2020). <span style="color:dodgerblue">**TabTransformer: Tabular Data Modeling Using Contextual Embeddings**</span>. arXiv preprint https://arxiv.org/pdf/2012.06678

Official repo: https://github.com/awslabs/autogluon/tree/master/tabular/src/autogluon/tabular/models/tab_transformer
"""

#|eval: false
#|hide
from tsai.imports import *

#|export
# This is an unofficial TabTransformer implementation in Pytorch developed by Ignacio Oguiza - oguiza@timeseriesAI.co based on:
# Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z. (2020). 
# TabTransformer: Tabular Data Modeling Using Contextual Embeddings. 
# arXiv preprint https://arxiv.org/pdf/2012.06678
# Official repo: https://github.com/awslabs/autogluon/tree/master/tabular/src/autogluon/tabular/models/tab_transformer

import torch
import torch.nn as nn
import torch.nn.functional as F


def ifnone(a, b):
    # From fastai.fastcore
    "`b` if `a` is None else `a`"
    return b if a is None else a

        
def _trunc_normal_(x, mean=0., std=1.):
    "Truncated normal initialization (approximation)"
    # From fastai.layers
    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12
    return x.normal_().fmod_(2).mul_(std).add_(mean)


class _Embedding(nn.Embedding):
    "Embedding layer with truncated normal initialization"
    # From fastai.layers
    def __init__(self, ni, nf, std=0.01):
        super(_Embedding, self).__init__(ni, nf)
        _trunc_normal_(self.weight.data, std=std)
        

class SharedEmbedding(nn.Module):
    def __init__(self, num_embeddings, embedding_dim, shared_embed=True, add_shared_embed=False, shared_embed_div=8):
        super().__init__()
        if shared_embed:
            if add_shared_embed:
                shared_embed_dim = embedding_dim
                self.embed = _Embedding(num_embeddings, embedding_dim)
            else:
                shared_embed_dim = embedding_dim // shared_embed_div
                self.embed = _Embedding(num_embeddings, embedding_dim - shared_embed_dim)
            self.shared_embed = nn.Parameter(torch.empty(1, 1, shared_embed_dim))
            _trunc_normal_(self.shared_embed.data, std=0.01)
            self.add_shared_embed = add_shared_embed
        else: 
            self.embed = _Embedding(num_embeddings, embedding_dim)
            self.shared_embed = None

    def forward(self, x):
        out = self.embed(x).unsqueeze(1)
        if self.shared_embed is None: return out
        if self.add_shared_embed:
            out += self.shared_embed
        else:
            shared_embed = self.shared_embed.expand(out.shape[0], -1, -1)
            out = torch.cat((out, shared_embed), dim=-1)
        return out


class FullEmbeddingDropout(nn.Module):
    '''From https://github.com/jrzaurin/pytorch-widedeep/blob/be96b57f115e4a10fde9bb82c35380a3ac523f52/pytorch_widedeep/models/tab_transformer.py#L153'''
    def __init__(self, dropout: float):
        super().__init__()
        self.dropout = dropout

    def forward(self, x):
        mask = x.new().resize_((x.size(1), 1)).bernoulli_(1 - self.dropout).expand_as(x) / (1 - self.dropout)
        return mask * x

    
class _MLP(nn.Module):
    def __init__(self, dims, bn=False, act=None, skip=False, dropout=0., bn_final=False):
        super().__init__()
        dims_pairs = list(zip(dims[:-1], dims[1:]))
        layers = []
        for i, (dim_in, dim_out) in enumerate(dims_pairs):
            is_last = i >= (len(dims) - 2)
            if bn and (not is_last or bn_final): layers.append(nn.BatchNorm1d(dim_in))
            if dropout and not is_last:
                layers.append(nn.Dropout(dropout))
            layers.append(nn.Linear(dim_in, dim_out))
            if is_last: break
            layers.append(ifnone(act, nn.ReLU()))
        self.mlp = nn.Sequential(*layers)
        self.shortcut = nn.Linear(dims[0], dims[-1]) if skip else None

    def forward(self, x):
        if self.shortcut is not None: 
            return self.mlp(x) + self.shortcut(x)
        else:
            return self.mlp(x)


class _ScaledDotProductAttention(nn.Module):
    def __init__(self, d_k:int, res_attention:bool=False): 
        super().__init__()
        self.d_k,self.res_attention = d_k,res_attention
        
    def forward(self, q, k, v, prev=None, attn_mask=None):

        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        scores = torch.matmul(q, k)                                    # scores : [bs x n_heads x q_len x q_len]

        # Scale
        scores = scores / (self.d_k ** 0.5)

        # Attention mask (optional)
        if attn_mask is not None:                                     # mask with shape [q_len x q_len]
            if attn_mask.dtype == torch.bool:
                scores.masked_fill_(attn_mask, float('-inf'))
            else:
                scores += attn_mask

        # SoftMax
        if prev is not None: scores = scores + prev

        attn = F.softmax(scores, dim=-1)                               # attn   : [bs x n_heads x q_len x q_len]

        # MatMul (attn, v)
        context = torch.matmul(attn, v)                                # context: [bs x n_heads x q_len x d_v]

        if self.res_attention: return context, attn, scores
        else: return context, attn


class _MultiheadAttention(nn.Module):
    def __init__(self, d_model:int, n_heads:int, d_k:int, d_v:int, res_attention:bool=False):
        """Input shape:  Q, K, V:[batch_size (bs) x q_len x d_model], mask:[q_len x q_len]"""
        super().__init__()
        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v

        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)

        self.W_O = nn.Linear(n_heads * d_v, d_model, bias=False)

        self.res_attention = res_attention

        # Scaled Dot-Product Attention (multiple heads)
        if self.res_attention:
            self.sdp_attn = _ScaledDotProductAttention(self.d_k, self.res_attention)
        else:
            self.sdp_attn = _ScaledDotProductAttention(self.d_k)

        
    def forward(self, Q, K, V, prev=None, attn_mask=None):

        bs = Q.size(0)

        # Linear (+ split in multiple heads)
        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x q_len x d_k]
        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)
        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]

        # Scaled Dot-Product Attention (multiple heads)
        if self.res_attention:
            context, attn, scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, attn_mask=attn_mask)
        else:
            context, attn = self.sdp_attn(q_s, k_s, v_s, attn_mask=attn_mask)
        # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]

        # Concat
        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # context: [bs x q_len x n_heads * d_v]

        # Linear
        output = self.W_O(context)                                                           # context: [bs x q_len x d_model]

        if self.res_attention: return output, attn, scores
        else: return output, attn                                                            # output: [bs x q_len x d_model]

        
class _TabEncoderLayer(nn.Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, 
                 res_dropout=0.1, activation="gelu", res_attention=False):

        super().__init__()
        assert not d_model%n_heads, f"d_model ({d_model}) must be divisible by n_heads ({n_heads})"
        d_k = ifnone(d_k, d_model // n_heads)
        d_v = ifnone(d_v, d_model // n_heads)
        d_ff = ifnone(d_ff, d_model * 4)

        # Multi-Head attention
        self.res_attention = res_attention
        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, res_attention=res_attention)

        # Add & Norm
        self.dropout_attn = nn.Dropout(res_dropout)
        self.layernorm_attn = nn.LayerNorm(d_model)

        # Position-wise Feed-Forward
        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), self._get_activation_fn(activation), nn.Linear(d_ff, d_model))

        # Add & Norm
        self.dropout_ffn = nn.Dropout(res_dropout)
        self.layernorm_ffn = nn.LayerNorm(d_model)

    def forward(self, src, prev=None, attn_mask=None):

        # Multi-Head attention sublayer
        ## Multi-Head attention
        if self.res_attention:
            src2, attn, scores = self.self_attn(src, src, src, prev, attn_mask=attn_mask)
        else:
            src2, attn = self.self_attn(src, src, src, attn_mask=attn_mask)
        self.attn = attn
        ## Add & Norm
        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout
        src = self.layernorm_attn(src) # Norm: layernorm 

        # Feed-forward sublayer
        ## Position-wise Feed-Forward
        src2 = self.ff(src)
        ## Add & Norm
        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout
        src = self.layernorm_ffn(src) # Norm: layernorm

        if self.res_attention:
            return src, scores
        else:
            return src

    def _get_activation_fn(self, activation):
        if callable(activation): return activation()
        elif activation.lower() == "relu": return nn.ReLU()
        elif activation.lower() == "gelu": return nn.GELU()
        raise ValueError(f'{activation} is not available. You can use "relu", "gelu", or a callable')


class _TabEncoder(nn.Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, res_dropout=0.1, activation='gelu', res_attention=False, n_layers=1):
        super().__init__()
        self.layers = nn.ModuleList([_TabEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, 
                                                            activation=activation, res_attention=res_attention) for i in range(n_layers)])
        self.res_attention = res_attention

    def forward(self, src, attn_mask=None):
        output = src
        scores = None
        if self.res_attention:
            for mod in self.layers: output, scores = mod(output, prev=scores, attn_mask=attn_mask)
            return output
        else:
            for mod in self.layers: output = mod(output, attn_mask=attn_mask)
            return output

        
class TabTransformer(nn.Module):
    def __init__(self, classes, cont_names, c_out, column_embed=True, add_shared_embed=False, shared_embed_div=8, embed_dropout=0.1, drop_whole_embed=False, 
                 d_model=32, n_layers=6, n_heads=8, d_k=None, d_v=None, d_ff=None, res_attention=True, attention_act='gelu', res_dropout=0.1, norm_cont=True,
                 mlp_mults=(4, 2), mlp_dropout=0., mlp_act=None, mlp_skip=False, mlp_bn=False, bn_final=False):

        super().__init__()
        n_cat = len(classes)
        n_classes = [len(v) for v in classes.values()]
        n_cont = len(cont_names)
        self.embeds = nn.ModuleList([SharedEmbedding(ni, d_model, shared_embed=column_embed, add_shared_embed=add_shared_embed, 
                                                     shared_embed_div=shared_embed_div) for ni in n_classes])
        n_emb = sum(n_classes)
        self.n_emb,self.n_cont = n_emb,n_cont
        self.emb_drop = None
        if embed_dropout:
            self.emb_drop = FullEmbeddingDropout(embed_dropout) if drop_whole_embed else nn.Dropout(embed_dropout)
        self.transformer = _TabEncoder(n_cat, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout,
                                       activation=attention_act, res_attention=res_attention, n_layers=n_layers)
        self.norm = nn.LayerNorm(n_cont) if norm_cont else None
        mlp_input_size = (d_model * n_cat) + n_cont
        hidden_dimensions = list(map(lambda t: int(mlp_input_size * t), mlp_mults))
        all_dimensions = [mlp_input_size, *hidden_dimensions, c_out]
        self.mlp = _MLP(all_dimensions, act=mlp_act, skip=mlp_skip, bn=mlp_bn, dropout=mlp_dropout, bn_final=bn_final)

    def forward(self, x_cat, x_cont=None):
        if self.n_emb != 0:
            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]
            x = torch.cat(x, 1)
            if self.emb_drop is not None: x = self.emb_drop(x)
            x = self.transformer(x)
            x = x.flatten(1)
        if self.n_cont != 0:
            if self.norm is not None: x_cont = self.norm(x_cont)
            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont
        x = self.mlp(x)
        return x

from fastai.tabular.all import *

path = untar_data(URLs.ADULT_SAMPLE)
df = pd.read_csv(path/'adult.csv')
dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names="salary",
    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],
    cont_names = ['age', 'fnlwgt', 'education-num'],
    procs = [Categorify, FillMissing, Normalize])
x_cat, x_cont, yb = first(dls.train)
model = TabTransformer(dls.classes, dls.cont_names, dls.c)
test_eq(model(x_cat, x_cont).shape, (dls.train.bs, dls.c))

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/121_models.TabTransformer.ipynb saved at 2022-11-09 13:13:29

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:13:32 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/066_models.TabFusionTransformer.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TabFusionTransformer

"""
# TabFusionTransformer
"""

"""
This is a a Pytorch implementeation of  TabTransformerTransformer created by Ignacio Oguiza (oguiza@timeseriesAI.co)

This implementation is inspired by:

Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z. (2020). <span style="color:dodgerblue">**TabTransformer: Tabular Data Modeling Using Contextual Embeddings**</span>. arXiv preprint https://arxiv.org/pdf/2012.06678

Official repo: https://github.com/awslabs/autogluon/tree/master/tabular/src/autogluon/tabular/models/tab_transformer
"""

#|eval: false
#|hide
from tsai.imports import *

#|export
# This is a modified Pytorch implementation based on TabTransformer created by Ignacio Oguiza (oguiza@timeseriesAI.co):
# Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z. (2020). 
# TabTransformer: Tabular Data Modeling Using Contextual Embeddings. 
# arXiv preprint https://arxiv.org/pdf/2012.06678
# Official repo: https://github.com/awslabs/autogluon/tree/master/tabular/src/autogluon/tabular/models/tab_transformer

import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict


def ifnone(a, b):
    # From fastai.fastcore
    "`b` if `a` is None else `a`"
    return b if a is None else a


class _Flatten(nn.Module):
    def __init__(self, full=False):
        super().__init__()
        self.full = full
    def forward(self, x):
        return x.view(-1) if self.full else x.view(x.size(0), -1)


class Sequential(nn.Sequential):
    """Class that allows you to pass one or multiple inputs"""
    def forward(self, *x):
        for i, module in enumerate(self._modules.values()):
            x = module(*x) if isinstance(x, (list, tuple)) else module(x)
        return x


class _MLP(nn.Module):
    def __init__(self, dims, bn=False, act=None, skip=False, dropout=0., bn_final=False):
        super().__init__()
        dims_pairs = list(zip(dims[:-1], dims[1:]))
        layers = []
        for i, (dim_in, dim_out) in enumerate(dims_pairs):
            is_last = i >= (len(dims) - 2)
            if bn and (not is_last or bn_final): layers.append(nn.BatchNorm1d(dim_in))
            if dropout and not is_last:
                layers.append(nn.Dropout(dropout))
            layers.append(nn.Linear(dim_in, dim_out))
            if is_last: break
            layers.append(ifnone(act, nn.ReLU()))
        self.mlp = nn.Sequential(*layers)
        self.shortcut = nn.Linear(dims[0], dims[-1]) if skip else None

    def forward(self, x):
        if self.shortcut is not None: 
            return self.mlp(x) + self.shortcut(x)
        else:
            return self.mlp(x)
        

class _ScaledDotProductAttention(nn.Module):
    def __init__(self, d_k:int, res_attention:bool=False): 
        super().__init__()
        self.d_k,self.res_attention = d_k,res_attention
        
    def forward(self, q, k, v, prev=None, attn_mask=None):

        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        scores = torch.matmul(q, k)                                    # scores : [bs x n_heads x q_len x q_len]

        # Scale
        scores = scores / (self.d_k ** 0.5)

        # Attention mask (optional)
        if attn_mask is not None:                                     # mask with shape [q_len x q_len]
            if attn_mask.dtype == torch.bool:
                scores.masked_fill_(attn_mask, float('-inf'))
            else:
                scores += attn_mask

        # SoftMax
        if prev is not None: scores = scores + prev

        attn = F.softmax(scores, dim=-1)                               # attn   : [bs x n_heads x q_len x q_len]

        # MatMul (attn, v)
        context = torch.matmul(attn, v)                                # context: [bs x n_heads x q_len x d_v]

        if self.res_attention: return context, attn, scores
        else: return context, attn


class _MultiheadAttention(nn.Module):
    def __init__(self, d_model:int, n_heads:int, d_k:int, d_v:int, res_attention:bool=False):
        """Input shape:  Q, K, V:[batch_size (bs) x q_len x d_model], mask:[q_len x q_len]"""
        super().__init__()
        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v

        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)
        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)

        self.W_O = nn.Linear(n_heads * d_v, d_model, bias=False)

        self.res_attention = res_attention

        # Scaled Dot-Product Attention (multiple heads)
        if self.res_attention:
            self.sdp_attn = _ScaledDotProductAttention(self.d_k, self.res_attention)
        else:
            self.sdp_attn = _ScaledDotProductAttention(self.d_k)

        
    def forward(self, Q, K, V, prev=None, attn_mask=None):

        bs = Q.size(0)

        # Linear (+ split in multiple heads)
        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x q_len x d_k]
        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)
        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]

        # Scaled Dot-Product Attention (multiple heads)
        if self.res_attention:
            context, attn, scores = self.sdp_attn(q_s, k_s, v_s, prev=prev, attn_mask=attn_mask)
        else:
            context, attn = self.sdp_attn(q_s, k_s, v_s, attn_mask=attn_mask)
        # context: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len]

        # Concat
        context = context.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # context: [bs x q_len x n_heads * d_v]

        # Linear
        output = self.W_O(context)                                                           # context: [bs x q_len x d_model]

        if self.res_attention: return output, attn, scores
        else: return output, attn                                                            # output: [bs x q_len x d_model]


class _TabFusionEncoderLayer(nn.Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, 
                 res_dropout=0.1, activation="gelu", res_attention=False):

        super().__init__()
        assert not d_model%n_heads, f"d_model ({d_model}) must be divisible by n_heads ({n_heads})"
        d_k = ifnone(d_k, d_model // n_heads)
        d_v = ifnone(d_v, d_model // n_heads)
        d_ff = ifnone(d_ff, d_model * 4)

        # Multi-Head attention
        self.res_attention = res_attention
        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, res_attention=res_attention)

        # Add & Norm
        self.dropout_attn = nn.Dropout(res_dropout)
        self.layernorm_attn = nn.LayerNorm(d_model)

        # Position-wise Feed-Forward
        self.ff = nn.Sequential(nn.Linear(d_model, d_ff), self._get_activation_fn(activation), nn.Linear(d_ff, d_model))

        # Add & Norm
        self.dropout_ffn = nn.Dropout(res_dropout)
        self.layernorm_ffn = nn.LayerNorm(d_model)

    def forward(self, src, prev=None, attn_mask=None):

        # Multi-Head attention sublayer
        ## Multi-Head attention
        if self.res_attention:
            src2, attn, scores = self.self_attn(src, src, src, prev, attn_mask=attn_mask)
        else:
            src2, attn = self.self_attn(src, src, src, attn_mask=attn_mask)
        self.attn = attn
        ## Add & Norm
        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout
        src = self.layernorm_attn(src) # Norm: layernorm 

        # Feed-forward sublayer
        ## Position-wise Feed-Forward
        src2 = self.ff(src)
        ## Add & Norm
        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout
        src = self.layernorm_ffn(src) # Norm: layernorm

        if self.res_attention:
            return src, scores
        else:
            return src

    def _get_activation_fn(self, activation):
        if callable(activation): return activation()
        elif activation.lower() == "relu": return nn.ReLU()
        elif activation.lower() == "gelu": return nn.GELU()
        elif activation.lower() == "mish": return Mish()
        raise ValueError(f'{activation} is not available. You can use "relu", "gelu", "mish" or a callable')


class _TabFusionEncoder(nn.Module):
    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, res_dropout=0.1, activation='gelu', res_attention=False, n_layers=1):
        super().__init__()
        self.layers = nn.ModuleList([_TabFusionEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, 
                                                            activation=activation, res_attention=res_attention) for i in range(n_layers)])
        self.res_attention = res_attention

    def forward(self, src, attn_mask=None):
        output = src
        scores = None
        if self.res_attention:
            for mod in self.layers: output, scores = mod(output, prev=scores, attn_mask=attn_mask)
            return output
        else:
            for mod in self.layers: output = mod(output, attn_mask=attn_mask)
            return output


class TabFusionBackbone(nn.Module):
    def __init__(self, classes, cont_names, d_model=32, n_layers=6, n_heads=8, d_k=None, d_v=None, d_ff=None, init=True,
                 res_attention=True, attention_act='gelu', res_dropout=0.):

        super().__init__()
        
        # Categorical
        n_cat = len(classes)
        n_classes = [len(v) for v in classes.values()]
        self.n_emb = sum(n_classes)
        self.embeds = nn.ModuleList([nn.Embedding(ni, d_model) for ni in n_classes])
        
        # Continuous
        n_cont = len(cont_names)
        self.n_cont = n_cont
        self.conv = nn.Conv1d(1, d_model, 1)
        if init: nn.init.kaiming_normal_(self.conv.weight)

        # Transformer
        self.res_drop = nn.Dropout(res_dropout) if res_dropout else None
        self.pos_enc = nn.Parameter(torch.zeros(1, (n_cat  + n_cont), d_model))
        self.transformer = _TabFusionEncoder(n_cat + n_cont, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, 
                                             activation=attention_act, res_attention=res_attention, n_layers=n_layers)


    def forward(self, x_cat, x_cont=None):
        
        # Input encoding
        if self.n_emb != 0:
            x = [e(x_cat[:,i]).unsqueeze(1) for i,e in enumerate(self.embeds)]
            x = torch.cat(x, 1)
        if self.n_cont != 0:
            x_cont = self.conv(x_cont.unsqueeze(1)).transpose(1,2)
            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont

        # Transformer
        x += self.pos_enc
        if self.res_drop is not None: x = self.res_drop(x)
        x = self.transformer(x)

        return x


class TabFusionTransformer(Sequential):
    def __init__(self, classes, cont_names, c_out, 
                 d_model=32, n_layers=6, n_heads=8, d_k=None, d_v=None, d_ff=None, res_attention=True, attention_act='gelu', res_dropout=0.,
                 fc_mults=(4, 2), fc_dropout=0., fc_act=None, fc_skip=False, fc_bn=False, bn_final=False, init=True):

        super().__init__()
        
        # Backbone
        backbone = TabFusionBackbone(classes, cont_names, d_model=d_model, n_layers=n_layers, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, init=init,
                                     res_attention=res_attention, attention_act=attention_act, res_dropout=res_dropout)
        
        # Head
        mlp_input_size = (d_model * (len(classes)  + len(cont_names)))
        hidden_dimensions = list(map(lambda t: int(mlp_input_size * t), fc_mults))
        all_dimensions = [mlp_input_size, *hidden_dimensions, c_out]
        self.head_nf = mlp_input_size
        head = nn.Sequential(*[_Flatten(), _MLP(all_dimensions, act=fc_act, skip=fc_skip, bn=fc_bn, dropout=fc_dropout, bn_final=bn_final)])

        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))

from fastai.tabular.all import *

path = untar_data(URLs.ADULT_SAMPLE)
df = pd.read_csv(path/'adult.csv')
dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names="salary",
    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],
    cont_names = ['age', 'fnlwgt', 'education-num'],
    procs = [Categorify, FillMissing, Normalize])
x_cat, x_cont, yb = first(dls.train)
model = TabFusionTransformer(dls.classes, dls.cont_names, dls.c)
test_eq(model(x_cat, x_cont).shape, (dls.train.bs, dls.c))

#|export
class TSTabFusionTransformer(nn.Module):
    def __init__(self, c_in, c_out, seq_len, classes, cont_names, 
                 d_model=32, n_layers=6, n_heads=8, d_k=None, d_v=None, d_ff=None, res_attention=True, attention_act='gelu', res_dropout=0., 
                 fc_mults=(1, .5), fc_dropout=0., fc_act=None, fc_skip=False, fc_bn=False, bn_final=False, init=True):

        super().__init__()
        
        # Time series
        self.W_P = nn.Conv1d(c_in, d_model, 1)
        
        # Categorical
        n_cat = len(classes)
        n_classes = [len(v) for v in classes.values()]
        self.n_emb = sum(n_classes)
        self.embeds = nn.ModuleList([nn.Embedding(ni, d_model) for ni in n_classes])
        
        # Continuous
        n_cont = len(cont_names)
        self.n_cont = n_cont
        self.conv = nn.Conv1d(1, d_model, 1)
        if init: nn.init.kaiming_normal_(self.conv.weight)

        # Transformer
        self.res_drop = nn.Dropout(res_dropout) if res_dropout else None
        self.pos_enc = nn.Parameter(torch.zeros(1, (n_cat  + n_cont + seq_len), d_model))
        self.transformer = _TabFusionEncoder(n_cat + n_cont, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, res_dropout=res_dropout, 
                                             activation=attention_act, res_attention=res_attention, n_layers=n_layers)
        
        # Head
        mlp_input_size = (d_model * (n_cat  + n_cont + seq_len))
        hidden_dimensions = list(map(lambda t: int(mlp_input_size * t), fc_mults))
        all_dimensions = [mlp_input_size, *hidden_dimensions, c_out]
        self.head_nf = mlp_input_size
        self.head = nn.Sequential(*[_Flatten(), _MLP(all_dimensions, act=fc_act, skip=fc_skip, bn=fc_bn, dropout=fc_dropout, bn_final=bn_final)])

    def forward(self, x):
        x_ts, (x_cat, x_cont) = x
        
        # Time series
        x = self.W_P(x_ts).transpose(1,2)
        
        # Input encoding
        if self.n_emb != 0:
            x_cat = [e(x_cat[:,i]).unsqueeze(1) for i,e in enumerate(self.embeds)]
            x_cat = torch.cat(x_cat, 1)
            x = torch.cat([x, x_cat], 1)
        if self.n_cont != 0:
            x_cont = self.conv(x_cont.unsqueeze(1)).transpose(1,2)
            x = torch.cat([x, x_cont], 1)

        # Transformer
        x += self.pos_enc
        if self.res_drop is not None: x = self.res_drop(x)
        x = self.transformer(x)

        # Head
        x = self.head(x)
        return x

classes = {'education': ['#na#', '10th', '11th', '12th', '1st-4th', '5th-6th', '7th-8th', '9th', 'Assoc-acdm', 'Assoc-voc', 'Bachelors', 'Doctorate', 
                         'HS-grad', 'Masters', 'Preschool', 'Prof-school', 'Some-college'],
 'education-num_na': ['#na#', False, True],
 'marital-status': ['#na#', 'Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent', 'Never-married', 'Separated', 'Widowed'],
 'occupation': ['#na#', '?', 'Adm-clerical', 'Armed-Forces', 'Craft-repair', 'Exec-managerial', 'Farming-fishing', 'Handlers-cleaners', 'Machine-op-inspct', 
                'Other-service', 'Priv-house-serv', 'Prof-specialty', 'Protective-serv', 'Sales', 'Tech-support', 'Transport-moving'],
 'race': ['#na#', 'Amer-Indian-Eskimo', 'Asian-Pac-Islander', 'Black', 'Other', 'White'],
 'relationship': ['#na#', 'Husband', 'Not-in-family', 'Other-relative', 'Own-child', 'Unmarried', 'Wife'],
 'workclass': ['#na#', '?', 'Federal-gov', 'Local-gov', 'Never-worked', 'Private', 'Self-emp-inc', 'Self-emp-not-inc', 'State-gov', 'Without-pay']}

cont_names = ['a', 'b', 'c']
c_out = 6
x_ts = torch.randn(64, 3, 10)
x_cat = torch.randint(0,3,(64,7))
x_cont = torch.randn(64,3)
model = TSTabFusionTransformer(x_ts.shape[1], c_out, x_ts.shape[-1], classes, cont_names)
x = (x_ts, (x_cat, x_cont))
test_eq(model(x).shape, (x_ts.shape[0], c_out))

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/122_models.TabFusionTransformer.ipynb saved at 2022-11-09 13:12:15

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:12:18 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/067_models.TSPerceiver.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TSPerceiver

"""
# TSPerceiver
"""

"""
This implementation is inspired by:

Jaegle, A., Gimeno, F., Brock, A., Zisserman, A., Vinyals, O., & Carreira, J. (2021). 

<span style="color:dodgerblue">**Perceiver: General Perception with Iterative Attention**</span>. arXiv preprint arXiv:2103.03206.

Paper: https://arxiv.org/pdf/2103.03206.pdf

Official repo: Not available as og April, 2021.
"""

#|export
from tsai.imports import *
from tsai.models.layers import *

#|exporti
class ScaledDotProductAttention(Module):
    def __init__(self, d_k:int, res_attention:bool=False): 
        self.d_k,self.res_attention = d_k,res_attention

    def forward(self, q:Tensor, k:Tensor, v:Tensor, prev:Optional[Tensor]=None, key_padding_mask:Optional[Tensor]=None, attn_mask:Optional[Tensor]=None):
        '''
        Input shape:
            q               : [bs x n_heads x q_len x d_k]
            k               : [bs x n_heads x d_k x seq_len]
            v               : [bs x n_heads x seq_len x d_k]
            key_padding_mask: [bs x seq_len]
            attn_mask       : [seq_len x seq_len]

        Output shape: 
            context: [bs x n_heads x q_len x d_v]
            attn   : [bs x n_heads x q_len x seq_len]
        '''

        # MatMul (q, k) - similarity scores for all pairs of positions in an input sequence
        scores = torch.matmul(q, k)                                   # scores : [bs x n_heads x q_len x seq_len]

        # Scale
        scores = scores / (self.d_k ** 0.5)

        # Add previous scores (optional)
        if prev is not None: scores = scores + prev

        # Attention mask (optional)
        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len
            if attn_mask.dtype == torch.bool:
                scores.masked_fill_(attn_mask, float('-inf'))
            else:
                scores += attn_mask

        # Key padding mask (optional)
        if key_padding_mask is not None:                              # key_padding_mask with shape [bs x seq_len]
            scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), float('-inf'))

        # SoftMax
        attn = F.softmax(scores, dim=-1)                               # attn   : [bs x n_heads x q_len x seq_len]

        # MatMul (attn, v)
        context = torch.matmul(attn, v)                                # context: [bs x n_heads x q_len x d_v]

        if self.res_attention: return context, attn, scores
        else: return context, attn


class Attention(Module):
    def __init__(self, d_latent:int, d_context:Optional[int]=None, n_heads:int=8, d_head:Optional[int]=None, attn_dropout:float=0., res_attention:bool=False):

        d_context = ifnone(d_context, d_latent)
        n_heads = ifnone(n_heads, 1)
        d_head = ifnone(d_head, d_context//n_heads)

        self.scale = d_head ** -0.5
        self.n_heads, self.d_head, self.res_attention = n_heads, d_head, res_attention

        self.to_q = nn.Linear(d_latent, d_head * n_heads, bias=False)
        self.to_kv = nn.Linear(d_context, d_head * n_heads * 2, bias=False)

        self.attn = ScaledDotProductAttention(d_k=d_head, res_attention=res_attention)

        self.to_out = nn.Sequential(nn.Linear(d_head * n_heads, d_latent), nn.Dropout(attn_dropout))

    def forward(self, x, context=None, mask=None):
        h,d = self.n_heads, self.d_head
        bs = x.shape[0]
        q = self.to_q(x).view(bs, -1, h, d).transpose(1,2)
        context = ifnone(context, x)
        k, v = self.to_kv(context).chunk(2, dim=-1)
        k = k.view(bs, -1, h, d).permute(0,2,3,1)
        v = v.view(bs, -1, h, d).transpose(1,2)

        if self.res_attention:
            x, _, scores = self.attn(q, k, v)
        else:
            x, _ = self.attn(q, k, v)
        x = x.permute(0, 2, 1, 3).reshape(bs, -1, h * d)

        x = self.to_out(x)
        if self.res_attention:
            return x, scores
        else: 
            return x


class GEGLU(Module):
    def forward(self, x):
        x, gates = x.chunk(2, dim = -1)
        return x * F.gelu(gates)


class FeedForward(nn.Sequential):
    def __init__(self, dim, mult=2, dropout=0.):
        layers = [nn.Linear(dim, dim * mult), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim * mult, dim)]
        # layers = [nn.Linear(dim, dim * mult * 2), GEGLU(), nn.Dropout(dropout), nn.Linear(dim * mult, dim)]
        super().__init__(*layers)


class CrossAttention(Module):
    def __init__(self, d_latent, d_context=None, n_heads=8, d_head=None, attn_dropout=0., fc_dropout=0.):
        d_context = ifnone(d_context, d_latent)
        self.norm_latent= nn.LayerNorm(d_latent)
        self.norm_context = nn.LayerNorm(d_context) if d_context is not None else None
        self.attn = Attention(d_latent, d_context=d_context, n_heads=n_heads, d_head=d_head, attn_dropout=attn_dropout)
        self.norm_ff = nn.LayerNorm(d_latent)
        self.ff = FeedForward(d_latent, dropout=fc_dropout)
    
    def forward(self, x, context=None, mask=None):
        x = self.norm_latent(x)
        if context is not None: 
            context = self.norm_context(context)
        context = ifnone(context, x)
        x = self.attn(x, context)
        x = self.norm_ff(x)
        x = self.ff(x)
        return x


class LatentTransformer(Module):
    def __init__(self, d_latent, n_heads=8, d_head=None, attn_dropout=0., fc_dropout=0., self_per_cross_attn=1):
        self.layers = nn.ModuleList()
        for _ in range(self_per_cross_attn):
            self.layers.append(nn.ModuleList([nn.LayerNorm(d_latent), 
                                              Attention(d_latent, n_heads=n_heads, d_head=d_head, attn_dropout=attn_dropout), 
                                              nn.LayerNorm(d_latent) , 
                                              FeedForward(d_latent, dropout=fc_dropout)
                                              ]))

    def forward(self, x, mask=None):
        for attn_norm, att, ff_norm, ff in self.layers:
            x = attn_norm(x)
            x = att(x)
            x = ff_norm(x)
            x = ff(x)
        return x        

#|export
class TSPerceiver(Module):
    def __init__(self, c_in, c_out, seq_len, cat_szs=0, n_cont=0, n_latents=512, d_latent=128, d_context=None, n_layers=6, self_per_cross_attn=1, 
                 share_weights=True, cross_n_heads=1, self_n_heads=8, d_head=None, attn_dropout=0., fc_dropout=0., concat_pool=False):
        
        d_context = ifnone(d_context, d_latent)
        
        # Embedding
        self.to_ts_emb = nn.Linear(c_in, d_context)
        self.to_cat_emb = nn.ModuleList([nn.Embedding(s, d_context) for s in cat_szs]) if cat_szs else None
        self.to_cont_emb = nn.ModuleList([nn.Linear(1, d_context) for i in range(n_cont)]) if n_cont else None

        self.latent_array = nn.Parameter(torch.zeros(1, n_latents, d_context)) # N = q_len = indices = n_latents  

        # Positional encoding
        # self.ts_pos_enc = nn.Parameter(torch.zeros(1, 1, d_context))
        # self.cat_pos_enc = nn.Parameter(torch.zeros(1, 1, d_context)) if cat_szs else None
        # self.cont_pos_enc = nn.Parameter(torch.zeros(1, 1, d_context)) if n_cont else None 
        self.ts_pos_enc = nn.Parameter(torch.zeros(1, 1, 1))
        self.cat_pos_enc = nn.Parameter(torch.zeros(1, 1, 1)) if cat_szs else None
        self.cont_pos_enc = nn.Parameter(torch.zeros(1, 1, 1)) if n_cont else None 
        # self.pos_enc = nn.Parameter(torch.zeros(1, seq_len + (len(cat_szs) if cat_szs else 0) + n_cont, d_context))
        pos_enc = torch.linspace(-1, 1, seq_len + (len(cat_szs) if cat_szs else 0) + n_cont).unsqueeze(0).unsqueeze(-1).repeat(1, 1, d_context)
        self.pos_enc = nn.Parameter(pos_enc, requires_grad=False)

        # Cross-attention & Latent-transformer
        self.self_per_cross_attn = self_per_cross_attn
        self.attn = nn.ModuleList()
        for i in range(n_layers):
            if i < 2 or not share_weights: 
                attn = [CrossAttention(d_latent, d_context=d_context, n_heads=cross_n_heads, d_head=d_head, attn_dropout=attn_dropout, 
                                       fc_dropout=fc_dropout)]
                if self_per_cross_attn != 0:
                    attn += [LatentTransformer(d_latent, n_heads=self_n_heads, d_head=d_head, attn_dropout=attn_dropout, fc_dropout=fc_dropout, 
                                               self_per_cross_attn=self_per_cross_attn)]
            self.attn.append(nn.ModuleList(attn))

        self.head = nn.Sequential(GACP1d() if concat_pool else GAP1d(), nn.BatchNorm1d(d_latent*(1+concat_pool)), nn.Linear(d_latent*(1+concat_pool), c_out))

    def forward(self, x):
        # Embedding
        # Time series
        if isinstance(x, tuple):
            x_ts, (x_cat, x_cont) = x
        else: 
            x_ts, x_cat, x_cont = x, None, None
        context = self.to_ts_emb(x_ts.transpose(1,2))
        context += self.ts_pos_enc
        # Categorical
        if self.to_cat_emb is not None: 
            x_cat = torch.cat([e(x_cat[:,i]).unsqueeze(1) for i,e in enumerate(self.to_cat_emb)], 1)
            x_cat += self.cat_pos_enc
            context = torch.cat([context, x_cat], 1)
        # Continuous
        if self.to_cont_emb is not None:
            x_cont = torch.cat([e(x_cont[:,i].unsqueeze(1).unsqueeze(2)) for i,e in enumerate(self.to_cont_emb)], 1)
            x_cont += self.cont_pos_enc
            context = torch.cat([context, x_cont], 1)
        context += self.pos_enc
        
        # Latent array
        x = self.latent_array.repeat(context.shape[0], 1, 1)
        
        # Cross-attention & Latent transformer
        for i, attn in enumerate(self.attn):
            x = attn[0](x, context=context) + x # cross-attention
            if self.self_per_cross_attn != 0:
                x = attn[1](x) + x              # latent transformer

        x = x.transpose(1,2)
        
        #Head
        out = self.head(x)
        return out

from tsai.basics import *
from tsai.data.all import *

#|extras
dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, split_data=False)
ts_features_df = get_ts_features(X, y)
ts_features_df.shape
# Output:
#   Feature Extraction: 100%|██████████████████████████████████████████| 30/30 [00:00<00:00, 189.16it/s]

#   (60, 11)

#|extras
# raw ts
tfms  = [None, [Categorize()]]
batch_tfms = TSStandardize(by_sample=True)
ts_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)

# ts features
cat_names = None
cont_names = ts_features_df.columns[:-2]
y_names = 'target'
tab_dls = get_tabular_dls(ts_features_df, cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)

# mixed
mixed_dls = get_mixed_dls(ts_dls, tab_dls)
xb, yb = mixed_dls.one_batch()

#|extras
model = TSPerceiver(ts_dls.vars, ts_dls.c, ts_dls.len, cat_szs=0, 
                    # n_cont=0, 
                    n_cont=xb[1][1].shape[1], 
                    n_latents=128, d_latent=128, n_layers=3, self_per_cross_attn=1, share_weights=True,
                    cross_n_heads=16, self_n_heads=16, d_head=None, attn_dropout=0., fc_dropout=0.).to(device)
test_eq(model(xb).shape, (yb.shape[0], len(np.unique(y))))

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/123_models.TSPerceiver.ipynb saved at 2022-11-09 13:11:59

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:12:02 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/069_models.TSSequencerPlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TSSequencerPlus

"""
# TSSequencerPlus
"""

"""
>This is a PyTorch implementation created by Ignacio Oguiza (oguiza@timeseriesAI.co) based on Sequencer: Deep LSTM for Image Classification
"""

#|export
from tsai.imports import *
from tsai.models.utils import *
from tsai.models.layers import *
from typing import Callable

#|export
class _TSSequencerEncoderLayer(nn.Module):
    def __init__(self, d_model:int, q_len:int=None, lstm_dropout:float=0., dropout:float=0, drop_path_rate:float=0.,
                 mlp_ratio:int=1, lstm_bias:bool=True, act:str='gelu', pre_norm:bool=False):
        super().__init__()
        self.bilstm = nn.LSTM(q_len, q_len, num_layers=1, bidirectional=True, bias=lstm_bias)
        self.dropout = nn.Dropout(lstm_dropout) if lstm_dropout else nn.Identity()
        self.fc = nn.Linear(2 * q_len, q_len)
        self.lstm_norm = nn.LayerNorm(d_model)
        self.pwff =  PositionwiseFeedForward(d_model, dropout=dropout, act=act, mlp_ratio=mlp_ratio)
        self.ff_norm = nn.LayerNorm(d_model)
        self.drop_path = DropPath(drop_path_rate) if drop_path_rate != 0 else nn.Identity()
        self.pre_norm = pre_norm
        self.transpose = Transpose(1,2)

    def forward(self, x):
        if self.pre_norm:
            x = self.drop_path(self.dropout(self.transpose(self.fc(self.bilstm(self.transpose(self.lstm_norm(x)))[0])))) + x
            x = self.drop_path(self.pwff(self.ff_norm(x))) + x
        else:
            x = self.lstm_norm(self.drop_path(self.dropout(self.transpose(self.fc(self.bilstm(self.transpose(x))[0])))) + x)
            x = self.ff_norm(self.drop_path(self.pwff(x)) + x)
        return x

#|export
class _TSSequencerEncoder(nn.Module):
    def __init__(self, d_model, depth:int=6, q_len:int=None, lstm_dropout:float=0., dropout:float=0, drop_path_rate:float=0.,
                 mlp_ratio:int=1, lstm_bias:bool=True, act:str='gelu', pre_norm:bool=False):
        super().__init__()
        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]
        layers = []
        for i in range(depth):
            layer = _TSSequencerEncoderLayer(d_model, q_len=q_len, lstm_dropout=lstm_dropout, dropout=dropout, drop_path_rate=dpr[i],
                                      mlp_ratio=mlp_ratio, lstm_bias=lstm_bias, act=act, pre_norm=pre_norm)
            layers.append(layer)
        self.encoder = nn.Sequential(*layers)
        self.norm = nn.LayerNorm(d_model) if pre_norm else nn.Identity()

    def forward(self, x):
        x = self.encoder(x)
        x = self.norm(x)
        return x

#|export
class _TSSequencerBackbone(Module):
    def __init__(self, c_in:int, seq_len:int, depth:int=6, d_model:int=128, act:str='gelu',
                 lstm_bias:bool=True, lstm_dropout:float=0., dropout:float=0., drop_path_rate:float=0., mlp_ratio:int=1,
                 pre_norm:bool=False, use_token:bool=True,  use_pe:bool=True, n_cat_embeds:Optional[list]=None, cat_embed_dims:Optional[list]=None,
                 cat_padding_idxs:Optional[list]=None, cat_pos:Optional[list]=None, feature_extractor:Optional[Callable]=None,
                 token_size:int=None, tokenizer:Optional[Callable]=None):

        # Categorical embeddings
        if n_cat_embeds is not None:
            n_cat_embeds = listify(n_cat_embeds)
            if cat_embed_dims is None:
                cat_embed_dims = [emb_sz_rule(s) for s in n_cat_embeds]
            self.to_cat_embed = MultiEmbedding(c_in, n_cat_embeds, cat_embed_dims=cat_embed_dims, cat_padding_idxs=cat_padding_idxs, cat_pos=cat_pos)
            c_in, seq_len = output_size_calculator(self.to_cat_embed, c_in, seq_len)
        else:
            self.to_cat_embed = nn.Identity()

        # Sequence embedding
        if token_size is not None:
            self.tokenizer = SeqTokenizer(c_in, d_model, token_size)
            c_in, seq_len = output_size_calculator(self.tokenizer, c_in, seq_len)
        elif tokenizer is not None:
            if isinstance(tokenizer, nn.Module):  self.tokenizer = tokenizer
            else: self.tokenizer = tokenizer(c_in, d_model)
            c_in, seq_len = output_size_calculator(self.tokenizer, c_in, seq_len)
        else:
            self.tokenizer = nn.Identity()

        # Feature extractor
        if feature_extractor is not None:
            if isinstance(feature_extractor, nn.Module):  self.feature_extractor = feature_extractor
            else: self.feature_extractor = feature_extractor(c_in, d_model)
            c_in, seq_len = output_size_calculator(self.feature_extractor, c_in, seq_len)
        else:
            self.feature_extractor = nn.Identity()

        # Linear projection
        self.transpose = Transpose(1,2)
        if token_size is None and tokenizer is None and feature_extractor is None:
            self.linear_proj = nn.Linear(c_in, d_model)
            # self.linear_proj = nn.Conv1d(c_in, d_model, 1)
        else:
            self.linear_proj = nn.Identity()

        # Position embedding & token
        if use_pe:
            self.pos_embed = nn.Parameter(torch.zeros(1, seq_len, d_model))
        self.use_pe = use_pe
        self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))
        self.use_token = use_token
        self.emb_dropout = nn.Dropout(dropout) if dropout else nn.Identity()

        # Encoder
        self.encoder = _TSSequencerEncoder(d_model, depth=depth, q_len=seq_len + use_token, lstm_bias=lstm_bias,
                                         lstm_dropout=lstm_dropout, dropout=dropout,
                                         mlp_ratio=mlp_ratio, drop_path_rate=drop_path_rate, act=act, pre_norm=pre_norm)

    def forward(self, x):

        # Categorical embeddings
        x = self.to_cat_embed(x)

        # Sequence embedding
        x = self.tokenizer(x)

        # Feature extractor
        x = self.feature_extractor(x)

        # Linear projection
        x = self.transpose(x)
        x = self.linear_proj(x)

        # Position embedding & token
        if self.use_pe:
            x = x + self.pos_embed
        if self.use_token: # token is concatenated after position embedding so that embedding can be learned using self.supervised learning
            x = torch.cat((self.cls_token.expand(x.shape[0], -1, -1), x), dim=1)
        x = self.emb_dropout(x)

        # Encoder
        x = self.encoder(x)

        # Output
        x = x.transpose(1,2)
        return x

#|exports
class TSSequencerPlus(nn.Sequential):
    r"""Time Series Sequencer model based on:

    Tatsunami, Y., & Taki, M. (2022). Sequencer: Deep LSTM for Image Classification. arXiv preprint arXiv:2205.01972.
    Official implementation: https://github.com/okojoalg/sequencer

    Args:
        c_in:               the number of features (aka variables, dimensions, channels) in the time series dataset.
        c_out:              the number of target classes.
        seq_len:            number of time steps in the time series.
        d_model:            total dimension of the model (number of features created by the model).
        depth:              number of blocks in the encoder.
        act:                the activation function of positionwise feedforward layer.
        lstm_dropout:       dropout rate applied to the lstm sublayer.
        dropout:            dropout applied to to the embedded sequence steps after position embeddings have been added and
                            to the mlp sublayer in the encoder.
        drop_path_rate:     stochastic depth rate.
        mlp_ratio:          ratio of mlp hidden dim to embedding dim.
        lstm_bias:          determines whether bias is applied to the LSTM layer.
        pre_norm:           if True normalization will be applied as the first step in the sublayers. Defaults to False.
        use_token:          if True, the output will come from the transformed token. This is meant to be use in classification tasks.
        use_pe:             flag to indicate if positional embedding is used.
        n_cat_embeds:       list with the sizes of the dictionaries of embeddings (int).
        cat_embed_dims:     list with the sizes of each embedding vector (int).
        cat_padding_idxs:       If specified, the entries at cat_padding_idxs do not contribute to the gradient; therefore, the embedding vector at cat_padding_idxs
                            are not updated during training. Use 0 for those categorical embeddings that may have #na# values. Otherwise, leave them as None.
                            You can enter a combination for different embeddings (for example, [0, None, None]).
        cat_pos:            list with the position of the categorical variables in the input.
        token_size:         Size of the embedding function used to reduce the sequence length (similar to ViT's patch size)
        tokenizer:          nn.Module or callable that will be used to reduce the sequence length
        feature_extractor:  nn.Module or callable that will be used to preprocess the time series before
                            the embedding step. It is useful to extract features or resample the time series.
        flatten:            flag to indicate if the 3d logits will be flattened to 2d in the model's head if use_token is set to False.
                            If use_token is False and flatten is False, the model will apply a pooling layer.
        concat_pool:        if True the head begins with fastai's AdaptiveConcatPool2d if concat_pool=True; otherwise, it uses traditional average pooling.
        fc_dropout:         dropout applied to the final fully connected layer.
        use_bn:             flag that indicates if batchnorm will be applied to the head.
        bias_init:          values used to initialized the output layer.
        y_range:            range of possible y values (used in regression tasks).
        custom_head:        custom head that will be applied to the network. It must contain all kwargs (pass a partial function)
        verbose:            flag to control verbosity of the model.

    Input:
        x: bs (batch size) x nvars (aka features, variables, dimensions, channels) x seq_len (aka time steps)
    """

    def __init__(self, c_in:int, c_out:int, seq_len:int, d_model:int=128, depth:int=6, act:str='gelu',
                 lstm_dropout:float=0., dropout:float=0., drop_path_rate:float=0., mlp_ratio:int=1, lstm_bias:bool=True,
                 pre_norm:bool=False, use_token:bool=False, use_pe:bool=True,
                 cat_pos:Optional[list]=None, n_cat_embeds:Optional[list]=None, cat_embed_dims:Optional[list]=None, cat_padding_idxs:Optional[list]=None,
                 token_size:int=None, tokenizer:Optional[Callable]=None, feature_extractor:Optional[Callable]=None,
                 flatten:bool=False, concat_pool:bool=True, fc_dropout:float=0., use_bn:bool=False,
                 bias_init:Optional[Union[float, list]]=None, y_range:Optional[tuple]=None, custom_head:Optional[Callable]=None, verbose:bool=True,
                 **kwargs):

        if use_token and c_out == 1:
            use_token = False
            pv("use_token set to False as c_out == 1", verbose)
        backbone = _TSSequencerBackbone(c_in, seq_len, depth=depth, d_model=d_model, act=act,
                                      lstm_dropout=lstm_dropout, dropout=dropout, drop_path_rate=drop_path_rate,
                                      pre_norm=pre_norm, mlp_ratio=mlp_ratio, use_pe=use_pe, use_token=use_token,
                                      n_cat_embeds=n_cat_embeds, cat_embed_dims=cat_embed_dims, cat_padding_idxs=cat_padding_idxs, cat_pos=cat_pos,
                                      feature_extractor=feature_extractor, token_size=token_size, tokenizer=tokenizer)

        self.head_nf = d_model
        self.c_out = c_out
        self.seq_len = seq_len

        # Head
        if custom_head:
            if isinstance(custom_head, nn.Module): head = custom_head
            else: head = custom_head(self.head_nf, c_out, seq_len, **kwargs)
        else:
            nf = d_model
            layers = []
            if use_token:
                layers += [TokenLayer()]
            elif flatten:
                layers += [Reshape(-1)]
                nf = nf * seq_len
            else:
                if concat_pool: nf *= 2
                layers = [GACP1d(1) if concat_pool else GAP1d(1)]
            if use_bn: layers += [nn.BatchNorm1d(nf)]
            if fc_dropout: layers += [nn.Dropout(fc_dropout)]

            # Last layer
            linear = nn.Linear(nf, c_out)
            if bias_init is not None:
                if isinstance(bias_init, float): nn.init.constant_(linear.bias, bias_init)
                else: linear.bias = nn.Parameter(torch.as_tensor(bias_init, dtype=torch.float32))
            layers += [linear]

            if y_range: layers += [SigmoidRange(*y_range)]
            head = nn.Sequential(*layers)
        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))


TSSequencer = TSSequencerPlus

bs = 16
nvars = 4
seq_len = 50
c_out = 2
xb = torch.rand(bs, nvars, seq_len)
model = TSSequencerPlus(nvars, c_out, seq_len)

bs = 16
nvars = 4
seq_len = 50
c_out = 2
xb = torch.rand(bs, nvars, seq_len)
model = TSSequencerPlus(nvars, c_out, seq_len, lstm_dropout=.1, dropout=.1, use_token=True)
test_eq(model(xb).shape, (bs, c_out))
model = TSSequencerPlus(nvars, c_out, seq_len, lstm_dropout=.1, dropout=.1, use_token=False)
test_eq(model(xb).shape, (bs, c_out))

bs = 16
nvars = 4
seq_len = 50
c_out = 2
xb = torch.rand(bs, nvars, seq_len)
bias_init = np.array([0.8, .2])
model = TSSequencerPlus(nvars, c_out, seq_len, bias_init=bias_init)
test_eq(model(xb).shape, (bs, c_out))
test_eq(model.head[1].bias.data, tensor(bias_init))

bs = 16
nvars = 4
seq_len = 50
c_out = 1
xb = torch.rand(bs, nvars, seq_len)
bias_init = 8.5
model = TSSequencerPlus(nvars, c_out, seq_len, bias_init=bias_init)
test_eq(model(xb).shape, (bs, c_out))
test_eq(model.head[1].bias.data, tensor([bias_init]))

bs = 16
nvars = 4
seq_len = 50
c_out = 2
xb = torch.rand(bs, nvars, seq_len)
bias_init = np.array([0.8, .2])
model = TSSequencerPlus(nvars, c_out, seq_len, bias_init=bias_init)
test_eq(model(xb).shape, (bs, c_out))
test_eq(model.head[1].bias.data, tensor(bias_init))

"""
## Feature extractor

It's a known fact that transformers cannot be directly applied to long sequences. To avoid this, we have included a way to subsample the sequence to generate a more manageable input.
"""

from tsai.data.validation import get_splits
from tsai.data.core import get_ts_dls

X = np.zeros((10, 3, 5000))
y = np.random.randint(0,2,X.shape[0])
splits = get_splits(y)
dls = get_ts_dls(X, y, splits=splits)
xb, yb = dls.train.one_batch()
xb
# Output:
#   <Figure size 1600x50 with 1 Axes>
#   TSTensor(samples:8, vars:3, len:5000, device=mps:0, dtype=torch.float32)

"""
If you try to use SequencerPlus, it's likely you'll get an 'out-of-memory' error.

To avoid this you can subsample the sequence reducing the input's length. This can be done in multiple ways. Here are a few examples: 
"""

# Separable convolution (to avoid mixing channels)
feature_extractor = Conv1d(xb.shape[1], xb.shape[1], ks=100, stride=50, padding=0, groups=xb.shape[1]).to(default_device())
feature_extractor.to(xb.device)(xb).shape
# Output:
#   torch.Size([8, 3, 99])

# Convolution (if you want to mix channels or change number of channels)
feature_extractor=MultiConv1d(xb.shape[1], 64, kss=[1,3,5,7,9], keep_original=True).to(default_device())
test_eq(feature_extractor.to(xb.device)(xb).shape, (xb.shape[0], 64, xb.shape[-1]))

# MaxPool
feature_extractor = nn.Sequential(Pad1d((0, 50), 0), nn.MaxPool1d(kernel_size=100, stride=50)).to(default_device())
feature_extractor.to(xb.device)(xb).shape
# Output:
#   torch.Size([8, 3, 100])

# AvgPool
feature_extractor = nn.Sequential(Pad1d((0, 50), 0), nn.AvgPool1d(kernel_size=100, stride=50)).to(default_device())
feature_extractor.to(xb.device)(xb).shape
# Output:
#   torch.Size([8, 3, 100])

"""
Once you decide what type of transform you want to apply, you just need to pass the layer as the feature_extractor attribute:
"""

bs = 16
nvars = 4
seq_len = 1000
c_out = 2
d_model = 128

xb = torch.rand(bs, nvars, seq_len)
feature_extractor = partial(Conv1d, ks=5, stride=3, padding=0, groups=xb.shape[1])
model = TSSequencerPlus(nvars, c_out, seq_len, d_model=d_model, feature_extractor=feature_extractor)
test_eq(model.to(xb.device)(xb).shape, (bs, c_out))

"""
## Categorical variables
"""

from tsai.utils import alphabet, ALPHABET

a = alphabet[np.random.randint(0,3,40)]
b = ALPHABET[np.random.randint(6,10,40)]
c = np.random.rand(40).reshape(4,1,10)
map_a = {k:v for v,k in enumerate(np.unique(a))}
map_b = {k:v for v,k in enumerate(np.unique(b))}
n_cat_embeds = [len(m.keys()) for m in [map_a, map_b]]
szs = [emb_sz_rule(n) for n in n_cat_embeds]
a = np.asarray(a.map(map_a)).reshape(4,1,10)
b = np.asarray(b.map(map_b)).reshape(4,1,10)
inp = torch.from_numpy(np.concatenate((c,a,b), 1)).float()
feature_extractor = partial(Conv1d, ks=3, padding='same')
model = TSSequencerPlus(3, 2, 10, d_model=64, cat_pos=[1,2], feature_extractor=feature_extractor)
test_eq(model(inp).shape, (4,2))

"""
## Sequence Embedding
"""

"""
Sometimes you have a samples with a very long sequence length. In those cases you may want to reduce it's length before passing it to the transformer. To do that you may just pass a token_size like in this example:
"""

t = torch.rand(8, 2, 10080)
SeqTokenizer(2, 128, 60)(t).shape
# Output:
#   torch.Size([8, 128, 168])

t = torch.rand(8, 2, 10080)
model = TSSequencerPlus(2, 5, 10080, d_model=64, token_size=60)
model(t).shape
# Output:
#   torch.Size([8, 5])

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/069_models.TSSequencerPlus.ipynb saved at 2025-03-01 15:24:12

#   Correct notebook to script conversion! 😃

#   Saturday 01/03/25 15:24:15 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/070_models.MultiInputNet.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.MultiInputNet

"""
# MultiInputNet
"""

"""
This is an implementation created by Ignacio Oguiza (oguiza@timeseriesAI.co).

It can be used to combine different types of deep learning models into a single one that will accept multiple inputs from a MixedDataLoaders.
"""

#|export
from tsai.imports import *
from tsai.models.layers import *
from tsai.models.utils import *

#|export
class MultiInputNet(Module):
    
    def __init__(self, *models, c_out=None, reshape_fn=None, multi_output=False, custom_head=None, device=None, **kwargs):
        r"""
        Args:
            models       : list of models (one model per dataloader in dls). They all must have a head.
            c_out        : output layer size.
            reshape_fn   : callable to transform a 3d input into a 2d input (Noop, Reshape(-1), GAP1d())
            multi_output : determines if the model creates M+1 output (one per model plus a combined one), or just a single output (combined one).
            custom_head  : allows you to pass a custom joint head. If None a MLP will be created (you can pass 'layers' to this default head using kwargs)
            device       : cpu or cuda. If None, default_device() will be chosen.
            kwargs       : head kwargs
        """

        c_out = ifnone(c_out, get_layers(models[0], cond=is_linear)[-1].out_features)
        self.M = len(models)
        self.m = []
        self.backbones = nn.ModuleList()
        self.heads = nn.ModuleList()
        head_nf = 0
        min_nf = np.inf
        for i, model in enumerate(models):
            try: # if subscriptable
                self.heads.append(model[1])
                self.backbones.append(model[0])
            except:
                self.heads.append(model.head)
                model.head = Identity()
                self.backbones.append(model)
            self.m.append(Sequential(self.backbones[-1], self.heads[-1]))
            head_nf += model.head_nf
            min_nf = min(min_nf, model.head_nf)

        self.head_nf = head_nf
        if custom_head is None: head = create_fc_head(head_nf, c_out, 1, **kwargs)
        else: head = custom_head(self.head_nf, c_out, **kwargs)
        self.heads.append(head)
        self.multi_output = multi_output
        self.m.append(self)
        self.reshape = ifnone(reshape_fn, GAP1d())
        self.concat = Concat(dim=1)
        device = ifnone(device, default_device())
        self.to(device=device)

    def forward(self, xs):
        xs = tuple(*xs) if len(xs) == 1 else xs
        out = []
        for k in range(self.M):
            x = xs[k]
            # Create separate features
            feat = self.backbones[k](*x) if isinstance(x, (list, tuple, L)) else self.backbones[k](x)

            # Process features separately
            if self.training and self.multi_output: out.append(self.heads[k](feat))
            
            # Concat features
            if feat.ndim == 3: feat = self.reshape(feat)
            concat_feats = feat if k==0 else self.concat([concat_feats, feat])
            
        # Process joint features
        out.append(self.heads[-1](concat_feats))
        if self.training and self.multi_output: return out
        else:  return out[0]

from tsai.basics import *
from tsai.data.all import *
from tsai.models.utils import *
from tsai.models.InceptionTimePlus import *
from tsai.models.TabModel import *

#|extras
dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, split_data=False)
ts_features_df = get_ts_features(X, y)
# Output:
#   Feature Extraction: 100%|███████████████████████████████████████████| 40/40 [00:07<00:00,  5.23it/s]


#|extras
# raw ts
tfms  = [None, [TSCategorize()]]
batch_tfms = TSStandardize()
ts_dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
ts_model = build_ts_model(InceptionTimePlus, dls=ts_dls)

# ts features
cat_names = None
cont_names = ts_features_df.columns[:-2]
y_names = 'target'
tab_dls = get_tabular_dls(ts_features_df, cat_names=cat_names, cont_names=cont_names, y_names=y_names, splits=splits)
tab_model = build_tabular_model(TabModel, dls=tab_dls)

# mixed
mixed_dls = get_mixed_dls(ts_dls, tab_dls)
MultiModalNet = MultiInputNet(ts_model, tab_model)
learn = Learner(mixed_dls, MultiModalNet, metrics=[accuracy, RocAuc()])
learn.fit_one_cycle(1, 1e-3)
# Output:
#   <IPython.core.display.HTML object>

#|extras
(ts, (cat, cont)),yb = mixed_dls.one_batch()
learn.model((ts, (cat, cont))).shape
# Output:
#   torch.Size([64, 6])

#|extras
tab_dls.c, ts_dls.c, ts_dls.cat
# Output:
#   (6, 6, True)

#|extras
learn.loss_func
# Output:
#   FlattenedLoss of CrossEntropyLoss()

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/130_models.MultiInputNet.ipynb saved at 2022-11-09 13:16:50

#   Correct notebook to script conversion! 😃

#   Wednesday 09/11/22 13:16:53 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/073_wandb.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp wandb

"""
# Weights & Biases Sweeps
"""

"""
>Weights & Biases Sweeps are used to automate hyperparameter optimization and explore the space of possible models.
"""

#|export
import warnings

from fastcore.script import *

from tsai.export import *
from tsai.imports import *
from tsai.utils import *

#|export
def wandb_agent(script_path, sweep, entity=None, project=None, count=None, run=True):
    "Run `wandb agent` with `sweep` and `script_path"
    try: import wandb
    except ImportError: raise ImportError('You need to install wandb to run sweeps!')
    if 'program' not in sweep.keys(): sweep["program"] = script_path
    sweep_id = wandb.sweep(sweep, entity=entity, project=project)
    entity = ifnone(entity, os.environ['WANDB_ENTITY'])
    project = ifnone(project, os.environ['WANDB_PROJECT'])
    print(f"\nwandb agent {entity}/{project}/{sweep_id}\n")
    if run: wandb.agent(sweep_id, function=None, count=count)

get_wandb_agent = named_partial("get_wandb_agent", wandb_agent, run=False)

run_wandb_agent = named_partial("run_wandb_agent", wandb_agent, run=True)

#|export
def update_run_config(config, new_config, verbose=False):
    "Update `config` with `new_config`"
    config_dict = config.copy()
    if hasattr(config_dict, "sweep"):
        del config_dict["sweep"]
    for k, v in new_config.items():
        if k in config_dict.keys():
            if verbose:
                print(f"config.{k} {config_dict[k]} updated to {new_config[k]}")
            config_dict[k] = new_config[k]
        elif (
            hasattr(config_dict, "arch_config")
            and k in config_dict["arch_config"].keys()
        ):
            if verbose:
                print(
                    f"config.arch_config.{k} {config['arch_config'][k]} updated to {new_config[k]}"
                )
            config["arch_config"][k] = new_config[k]
        else:
            warnings.warn(f"{k} not available in config or config.arch_config")
    return config_dict

#|export
def get_sweep_config(config):
    "Get sweep config from `config`"
    if not hasattr(config, "sweep") or not config["sweep"]: 
        return {}
    if isinstance(config["sweep"], str):
        file_path = Path(config["sweep"])
        file_path = to_root_path(file_path)
        sweep = yaml2dict(file_path, attrdict=False)
    else:
        sweep = attrdict2dict(config["sweep"])
    if hasattr(sweep, "sweep"):
        sweep = sweep["sweep"]
    return sweep

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/073_wandb.ipynb saved at 2023-03-07 19:53:26

#   Correct notebook to script conversion! 😃

#   Tuesday 07/03/23 19:53:29 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/078_models.TransformerRNNPlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.TransformerRNNPlus

"""
# TransformerRNNPlus
"""

"""
These is a Pytorch implementation of a Transformer + RNN created by Ignacio Oguiza - oguiza@timeseriesAI.co inspired by the code created by Baurzhan Urazalinov (https://www.kaggle.com/baurzhanurazalinov).

Baurzhan Urazalinov won a Kaggle competition (Parkinson's Freezing of Gait Prediction: Event detection from wearable sensor data - 2023) using the following original tensorflow code:

* https://www.kaggle.com/code/baurzhanurazalinov/parkinson-s-freezing-defog-training-code
* https://www.kaggle.com/code/baurzhanurazalinov/parkinson-s-freezing-tdcsfog-training-code
* https://www.kaggle.com/code/baurzhanurazalinov/parkinson-s-freezing-submission-code

I'd like to congratulate Baurzhan for winning this competition, and for sharing the code he used.
"""

#|export
import torch
from torch import nn
from torch.nn import TransformerEncoder, TransformerEncoderLayer
from collections import OrderedDict
from tsai.models.layers import lin_nd_head

from tsai.models.utils import count_parameters

t = torch.rand(4, 864, 54)
encoder_layer = torch.nn.TransformerEncoderLayer(54, 6, dim_feedforward=2048, dropout=0.1, 
                                                 activation="relu", layer_norm_eps=1e-05, 
                                                 batch_first=True, norm_first=False)
print(encoder_layer(t).shape)
print(count_parameters(encoder_layer))
# Output:
#   torch.Size([4, 864, 54])

#   235382


#|export
class _TransformerRNNEncoder(nn.Module):
    def __init__(self, 
        cell:nn.Module, # A RNN cell instance.
        c_in:int, # Number of channels in the input tensor.
        seq_len:int, # Number of time steps in the input tensor.
        d_model:int, # The number of expected features in the input.
        nhead:int, # Number of parallel attention heads (d_model will be split across nhead - each head will have dimension d_model // nhead).
        proj_dropout:float=0.1, # Dropout probability after the projection linear layer. Default: 0.1.
        num_encoder_layers:int=1, # Number of transformer layers in the encoder. Default: 1.
        dim_feedforward:int=2048, # The dimension of the feedforward network model. Default: 2048.
        dropout:float=0.1, # Transformer encoder layers dropout. Default: 0.1.
        num_rnn_layers:int=1, # Number of RNN layers in the encoder. Default: 1.
        bidirectional:bool=True, # If True, becomes a bidirectional RNN. Default: True.
        ):
        super().__init__()

        # projection layer
        self.proj_linear = nn.Linear(c_in, d_model)
        self.proj_dropout = nn.Dropout(proj_dropout)

        # transformer encoder layers
        self.num_encoder_layers = num_encoder_layers
        dim_feedforward = dim_feedforward or d_model
        self.enc_layers = nn.ModuleList([TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True, ) for _ in range(num_encoder_layers)])

        # rnn layers
        self.num_rnn_layers = num_rnn_layers
        self.rnn_layers = nn.ModuleList([cell(d_model * (1 + bidirectional) ** i, d_model * (1 + bidirectional) ** i, bidirectional=bidirectional) for i in range(num_rnn_layers)])
        self.seq_len = seq_len
        self.pos_encoding = nn.Parameter(torch.randn(1, self.seq_len, d_model) * 0.02)

    def forward(self, x): # (batch_size, c_in, seq_len), Example shape (4, 54, 864) 
        
        x = x.swapaxes(1, 2) # (batch_size, seq_len, c_in), Example shape (4, 864, 54)
        batch_size = x.shape[0]

        # projection layer
        x = self.proj_linear(x) # (batch_size, seq_len, d_model), Example shape (4, 864, 320)
        x = x + self.pos_encoding.repeat(batch_size, 1, 1)
        x = self.proj_dropout(x)

        # transformer encoder layers
        for i in range(self.num_encoder_layers): 
            x = self.enc_layers[i](x.transpose(0, 1)).transpose(0, 1) # (batch_size, seq_len, d_model), Example shape (4, 864, 320)
        
        # rnn layers
        for i in range(self.num_rnn_layers): 
            x, _ = self.rnn_layers[i](x) # (batch_size, seq_len, CFG['fog_model_dim']*2), Example shape (4, 864, 640)
        
        x = x.swapaxes(1, 2)
        return x

bs = 4
c_in = 5
seq_len = 50

encoder = _TransformerRNNEncoder(nn.LSTM, c_in=c_in, seq_len=seq_len, d_model=128, nhead=4, num_encoder_layers=1, dim_feedforward=None, proj_dropout=0.1, dropout=0.1, num_rnn_layers=3, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
print(encoder(t).shape)
# Output:
#   torch.Size([4, 1024, 50])


#|export
class _TransformerRNNPlus(nn.Sequential):
    def __init__(self, 
        c_in:int, # Number of channels in the input tensor.
        c_out:int, # Number of output channels.
        seq_len:int, # Number of time steps in the input tensor.
        d:tuple=None, # int or tuple with shape of the output tensor
        d_model:int=128, # Total dimension of the model.
        nhead:int=16, # Number of parallel attention heads (d_model will be split across nhead - each head will have dimension d_model // nhead).
        proj_dropout:float=0.1, # Dropout probability after the first linear layer. Default: 0.1.
        num_encoder_layers:int=1, # Number of transformer encoder layers. Default: 1.
        dim_feedforward:int=2048, # The dimension of the feedforward network model. Default: 2048.
        dropout:float=0.1, # Transformer encoder layers dropout. Default: 0.1.
        num_rnn_layers:int=1, # Number of RNN layers in the encoder. Default: 1.
        bidirectional:bool=True, # If True, becomes a bidirectional RNN. Default: True.
        custom_head=None, # Custom head that will be applied to the model. If None, a head with `c_out` outputs will be used. Default: None.
        **kwargs
        ):

        backbone = _TransformerRNNEncoder(cell=self._cell, c_in=c_in, seq_len=seq_len, proj_dropout=proj_dropout, 
                                          d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers, dim_feedforward=dim_feedforward, dropout=dropout, 
                                          num_rnn_layers=num_rnn_layers, bidirectional=bidirectional)
        self.head_nf = d_model * ((1 + bidirectional) ** (num_rnn_layers))
        if custom_head:
            if isinstance(custom_head, nn.Module): head = custom_head
            else: head = custom_head(self.head_nf, c_out, seq_len, d=d, **kwargs)
        else:
            head = lin_nd_head(self.head_nf, c_out, seq_len=seq_len, d=d)
        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))

class TransformerRNNPlus(_TransformerRNNPlus):
    _cell = nn.RNN

class TransformerLSTMPlus(_TransformerRNNPlus):
    _cell = nn.LSTM

class TransformerGRUPlus(_TransformerRNNPlus):
    _cell = nn.GRU

bs = 4
c_in = 5
c_out = 1
seq_len = 50
d = None

model = TransformerRNNPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == torch.Size([4]) 
print(model(t).shape)

model = TransformerLSTMPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == torch.Size([4])
print(model(t).shape)

model = TransformerGRUPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == torch.Size([4])
print(model(t).shape)
# Output:
#   torch.Size([4])

#   torch.Size([4])

#   torch.Size([4])


bs = 4
c_in = 5
c_out = 3
seq_len = 50
d = None

model = TransformerRNNPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, c_out)
print(model(t).shape)

model = TransformerLSTMPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, c_out)
print(model(t).shape)

model = TransformerGRUPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, c_out)
print(model(t).shape)
# Output:
#   torch.Size([4, 3])

#   torch.Size([4, 3])

#   torch.Size([4, 3])


bs = 4
c_in = 5
c_out = 3
seq_len = 50
d = 50

model = TransformerRNNPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, d, c_out)
print(model(t).shape)

model = TransformerLSTMPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, d, c_out)
print(model(t).shape)

model = TransformerGRUPlus(c_in=c_in, c_out=c_out, seq_len=seq_len, d=d, proj_dropout=0.1, d_model=128, nhead=4, num_encoder_layers=2, dropout=0.1, num_rnn_layers=1, bidirectional=True)
t = torch.randn(bs, c_in, seq_len)
assert model(t).shape == (bs, d, c_out)
print(model(t).shape)
# Output:
#   torch.Size([4, 50, 3])

#   torch.Size([4, 50, 3])

#   torch.Size([4, 50, 3])


"""
## Export -
"""

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/078_models.TransformerRNNPlus.ipynb couldn't be saved automatically. You should save it manually 👋

#   Correct notebook to script conversion! 😃

#   Saturday 17/06/23 12:20:57 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/079_models.HydraPlus.ipynb
================================================
# Jupyter notebook converted to Python script.

#|default_exp models.HydraPlus

"""
# HydraPlus
"""

"""
>Hydra: competing convolutional kernels for fast and accurate time series classification.

This is a Pytorch implementation of Hydra adapted by Ignacio Oguiza and based on:

Dempster, A., Schmidt, D. F., & Webb, G. I. (2023). Hydra: Competing convolutional kernels for fast and accurate time series classification. Data Mining and Knowledge Discovery, 1-27.

Original paper: https://link.springer.com/article/10.1007/s10618-023-00939-3

Original repository:  https://github.com/angus924/hydra
"""

#| export
from collections import OrderedDict
from typing import Any

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from tsai.imports import default_device
from tsai.models.layers import Flatten, rocket_nd_head

#| export
class HydraBackbonePlus(nn.Module):

    def __init__(self, c_in, c_out, seq_len, k = 8, g = 64, max_c_in = 8, clip=True, device=default_device(), zero_init=True):

        super().__init__()

        self.k = k # num kernels per group
        self.g = g # num groups

        max_exponent = np.log2((seq_len - 1) / (9 - 1)) # kernel length = 9

        self.dilations = 2 ** torch.arange(int(max_exponent) + 1, device=device)
        self.num_dilations = len(self.dilations)

        self.paddings = torch.div((9 - 1) * self.dilations, 2, rounding_mode = "floor").int()

        # if g > 1, assign: half the groups to X, half the groups to diff(X)
        divisor = 2 if self.g > 1 else 1
        _g = g // divisor
        self._g = _g
        self.W = [self.normalize(torch.randn(divisor, k * _g, 1, 9)).to(device=device) for _ in range(self.num_dilations)]


        # combine c_in // 2 channels (2 < n < max_c_in)
        c_in_per = np.clip(c_in // 2, 2, max_c_in)
        self.I = [torch.randint(0, c_in, (divisor, _g, c_in_per), device=device) for _ in range(self.num_dilations)]

        # clip values
        self.clip = clip

        self.device = device
        self.num_features = min(2, self.g) * self._g * self.k * self.num_dilations * 2

    @staticmethod
    def normalize(W):
        W -= W.mean(-1, keepdims = True)
        W /= W.abs().sum(-1, keepdims = True)
        return W

    # transform in batches of *batch_size*
    def batch(self, X, split=None, batch_size=256):
        bs = X.shape[0]
        if bs <= batch_size:
            return self(X)
        elif split is None:
            Z = []
            for i in range(0, bs, batch_size):
                Z.append(self(X[i:i+batch_size]))
            return torch.cat(Z)
        else:
            Z = []
            batches = torch.as_tensor(split).split(batch_size)
            for i, batch in enumerate(batches):
                Z.append(self(X[batch]))
            return torch.cat(Z)

    def forward(self, X):

        bs = X.shape[0]

        if self.g > 1:
            diff_X = torch.diff(X)

        Z = []

        for dilation_index in range(self.num_dilations):

            d = self.dilations[dilation_index].item()
            p = self.paddings[dilation_index].item()

            # diff_index == 0 -> X
            # diff_index == 1 -> diff(X)
            for diff_index in range(min(2, self.g)):
                _Z = F.conv1d(X[:, self.I[dilation_index][diff_index]].sum(2) if diff_index == 0 else diff_X[:, self.I[dilation_index][diff_index]].sum(2),
                              self.W[dilation_index][diff_index], dilation = d, padding = p, groups = self._g).view(bs, self._g, self.k, -1)

                max_values, max_indices = _Z.max(2)
                count_max = torch.zeros(bs, self._g, self.k, device=self.device)

                min_values, min_indices = _Z.min(2)
                count_min = torch.zeros(bs, self._g, self.k, device=self.device)

                count_max.scatter_add_(-1, max_indices, max_values)
                count_min.scatter_add_(-1, min_indices, torch.ones_like(min_values))

                Z.append(count_max)
                Z.append(count_min)

        Z = torch.cat(Z, 1).view(bs, -1)

        if self.clip:
            Z = F.relu(Z)

        return Z

#| export
class HydraPlus(nn.Sequential):

    def __init__(self,
        c_in:int, # num of channels in input
        c_out:int, # num of channels in output
        seq_len:int, # sequence length
        d:tuple=None, # shape of the output (when ndim > 1)
        k:int=8, # number of kernels per group
        g:int=64, # number of groups
        max_c_in:int=8, # max number of channels per group
        clip:bool=True, # clip values >= 0
        use_bn:bool=True, # use batch norm
        fc_dropout:float=0., # dropout probability
        custom_head:Any=None, # optional custom head as a torch.nn.Module or Callable
        zero_init:bool=True, # set head weights and biases to zero
        use_diff:bool=True, # use diff(X) as input
        device:str=default_device(), # device to use
        ):

        # Backbone
        backbone = HydraBackbonePlus(c_in, c_out, seq_len, k=k, g=g, max_c_in=max_c_in, clip=clip, device=device, zero_init=zero_init)
        num_features = backbone.num_features


        # Head
        self.head_nf = num_features
        if custom_head is not None:
            if isinstance(custom_head, nn.Module): head = custom_head
            else: head = custom_head(self.head_nf, c_out, 1)
        elif d is not None:
            head = rocket_nd_head(num_features, c_out, seq_len=None, d=d, use_bn=use_bn, fc_dropout=fc_dropout, zero_init=zero_init)
        else:
            layers = [Flatten()]
            if use_bn:
                layers += [nn.BatchNorm1d(num_features)]
            if fc_dropout:
                layers += [nn.Dropout(fc_dropout)]
            linear = nn.Linear(num_features, c_out)
            if zero_init:
                nn.init.constant_(linear.weight.data, 0)
                nn.init.constant_(linear.bias.data, 0)
            layers += [linear]
            head = nn.Sequential(*layers)

        super().__init__(OrderedDict([('backbone', backbone), ('head', head)]))

Hydra = HydraPlus

xb = torch.randn(16, 5, 20).to(default_device())
yb = torch.randint(0, 3, (16, 20)).to(default_device())

model = HydraPlus(5, 3, 20, d=None).to(default_device())
output = model(xb)
assert output.shape == (16, 3)
output.shape
# Output:
#   torch.Size([16, 3])

xb = torch.randn(16, 5, 20).to(default_device())
yb = torch.randint(0, 3, (16, 20)).to(default_device())

model = HydraPlus(5, 3, 20, d=None, use_diff=False).to(default_device())
output = model(xb)
assert output.shape == (16, 3)
output.shape
# Output:
#   torch.Size([16, 3])

xb = torch.randn(16, 5, 20).to(default_device())
yb = torch.randint(0, 3, (16, 5, 20)).to(default_device())

model = HydraPlus(5, 3, 20, d=20, use_diff=True).to(default_device())
output = model(xb)
assert output.shape == (16, 20, 3)
output.shape
# Output:
#   torch.Size([16, 20, 3])

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/079_models.HydraPlus.ipynb saved at 2024-02-10 22:16:56

#   Correct notebook to script conversion! 😃

#   Saturday 10/02/24 22:16:59 CET

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/_quarto.yml
================================================
project:
  type: website

format:
  html:
    theme: cosmo
    css: styles.css
    toc: true
    toc-depth: 4

website:
  reader-mode: true
  twitter-card: true
  open-graph: true
  repo-actions: [issue]
  navbar:
    background: primary
    search: true
    right:
      - icon: github
        href: "https://github.com/timeseriesAI/tsai"
  sidebar:
    style: floating

metadata-files: [nbdev.yml, sidebar.yml]


================================================
FILE: nbs/index.ipynb
================================================
# Jupyter notebook converted to Python script.

#|eval: false
#|hide
from tsai.all import *

"""
<div align="center">
<img src="https://github.com/timeseriesAI/tsai/blob/main/nbs/multimedia/tsai_logo.svg?raw=true" width="50%">
</div>
<br /> <br />
"""

"""
# tsai
"""

"""
![CI](https://github.com/timeseriesai/tsai/workflows/CI/badge.svg) 
[![PyPI](https://img.shields.io/pypi/v/tsai?color=blue&label=pypi%20version)](https://pypi.org/project/tsai/#description) 
[![Conda (channel only)](https://img.shields.io/conda/vn/timeseriesai/tsai?color=brightgreen&label=conda%20version)](https://anaconda.org/timeseriesai/tsai)
[![DOI](https://zenodo.org/badge/211822289.svg)](https://zenodo.org/badge/latestdoi/211822289) 
![PRs](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)
"""

"""
## Description
> State-of-the-art Deep Learning library for Time Series and Sequences. 

`tsai` is an open-source deep learning package built on top of Pytorch & fastai focused on state-of-the-art techniques for time series tasks like classification, regression, forecasting, imputation...

`tsai` is currently under active development by timeseriesAI.
"""

"""
## What's new:

During the last few releases, here are some of the most significant additions to `tsai`:

* **New models**: PatchTST (Accepted by ICLR 2023), RNN with Attention (RNNAttention, LSTMAttention, GRUAttention), TabFusionTransformer, ...
* **New datasets**: we have increased the number of datasets you can download using `tsai`:
    - 128 univariate classification datasets
    - 30 multivariate classification datasets
    - 15 regression datasets
    - 62 forecasting datasets
    - 9 long term forecasting datasets
* **New tutorials**: [PatchTST](https://github.com/timeseriesAI/tsai/blob/main/tutorial_nbs/15_PatchTST_a_new_transformer_for_LTSF.ipynb). Based on some of your requests, we are planning to release additional tutorials on data preparation and forecasting.
* **New functionality**: sklearn-type pipeline transforms, walk-foward cross validation, reduced RAM requirements, and a lot of new functionality to perform more accurate time series forecasts.
* Pytorch 2.0 support.

"""

"""
## Installation
"""

"""
### Pip install

You can install the **latest stable** version from pip using:
```python
pip install tsai
```

If you plan to develop tsai yourself, or want to be on the cutting edge, you can use an editable install. First install PyTorch, and then:

```python
git clone https://github.com/timeseriesAI/tsai
pip install -e "tsai[dev]"
```

Note: starting with tsai 0.3.0 tsai will only install hard dependencies. Other soft dependencies (which are only required for selected tasks) will not be installed by default (this is the recommended approach. If you require any of the dependencies that is not installed, tsai will ask you to install it when necessary). If you still want to install tsai with all its dependencies you can do it by running:
```python
pip install tsai[extras]
```

### Conda install

You can also install tsai using conda (note that if you replace conda with mamba the install process will be much faster and more reliable):

```python
conda install -c timeseriesai tsai
```
"""

"""
## Documentation
"""

"""
Here's the link to the [documentation](https://timeseriesai.github.io/tsai/).
"""

"""
## Available models:
"""

"""
Here's a list with some of the state-of-the-art models available in `tsai`:

- [LSTM](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/RNN.py) (Hochreiter, 1997) ([paper](https://ieeexplore.ieee.org/abstract/document/6795963/))
- [GRU](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/RNN.py) (Cho, 2014) ([paper](https://arxiv.org/abs/1412.3555))
- [MLP](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/MLP.py) - Multilayer Perceptron (Wang, 2016) ([paper](https://arxiv.org/abs/1611.06455))
- [FCN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/FCN.py) - Fully Convolutional Network (Wang, 2016) ([paper](https://arxiv.org/abs/1611.06455))
- [ResNet](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/ResNet.py) - Residual Network (Wang, 2016) ([paper](https://arxiv.org/abs/1611.06455))
- [LSTM-FCN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/RNN_FCN.py) (Karim, 2017) ([paper](https://arxiv.org/abs/1709.05206))
- [GRU-FCN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/RNN_FCN.py) (Elsayed, 2018) ([paper](https://arxiv.org/abs/1812.07683))
- [mWDN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/mWDN.py) - Multilevel wavelet decomposition network (Wang, 2018) ([paper](https://dl.acm.org/doi/abs/10.1145/3219819.3220060))
- [TCN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TCN.py) - Temporal Convolutional Network (Bai, 2018) ([paper](https://arxiv.org/abs/1803.01271))
- [MLSTM-FCN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/RNN_FCN.py) - Multivariate LSTM-FCN (Karim, 2019) ([paper](https://www.sciencedirect.com/science/article/abs/pii/S0893608019301200))
- [InceptionTime](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/InceptionTime.py) (Fawaz, 2019) ([paper](https://arxiv.org/abs/1909.04939))
- [Rocket](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/ROCKET.py) (Dempster, 2019) ([paper](https://arxiv.org/abs/1910.13051))
- [XceptionTime](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/XceptionTime.py) (Rahimian, 2019) ([paper](https://arxiv.org/abs/1911.03803))
- [ResCNN](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/ResCNN.py) - 1D-ResCNN (Zou , 2019) ([paper](https://www.sciencedirect.com/science/article/pii/S0925231219311506))
- [TabModel](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TabModel.py) - modified from fastai's [TabularModel](https://docs.fast.ai/tabular.model.html#TabularModel)
- [OmniScale](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/OmniScaleCNN.py) - Omni-Scale 1D-CNN (Tang, 2020) ([paper](https://arxiv.org/abs/2002.10061))
- [TST](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TST.py) - Time Series Transformer (Zerveas, 2020) ([paper](https://dl.acm.org/doi/abs/10.1145/3447548.3467401))
- [TabTransformer](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TabTransformer.py) (Huang, 2020) ([paper](https://arxiv.org/pdf/2012.06678))
- [TSiT](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TSiTPlus.py) Adapted from ViT (Dosovitskiy, 2020) ([paper](https://arxiv.org/abs/2010.11929))
- [MiniRocket](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/MINIROCKET.py) (Dempster, 2021) ([paper](https://arxiv.org/abs/2102.00457))
- [XCM](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/XCM.py) - An Explainable Convolutional Neural Network (Fauvel, 2021) ([paper](https://hal.inria.fr/hal-03469487/document))
- [gMLP](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/gMLP.py) - Gated Multilayer Perceptron (Liu, 2021) ([paper](https://arxiv.org/abs/2105.08050))
- [TSPerceiver](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TSPerceiver.py) - Adapted from Perceiver IO (Jaegle, 2021) ([paper](https://arxiv.org/abs/2107.14795))
- [GatedTabTransformer](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/GatedTabTransformer.py) (Cholakov, 2022) ([paper](https://arxiv.org/abs/2201.00199))
- [TSSequencerPlus](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/TSSequencerPlus.py) - Adapted from Sequencer (Tatsunami, 2022) ([paper](https://arxiv.org/abs/2205.01972))
- [PatchTST](https://github.com/timeseriesAI/tsai/blob/main/tsai/models/PatchTST.py) - (Nie, 2022) ([paper](https://arxiv.org/abs/2211.14730))

plus other custom models like: TransformerModel, LSTMAttention, GRUAttention, ...
"""

"""
## How to start using tsai?
"""

"""
To get to know the tsai package, we'd suggest you start with this notebook in Google Colab: **[01_Intro_to_Time_Series_Classification](https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/01_Intro_to_Time_Series_Classification.ipynb)**
It provides an overview of a time series classification task.

We have also develop many other [tutorial notebooks](https://github.com/timeseriesAI/tsai/tree/main/tutorial_nbs). 

To use tsai in your own notebooks, the only thing you need to do after you have installed the package is to run this:
```python
from tsai.all import *
```
"""

"""
## Examples
"""

"""
These are just a few examples of how you can use `tsai`:
"""

"""
### Binary, univariate classification
"""

"""
**Training:**
```python
from tsai.basics import *

X, y, splits = get_classification_data('ECG200', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize()
clf = TSClassifier(X, y, splits=splits, path='models', arch="InceptionTimePlus", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())
clf.fit_one_cycle(100, 3e-4)
clf.export("clf.pkl") 
```

**Inference:** 

```python
from tsai.inference import load_learner

clf = load_learner("models/clf.pkl")
probas, target, preds = clf.get_X_preds(X[splits[1]], y[splits[1]])
```
"""

"""
### Multi-class, multivariate classification
"""

"""
**Training:**
```python
from tsai.basics import *

X, y, splits = get_classification_data('LSST', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
mv_clf = TSClassifier(X, y, splits=splits, path='models', arch="InceptionTimePlus", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())
mv_clf.fit_one_cycle(10, 1e-2)
mv_clf.export("mv_clf.pkl")
```

**Inference:** 

```python
from tsai.inference import load_learner

mv_clf = load_learner("models/mv_clf.pkl")
probas, target, preds = mv_clf.get_X_preds(X[splits[1]], y[splits[1]])
```
"""

"""
### Multivariate Regression
"""

"""
**Training:**
```python
from tsai.basics import *

X, y, splits = get_regression_data('AppliancesEnergy', split_data=False)
tfms = [None, TSRegression()]
batch_tfms = TSStandardize(by_sample=True)
reg = TSRegressor(X, y, splits=splits, path='models', arch="TSTPlus", tfms=tfms, batch_tfms=batch_tfms, metrics=rmse, cbs=ShowGraph(), verbose=True)
reg.fit_one_cycle(100, 3e-4)
reg.export("reg.pkl")
```

**Inference:**
```python
from tsai.inference import load_learner

reg = load_learner("models/reg.pkl")
raw_preds, target, preds = reg.get_X_preds(X[splits[1]], y[splits[1]])
```
"""

"""
The ROCKETs (RocketClassifier, RocketRegressor, MiniRocketClassifier, MiniRocketRegressor, MiniRocketVotingClassifier or MiniRocketVotingRegressor) are somewhat different models. They are not actually deep learning models (although they use convolutions) and are used in a different way.

⚠️ You'll also need to install sktime to be able to use them. You can install it separately:
```python
pip install sktime
```
or use:
```python
pip install tsai[extras]
```
"""

"""
**Training:**

```python
from sklearn.metrics import mean_squared_error, make_scorer
from tsai.data.external import get_Monash_regression_data
from tsai.models.MINIROCKET import MiniRocketRegressor

X_train, y_train, *_ = get_Monash_regression_data('AppliancesEnergy')
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
reg = MiniRocketRegressor(scoring=rmse_scorer)
reg.fit(X_train, y_train)
reg.save('MiniRocketRegressor')
```

**Inference:**

```python
from sklearn.metrics import mean_squared_error
from tsai.data.external import get_Monash_regression_data
from tsai.models.MINIROCKET import load_minirocket

*_, X_test, y_test = get_Monash_regression_data('AppliancesEnergy')
reg = load_minirocket('MiniRocketRegressor')
y_pred = reg.predict(X_test)
mean_squared_error(y_test, y_pred, squared=False)
```
"""

"""
### Forecasting
"""

"""
You can use tsai for forecast in the following scenarios: 

* univariate or multivariate time series input
* univariate or multivariate time series output
* single or multi-step ahead

You'll need to:
* prepare X (time series input) and the target y (see [documentation](https://timeseriesai.github.io/tsai/data.preparation.html))
* select PatchTST or one of tsai's models ending in Plus (TSTPlus, InceptionTimePlus, TSiTPlus, etc). The model will auto-configure a head to yield an output with the same shape as the target input y. 
"""

"""
#### Single step
"""

"""
**Training:**
```python
from tsai.basics import *

ts = get_forecasting_time_series("Sunspots").values
X, y = SlidingWindow(60, horizon=1)(ts)
splits = TimeSplitter(235)(y) 
tfms = [None, TSForecasting()]
batch_tfms = TSStandardize()
fcst = TSForecaster(X, y, splits=splits, path='models', tfms=tfms, batch_tfms=batch_tfms, bs=512, arch="TSTPlus", metrics=mae, cbs=ShowGraph())
fcst.fit_one_cycle(50, 1e-3)
fcst.export("fcst.pkl")
```

**Inference:**
```python
from tsai.inference import load_learner

fcst = load_learner("models/fcst.pkl", cpu=False)
raw_preds, target, preds = fcst.get_X_preds(X[splits[1]], y[splits[1]])
raw_preds.shape
# torch.Size([235, 1])
```
"""

"""
#### Multi-step
"""

"""
This example show how to build a 3-step ahead univariate forecast.
"""

"""
**Training:**
```python
from tsai.basics import *

ts = get_forecasting_time_series("Sunspots").values
X, y = SlidingWindow(60, horizon=3)(ts)
splits = TimeSplitter(235, fcst_horizon=3)(y) 
tfms = [None, TSForecasting()]
batch_tfms = TSStandardize()
fcst = TSForecaster(X, y, splits=splits, path='models', tfms=tfms, batch_tfms=batch_tfms, bs=512, arch="TSTPlus", metrics=mae, cbs=ShowGraph())
fcst.fit_one_cycle(50, 1e-3)
fcst.export("fcst.pkl")
```

**Inference:**
```python
from tsai.inference import load_learner
fcst = load_learner("models/fcst.pkl", cpu=False)
raw_preds, target, preds = fcst.get_X_preds(X[splits[1]], y[splits[1]])
raw_preds.shape
# torch.Size([235, 3])
```
"""

"""
## Input data format
"""

"""
The input format for all time series models and image models in tsai is the same. An np.ndarray (or array-like object like zarr, etc) with 3 dimensions:

**[# samples x # variables x sequence length]**

The input format for tabular models in tsai (like TabModel, TabTransformer and TabFusionTransformer) is a pandas dataframe. See [example](https://timeseriesai.github.io/tsai/models.TabModel.html).
"""

"""
## How to contribute to tsai?
"""

"""
We welcome contributions of all kinds. Development of enhancements, bug fixes, documentation, tutorial notebooks, ... 

We have created a guide to help you start contributing to tsai. You can read it [here](https://github.com/timeseriesAI/tsai/blob/main/CONTRIBUTING.md).
"""

"""
## Enterprise support and consulting services:
"""

"""
Want to make the most out of timeseriesAI/tsai in a professional setting? Let us help. Send us an email to learn more: info@timeseriesai.co 
"""

"""
## Citing tsai
"""

"""
If you use tsai in your research please use the following BibTeX entry:

```text
@Misc{tsai,
    author =       {Ignacio Oguiza},
    title =        {tsai - A state-of-the-art deep learning library for time series and sequential data},
    howpublished = {Github},
    year =         {2023},
    url =          {https://github.com/timeseriesAI/tsai}
}
```
"""

#|eval: false
#|hide
from tsai.export import get_nb_name; nb_name = get_nb_name(locals())
from tsai.imports import create_scripts; create_scripts(nb_name)
# Output:
#   <IPython.core.display.Javascript object>
#   /Users/nacho/notebooks/tsai/nbs/index.ipynb saved at 2023-10-23 11:12:34

#   Correct notebook to script conversion! 😃

#   Monday 23/10/23 11:12:37 CEST

#   <IPython.lib.display.Audio object>



================================================
FILE: nbs/nbdev.yml
================================================
project:
  output-dir: _docs

website:
  title: "tsai"
  site-url: "https://timeseriesAI.github.io/tsai/"
  description: "Practical Deep Learning for Time Series / Sequential Data library based on fastai & Pytorch"
  repo-branch: main
  repo-url: "https://github.com/timeseriesAI/tsai/"



================================================
FILE: nbs/renum.py
================================================
#!/usr/bin/env python
"Rename ipynb files starting at 01"

import re
import os
from pathlib import Path

dir_path = os.path.dirname(os.path.realpath(__file__))
os.chdir(dir_path)

i = 1
for p in sorted(list(Path().glob('*.ipynb'))):
    pre = re.findall(r'^(\d+)[a-z]?[A-Z]?_(.*)', str(p))
    if not pre:
        continue
    new = f'{i:03d}_{pre[0][1]}'
    print(p, new)
    os.rename(p, new)
    i+=1


================================================
FILE: nbs/styles.css
================================================
div.description {
  font-style: italic;
}

.cell-output pre {
    margin-left: 0.8rem;
    margin-top: 0;
    background: none;
    border-left: 2px solid lightsalmon;
    border-top-left-radius: 0;
    border-top-right-radius: 0;
  }

  .cell-output .sourceCode {
    background: none;
    margin-top: 0;
  }

  .cell > .sourceCode {
    margin-bottom: 0;
  }



================================================
FILE: nbs/data/TSCategoricalEncoder.joblib
================================================
[Non-text file]


================================================
FILE: nbs/data/TSDateTimeEncoder.joblib
================================================
[Non-text file]


================================================
FILE: nbs/data/TSMissingnessEncoder.joblib
================================================
[Non-text file]




================================================
FILE: tsai/__init__.py
================================================
__version__ = "0.4.1"


================================================
FILE: tsai/all.py
================================================
import tsai
from .imports import *
from .utils import *
from .data.all import *
from .losses import *
from .metrics import *
from .learner import *
from .inference import *
from .analysis import *
from .calibration import *
from .tslearner import *
from .optimizer import *
from .models.all import *
from .callback.all import *
from .optuna import *
from .wandb import *
from .export import *


================================================
FILE: tsai/index.py
================================================
# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/index.ipynb (unless otherwise specified).

__all__ = []


================================================
FILE: tsai/callback/__init__.py
================================================



================================================
FILE: tsai/callback/all.py
================================================
from .core import *
from .experimental import *
from .noisy_student import *
from .MVP import *
from .PredictionDynamics import *


================================================
FILE: tsai/data/__init__.py
================================================



================================================
FILE: tsai/models/__init__.py
================================================



================================================
FILE: tutorial_nbs/00_How_to_efficiently_work_with_very_large_numpy_arrays.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## How to efficiently work with (very large) Numpy Arrays? 👷‍♀️
"""

"""
Sometimes we need to work with some very large numpy arrays that don't fit in memory. I'd like to share with you a way that works well for me.
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os             : Darwin

#   os version     : 19.6.0

#   python         : 3.6.13

#   tsai           : 0.2.20

#   fastai         : 2.5.2

#   fastcore       : 1.3.26

#   numba          : 0.53.1

#   torch          : 1.9.0

#   n_cpus         : 8

#   device         : cpu


"""
## Introduction 🤝
"""

"""
I normally work with time series data. I made the decision to use numpy arrays to store my data since they can easily handle multiple dimensions, and are really very efficient.

But sometimes datasets are really big (many GBs) and don't fit in memory. So I started looking around and found something that works very well: [**np.memmap**](https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html). Conceptually they work as arrays on disk, and that's how I often call them.

np.memmap creates a map to numpy arrays you have previously saved on disk, so that you can efficiently access small segments of those (small or large) files on disk, without reading the entire file into memory. And that's exactly what we need with deep learning, be able to quickly create a batch in memory, without reading the entire file (that is stored on disk). 

The best analogy I've found are image files. You may have a very large dataset on disk (that far exceeds your RAM). In order to create your DL datasets, what you pass are the paths to each individual file, so that you can then load a few images and create a batch on demand.

You can view np.memmap as the path collection that can be used to load numpy data on demand when you need to create a batch.

So let's see how you can work with larger than RAM arrays on disk.
"""

"""
On my laptop I have only 8GB of RAM.
"""

"""
I will try to demonstrate how you can handle a 10 GB numpy array dataset in an efficient way. 
"""

"""
## Create and save a larger-than-memory array 🥴
"""

"""
I will now create a large numpy array that doesn't fit in memory. 
Since I don't have enough RAM, I'll create an empty array on disk, and then load data in chunks that fit in memory.

⚠️ If you want to to experiment with large datasets, you may uncomment and run this code. **It will create a ~10GB file on your disk** (we'll delete it at the end of this notebook).

In my laptop it took me around **2 mins to create the data.**
"""

# path = Path('./data')
# X = create_empty_array((100_000, 50, 512), fname='X_on_disk', path=path, mode='r+')

# chunksize = 10_000
# pbar = progress_bar(range(math.ceil(len(X) / chunksize)))
# start = 0
# for i in pbar:
#     end = start + chunksize
#     X[start:end] = np.random.rand(chunksize, X.shape[-2], X.shape[-1])
#     start = end

# # I will create a smaller array. Sinc this fits in memory, I don't need to use a memmap
# y_fn = path/'y_on_disk.npy'
# y = np.random.randint(0, 10, X.shape[0])
# labels = np.array(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])
# np.save(y_fn, labels[y])

# del X, y
# Output:
#   <IPython.core.display.HTML object>

"""
Ok. So let's check the size of these files if they were in memory.
"""

print(f'X array: {os.path.getsize("./data/X_on_disk.npy"):12} bytes ({bytes2str(os.path.getsize("./data/X_on_disk.npy"))})')
print(f'y array: {os.path.getsize("./data/y_on_disk.npy"):12} bytes ({bytes2str(os.path.getsize("./data/y_on_disk.npy"))})')

# Output:
#   X array:  10240000128 bytes (9.54 GB)

#   y array:       400128 bytes (0.00 GB)


"""
## Load an array on disk (np.memmap) 🧠
"""

"""
Remember I only have an 8 GB RAM on this laptop, so I couldn't load these datasets in memory.

☣️ Actually I accidentally loaded the "X_on_disk.npy" file, and my laptop crashed so I had to reboot it!

So let's now load data as arrays on disk (np.memmap). The way to do it is super simple, and very efficient. You just do it as you would with a normal array, but add an mmap_mode.

There are 4 modes: 

- ‘r’	Open existing file for reading only.
- ‘r+’	Open existing file for reading and writing.
- ‘w+’	Create or overwrite existing file for reading and writing.
- ‘c’	Copy-on-write: assignments affect data in memory, but changes are not saved to disk. The file on disk is read-only.

I normally use mode 'c' since I want to be able to make changes to data in memory (transforms for example), without affecting data on disk (same approach as with image data). This is the same thing you do with image files on disk, that are just read, and then modified in memory, without changing the file on disk.

But if you also want to be able to modify data on disk, you can load the array with mmap_mode='r+'.
"""

X_on_disk = np.load('./data/X_on_disk.npy', mmap_mode='c')
y_on_disk = np.load('./data/y_on_disk.npy', mmap_mode='c')

"""
**Fast load**: it only takes a few ms to "load" a memory map to a 10 GB array on disk.

In fact, the only thing that is loaded is a map to the array stored on disk. That's why it's so fast.
"""

"""
## Arrays on disk: main features 📀
"""

"""
### Very limited RAM usage
"""

print(X_on_disk.shape, y_on_disk.shape)
# Output:
#   (100000, 50, 512) (100000,)


print(f'X array on disk: {sys.getsizeof(X_on_disk):12} bytes ({bytes2str(sys.getsizeof(X_on_disk))})')
print(f'y array on disk: {sys.getsizeof(y_on_disk):12} bytes ({bytes2str(sys.getsizeof(y_on_disk))})')
# Output:
#   X array on disk:          152 bytes (0.000 GB)

#   y array on disk:          120 bytes (0.000 GB)


"""
**152 bytes of RAM for a 10GB array**. This is the great benefit of arrays on disk.

Arrays on disk barely use any RAM until they are accessed or sliced and an element is converted into a np.array or a tensor.

This is equivalent to the size of file paths in images (very limited) compared to the files themselves (actual images). 
"""

"""
### Types
"""

"""
np.memmap is a subclass of np.ndarray
"""

isinstance(X_on_disk, np.ndarray)
# Output:
#   True

type(X_on_disk)
# Output:
#   numpy.memmap

"""
### Operations
"""

"""
With np.memmap you can perform the same operations you would with a normal numpy array. 
The most common operations you will perform in deep learning are:

- slicing
- calculating stats: mean and std
- scaling (using normalize or standardize)
- transformation into a tensor

Once you get the slice from the array on disk, you'll convert it into a tensor, move to a GPU and performs operations there.
"""

"""

⚠️ You need to be careful though not to convert the entire np.memmap to an array/ tensor if it's larger than your RAM. This will crash your computer unless you have enough RAM, so you would have to reboot!

**DON'T DO THIS:  torch.from_numpy(X) or np.array(X)** unless you have enough RAM.

To avoid issues during test, I created a smaller array on disk (that I can store in memory). When I want to test something I test it with that array first. It's important to always verify that the type output of your operations is np.memmap, which means data is still in memory.
"""

"""
#### Slicing
"""

"""
To ensure you don't bring the entire array in memory (which may crash your computer) you can always work with slices of data, which is by the way how fastai works.

If you use mode 'r' you can grab a sample and make changes to it, but this won't modify data on disk.
"""

x = X_on_disk[0]
x
# Output:
#   memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 , 0.04008082,

#            0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935, 0.345074  ,

#            0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 , 0.67118037,

#            0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279, 0.3053631 ,

#            0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526, 0.6705215 ,

#            0.9529823 ]], dtype=float32)

"""
It's important to note that **when we perform a math operation on a np.memmap (add, subtract, ...) the output is a np.array, and no longer a np.memmap.**

⚠️ Remember you don't want to run this type of operations with a memmap larger than your RAM!! That's why I do it with a slice.
"""

x = X_on_disk[0] + 1
x
# Output:
#   array([[1.3480375, 1.0408969, 1.7991264, ..., 1.3777052, 1.8188598,

#           1.1730163],

#          [1.6830332, 1.6505463, 1.3793545, ..., 1.808531 , 1.0400808,

#           1.2903932],

#          [1.9397006, 1.893645 , 1.1604928, ..., 1.1500794, 1.3450739,

#           1.1874511],

#          ...,

#          [1.0391452, 1.2724888, 1.3282523, ..., 1.9183815, 1.6711804,

#           1.3944496],

#          [1.7406857, 1.1652381, 1.1856246, ..., 1.1837728, 1.305363 ,

#           1.3580035],

#          [1.2749133, 1.7390122, 1.9457232, ..., 1.1827552, 1.6705215,

#           1.9529823]], dtype=float32)

x = torch.from_numpy(X_on_disk[0])
x2 = x + 1
x2
# Output:
#   tensor([[1.3480, 1.0409, 1.7991,  ..., 1.3777, 1.8189, 1.1730],

#           [1.6830, 1.6505, 1.3794,  ..., 1.8085, 1.0401, 1.2904],

#           [1.9397, 1.8936, 1.1605,  ..., 1.1501, 1.3451, 1.1875],

#           ...,

#           [1.0391, 1.2725, 1.3283,  ..., 1.9184, 1.6712, 1.3944],

#           [1.7407, 1.1652, 1.1856,  ..., 1.1838, 1.3054, 1.3580],

#           [1.2749, 1.7390, 1.9457,  ..., 1.1828, 1.6705, 1.9530]])

"""
As you can see, this doesn't affect the original np.memmap
"""

X_on_disk[0]
# Output:
#   memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 , 0.04008082,

#            0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935, 0.345074  ,

#            0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 , 0.67118037,

#            0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279, 0.3053631 ,

#            0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526, 0.6705215 ,

#            0.9529823 ]], dtype=float32)

"""
You can slice an array on disk by any axis, and it'll return a memmap. Slicing by any axis is very fast.
"""

X_on_disk[0]
# Output:
#   memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 , 0.04008082,

#            0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935, 0.345074  ,

#            0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 , 0.67118037,

#            0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279, 0.3053631 ,

#            0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526, 0.6705215 ,

#            0.9529823 ]], dtype=float32)

X_on_disk[:, 0]
# Output:
#   memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.9259249 , 0.514623  , 0.50216776, ..., 0.8823718 , 0.561646  ,

#            0.25591376],

#           [0.06298492, 0.10742943, 0.43376994, ..., 0.01061168, 0.3993792 ,

#            0.5877482 ],

#           ...,

#           [0.36538476, 0.6251516 , 0.13214637, ..., 0.56368643, 0.03602772,

#            0.02040654],

#           [0.7697917 , 0.06593986, 0.12318378, ..., 0.24622898, 0.4352764 ,

#            0.8795757 ],

#           [0.30351886, 0.05458342, 0.18446152, ..., 0.00465104, 0.35671628,

#            0.12464925]], dtype=float32)

"""
However, bear in mind that if you use multiple indices, the output will be a regular numpy array. This is important as it will use more RAM. 
"""

X_on_disk[[0,1]]
# Output:
#   array([[[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525,

#            0.8188598 , 0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 ,

#            0.04008082, 0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935,

#            0.345074  , 0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 ,

#            0.67118037, 0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279,

#            0.3053631 , 0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526,

#            0.6705215 , 0.9529823 ]],

#   

#          [[0.9259249 , 0.514623  , 0.50216776, ..., 0.8823718 ,

#            0.561646  , 0.25591376],

#           [0.81914663, 0.79375005, 0.65909016, ..., 0.884909  ,

#            0.23646063, 0.5160194 ],

#           [0.99880844, 0.6775859 , 0.16700691, ..., 0.84936655,

#            0.051814  , 0.20492136],

#           ...,

#           [0.4639562 , 0.41425797, 0.49373862, ..., 0.58005303,

#            0.17869665, 0.97369766],

#           [0.56871843, 0.20894419, 0.6577927 , ..., 0.8131621 ,

#            0.88691944, 0.5066556 ],

#           [0.3088769 , 0.883312  , 0.8087257 , ..., 0.9424154 ,

#            0.26620054, 0.32207966]]], dtype=float32)

"""
Unless you use a slice with consecutive indices like this:
"""

X_on_disk[:2]
# Output:
#   memmap([[[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525,

#             0.8188598 , 0.17301634],

#            [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 ,

#             0.04008082, 0.2903932 ],

#            [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935,

#             0.345074  , 0.1874511 ],

#            ...,

#            [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 ,

#             0.67118037, 0.39444962],

#            [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279,

#             0.3053631 , 0.3580035 ],

#            [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526,

#             0.6705215 , 0.9529823 ]],

#   

#           [[0.9259249 , 0.514623  , 0.50216776, ..., 0.8823718 ,

#             0.561646  , 0.25591376],

#            [0.81914663, 0.79375005, 0.65909016, ..., 0.884909  ,

#             0.23646063, 0.5160194 ],

#            [0.99880844, 0.6775859 , 0.16700691, ..., 0.84936655,

#             0.051814  , 0.20492136],

#            ...,

#            [0.4639562 , 0.41425797, 0.49373862, ..., 0.58005303,

#             0.17869665, 0.97369766],

#            [0.56871843, 0.20894419, 0.6577927 , ..., 0.8131621 ,

#             0.88691944, 0.5066556 ],

#            [0.3088769 , 0.883312  , 0.8087257 , ..., 0.9424154 ,

#             0.26620054, 0.32207966]]], dtype=float32)

"""
This continues to be a memmap
"""

"""
There's a trick we can use avoid this making use of the excellent new L class in fastai. It is to **itemify** the np.memmap/s. 
"""

def itemify(*x): return L(*x).zip()

"""
To itemify one or several np.memmap/s is very fast. Let's see how long it takes with a 10 GB array.
"""

X_on_disk_as_items = itemify(X_on_disk)

"""
5 seconds to return individual records on disk! Bear in mind you only need to perform this once!

So now, you can select multiple items at the same time, and they will all still be on disk:
"""

X_on_disk_as_items[0,1]
# Output:
#   (#2) [(memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 , 0.04008082,

#            0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935, 0.345074  ,

#            0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 , 0.67118037,

#            0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279, 0.3053631 ,

#            0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526, 0.6705215 ,

#            0.9529823 ]], dtype=float32),),(memmap([[0.9259249 , 0.514623  , 0.50216776, ..., 0.8823718 , 0.561646  ,

#            0.25591376],

#           [0.81914663, 0.79375005, 0.65909016, ..., 0.884909  , 0.23646063,

#            0.5160194 ],

#           [0.99880844, 0.6775859 , 0.16700691, ..., 0.84936655, 0.051814  ,

#            0.20492136],

#           ...,

#           [0.4639562 , 0.41425797, 0.49373862, ..., 0.58005303, 0.17869665,

#            0.97369766],

#           [0.56871843, 0.20894419, 0.6577927 , ..., 0.8131621 , 0.88691944,

#            0.5066556 ],

#           [0.3088769 , 0.883312  , 0.8087257 , ..., 0.9424154 , 0.26620054,

#            0.32207966]], dtype=float32),)]

"""
You can also itemify several items at once: X and y for example. When you slice the list, you'll get tuples.
"""

Xy_on_disk_as_items = itemify(X_on_disk, y_on_disk)

Xy_on_disk_as_items[0, 1]
# Output:
#   (#2) [(memmap([[0.34803748, 0.04089686, 0.7991264 , ..., 0.37770525, 0.8188598 ,

#            0.17301634],

#           [0.6830333 , 0.6505463 , 0.37935442, ..., 0.8085311 , 0.04008082,

#            0.2903932 ],

#           [0.9397006 , 0.89364505, 0.16049282, ..., 0.15007935, 0.345074  ,

#            0.1874511 ],

#           ...,

#           [0.0391452 , 0.2724889 , 0.3282523 , ..., 0.9183814 , 0.67118037,

#            0.39444962],

#           [0.74068576, 0.16523811, 0.18562464, ..., 0.18377279, 0.3053631 ,

#            0.3580035 ],

#           [0.27491328, 0.7390123 , 0.9457232 , ..., 0.18275526, 0.6705215 ,

#            0.9529823 ]], dtype=float32), 'h'),(memmap([[0.9259249 , 0.514623  , 0.50216776, ..., 0.8823718 , 0.561646  ,

#            0.25591376],

#           [0.81914663, 0.79375005, 0.65909016, ..., 0.884909  , 0.23646063,

#            0.5160194 ],

#           [0.99880844, 0.6775859 , 0.16700691, ..., 0.84936655, 0.051814  ,

#            0.20492136],

#           ...,

#           [0.4639562 , 0.41425797, 0.49373862, ..., 0.58005303, 0.17869665,

#            0.97369766],

#           [0.56871843, 0.20894419, 0.6577927 , ..., 0.8131621 , 0.88691944,

#            0.5066556 ],

#           [0.3088769 , 0.883312  , 0.8087257 , ..., 0.9424154 , 0.26620054,

#            0.32207966]], dtype=float32), 'i')]

"""
Slicing is very fast, even if there are 100.000 samples.
"""

# axis 0
%timeit X_on_disk[0]
# Output:
#   The slowest run took 21.11 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.93 µs per loop


# axis 1
%timeit X_on_disk[:, 0]
# Output:
#   The slowest run took 16.79 times longer than the fastest. This could mean that an intermediate result is being cached.

#   100000 loops, best of 3: 1.96 µs per loop


# axis 2
%timeit X_on_disk[..., 0]
# Output:
#   The slowest run took 19.08 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.94 µs per loop


# aixs 0,1
%timeit X_on_disk[0, 0]
# Output:
#   The slowest run took 20.50 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.97 µs per loop


"""
To compare how fast you can slice a np.memmap, let's create a smaller array that I can fit in memory (X_in_memory). This is 10 times smaller (100 MB) than the one on disk.
"""

X_in_memory_small = np.random.rand(10000, 50, 512)

%timeit X_in_memory_small[0]
# Output:
#   The slowest run took 46.56 times longer than the fastest. This could mean that an intermediate result is being cached.

#   10000000 loops, best of 3: 183 ns per loop


"""
Let's create the same array on disk. It's super simple:
"""

np.save('./data/X_on_disk_small.npy', X_in_memory_small)
X_on_disk_small = np.load('./data/X_on_disk_small.npy', mmap_mode='c')

%timeit X_on_disk_small[0]
# Output:
#   The slowest run took 20.41 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.95 µs per loop


"""
This is approximately 10 times slower than having arrays on disk, although it's still pretty fast.

However, if we use the itemified version, it's much faster:
"""

%timeit X_on_disk_as_items[0]
# Output:
#   The slowest run took 15.68 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 877 ns per loop


"""
This is much better! So now you can access 1 of multiple items on disk with a pretty good performance.
"""

"""
#### Calculating stats: mean and std
"""

"""
Another benefit of using arrays on disk is that you can calculate the mean and std deviation of the entire dataset. 

It takes a considerable time since the array is very big (10GB), but it's feasible:

- mean (0.4999966):  1 min 45 s
- std  (0.2886839): 11 min 43 s 

in my laptop. 
If you need them, you could calculate these stats once, and store the results (similar to ImageNet stats).
However, you usually need to claculate these metrics for labeled (train) datasets, that tend to be smaller.
"""

# X_mean = X_on_disk.mean()
# X_mean

# X_std = X_on_disk.std()
# X_std

"""
#### Conversion into a tensor
"""

"""
Conversion from an array on disk slice into a tensor is also very fast:
"""

torch.from_numpy(X_on_disk[0])
# Output:
#   tensor([[0.3480, 0.0409, 0.7991,  ..., 0.3777, 0.8189, 0.1730],

#           [0.6830, 0.6505, 0.3794,  ..., 0.8085, 0.0401, 0.2904],

#           [0.9397, 0.8936, 0.1605,  ..., 0.1501, 0.3451, 0.1875],

#           ...,

#           [0.0391, 0.2725, 0.3283,  ..., 0.9184, 0.6712, 0.3944],

#           [0.7407, 0.1652, 0.1856,  ..., 0.1838, 0.3054, 0.3580],

#           [0.2749, 0.7390, 0.9457,  ..., 0.1828, 0.6705, 0.9530]])

X_on_disk_small_0 = X_on_disk_small[0]
X_in_memory_small_0 = X_in_memory_small[0]

%timeit torch.from_numpy(X_on_disk_small_0)
# Output:
#   The slowest run took 44.11 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.13 µs per loop


%timeit torch.from_numpy(X_in_memory_small_0 )
# Output:
#   The slowest run took 46.27 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.16 µs per loop


"""
So it takes the same time to convert from numpy.memmap or from a np.array in memory.
"""

"""
#### Combined operations: slicing plus conversion to tensor
"""

"""
Let's now check performance of the combined process: slicing plus conversion to a tensor. Based on what we've seen there are 3 options: 

- slice np.array in memory + conversion to tensor
- slice np.memmap on disk + conversion to tensor
- slice itemified np.memmap + converion to tensor
"""

%timeit torch.from_numpy(X_in_memory_small[0])
# Output:
#   The slowest run took 76.50 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000000 loops, best of 3: 1.44 µs per loop


%timeit torch.from_numpy(X_on_disk_small[0])
# Output:
#   The slowest run took 24.08 times longer than the fastest. This could mean that an intermediate result is being cached.

#   100000 loops, best of 3: 3.89 µs per loop


X_on_disk_small_as_items = itemify(X_on_disk_small)

%timeit torch.from_numpy(X_on_disk_small_as_items[0][0])
# Output:
#   The slowest run took 23.52 times longer than the fastest. This could mean that an intermediate result is being cached.

#   100000 loops, best of 3: 2.35 µs per loop


"""
So this last method is **almost as fast as having the array in memory**!! This is an excellent outcome, since slicing arrays in memory is a highly optimized operation. 

And we have the benefit of having access to very large datasets if needed.
"""

"""
## Remove the arrays on disk
"""

"""
Don't forget to remove the arrays you have created on disk.
"""

os.remove('./data/X_on_disk.npy')
os.remove('./data/X_on_disk_small.npy')
os.remove('./data/y_on_disk.npy')

"""
## Summary ✅
"""

"""
We now have a very efficient way to work with very large numpy arrays.

The process is very simple:

- create and save the array on disk (as described before)
- load it with a mmap_mode='c' if you want to be able to modify data in memory but not on dis, or 'r+ if you want to modify data both in memory and on disk.

So my recommendation would be:

- use numpy arrays in memory when possible (if your data fits in memory)
- use numpy memmap (arrays on disk) when data doesn't fit. You will still have a great performance.
"""



================================================
FILE: tutorial_nbs/00b_How_to_use_numpy_arrays_in_fastai.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/00b_How_to_use_numpy_arrays_in_fastai.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## How to work with numpy arrays in fastai: a time series classification example ⏳ 
"""

"""
I'd like to share with you how you can work with numpy arrays in **fastai** through a time series classification example. 

I've used timeseriesAI (based on v1 extensively). To be able to use fastai v2 I have a few requirements: 

* Use univariate and multivariate time series
* Use labelled (X,y) and unlabelled (X,) datasets
* Data may be already split in train/valid
* In-memory and on-disk np.arrays (np.memmap in case of larger than RAM data)
* Slice the dataset (based on selected variables and/ or sequence steps)
* Use item and batch tfms (transforms)
* Create batch with specified output types (TSTensor, TensorCategory, etc)
* Show batch (with tfms)
* Show results
* Add test data and unlabelled datasets
* Export and predict on new data
* Equal or better performance than native Pytorch, fastai v1 & vanilla fastai v2

These are pretty challenging. Let's see if fastai can meet them (with limited customization).
"""

"""
## Import libraries 📚
"""

# **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
stable = True # Set to True for latest pip version or False for main branch in GitHub
!pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os             : Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic

#   python         : 3.7.13

#   tsai           : 0.3.1

#   fastai         : 2.6.3

#   fastcore       : 1.4.2

#   torch          : 1.11.0+cu113

#   device         : 1 gpu (['Tesla P100-PCIE-16GB'])

#   cpu cores      : 2

#   RAM            : 12.68 GB

#   GPU memory     : [15.9] GB


"""
## Load data 🔢
"""

# dataset id
dsid = 'StarLightCurves'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=False)
X_on_disk, y_on_disk, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=True, return_split=False)
X_in_memory, y_in_memory, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=False, return_split=False)
# Output:
#   Dataset: StarLightCurves

#   downloading data...

#   ...data downloaded

#   decompressing data...

#   ...data decompressed

#   loading ts files to dataframe...

#   ...ts files loaded

#   preparing numpy arrays...

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   ...numpy arrays correctly saved

#   X_train: (1000, 1, 1024)

#   y_train: (1000,)

#   X_valid: (8236, 1, 1024)

#   y_valid: (8236,) 

#   

#   Dataset: StarLightCurves

#   X      : (9236, 1, 1024)

#   y      : (9236,)

#   splits : (#1000) [0,1,2,3,4,5,6,7,8,9...] (#8236) [1000,1001,1002,1003,1004,1005,1006,1007,1008,1009...] 

#   

#   Dataset: StarLightCurves

#   X      : (9236, 1, 1024)

#   y      : (9236,)

#   splits : (#1000) [0,1,2,3,4,5,6,7,8,9...] (#8236) [1000,1001,1002,1003,1004,1005,1006,1007,1008,1009...] 

#   


bs = 128
idx = np.random.randint(len(X_in_memory), size=bs)
train_idx = np.random.randint(len(splits[0]), size=bs)
valid_idx = np.random.randint(len(splits[1]), size=bs)

"""
## Building blocks: NumpyTensor/ TSTensor 🧱
"""

"""
Since fastai is based on Pytorch, you'll need to somehow transform the numpy arrays to tensors (NumpyTensor or TSTensor for TS). 

There are transform functions called ToNumpyTensor/ ToTSTensor that transform an array into a tensor of type NumpyTensor/ TSTensor (both have a show method).
"""

nt = NumpyTensor(X_in_memory)
print(nt)
nt.show();
# Output:
#   NumpyTensor(shape:(9236, 1, 1024), device=cpu, dtype=torch.float32)

#   <Figure size 432x288 with 1 Axes>

tstensor = TSTensor(X_in_memory)
print(tstensor)
tstensor[0].show();
# Output:
#   TSTensor(samples:9236, vars:1, len:1024, device=cpu, dtype=torch.float32)

#   <Figure size 432x288 with 1 Axes>

"""
## Performance benchmarks ⏱
"""

"""
In fastai v2 there are multiple options to create dataloaders. Let's see some of them and most importantly whether they meet our requirements.

I will compare performance on 2 processes: 

- cycle_dl: process to cycle through the entire valid dataset (adapted from a function developed by Thomas Capelle (fastai's @tcapelle))
- train model for 25 epochs
"""

"""
### Pytorch dataloader & NumpyDataset
"""

"""
For reference, we'll test performance in the most simple dataset we can have and the native Pytorch dataloader:
"""

valid_ds    = TorchDataset(np.array(X_valid), np.array(y_valid).astype(int))
valid_dl    = torch.utils.data.DataLoader(valid_ds, batch_size=128)
xb, yb = next(iter(valid_dl))
xb, yb
# Output:
#   (tensor([[[-0.5697, -0.5679, -0.5659,  ..., -0.5485, -0.5545, -0.5608]],

#    

#            [[-0.5283, -0.5209, -0.5129,  ..., -0.6006, -0.5799, -0.5563]],

#    

#            [[ 0.1642,  0.1819,  0.1986,  ...,  0.1773,  0.1694,  0.1617]],

#    

#            ...,

#    

#            [[ 0.5924,  0.5822,  0.5737,  ...,  0.6469,  0.6374,  0.6268]],

#    

#            [[ 0.5427,  0.5495,  0.5557,  ...,  0.4949,  0.4907,  0.4858]],

#    

#            [[-0.1532, -0.1441, -0.1353,  ..., -0.1930, -0.1855, -0.1781]]]),

#    tensor([2, 3, 3, 1, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3,

#            2, 1, 3, 1, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 2, 1, 1, 3,

#            3, 3, 3, 2, 1, 1, 3, 3, 3, 3, 3, 3, 1, 1, 2, 3, 3, 2, 3, 3, 3, 1, 1, 3,

#            2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 1, 3, 1, 3,

#            3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 2, 1, 3, 3, 1, 3, 3, 2, 3, 2, 3, 3,

#            3, 3, 3, 3, 2, 3, 3, 1]))

timer.start()
cycle_dl(valid_dl)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.076862


timer.start()
cycle_dl_to_device(valid_dl)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:10.110983


%timeit xb.to(default_device()), yb.to(default_device())
# Output:
#   10000 loops, best of 5: 178 µs per loop


"""
This is very fast, but:

* batch is returned on **cpu** (so additional time is required to pass it to the gpu). The challenging benchmark is the one in the cycle_dl_to_device(valid_dl) test.
* cannot be easily integrated with fastai.

It will be difficult to find a solution that performs at the same level 😅!
"""

"""
If you want a simple solution that you can use with fastai you will need to use DataLoader (fastai's default dataloader) instead of Pytorch's native dataloader.
"""

train_ds = TSDataset(np.array(X_train), np.array(y_train).astype(int) - 1, types=(TSTensor, TSLabelTensor))
train_dl = DataLoader(train_ds, bs=128, num_workers=0)
valid_ds = TSDataset(np.array(X_valid), np.array(y_valid).astype(int) - 1, types=(TSTensor, TSLabelTensor))
valid_dl = DataLoader(valid_ds, bs=128, num_workers=0)
dls      = DataLoaders(train_dl, valid_dl, device=default_device())
xb,yb = next(iter(dls.valid))
print(xb, yb)
print(f'shape: {str(len(train_ds)):10}   bs: {xb.shape}')
timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   TSTensor(samples:128, vars:1, len:1024, device=cuda:0, dtype=torch.float32) TSLabelTensor(shape:(128,), device=cuda:0, dtype=torch.int64)

#   shape: 1000         bs: torch.Size([128, 1, 1024])

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.870320


"""
But this is relatively slow, as DataLoader processes samples one at a time, and each item needs to be cast to the appropriate type.

Note: we'll see how this can be accelerated later by processing all batch samples at once.
"""

c = len(np.unique(y_train))
model = InceptionTime(X_train.shape[-2], c)
learn = Learner(dls, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:01:26.815917


"""
### Fastai v1
"""

"""
For comparison, I've run the same exact test in the same machine with fastai v1 timeseries code and these are the timings: : 

- cycle_dl:  1.01s
- training time: 102 s

These are the timings we'd like to beat if we want to have a faster TS framework.
"""

"""
### Fastai v2:  Factory method
"""

"""
Since UCR data was already split into train and test, we'll pass IndexSplitter(splits[1]) as splitter so we get exactly the same split.
"""

dls = TSDataLoaders.from_numpy(X_in_memory, y_in_memory, splitter=IndexSplitter(splits[1]), bs=64, val_bs=128, num_workers=0)
next(iter(dls.valid))
# Output:
#   (TSTensor(samples:128, vars:1, len:1024, device=cuda:0, dtype=torch.float32),

#    TSTensor(len:128, device=cuda:0, dtype=torch.int64))

%time cycle_dl(dls.train)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   CPU times: user 672 ms, sys: 4.04 ms, total: 676 ms

#   Wall time: 683 ms


%time cycle_dl(dls.valid)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   CPU times: user 5.28 s, sys: 42.7 ms, total: 5.32 s

#   Wall time: 5.33 s


model = InceptionTime(X_in_memory.shape[-2], dls.c)
learn = Learner(dls, model, metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   203.65851879119873


"""
This method is very easy to use, but it's pretty slow.
"""

"""
### Fastai v2:  Datablock API
"""

getters = [ItemGetter(0), ItemGetter(1)]
dblock = DataBlock(blocks=(TSTensorBlock, CategoryBlock()),
                   getters=getters,
                   splitter=IndexSplitter(splits[1]),
                   item_tfms=None,
                   batch_tfms=None)
source = itemify(X_in_memory, y_in_memory)
dls = dblock.dataloaders(source, bs=64, val_bs=128, num_workers=0)
xb,yb = next(iter(dls.valid))
print(f'shape: {str(len(dls.valid.dataset)):10}   bs: {xb.shape}')
# Output:
#   shape: 8236         bs: torch.Size([128, 1, 1024])


timer.start()
cycle_dl(dls.train)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.647535


timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:05.103905


"""
So it takes more than 3 seconds to cycle the entire dataloader. This is much slower than Pytorch simple model (although fastai v2 provides a lot more functionality!).
"""

model = InceptionTime(X_in_memory.shape[-2], dls.c)
learn = Learner(dls, model, metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   201.2871057987213


"""
This is very slow compared to the native Pytorch, and even to fastai v1.
"""

"""
### Hybrid: Pytorch dataset + Fastai DataLoaders
"""

"""


Sylvain Gugger provided an alternative recommendation to use numpy arrays in this [post](https://forums.fast.ai/t/datablock-with-numpy-input/64848/2):

"You can create a DataLoaders object from regular PyTorch datasets (though all the visualization methods like show_batch and show_results will fail)."
"""

train_ds = TorchDataset(np.array(X_train), np.array(y_train).astype(int) - 1)
valid_ds = TorchDataset(np.array(X_valid), np.array(y_valid).astype(int) - 1)
dls = DataLoaders.from_dsets(train_ds, valid_ds, batch_size=128, num_workers=0, device=default_device())
xb,yb = next(iter(dls.valid))
print(f'shape: {str(len(dls.valid.dataset)):10}   bs: {xb.shape}')
# Output:
#   shape: 8236         bs: torch.Size([128, 1, 1024])


timer.start()
cycle_dl(dls.train)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.044370


timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.119733


model = InceptionTime(X_in_memory.shape[-2], len(np.unique(y_in_memory)))
learn = Learner(dls, model, loss_func=nn.CrossEntropyLoss(), metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   57.06522464752197


"""
This is definitely an improvement in terms of speed.

It is now better than fastai v1! 
"""

"""
## NumpyDatasets & NumpyDataLoaders 🤩
"""

"""
So far we we've seen fastai v2 is very flexible and easy to use, but it's slow compared to v1 (in this example the Datablock API was 65% slower). 

There are at least 3 major differences between vision and time series -TS- (and numpy based data in general) that we can leverage to improve performance: 

1. Vision typically requires some item preprocessing that is sometimes random. For example, when you randomly crop an image. Each time it'll return a different value. However, with time series, most item transforms are **deterministic** (actually most impact the label only).

2. In vision problems, you usually derive the image and label from a single item (path). In TS problems, it's common to have data already **split between X and y**. It doesn't make much sense to have data already split (into X and y) to merge them in a single item and process them together. 

3. In vision problems, you can only create a batch processing one image at a time. However with numpy datasets, you can create a batch **processing all batch items** at the same time, just by slicing an array/ tensor, which is much faster.

Based on these ideas, we could modify datasets and dataloader and:

1. **Preprocess item tfms in place** during datasets initialization, and thus save this time in every epoch

2. **Apply the tfms independently to the inputs (X) and labels (y)**. The output of this process 2 arrays or tensors that can be easily sliced. Slicing is a much faster operation than applying a transform.

3. Remove the collate function, and instead **slice using all indices at the same time**. Then we can cast the output to the desired subclasses.

To test this approach, I've created a NumpyDatasets and NumpyDataLoader that leverage the characteristics of numpy-based datasets.

BTW, something important as well, is that fastai v2 design allows the use of larger than RAM datasets, as data can be sliced directly from disk before loading in memory. If you want to learn more about the usage of np.memmap you may want to see nb 00.
"""

"""
You can use inplace=True whenever you want to speed up training **and**:

* you are **not using any tfms, or**
* if you are using tfms, **transformed X (and y) both fit in memory**

Using `inplace` won't be effective for items of type np.memmap (to avoid trying to load in memory larger that RAM datasets). In many time series problems, X transforms can be applied after a batch has been created. In all these cases, you can use inplace=True.

`inplace=true` only impact item transforms.
"""

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, tfms=tfms, splits=splits, inplace=True)
print(dsets[0])
show_at(dsets, 0);
# Output:
#   (TSTensor(vars:1, len:1024, device=cpu, dtype=torch.float32), TensorCategory(2))

#   <Figure size 432x288 with 1 Axes>

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, tfms=tfms, splits=splits, inplace=True)
print(dsets[0])
show_at(dsets, 0);
# Output:
#   (TSTensor(vars:1, len:1024, device=cpu, dtype=torch.float32), TensorCategory(2))

#   <Figure size 432x288 with 1 Axes>

"""
If you have test data, you can just do this: 
"""

test_ds = dsets.add_test(X_in_memory, y_in_memory)
test_ds[0]
# Output:
#   (TSTensor(vars:1, len:1024, device=cpu, dtype=torch.float32),

#    TensorCategory(2))

"""
To create dataloaders, you just need this:
"""

dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)
b = next(iter(dls.train))
b
# Output:
#   (TSTensor(samples:64, vars:1, len:1024, device=cuda:0, dtype=torch.float32),

#    TensorCategory([2, 0, 2, 1, 2, 2, 2, 2, 0, 1, 0, 2, 0, 2, 1, 1, 1, 1, 2, 1, 2, 1, 0, 2,

#            2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,

#            1, 0, 2, 2, 2, 0, 2, 1, 1, 2, 1, 2, 1, 0, 0, 1], device='cuda:0'))

dls.train.show_batch(sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
Let's now establish another benchmark. 

If we think of it, the fastest and simplest way to create a batch to be used in fastai v2 would be to:

1. split the X and y between train and valid. This can be done at initialization. 

2. Slice the data based on random idx, cast the outputs to the expected classes, and create a tuple. 

This process takes about 200 µs in my machine. So it's very fast.
"""

X_val = X_in_memory[splits[1]]
y_val = y_in_memory[splits[1]].astype(int)
tuple((TSTensor(X_val[valid_idx]), TensorCategory(y_val[valid_idx])))
# Output:
#   (TSTensor(samples:128, vars:1, len:1024, device=cpu, dtype=torch.float32),

#    TensorCategory([3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 1, 3,

#            3, 3, 3, 1, 2, 3, 3, 3, 3, 1, 2, 2, 3, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 1,

#            3, 2, 2, 2, 3, 1, 3, 2, 3, 3, 1, 2, 1, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3,

#            3, 3, 3, 3, 3, 1, 1, 2, 2, 2, 3, 2, 1, 3, 3, 3, 1, 2, 3, 3, 3, 3, 2, 3,

#            1, 2, 1, 3, 2, 3, 3, 1, 1, 3, 3, 3, 1, 3, 2, 2, 1, 3, 3, 3, 3, 3, 1, 3,

#            2, 3, 3, 3, 3, 2, 3, 2]))

%timeit tuple((TSTensor(X_val[valid_idx]), TensorCategory(y_val[valid_idx])))
# Output:
#   The slowest run took 4.32 times longer than the fastest. This could mean that an intermediate result is being cached.

#   1000 loops, best of 5: 211 µs per loop


"""
Let's see how this compares to NumpyDatasets when tfms are not preprocessed:
"""

# Preprocess = False
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, sel_vars=None, sel_steps=None, tfms=tfms, splits=splits, inplace=False)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)

valid_ds = dsets.valid
%timeit valid_ds[valid_idx]
# Output:
#   100 loops, best of 5: 13.7 ms per loop


timer.start()
cycle_dl(dls.train)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.143769


timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:01.042833


"""
Let's see how the performance when data is preprocessed:
"""

# Preprocess = True
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, sel_vars=None, sel_steps=None, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)

valid_ds = dsets.valid
%timeit valid_ds[valid_idx]
# Output:
#   10000 loops, best of 5: 172 µs per loop


"""
😲 Wow! This is superfast! Since we only perform slicing and casting at batch creation time performance is excellent. And it's much faster than when inplace=False. 
"""

timer.start()
cycle_dl(dls.train)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.052396


timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.076500


"""
🙃 This is even faster than the simple Pytorch dataloader, and much more flexible and with many additional benefits ❣️
"""

"""
Let's now measure the timing with data on-disk instead of in memory.
"""

# Preprocess = True
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_on_disk, y_on_disk, sel_vars=None, sel_steps=None, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)

valid_ds = dsets.valid
%timeit valid_ds[valid_idx]
# Output:
#   10000 loops, best of 5: 176 µs per loop


timer.start()
cycle_dl(dls.train)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.047280


timer.start()
cycle_dl(dls.valid)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time        : 0:00:00.071860


"""
⚠️ There's a delay in batch creation when data is on disk, but it's not too bad. It shouldn't have much impact during training!
"""

"""


Let's now compare the time to train the model.
"""

# inplace=False, Data in memory
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, tfms=tfms, splits=splits, inplace=False)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   86.28207302093506


"""
⚠️ This NumpyDataLoader is faster than fastai v1 even when inplace=False. 
"""

# inplace=True, Data in memory
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_in_memory, y_in_memory, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   59.19933795928955


"""
🍻 🎉 I think this is a great result. It means that just preprocessing the item transforms can greatly reduce total training time!!
"""

# inplace=True, Data on disk
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_on_disk, y_on_disk, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], num_workers=0)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
timer.start()
learn.fit_one_cycle(25, lr_max=1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   59.18419694900513


"""
⚠️ This is also very important, as it means we can now train very large datasets with a good performance without loading data in memory.
"""

"""
## End-to-end process with recommended approach 🏁
"""

"""
Let's simulate an end-to-end process to confirm everything works as expected.

We'll first build the datasets, learner and train a model:
"""

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', verbose=True, on_disk=True, return_split=False)
# Output:
#   Dataset: NATOPS

#   downloading data...

#   ...data downloaded

#   decompressing data...

#   ...data decompressed

#   loading ts files to dataframe...

#   ...ts files loaded

#   preparing numpy arrays...

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   ...numpy arrays correctly saved

#   X      : (360, 24, 51)

#   y      : (360,)

#   splits : (#180) [0,1,2,3,4,5,6,7,8,9...] (#180) [180,181,182,183,184,185,186,187,188,189...] 

#   


tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits) # inplace=True by default
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
learn.fit_one_cycle(25, lr_max=1e-3)
learn.recorder.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>

"""
Let's simulate we need to end the working session now but want to continue working with this datasets and learner in the future. 

To save everything you can use a convenience function I've created that saves the learner with the model, the data and the opt function status: 
"""

learn.save_all()

"""
As soon as we've done this, we can end the session, and continue at any time in the future. 

Let's simulate that we need to end the session now:
"""

del learn, dsets, dls

"""
Next time we go back to work, we'll need to reload the datasets and learner (with the same status we had):
"""

learn = load_learner_all(path='export', dls_fname='dls', model_fname='model', learner_fname='learner', device='cpu')
dls = learn.dls
first(dls.valid)
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cpu, dtype=torch.float32),

#    TensorCategory([3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3, 2, 4, 1, 0, 4, 0, 4, 0, 2, 3, 5, 5,

#            1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 2, 1, 5, 0, 2, 4, 3,

#            2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1, 4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3,

#            0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5, 1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2,

#            1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1,

#            0, 3, 4, 3, 1, 2, 2, 2]))

"""
We can now analyze the results:
"""

learn.show_results(sharey=True)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1296x864 with 9 Axes>

valid_probas, valid_targets, valid_preds = learn.get_preds(dl=dls.valid, with_decoded=True)
valid_probas, valid_targets, valid_preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([[0.0224, 0.0124, 0.0075, 0.9290, 0.0202, 0.0085],

#            [0.0076, 0.0047, 0.0035, 0.0105, 0.9602, 0.0135],

#            [0.0198, 0.0204, 0.0076, 0.0110, 0.0260, 0.9152],

#            ...,

#            [0.0047, 0.0025, 0.0026, 0.0079, 0.9759, 0.0064],

#            [0.0178, 0.0091, 0.0055, 0.9452, 0.0163, 0.0061],

#            [0.0153, 0.0056, 0.0038, 0.9274, 0.0429, 0.0049]]),

#    TensorCategory([3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3, 2, 4, 1, 0, 4, 0, 4, 0, 2, 3, 5, 5,

#            1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 2, 1, 5, 0, 2, 4, 3,

#            2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1, 4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3,

#            0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5, 1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2,

#            1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1,

#            0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0, 0, 1, 3, 4, 4, 2, 1, 1, 1, 4, 4, 3,

#            1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5, 4, 3, 5, 1, 3, 2, 3, 0, 1, 3, 0, 2,

#            5, 2, 1, 5, 3, 1, 0, 5, 2, 4, 3, 3]),

#    TensorBase([3, 4, 5, 0, 3, 0, 0, 0, 0, 0, 4, 3, 0, 4, 0, 0, 4, 0, 4, 0, 0, 3, 5, 5,

#            0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 3, 5, 3, 0, 3, 5, 4, 0, 0, 5, 0, 0, 4, 3,

#            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 5, 0, 5, 0, 0, 0, 0, 4, 0, 5, 3,

#            0, 3, 4, 3, 0, 4, 4, 0, 0, 3, 3, 5, 0, 5, 0, 5, 5, 4, 4, 0, 4, 3, 5, 0,

#            0, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0,

#            0, 3, 4, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 4, 4, 3,

#            0, 4, 0, 4, 5, 5, 0, 5, 3, 3, 5, 5, 4, 3, 5, 0, 3, 0, 3, 0, 0, 3, 0, 0,

#            5, 0, 0, 5, 3, 0, 0, 5, 0, 4, 3, 3]))

"""
We can confirm the learner has the same status it had at the end of training, by confirming the validation accuracy is the same:
"""

(valid_targets == valid_preds).float().mean()
# Output:
#   TensorCategory(0.6611)

"""
Great! It's the same. This means we have now the learner at the same point where we left it.
"""

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>

"""
### Add additional labelled test data
"""

# labelled test data
test_ds = dls.valid.dataset.add_test(X, y)
test_dl = dls.valid.new(test_ds)
next(iter(test_dl))
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cpu, dtype=torch.float32),

#    TensorCategory([3, 2, 2, 3, 2, 4, 0, 5, 2, 1, 5, 0, 3, 5, 2, 1, 2, 1, 1, 5, 3, 2, 4, 3,

#            0, 5, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 2, 0, 3, 5, 2, 3, 3, 5, 0, 5, 1, 0,

#            0, 5, 3, 0, 2, 2, 1, 0, 4, 0, 1, 4, 3, 4, 1, 4, 0, 5, 2, 0, 1, 0, 2, 3,

#            3, 2, 4, 1, 1, 2, 2, 5, 5, 0, 1, 4, 1, 1, 3, 4, 5, 3, 1, 2, 0, 2, 0, 4,

#            5, 5, 4, 4, 5, 3, 1, 0, 1, 1, 1, 5, 4, 3, 2, 3, 0, 2, 4, 4, 4, 3, 2, 5,

#            2, 0, 2, 3, 0, 5, 1, 0]))

test_probas, test_targets, test_preds = learn.get_preds(dl=test_dl, with_decoded=True, save_preds=None, save_targs=None)
test_probas, test_targets, test_preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([[0.0128, 0.0052, 0.0030, 0.9658, 0.0092, 0.0041],

#            [0.2783, 0.1617, 0.1415, 0.0999, 0.1340, 0.1846],

#            [0.4428, 0.1452, 0.1012, 0.0623, 0.1335, 0.1151],

#            ...,

#            [0.0047, 0.0025, 0.0026, 0.0079, 0.9759, 0.0064],

#            [0.0178, 0.0091, 0.0055, 0.9452, 0.0163, 0.0061],

#            [0.0153, 0.0056, 0.0038, 0.9274, 0.0429, 0.0049]]),

#    TensorCategory([3, 2, 2, 3, 2, 4, 0, 5, 2, 1, 5, 0, 3, 5, 2, 1, 2, 1, 1, 5, 3, 2, 4, 3,

#            0, 5, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 2, 0, 3, 5, 2, 3, 3, 5, 0, 5, 1, 0,

#            0, 5, 3, 0, 2, 2, 1, 0, 4, 0, 1, 4, 3, 4, 1, 4, 0, 5, 2, 0, 1, 0, 2, 3,

#            3, 2, 4, 1, 1, 2, 2, 5, 5, 0, 1, 4, 1, 1, 3, 4, 5, 3, 1, 2, 0, 2, 0, 4,

#            5, 5, 4, 4, 5, 3, 1, 0, 1, 1, 1, 5, 4, 3, 2, 3, 0, 2, 4, 4, 4, 3, 2, 5,

#            2, 0, 2, 3, 0, 5, 1, 0, 5, 3, 0, 1, 4, 5, 5, 0, 5, 3, 5, 1, 0, 0, 0, 3,

#            0, 5, 5, 2, 1, 5, 5, 2, 4, 4, 0, 1, 1, 4, 1, 2, 2, 4, 1, 3, 5, 3, 4, 1,

#            1, 4, 3, 0, 5, 1, 3, 3, 4, 0, 3, 3, 3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3,

#            2, 4, 1, 0, 4, 0, 4, 0, 2, 3, 5, 5, 1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5,

#            3, 0, 3, 5, 4, 2, 1, 5, 0, 2, 4, 3, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1,

#            4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3, 0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5,

#            1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2, 1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0,

#            2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1, 0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0,

#            0, 1, 3, 4, 4, 2, 1, 1, 1, 4, 4, 3, 1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5,

#            4, 3, 5, 1, 3, 2, 3, 0, 1, 3, 0, 2, 5, 2, 1, 5, 3, 1, 0, 5, 2, 4, 3, 3]),

#    TensorBase([3, 0, 0, 3, 0, 4, 0, 5, 0, 0, 5, 0, 3, 5, 0, 0, 0, 0, 0, 5, 3, 0, 4, 3,

#            0, 5, 0, 4, 4, 4, 0, 4, 0, 4, 3, 4, 0, 0, 3, 5, 0, 3, 3, 5, 0, 5, 0, 0,

#            0, 5, 3, 0, 0, 0, 0, 0, 4, 0, 0, 4, 3, 4, 0, 4, 0, 5, 0, 0, 0, 0, 0, 3,

#            3, 0, 4, 0, 0, 0, 0, 5, 5, 0, 0, 4, 0, 0, 3, 4, 5, 3, 0, 0, 0, 0, 0, 4,

#            5, 5, 4, 4, 5, 3, 0, 0, 0, 0, 0, 5, 4, 3, 0, 3, 0, 0, 4, 4, 4, 3, 0, 5,

#            0, 0, 0, 3, 0, 5, 0, 0, 5, 3, 0, 0, 4, 5, 5, 0, 5, 3, 5, 0, 0, 0, 0, 3,

#            0, 5, 5, 0, 0, 5, 5, 0, 4, 4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 3, 5, 3, 4, 0,

#            0, 4, 3, 0, 5, 0, 3, 3, 4, 0, 3, 3, 3, 4, 5, 0, 3, 0, 0, 0, 0, 0, 4, 3,

#            0, 4, 0, 0, 4, 0, 4, 0, 0, 3, 5, 5, 0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 3, 5,

#            3, 0, 3, 5, 4, 0, 0, 5, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0,

#            4, 5, 0, 5, 0, 0, 0, 0, 4, 0, 5, 3, 0, 3, 4, 3, 0, 4, 4, 0, 0, 3, 3, 5,

#            0, 5, 0, 5, 5, 4, 4, 0, 4, 3, 5, 0, 0, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0,

#            0, 5, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 3, 4, 3, 0, 0, 0, 0, 0, 0, 4, 0,

#            0, 0, 3, 4, 4, 0, 0, 0, 0, 4, 4, 3, 0, 4, 0, 4, 5, 5, 0, 5, 3, 3, 5, 5,

#            4, 3, 5, 0, 3, 0, 3, 0, 0, 3, 0, 0, 5, 0, 0, 5, 3, 0, 0, 5, 0, 4, 3, 3]))

"""
### Add additional unlabelled test data
"""

# Unlabelled test data
test_ds = dls.dataset.add_test(X)
test_dl = dls.valid.new(test_ds)
next(iter(test_dl))
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cpu, dtype=torch.float32),)

test_probas, *_ = learn.get_preds(dl=test_dl, save_preds=None)
test_probas
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   TensorBase([[0.0128, 0.0052, 0.0030, 0.9658, 0.0092, 0.0041],

#           [0.2783, 0.1617, 0.1415, 0.0999, 0.1340, 0.1846],

#           [0.4428, 0.1452, 0.1012, 0.0623, 0.1335, 0.1151],

#           ...,

#           [0.0047, 0.0025, 0.0026, 0.0079, 0.9759, 0.0064],

#           [0.0178, 0.0091, 0.0055, 0.9452, 0.0163, 0.0061],

#           [0.0153, 0.0056, 0.0038, 0.9274, 0.0429, 0.0049]])

"""
## Conclusions ✅
"""

"""
In summary, we've seen how we can now enjoy all the benefits of v2 when using numpy arrays with a simple scikit-learn-like API, that is much faster than v1. 

The key benefits are: 

* We can easily use numpy arrays (or anything that can be converted into np arrays). For example, this can be used for **univariate and multivariate time series**.
* Easy to use scikit-learn type of API (X, (y))
* We can use both **labelled and unlabelled datasets**
* We can also use **larger than RAM datasets**, keeping data on disk (using np.memmap -see [notebook 00](00_How_to_efficiently_work_with_very_large_numpy_arrays.ipynb) for more details-).
* Use item and batch tfms
* Show batch method after tfms have been applied
* Show results after training
* **Easily export** the model to continue at a later time.
* With NumpyDatasets + NumpyDataLoaders batch creation is **25+x faster than fastai v1** and **100+ times faster than vanilla fastai v2** (for numpy arrays).
* This results in **2.5-3x faster training** than fastai v1 and **4-5x faster than vanilla fastai v2** (for numpy arrays).
"""



================================================
FILE: tutorial_nbs/00c_Time_Series_data_preparation.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/00c_Time_Series_data_preparation.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## Import libraries 📚
"""

"""
Since some of you have been asking questions as to how to prepare your data to be able to use timeserisAI, I've prepared a short tutorial to address this.

There are endless options in terms of how your source data may be stored, so I'll cover a few of the most frequent ones I've seen. I may be expanding this in the future if needed.
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
computer_setup()
# Output:
#   os             : Darwin-19.6.0-x86_64-i386-64bit

#   python         : 3.6.13

#   tsai           : 0.2.23

#   fastai         : 2.5.3

#   fastcore       : 1.3.27

#   torch          : 1.9.1

#   n_cpus         : 8

#   device         : cpu


"""
## Required input shape 🔶
"""

"""
To be able to use timeseriesAI your data needs to have 3 dimensions: 

* **number of samples**
* **number of features** (aka variables, dimensions, channels)
* **number of steps** (or length, time steps, sequence steps)

There are a few convenience functions that you may want to use to prepare your data. 

We are going to see how you could prepare your data in a few scenarios. 
"""

"""
**Note: I've recently modified timeseriesAI so that you can also use 2d input data in the case of univariate time series (they'll be converted to 3d internally), although you can still pass univariate time series as 3d or pass them if you prefer. You'll get the same result.**
"""

"""
## UCR time series data ⏳
"""

"""
The easiest case if if you want to use some of the data already preprocessed in timeseriesAI (all UCR datasets have been included). In this case, the only thing you need to do is:

* select a univariate or multivariate dataset from the list
* use the get_UCR_data function
"""

print('univariate datasets: ', get_UCR_univariate_list())
# Output:
#   univariate datasets:  ['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', 'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf', 'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves', 'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga']


print('multivariate datasets: ', get_UCR_multivariate_list())
# Output:
#   multivariate datasets:  ['ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions', 'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms', 'Epilepsy', 'ERing', 'EthanolConcentration', 'FaceDetection', 'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat', 'InsectWingbeat', 'JapaneseVowels', 'Libras', 'LSST', 'MotorImagery', 'NATOPS', 'PEMS-SF', 'PenDigits', 'PhonemeSpectra', 'RacketSports', 'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits', 'StandWalkJump', 'UWaveGestureLibrary']


ds_name = 'NATOPS' 
X, y, splits = get_UCR_data(ds_name, return_split=False)
X.shape, y.shape, splits
# Output:
#   ((360, 24, 51),

#    (360,),

#    ((#180) [0,1,2,3,4,5,6,7,8,9...],

#     (#180) [180,181,182,183,184,185,186,187,188,189...]))

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#360) [(TSTensor(vars:24, len:51, device=cpu), TensorCategory(3)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(3)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(4)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(5)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(1))] ...]

"""
As you can see, X has 3 dimensions: 

* 360 samples
* 24 features
* 51 time steps

Let's visualize of the samples:
"""

plt.plot(X[0].T);
# Output:
#   <Figure size 432x288 with 1 Axes>

"""
## 2d or 3d np.ndarray/ torch.Tensor ⌗
"""

"""
Another option is that you have your data as an array or a tensor. 
In this case, the only thing you'll need to do is to transform your data to 3d (if not already done), and generate your splits.
We are going to simulate this scenario generating 2d data for a univariate dataset: 
"""

ds_name = 'OliveOil' 
X, y, _ = get_UCR_data(ds_name, return_split=False)
X_2d = X[:, 0]
X_2d.shape, y.shape
# Output:
#   ((60, 570), (60,))

"""
To make data 3d you use `to3d`:
"""

X_3d = to3d(X_2d)
X_3d.shape
# Output:
#   (60, 1, 570)

"""
To generate your splits, you would use `get_splits`. Here you need to indicate: 
* valid_size=0.2
* test_size (optional)
* stratify=True if you want stratified splits
* random_state=seed or None (random)
"""

splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=True)
splits
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   ((#48) [58,21,9,45,41,54,56,46,44,53...],

#    (#12) [55,38,40,18,16,24,3,28,50,14...])

X_3d.shape, y.shape, splits
# Output:
#   ((60, 1, 570),

#    (60,),

#    ((#48) [58,21,9,45,41,54,56,46,44,53...],

#     (#12) [55,38,40,18,16,24,3,28,50,14...]))

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_3d, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#60) [(TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3))] ...]

"""
In fastai I've modified TS datasets so that you can pass univariate time series as a 2d or 3d arrays.
"""

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X_2d, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#60) [(TSTensor(len:570, device=cpu), TensorCategory(3)), (TSTensor(len:570, device=cpu), TensorCategory(3)), (TSTensor(len:570, device=cpu), TensorCategory(1)), (TSTensor(len:570, device=cpu), TensorCategory(2)), (TSTensor(len:570, device=cpu), TensorCategory(1)), (TSTensor(len:570, device=cpu), TensorCategory(3)), (TSTensor(len:570, device=cpu), TensorCategory(3)), (TSTensor(len:570, device=cpu), TensorCategory(2)), (TSTensor(len:570, device=cpu), TensorCategory(2)), (TSTensor(len:570, device=cpu), TensorCategory(3))] ...]

"""
### Pre-split 2d or 3d np.ndarray/ torch.Tensor
"""

"""
If your data is already split into Train and Valid/ Test, you may the use `get_predefined_split` to generate the splits:
"""

ds_name = 'OliveOil' 
X_train, y_train, X_valid, y_valid = get_UCR_data(ds_name, return_split=True)

X, y, splits = combine_split_data([X_train, X_valid], [y_train, y_valid])

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#60) [(TSTensor(vars:1, len:570, device=cpu), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(0)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1))] ...]

"""
## Pandas dataframe with samples as rows 🐼
"""

"""
### Univariate
"""

ds_name = 'OliveOil'
X, y, _ = get_UCR_data(ds_name, return_split=False)
X = X[:, 0]
y = y.reshape(-1, 1)
data = np.concatenate((X, y), axis=-1)
df = pd.DataFrame(data)
df = df.rename(columns={570: 'target'})
df.head()
# Output:
#                0            1            2            3           4  \

#   0   -0.6113753  -0.61058575  -0.60655695   -0.6011323  -0.5943146   

#   1  -0.61539173  -0.61372936   -0.6092278   -0.6043151  -0.5987679   

#   2  -0.61199886   -0.6105003    -0.606374   -0.6004454  -0.5930837   

#   3  -0.62278444   -0.6222215   -0.6190489   -0.6132514  -0.6058886   

#   4  -0.62179345  -0.62127197  -0.61729795  -0.61207414  -0.6054717   

#   

#                5            6            7            8            9  ...  \

#   0   -0.5857617  -0.57741904  -0.57017505  -0.56328535   -0.5574073  ...   

#   1  -0.59050655   -0.5816167   -0.5729264   -0.5653742   -0.5599074  ...   

#   2   -0.5852453    -0.577118  -0.56882674  -0.56159616  -0.55609345  ...   

#   3  -0.59750843    -0.589047  -0.58069694  -0.57282245    -0.566727  ...   

#   4   -0.5976075   -0.5891649   -0.5814236  -0.57462037   -0.5684105  ...   

#   

#              561          562          563          564          565  \

#   0   -0.9803849  -0.98032784   -0.9802198   -0.9806911  -0.98133653   

#   1  -0.97933495  -0.97952265  -0.98003805   -0.9811463    -0.982332   

#   2   -0.9796634   -0.9799643   -0.9805631   -0.9813258   -0.9827439   

#   3  -0.96990246  -0.97058576   -0.9707182  -0.97119683   -0.9722684   

#   4   -0.9778305    -0.978376   -0.9787776  -0.97965574  -0.98114824   

#   

#             566          567          568          569 target  

#   0  -0.9823362   -0.9832128  -0.98367214   -0.9831198      1  

#   1  -0.9825703   -0.9826299   -0.9828504   -0.9825495      1  

#   2  -0.9831074   -0.9830329  -0.98395646  -0.98385817      1  

#   3  -0.9726537   -0.9728614  -0.97367114   -0.9736139      1  

#   4  -0.9817956  -0.98133105   -0.9812891  -0.98133105      1  

#   

#   [5 rows x 571 columns]

X, y = df2xy(df, target_col='target')
test_eq(X.shape, (60, 1, 570))
test_eq(y.shape, (60, ))

splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=True)
splits
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   ((#48) [58,21,9,45,41,54,56,46,44,53...],

#    (#12) [55,38,40,18,16,24,3,28,50,14...])

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#60) [(TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(1)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(2)), (TSTensor(vars:1, len:570, device=cpu), TensorCategory(3))] ...]

"""
### Multivariate
"""

ds_name = 'OliveOil'
X, y, _ = get_UCR_data(ds_name, return_split=False)
X = X[:, 0]
y = y.reshape(-1, 1)
data = np.concatenate((X, y), axis=-1)
df = pd.DataFrame(data).astype(float)
df = df.rename(columns={570: 'target'})
df1 = pd.concat([df, df + 10, df + 100], axis=0).reset_index(drop=False)
df2 = pd.DataFrame(np.array([1] * 60 + [2] * 60 + [3] * 60), columns=['feature'])
df = pd.merge(df2, df1, left_index=True, right_index=True)
df
# Output:
#        feature  index          0          1          2          3          4  \

#   0          1      0  -0.611375  -0.610586  -0.606557  -0.601132  -0.594315   

#   1          1      1  -0.615392  -0.613729  -0.609228  -0.604315  -0.598768   

#   2          1      2  -0.611999  -0.610500  -0.606374  -0.600445  -0.593084   

#   3          1      3  -0.622784  -0.622221  -0.619049  -0.613251  -0.605889   

#   4          1      4  -0.621793  -0.621272  -0.617298  -0.612074  -0.605472   

#   ..       ...    ...        ...        ...        ...        ...        ...   

#   175        3     55  99.377066  99.378307  99.383004  99.389189  99.396304   

#   176        3     56  99.390295  99.392517  99.397438  99.402816  99.409873   

#   177        3     57  99.387922  99.390261  99.394830  99.400812  99.407458   

#   178        3     58  99.390348  99.391047  99.394922  99.401168  99.408396   

#   179        3     59  99.377725  99.378153  99.381078  99.385643  99.392011   

#   

#                5          6          7  ...        561        562        563  \

#   0    -0.585762  -0.577419  -0.570175  ...  -0.980385  -0.980328  -0.980220   

#   1    -0.590507  -0.581617  -0.572926  ...  -0.979335  -0.979523  -0.980038   

#   2    -0.585245  -0.577118  -0.568827  ...  -0.979663  -0.979964  -0.980563   

#   3    -0.597508  -0.589047  -0.580697  ...  -0.969902  -0.970586  -0.970718   

#   4    -0.597607  -0.589165  -0.581424  ...  -0.977831  -0.978376  -0.978778   

#   ..         ...        ...        ...  ...        ...        ...        ...   

#   175  99.405102  99.414323  99.422454  ...  99.033363  99.032615  99.032609   

#   176  99.418803  99.427823  99.436244  ...  99.023249  99.022934  99.022428   

#   177  99.416016  99.425299  99.433606  ...  99.026371  99.026007  99.025971   

#   178  99.416801  99.425483  99.433159  ...  99.024331  99.023934  99.023716   

#   179  99.400396  99.408790  99.416355  ...  99.030874  99.030576  99.030334   

#   

#              564        565        566        567        568        569  target  

#   0    -0.980691  -0.981337  -0.982336  -0.983213  -0.983672  -0.983120     1.0  

#   1    -0.981146  -0.982332  -0.982570  -0.982630  -0.982850  -0.982549     1.0  

#   2    -0.981326  -0.982744  -0.983107  -0.983033  -0.983956  -0.983858     1.0  

#   3    -0.971197  -0.972268  -0.972654  -0.972861  -0.973671  -0.973614     1.0  

#   4    -0.979656  -0.981148  -0.981796  -0.981331  -0.981289  -0.981331     1.0  

#   ..         ...        ...        ...        ...        ...        ...     ...  

#   175  99.032021  99.031171  99.031198  99.030609  99.030441  99.030480   104.0  

#   176  99.021527  99.020822  99.020762  99.020462  99.019507  99.019367   104.0  

#   177  99.025246  99.024581  99.024234  99.023587  99.023002  99.023483   104.0  

#   178  99.022909  99.021966  99.021285  99.021127  99.020634  99.020106   104.0  

#   179  99.029671  99.028706  99.028079  99.027955  99.026948  99.026330   104.0  

#   

#   [180 rows x 573 columns]

X, y = df2xy(df, sample_col='index', feat_col='feature', target_col='target', data_cols=None)
test_eq(X.shape, (60, 3, 570))
test_eq(y.shape, (60, 3))

splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=True)
splits
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   ((#48) [58,21,9,45,41,54,56,46,44,53...],

#    (#12) [55,38,40,18,16,24,3,28,50,14...])

tfms  = [None, TSRegression()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   (#60) [(TSTensor(vars:3, len:570, device=cpu), tensor([  4.,  14., 104.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  4.,  14., 104.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  2.,  12., 102.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  3.,  13., 103.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  2.,  12., 102.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  4.,  14., 104.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  4.,  14., 104.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  3.,  13., 103.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  3.,  13., 103.])), (TSTensor(vars:3, len:570, device=cpu), tensor([  4.,  14., 104.]))] ...]

"""
## Single, long time series 🤥
"""

"""
Sometimes, instead of having the data already split into samples, you only have a single (univariate or multivariate) time series that you need to split. 
The recommended way to do this is to use a sliding window. In `timeseriesAI`there is a function called `SlidingWindow`that performs this task in a flexible way.

This function applies a sliding window to a 1d or 2d input (np.ndarray, torch.Tensor or pd.DataFrame). 
   
* Args:
    * window_length   = length of lookback window
    * stride          = n datapoints the window is moved ahead along the sequence. Default: 1. If None, stride=window_length (no overlap)
    * horizon         = number of future datapoints to predict. 0 for last step in the selected window. > 0 for future steps. List for several steps.
    * get_x          = indices of columns that contain the independent variable (xs). If get_x=None, all data will be used as x
    * get_y          = indices of columns that contain the target (ys). If y_idx is None, no y will be returned
    * seq_first       = True if input shape (seq_len, n_vars), False if input shape (n_vars, seq_len)
    * random_start    = determines the step where the first window is applied: 0 (default), a given step (int), or random within the 1st stride (None). 

* Input:
    * shape: (seq_len, ) or (seq_len, n_vars) if seq_first=True else (n_vars, seq_len)
"""

"""
### Univariate
"""

"""
You may use it just without a target
"""

window_length = 5
t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length)(t)
test_eq(X.shape, ((95, 1, 5)))
# Output:
#   input shape: (100,)


"""
If the target is the next step in the univariate time series set `horizon=1`:
"""

window_length = 5
horizon = 1

t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, horizon=horizon)(t)
test_eq(X.shape, ((95, 1, 5)))
test_eq(y.shape, ((95,)))
# Output:
#   input shape: (100,)


"""
Horizon may be > 1 to select multiple steps in the future:
"""

window_length = 5
horizon = 2

t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, horizon=horizon)(t)
test_eq(X.shape, ((94, 1, 5)))
test_eq(y.shape, ((94, 2)))
# Output:
#   input shape: (100,)


"""
To have non-overlapping samples, we need to set `stride=None`:
"""

window_length = 5
stride = None
horizon = 1
t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, stride=stride, horizon=horizon)(t)
test_eq(X.shape, ((19, 1, 5)))
test_eq(y.shape, ((19, )))
# Output:
#   input shape: (100,)


window_length = 5
stride = 3
horizon = 1
t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, stride=stride, horizon=horizon)(t)
test_eq(X.shape, ((32, 1, 5)))
test_eq(y.shape, ((32, )))
# Output:
#   input shape: (100,)


"""
We can also decide where to start the sliding window using `start`: 
"""

window_length = 5
stride = None
horizon = 1
t = np.arange(100)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, stride=stride, start=20, horizon=horizon)(t)
test_eq(X.shape, ((15, 1, 5)))
test_eq(y.shape, ((15, )))
# Output:
#   input shape: (100,)


"""
If the time series is of shape (1, seq_len) we need to set `seq_first=False`
"""

window_length = 5
stride = 3
horizon = 1
t = np.arange(100).reshape(1, -1)
print('input shape:', t.shape)
X, y = SlidingWindow(window_length, stride=stride, horizon=horizon, seq_first=False)(t)
test_eq(X.shape, ((32, 1, 5)))
test_eq(y.shape, ((32, )))
# Output:
#   input shape: (1, 100)


"""
Your univariate time series may be in a pandas DataFrame:
"""

window_length = 5
stride = None
horizon=1

t = np.arange(20)
df = pd.DataFrame(t, columns=['var'])
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, stride=stride, horizon=horizon)(df)
test_eq(X.shape, ((3, 1, 5)))
test_eq(y.shape, ((3, )))
# Output:
#   input shape: (20, 1)

#       var

#   0     0

#   1     1

#   2     2

#   3     3

#   4     4

#   5     5

#   6     6

#   7     7

#   8     8

#   9     9

#   10   10

#   11   11

#   12   12

#   13   13

#   14   14

#   15   15

#   16   16

#   17   17

#   18   18

#   19   19

window_length = 5
stride = None
horizon=1

t = np.arange(20)
df = pd.DataFrame(t, columns=['var']).T
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, stride=stride, horizon=horizon, seq_first=False)(df)
test_eq(X.shape, ((3, 1, 5)))
test_eq(y.shape, ((3, )))
# Output:
#   input shape: (1, 20)

#        0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  \

#   var   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17   

#   

#        18  19  

#   var  18  19  

"""
### Multivariate
"""

"""
When using multivariate data, all parameters shown before work in the same way, but you always need to indicate how to get the X data and the y data (as there are multiple features). To do that, we'll use get_x and get_y. 

By default get_x is set to None, which means that all features will be used.
By default get_y is set to None, which means that all features will be used as long as horizon > 0 (to avoid leakage).

If you get the time series in a np.ndarray or a torch.Tensor, you should use integers, a list or slice as get_x/ get_y.
"""

window_length = 5
stride = None
n_vars = 3

t = (np.random.rand(1000, n_vars) - .5).cumsum(0)
print(t.shape)
plt.plot(t)
plt.show()
X, y = SlidingWindow(window_length, stride=stride, get_x=[0,1], get_y=2)(t)
test_eq(X.shape, ((199, 2, 5)))
test_eq(y.shape, ((199, )))
# Output:
#   (1000, 3)

#   <Figure size 432x288 with 1 Axes>

window_length = 5
n_vars = 3

t = (torch.stack(n_vars * [torch.arange(10)]).T * tensor([1, 10, 100]))
df = pd.DataFrame(t, columns=[f'var_{i}' for i in range(n_vars)])
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length)(df)
test_eq(X.shape, ((5, 3, 5)))
test_eq(y.shape, ((5, 3)))
# Output:
#   input shape: (10, 3)

#          var_0       var_1        var_2

#   0  tensor(0)   tensor(0)    tensor(0)

#   1  tensor(1)  tensor(10)  tensor(100)

#   2  tensor(2)  tensor(20)  tensor(200)

#   3  tensor(3)  tensor(30)  tensor(300)

#   4  tensor(4)  tensor(40)  tensor(400)

#   5  tensor(5)  tensor(50)  tensor(500)

#   6  tensor(6)  tensor(60)  tensor(600)

#   7  tensor(7)  tensor(70)  tensor(700)

#   8  tensor(8)  tensor(80)  tensor(800)

#   9  tensor(9)  tensor(90)  tensor(900)

window_length = 5
n_vars = 3
horizon = 1

t = (torch.stack(n_vars * [torch.arange(10)]).T * tensor([1, 10, 100]))
df = pd.DataFrame(t, columns=[f'var_{i}' for i in range(n_vars)])
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, horizon=horizon)(df)
test_eq(X.shape, ((5, 3, 5)))
test_eq(y.shape, ((5, 3)))
# Output:
#   input shape: (10, 3)

#          var_0       var_1        var_2

#   0  tensor(0)   tensor(0)    tensor(0)

#   1  tensor(1)  tensor(10)  tensor(100)

#   2  tensor(2)  tensor(20)  tensor(200)

#   3  tensor(3)  tensor(30)  tensor(300)

#   4  tensor(4)  tensor(40)  tensor(400)

#   5  tensor(5)  tensor(50)  tensor(500)

#   6  tensor(6)  tensor(60)  tensor(600)

#   7  tensor(7)  tensor(70)  tensor(700)

#   8  tensor(8)  tensor(80)  tensor(800)

#   9  tensor(9)  tensor(90)  tensor(900)

"""
You may also get the target from a different column: 
"""

window_length = 5
n_vars = 3

t = (torch.stack(n_vars * [torch.arange(10)]).T * tensor([1, 10, 100]))
columns=[f'var_{i}' for i in range(n_vars-1)]+['target']
df = pd.DataFrame(t, columns=columns)
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, get_x=columns[:-1], get_y='target')(df)
test_eq(X.shape, ((5, 2, 5)))
test_eq(y.shape, ((5, )))
# Output:
#   input shape: (10, 3)

#          var_0       var_1       target

#   0  tensor(0)   tensor(0)    tensor(0)

#   1  tensor(1)  tensor(10)  tensor(100)

#   2  tensor(2)  tensor(20)  tensor(200)

#   3  tensor(3)  tensor(30)  tensor(300)

#   4  tensor(4)  tensor(40)  tensor(400)

#   5  tensor(5)  tensor(50)  tensor(500)

#   6  tensor(6)  tensor(60)  tensor(600)

#   7  tensor(7)  tensor(70)  tensor(700)

#   8  tensor(8)  tensor(80)  tensor(800)

#   9  tensor(9)  tensor(90)  tensor(900)

window_length = 5
n_vars = 5
horizon = 1

t = (torch.stack(n_vars * [torch.arange(10)]).T * tensor([10**i for i in range(n_vars)]))
columns=[f'var_{i}' for i in range(n_vars-1)]+['target']
df = pd.DataFrame(t, columns=columns)
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, horizon=horizon, get_x=columns[:-1], get_y='target')(df)
test_eq(X.shape, ((5, 4, 5)))
test_eq(y.shape, ((5, )))
# Output:
#   input shape: (10, 5)

#          var_0       var_1        var_2         var_3         target

#   0  tensor(0)   tensor(0)    tensor(0)     tensor(0)      tensor(0)

#   1  tensor(1)  tensor(10)  tensor(100)  tensor(1000)  tensor(10000)

#   2  tensor(2)  tensor(20)  tensor(200)  tensor(2000)  tensor(20000)

#   3  tensor(3)  tensor(30)  tensor(300)  tensor(3000)  tensor(30000)

#   4  tensor(4)  tensor(40)  tensor(400)  tensor(4000)  tensor(40000)

#   5  tensor(5)  tensor(50)  tensor(500)  tensor(5000)  tensor(50000)

#   6  tensor(6)  tensor(60)  tensor(600)  tensor(6000)  tensor(60000)

#   7  tensor(7)  tensor(70)  tensor(700)  tensor(7000)  tensor(70000)

#   8  tensor(8)  tensor(80)  tensor(800)  tensor(8000)  tensor(80000)

#   9  tensor(9)  tensor(90)  tensor(900)  tensor(9000)  tensor(90000)

window_length = 4
n_vars = 5
seq_len = 100
horizon = 1

t1 = (np.random.rand(seq_len, n_vars-1) - .5).cumsum(0)
t2 = np.random.randint(0, 10, (seq_len,1))
t = np.concatenate((t1, t2), axis=-1)
columns=[f'var_{i}' for i in range(n_vars-1)]+['target']
df = pd.DataFrame(t, columns=columns)
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, horizon=horizon, get_x=columns[:-1], get_y='target')(df)
splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=False)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   input shape: (100, 5)

#          var_0     var_1     var_2     var_3  target

#   0  -0.278922 -0.090157  0.107557 -0.331229     0.0

#   1  -0.439346 -0.393919  0.276158 -0.230226     8.0

#   2  -0.335883 -0.572737  0.272000  0.254256     5.0

#   3  -0.630172 -0.865450 -0.056542  0.086401     2.0

#   4  -0.793439 -0.649630 -0.376331  0.210082     2.0

#   ..       ...       ...       ...       ...     ...

#   95  0.958701  0.647505  2.281029  7.588593     3.0

#   96  0.469621  0.733098  2.399453  7.154065     3.0

#   97  0.536770  0.994313  2.125393  7.445057     9.0

#   98  0.971073  0.661072  2.073313  7.867993     5.0

#   99  1.390952  0.549541  2.475450  7.624701     8.0

#   

#   [100 rows x 5 columns]
#   <Figure size 1152x36 with 1 Axes>
#   (#96) [(TSTensor(vars:4, len:4, device=cpu), TensorCategory(2)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(5)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(4)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(9)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(0)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(8)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(0)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(7)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(7)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(4))] ...]

dsets[0][0].data, dsets[0][1].data
# Output:
#   (tensor([[-0.2789, -0.4393, -0.3359, -0.6302],

#            [-0.0902, -0.3939, -0.5727, -0.8654],

#            [ 0.1076,  0.2762,  0.2720, -0.0565],

#            [-0.3312, -0.2302,  0.2543,  0.0864]]),

#    TensorCategory(2))

window_length = 4
start = 3
n_vars = 5
seq_len = 100
horizon = 0

t1 = (np.random.rand(seq_len, n_vars-1) - .5).cumsum(0)
t2 = np.random.randint(0, 10, (seq_len,1))
t = np.concatenate((t1, t2), axis=-1)
columns=[f'var_{i}' for i in range(n_vars-1)]+['target']
df = pd.DataFrame(t, columns=columns).T
print('input shape:', df.shape)
display(df)
X, y = SlidingWindow(window_length, start=start, horizon=horizon, get_x=columns[:-1], get_y='target', seq_first=False)(df)
splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=False)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dsets
# Output:
#   input shape: (5, 100)

#                 0         1         2         3         4         5         6   \

#   var_0  -0.396826 -0.584793 -0.753035 -1.235078 -1.175882 -0.858514 -1.014738   

#   var_1   0.101784  0.140790 -0.166500 -0.262055 -0.401538  0.015751 -0.227840   

#   var_2   0.347239  0.509674  0.354078  0.252386  0.441122  0.842774  1.123163   

#   var_3  -0.440455 -0.246624  0.192573  0.573121  0.191180  0.424844  0.244777   

#   target  9.000000  2.000000  3.000000  2.000000  6.000000  8.000000  9.000000   

#   

#                 7         8         9   ...        90        91        92  \

#   var_0  -0.988155 -1.286932 -1.338068  ... -0.655102 -0.416278 -0.567191   

#   var_1  -0.124859  0.304027  0.686724  ...  3.522454  3.707845  3.302698   

#   var_2   0.684701  0.235142  0.070800  ... -0.612066 -0.588531 -0.690947   

#   var_3  -0.060199 -0.522611 -0.345458  ...  1.286289  1.525926  1.131440   

#   target  2.000000  2.000000  3.000000  ...  6.000000  5.000000  7.000000   

#   

#                 93        94        95        96        97        98        99  

#   var_0  -0.563334 -0.223816 -0.692494 -0.342047 -0.678553 -0.818982 -0.395287  

#   var_1   3.501154  3.150482  3.033596  2.931937  2.812061  2.997631  3.144549  

#   var_2  -1.007796 -0.673262 -0.387539 -0.857754 -1.226365 -0.996411 -0.800580  

#   var_3   0.790336  0.796382  0.752800  0.843915  0.646929  1.094649  0.820380  

#   target  0.000000  4.000000  4.000000  7.000000  2.000000  4.000000  0.000000  

#   

#   [5 rows x 100 columns]
#   <Figure size 1152x36 with 1 Axes>
#   (#94) [(TSTensor(vars:4, len:4, device=cpu), TensorCategory(9)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(2)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(2)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(3)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(6)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(1)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(2)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(9)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(7)), (TSTensor(vars:4, len:4, device=cpu), TensorCategory(3))] ...]

dsets[0][0].data, dsets[0][1].data
# Output:
#   (tensor([[-1.2351, -1.1759, -0.8585, -1.0147],

#            [-0.2621, -0.4015,  0.0158, -0.2278],

#            [ 0.2524,  0.4411,  0.8428,  1.1232],

#            [ 0.5731,  0.1912,  0.4248,  0.2448]]),

#    TensorCategory(9))

"""
## End-to-end example 🎬
"""

"""
### Data split by sample
"""

"""
This is a example using real data where the dataframe already has the data split by sample. Let's first simulate how you could get the pandas df.

In this case, you only need to convert the dataframe format to X and y using `df2xy`as we have seen before.
"""

ds_name = 'NATOPS' 
X, y, splits = get_UCR_data(ds_name, return_split=False)
data = np.concatenate((np.arange(len(X)).repeat(X.shape[1]).reshape(-1,1), np.tile(np.arange(X.shape[1]), len(X)).reshape(-1,1)), axis=1)
df1 = pd.DataFrame(data, columns=['sample', 'feature'])
df2 = pd.DataFrame(X.reshape(-1, 51))
df3 = pd.DataFrame(np.repeat(y, X.shape[1]), columns=['target'])
df = df1.merge(df2, left_index=True, right_index=True)
df = df.merge(df3, left_index=True, right_index=True)
df
# Output:
#         sample  feature         0         1         2         3         4  \

#   0          0        0 -0.372758 -0.367844 -0.378445 -0.386751 -0.417101   

#   1          0        1 -1.821679 -1.841987 -1.821358 -1.845643 -1.941721   

#   2          0        2 -0.846321 -0.846325 -0.839571 -0.848031 -0.885500   

#   3          0        3  0.465208  0.467033  0.471135  0.506153  0.611207   

#   4          0        4 -2.015072 -2.007557 -2.010042 -2.032552 -1.953282   

#   ...      ...      ...       ...       ...       ...       ...       ...   

#   8635     359       19 -1.658398 -1.617639 -1.623446 -1.690049 -1.596608   

#   8636     359       20 -0.679048 -0.654021 -0.656639 -0.711966 -0.742536   

#   8637     359       21  0.499991  0.390842  0.396292  0.395197  0.441420   

#   8638     359       22 -1.664080 -1.725331 -1.686976 -1.650568 -1.716866   

#   8639     359       23 -0.733138 -0.718382 -0.705195 -0.694358 -0.675056   

#   

#                5         6         7  ...        42        43        44  \

#   0    -0.447204 -0.423585 -0.318506  ... -0.477529 -0.487402 -0.485995   

#   1    -2.005778 -1.817611 -1.560247  ... -1.843810 -1.830620 -1.820712   

#   2    -1.002093 -1.227122 -1.452898  ... -0.737160 -0.750605 -0.727674   

#   3     0.697417  0.721512  0.652092  ...  0.510333  0.412795  0.412242   

#   4    -1.861078 -1.699443 -1.253402  ... -1.953984 -2.004474 -1.991646   

#   ...        ...       ...       ...  ...       ...       ...       ...   

#   8635 -1.631068 -1.524069 -1.515474  ... -1.195383 -1.413512 -1.810155   

#   8636 -0.748806 -0.806330 -0.913220  ... -0.841650 -0.782175 -0.734422   

#   8637  0.881352  1.140342  1.473447  ...  1.686165  1.448840  1.241460   

#   8638 -1.749081 -1.737207 -1.571937  ... -1.136640 -1.347163 -1.513772   

#   8639 -0.671773 -0.556493 -0.490029  ... -0.367544 -0.473136 -0.591317   

#   

#               45        46        47        48        49        50  target  

#   0    -0.480247 -0.496073 -0.491603 -0.537007 -0.475939 -0.479505     4.0  

#   1    -1.781465 -1.804775 -1.799706 -1.751323 -1.772353 -1.761632     4.0  

#   2    -0.726221 -0.749053 -0.776479 -0.603740 -0.763048 -0.793202     4.0  

#   3     0.455973  0.446786  0.425194  0.434855  0.468405  0.460464     4.0  

#   4    -1.997254 -1.998531 -1.976082 -1.960404 -2.006394 -1.969680     4.0  

#   ...        ...       ...       ...       ...       ...       ...     ...  

#   8635 -1.614774 -1.684754 -1.659315 -1.705025 -1.678066 -1.641795     4.0  

#   8636 -0.684311 -0.651485 -0.660619 -0.690759 -0.716252 -0.704824     4.0  

#   8637  1.038313  0.870652  0.754220  0.568415  0.550804  0.562437     4.0  

#   8638 -1.617310 -1.659452 -1.727294 -1.877402 -1.903281 -1.895895     4.0  

#   8639 -0.588854 -0.607189 -0.618963 -0.412571 -0.472645 -0.454302     4.0  

#   

#   [8640 rows x 54 columns]

"""
In this case, we can shuffle the data as the individual time series are independent from the rest.
"""

def y_func(o): return o[0]
X, y = df2xy(df, sample_col='sample', feat_col='feature', target_col='target', data_cols=df.columns[2:-1], y_func=y_func)
splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=True)
tfms  = [None, TSClassification()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dsets
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   (#360) [(TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0))] ...]

"""
### Single multivariate time series
"""

"""
In this second scenario, we have a single time series, and we'll need to decide how to create the individual samples using the `SlidingWindow`function.

This is how you could get the dataframe, with many columns for each feature, and a target.
"""

ds_name = 'NATOPS' 
X, y, splits = get_UCR_data(ds_name, return_split=False)
data = X.transpose(1,0,2).reshape(X.shape[1], -1)
print(X.shape, data.shape)
df = pd.DataFrame(data).T
df2 = pd.DataFrame(np.repeat(y, X.shape[2]), columns=['target'])
df = df.merge(df2, left_index=True, right_index=True)
df
# Output:
#   (360, 24, 51) (24, 18360)

#                 0         1         2         3         4         5         6  \

#   0     -0.372758 -1.821679 -0.846321  0.465208 -2.015072 -0.839242 -0.564097   

#   1     -0.367844 -1.841987 -0.846325  0.467033 -2.007557 -0.838151 -0.564499   

#   2     -0.378445 -1.821358 -0.839571  0.471135 -2.010042 -0.832021 -0.563753   

#   3     -0.386751 -1.845643 -0.848031  0.506153 -2.032552 -0.841696 -0.565008   

#   4     -0.417101 -1.941721 -0.885500  0.611207 -1.953282 -0.902529 -0.573550   

#   ...         ...       ...       ...       ...       ...       ...       ...   

#   18355 -0.845492 -1.919878 -0.583276  0.856647 -1.978063 -0.553987 -0.790264   

#   18356 -0.761116 -1.945017 -0.587023  0.680567 -1.992559 -0.566642 -0.759338   

#   18357 -0.679080 -1.933950 -0.615705  0.574144 -1.986102 -0.572386 -0.741427   

#   18358 -0.670308 -1.916436 -0.634439  0.478221 -2.078024 -0.620835 -0.731334   

#   18359 -0.651644 -1.911442 -0.656298  0.469341 -2.086228 -0.644960 -0.725837   

#   

#                 7         8         9  ...        15        16        17  \

#   0     -0.796225 -0.149604  0.599967  ...  0.577993 -1.534954 -0.673190   

#   1     -0.797622 -0.150012  0.597535  ...  0.576627 -1.532795 -0.671919   

#   2     -0.795704 -0.151608  0.597007  ...  0.576456 -1.532478 -0.671555   

#   3     -0.790238 -0.152350  0.599099  ...  0.579362 -1.535441 -0.672198   

#   4     -0.799730 -0.169575  0.606181  ...  0.626759 -1.482552 -0.659393   

#   ...         ...       ...       ...  ...       ...       ...       ...   

#   18355 -0.770808 -0.075527  0.673925  ...  0.857950 -1.527194 -0.315056   

#   18356 -0.790078 -0.090382  0.630602  ...  0.737224 -1.501386 -0.315699   

#   18357 -0.793610 -0.100764  0.607822  ...  0.659843 -1.503965 -0.324704   

#   18358 -0.790556 -0.109856  0.600801  ...  0.597387 -1.612530 -0.412526   

#   18359 -0.787746 -0.116215  0.597154  ...  0.591917 -1.623406 -0.413167   

#   

#                18        19        20        21        22        23  target  

#   0     -0.536343 -1.626957 -0.594337  0.619205 -1.771773 -0.810086     4.0  

#   1     -0.533816 -1.642514 -0.605328  0.617045 -1.796660 -0.818863     4.0  

#   2     -0.526319 -1.697145 -0.624302  0.624789 -1.738568 -0.788060     4.0  

#   3     -0.554538 -1.644413 -0.602884  0.634100 -1.749744 -0.816695     4.0  

#   4     -0.576196 -1.763092 -0.694843  0.680086 -1.664565 -0.857897     4.0  

#   ...         ...       ...       ...       ...       ...       ...     ...  

#   18355 -0.889773 -1.684754 -0.651485  0.870652 -1.659452 -0.607189     4.0  

#   18356 -0.642052 -1.659315 -0.660619  0.754220 -1.727294 -0.618963     4.0  

#   18357 -0.609636 -1.705025 -0.690759  0.568415 -1.877402 -0.412571     4.0  

#   18358 -0.560203 -1.678066 -0.716252  0.550804 -1.903281 -0.472645     4.0  

#   18359 -0.557817 -1.641795 -0.704824  0.562437 -1.895895 -0.454302     4.0  

#   

#   [18360 rows x 25 columns]

"""
In this case, you'll need to set the following parameters:
 
* window_length
* stride
* start
* horizon
* get_x
* get_y
* seq_first

You also need to bear in mind that you sould set shuffle=False when using splits since the individual time series are correlated with rest.
"""

window_length = X.shape[-1]  # window_length is usually selected based on prior domain knowledge or by trial and error
stride = None                # None for non-overlapping (stride = window_length) (default = 1). This depends on how often you want to predict once the model is trained
start = 0                    # use all data since the first time stamp (default = 0)
get_x = df.columns[:-1]      # Indicates which are the columns that contain the x data.
get_y = 'target'             # In multivariate time series, you must indicate which is/are the y columns
horizon = 0                  # 0 means y is taken from the last time stamp of the time sequence (default = 0)
seq_first = True
                            
X, y = SlidingWindow(window_length, stride=stride, start=start, get_x=get_x,  get_y=get_y, horizon=horizon, seq_first=seq_first)(df)
splits = get_splits(y, valid_size=.2, stratify=True, random_state=23, shuffle=False)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dsets
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   (#360) [(TSTensor(vars:24, len:51, device=cpu), TensorCategory(3)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(3)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(4)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(0)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(5)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(2)), (TSTensor(vars:24, len:51, device=cpu), TensorCategory(1))] ...]

beep()
# Output:
#   <IPython.lib.display.Audio object>



================================================
FILE: tutorial_nbs/01_Intro_to_Time_Series_Classification.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/01_Intro_to_Time_Series_Classification.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## Purpose 😇
"""

"""
The purpose of this notebook is to show you how you can create a simple, end-to-end, state-of-the-art time series classification model using the great **fastai-v2** library in 5 steps:
1. Import libraries
2. Prepare data
3. Build learner
4. Train model
5. Inference (predictions) on additional data

In general, there are 3 main ways to classify time series, based on the input to the neural network:

- raw data

- image data (encoded from raw data)

- feature data (extracted from raw data)

In this notebook, we will use the first approach.
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
import sklearn.metrics as skm
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
## Prepare data 🔢
"""

"""
### Download data ⬇️
"""

"""
In this notebook, we'll use one of the most widely used time series classification databases: UEA & UCR Time Series Classification Repository. As of Sep 2019 it contains 128 univariate datasets and 30 multivariate datasets.

"""

print(get_UCR_univariate_list())
# Output:
#   ['ACSF1', 'Adiac', 'AllGestureWiimoteX', 'AllGestureWiimoteY', 'AllGestureWiimoteZ', 'ArrowHead', 'Beef', 'BeetleFly', 'BirdChicken', 'BME', 'Car', 'CBF', 'Chinatown', 'ChlorineConcentration', 'CinCECGTorso', 'Coffee', 'Computers', 'CricketX', 'CricketY', 'CricketZ', 'Crop', 'DiatomSizeReduction', 'DistalPhalanxOutlineAgeGroup', 'DistalPhalanxOutlineCorrect', 'DistalPhalanxTW', 'DodgerLoopDay', 'DodgerLoopGame', 'DodgerLoopWeekend', 'Earthquakes', 'ECG200', 'ECG5000', 'ECGFiveDays', 'ElectricDevices', 'EOGHorizontalSignal', 'EOGVerticalSignal', 'EthanolLevel', 'FaceAll', 'FaceFour', 'FacesUCR', 'FiftyWords', 'Fish', 'FordA', 'FordB', 'FreezerRegularTrain', 'FreezerSmallTrain', 'Fungi', 'GestureMidAirD1', 'GestureMidAirD2', 'GestureMidAirD3', 'GesturePebbleZ1', 'GesturePebbleZ2', 'GunPoint', 'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'Ham', 'HandOutlines', 'Haptics', 'Herring', 'HouseTwenty', 'InlineSkate', 'InsectEPGRegularTrain', 'InsectEPGSmallTrain', 'InsectWingbeatSound', 'ItalyPowerDemand', 'LargeKitchenAppliances', 'Lightning2', 'Lightning7', 'Mallat', 'Meat', 'MedicalImages', 'MelbournePedestrian', 'MiddlePhalanxOutlineAgeGroup', 'MiddlePhalanxOutlineCorrect', 'MiddlePhalanxTW', 'MixedShapesRegularTrain', 'MixedShapesSmallTrain', 'MoteStrain', 'NonInvasiveFetalECGThorax1', 'NonInvasiveFetalECGThorax2', 'OliveOil', 'OSULeaf', 'PhalangesOutlinesCorrect', 'Phoneme', 'PickupGestureWiimoteZ', 'PigAirwayPressure', 'PigArtPressure', 'PigCVP', 'PLAID', 'Plane', 'PowerCons', 'ProximalPhalanxOutlineAgeGroup', 'ProximalPhalanxOutlineCorrect', 'ProximalPhalanxTW', 'RefrigerationDevices', 'Rock', 'ScreenType', 'SemgHandGenderCh2', 'SemgHandMovementCh2', 'SemgHandSubjectCh2', 'ShakeGestureWiimoteZ', 'ShapeletSim', 'ShapesAll', 'SmallKitchenAppliances', 'SmoothSubspace', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'StarLightCurves', 'Strawberry', 'SwedishLeaf', 'Symbols', 'SyntheticControl', 'ToeSegmentation1', 'ToeSegmentation2', 'Trace', 'TwoLeadECG', 'TwoPatterns', 'UMD', 'UWaveGestureLibraryAll', 'UWaveGestureLibraryX', 'UWaveGestureLibraryY', 'UWaveGestureLibraryZ', 'Wafer', 'Wine', 'WordSynonyms', 'Worms', 'WormsTwoClass', 'Yoga']


print(get_UCR_multivariate_list())
# Output:
#   ['ArticularyWordRecognition', 'AtrialFibrillation', 'BasicMotions', 'CharacterTrajectories', 'Cricket', 'DuckDuckGeese', 'EigenWorms', 'Epilepsy', 'ERing', 'EthanolConcentration', 'FaceDetection', 'FingerMovements', 'HandMovementDirection', 'Handwriting', 'Heartbeat', 'InsectWingbeat', 'JapaneseVowels', 'Libras', 'LSST', 'MotorImagery', 'NATOPS', 'PEMS-SF', 'PenDigits', 'PhonemeSpectra', 'RacketSports', 'SelfRegulationSCP1', 'SelfRegulationSCP2', 'SpokenArabicDigits', 'StandWalkJump', 'UWaveGestureLibrary']


"""
In the case of UCR data it's very easy to get data loaded. Let's select a dataset. You can modify this and select any one from the previous lists (univariate of multivariate).

`return_split` determines whether the UCR data will be returned already split between train and test or not.
"""

# dataset id
dsid = 'NATOPS' 
X, y, splits = get_UCR_data(dsid, return_split=False)
X.shape, y.shape, splits
# Output:
#   ((360, 24, 51),

#    (360,),

#    ((#180) [0,1,2,3,4,5,6,7,8,9...],

#     (#180) [180,181,182,183,184,185,186,187,188,189...]))

"""
☣️ **Something very important when you prepare your own data is that data needs to be in a 3-d array with the following format:**

1. Samples
2. Variables
3. Length (aka time or sequence steps)

Variables = 1 for univariate datasets and >1 for multivariate.

In the case your data is already separate between train and test like this:
"""

X_train, y_train, X_test, y_test  = get_UCR_data(dsid, return_split=True)

"""
you can use this convenience function to get X, y and splits:
"""

X, y, splits = combine_split_data([X_train, X_test], [y_train, y_test])

"""
All UEA & UCR Time Series Classification data have already been split between train and valid. When you use your own data, you'll have to split it yourself. We'll see examples of this in future notebooks.
"""

"""
### Prepare datasets 💿
"""

"""
The first step is to create datasets. This is very easy to do in v2. 

In TS classification problems, you will usually want to use an item tfm to transform y into categories.

We'll use `inplace=True` to preprocess data at dataset initialization. This will significantly speed up training. 
"""

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)

"""
We'll now build the `DataLoader`s (dls) that will create batches of data.

You will need to pass:

* datasets: usually 2 - train and valid -  or 1 - test or unlabelled- depending on the problem
* batch size(s): you may pass a single value (will be applied to all dls, or different values, one for each dl.
* batch_tfms (same as after_batch): you may decide to pass some tfms at the batch level. In this case for example, we'll standardize the data (0 mean and 1 std). You may get more details on how these transforms work in the transforms nb.
* num workers: num_workers > 0 is used to preprocess batches of data so that the next batch is ready for use when the current batch has been finished. More num_workers would consume more memory usage but is helpful to speed up the I/O process. This will depend on your machine, dataset, etc. You may want to start with 0, and test other values to see how to train faster. For me, 0 works better.
"""

dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)

"""
### Visualize data
"""

dls.show_batch(sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
## Build learner 🏗
"""

model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
learn.save('stage0')
# Output:
#   Path('models/stage0.pth')

"""
## Train model 🚵🏼‍
"""

"""
### LR find 🔎
"""

learn.load('stage0')
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.002511886414140463)
#   <Figure size 432x288 with 1 Axes>

"""
### Train 🏃🏽‍♀️
"""

learn.fit_one_cycle(25, lr_max=1e-3)
learn.save('stage1')
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Path('models/stage1.pth')

learn.recorder.plot_metrics()
# Output:
#   <Figure size 1440x288 with 3 Axes>

"""
Let's pretend we need to end the working session now for some reason, but we'd like to continue working with this datasets and learner in the future. 

To save everything you can use a convenience function I've created that saves the learner with the model, the data and the opt function status: 
"""

learn.save_all(path='export', dls_fname='dls', model_fname='model', learner_fname='learner')

"""
As soon as we've done this, we can end the session, and continue at any time in the future. 

Let's simulate that we need to end the session now:
"""

del learn, dsets, dls

"""
Next time we go back to work, we'll need to reload the datasets and learner (with the same status we had):
"""

learn = load_learner_all(path='export', dls_fname='dls', model_fname='model', learner_fname='learner')
dls = learn.dls
valid_dl = dls.valid
b = next(iter(valid_dl))
b
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cuda:0, dtype=torch.float32),

#    TensorCategory([3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3, 2, 4, 1, 0, 4, 0, 4, 0, 2,

#                    3, 5, 5, 1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 2,

#                    1, 5, 0, 2, 4, 3, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1, 4, 5, 0,

#                    5, 1, 1, 1, 2, 4, 1, 5, 3, 0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5,

#                    1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2, 1, 5, 0, 3, 0, 5, 3, 5, 0,

#                    5, 5, 0, 2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1, 0, 3, 4, 3, 1, 2,

#                    2, 2], device='cuda:0'))

valid_probas, valid_targets, valid_preds = learn.get_preds(dl=valid_dl, with_decoded=True)
valid_probas, valid_targets, valid_preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([[0.0063, 0.0120, 0.0193, 0.9306, 0.0150, 0.0167],

#                [0.0083, 0.0092, 0.0071, 0.0144, 0.9450, 0.0159],

#                [0.0089, 0.0044, 0.0021, 0.0089, 0.0056, 0.9701],

#                ...,

#                [0.0051, 0.0049, 0.0044, 0.0108, 0.9674, 0.0075],

#                [0.0045, 0.0084, 0.0135, 0.9502, 0.0102, 0.0131],

#                [0.0028, 0.0041, 0.0084, 0.9323, 0.0449, 0.0075]]),

#    tensor([3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3, 2, 4, 1, 0, 4, 0, 4, 0, 2, 3, 5, 5,

#            1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 2, 1, 5, 0, 2, 4, 3,

#            2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1, 4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3,

#            0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5, 1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2,

#            1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1,

#            0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0, 0, 1, 3, 4, 4, 2, 1, 1, 1, 4, 4, 3,

#            1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5, 4, 3, 5, 1, 3, 2, 3, 0, 1, 3, 0, 2,

#            5, 2, 1, 5, 3, 1, 0, 5, 2, 4, 3, 3]),

#    TensorBase([3, 4, 5, 0, 3, 2, 2, 2, 2, 0, 4, 3, 2, 4, 2, 0, 4, 0, 4, 0, 2, 3, 5,

#                5, 2, 2, 2, 0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 1, 1, 5, 0, 2,

#                4, 3, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 4, 1, 4, 5, 0, 5, 1, 1, 1, 2, 4,

#                1, 5, 3, 0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5, 2, 5, 2, 5, 5, 4, 4, 2,

#                4, 3, 5, 2, 1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 2, 5, 0, 1, 1, 4, 1,

#                0, 0, 2, 4, 1, 0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0, 0, 2, 3, 4, 4, 2,

#                1, 2, 1, 4, 4, 3, 1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5, 4, 3, 5, 1, 3,

#                1, 3, 0, 1, 3, 0, 2, 5, 2, 2, 5, 3, 1, 0, 5, 2, 4, 3, 3]))

"""
We can confirm the learner has the same status it had at the end of training, by confirming the validation accuracy is the same:
"""

(valid_targets == valid_preds).float().mean()
# Output:
#   TensorBase(0.9333)

"""
Great! It's the same. This means we have now the learner at the same point where we left it.
"""

"""
## Visualize results 👁
"""

learn.show_results()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1296x864 with 9 Axes>

learn.show_probas()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x432 with 1 Axes>

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>

interp.most_confused(min_val=3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   [('2.0', '3.0', 8), ('3.0', '2.0', 4)]

"""
## Inference on additional data 🆕
"""

"""
Let's say we want to predict labels on new data. Let's see how this works.
"""

"""
We may have additional data (test set) where we want to check our performance. In this case, we'd add a labelled dataset:
"""

# Labelled test data
test_ds = valid_dl.dataset.add_test(X, y)# In this case I'll use X and y, but this would be your test data
test_dl = valid_dl.new(test_ds)
next(iter(test_dl))
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cuda:0, dtype=torch.float32),

#    TensorCategory([3, 2, 2, 3, 2, 4, 0, 5, 2, 1, 5, 0, 3, 5, 2, 1, 2, 1, 1, 5, 3,

#                    2, 4, 3, 0, 5, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 2, 0, 3, 5, 2, 3,

#                    3, 5, 0, 5, 1, 0, 0, 5, 3, 0, 2, 2, 1, 0, 4, 0, 1, 4, 3, 4, 1,

#                    4, 0, 5, 2, 0, 1, 0, 2, 3, 3, 2, 4, 1, 1, 2, 2, 5, 5, 0, 1, 4,

#                    1, 1, 3, 4, 5, 3, 1, 2, 0, 2, 0, 4, 5, 5, 4, 4, 5, 3, 1, 0, 1,

#                    1, 1, 5, 4, 3, 2, 3, 0, 2, 4, 4, 4, 3, 2, 5, 2, 0, 2, 3, 0, 5,

#                    1, 0], device='cuda:0'))

"""
By selecting the valid dataset (valid_dl.dataset) we ensure that the same tfms applied to the valid data will be applied to the new data.
"""

test_probas, test_targets, test_preds = learn.get_preds(dl=test_dl, with_decoded=True, save_preds=None, save_targs=None)
test_probas, test_targets, test_preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([[0.0033, 0.0049, 0.0082, 0.9645, 0.0076, 0.0116],

#                [0.0038, 0.0470, 0.9334, 0.0045, 0.0087, 0.0026],

#                [0.0069, 0.0981, 0.8684, 0.0075, 0.0147, 0.0044],

#                ...,

#                [0.0051, 0.0049, 0.0044, 0.0108, 0.9674, 0.0075],

#                [0.0045, 0.0084, 0.0135, 0.9502, 0.0102, 0.0131],

#                [0.0028, 0.0041, 0.0084, 0.9323, 0.0449, 0.0075]]),

#    tensor([3, 2, 2, 3, 2, 4, 0, 5, 2, 1, 5, 0, 3, 5, 2, 1, 2, 1, 1, 5, 3, 2, 4, 3,

#            0, 5, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 2, 0, 3, 5, 2, 3, 3, 5, 0, 5, 1, 0,

#            0, 5, 3, 0, 2, 2, 1, 0, 4, 0, 1, 4, 3, 4, 1, 4, 0, 5, 2, 0, 1, 0, 2, 3,

#            3, 2, 4, 1, 1, 2, 2, 5, 5, 0, 1, 4, 1, 1, 3, 4, 5, 3, 1, 2, 0, 2, 0, 4,

#            5, 5, 4, 4, 5, 3, 1, 0, 1, 1, 1, 5, 4, 3, 2, 3, 0, 2, 4, 4, 4, 3, 2, 5,

#            2, 0, 2, 3, 0, 5, 1, 0, 5, 3, 0, 1, 4, 5, 5, 0, 5, 3, 5, 1, 0, 0, 0, 3,

#            0, 5, 5, 2, 1, 5, 5, 2, 4, 4, 0, 1, 1, 4, 1, 2, 2, 4, 1, 3, 5, 3, 4, 1,

#            1, 4, 3, 0, 5, 1, 3, 3, 4, 0, 3, 3, 3, 4, 5, 0, 3, 2, 1, 2, 2, 0, 4, 3,

#            2, 4, 1, 0, 4, 0, 4, 0, 2, 3, 5, 5, 1, 2, 1, 0, 1, 4, 2, 3, 5, 4, 3, 5,

#            3, 0, 3, 5, 4, 2, 1, 5, 0, 2, 4, 3, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 4, 1,

#            4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3, 0, 3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5,

#            1, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2, 1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0,

#            2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4, 1, 0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0,

#            0, 1, 3, 4, 4, 2, 1, 1, 1, 4, 4, 3, 1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5,

#            4, 3, 5, 1, 3, 2, 3, 0, 1, 3, 0, 2, 5, 2, 1, 5, 3, 1, 0, 5, 2, 4, 3, 3]),

#    TensorBase([3, 2, 2, 3, 2, 4, 0, 5, 2, 1, 5, 0, 3, 5, 2, 1, 2, 1, 1, 5, 3, 2, 4,

#                3, 0, 5, 2, 4, 4, 4, 2, 4, 2, 4, 3, 4, 2, 0, 3, 5, 2, 3, 3, 5, 0, 5,

#                1, 0, 0, 5, 3, 0, 2, 2, 2, 0, 4, 0, 1, 4, 3, 4, 1, 4, 0, 5, 2, 0, 1,

#                0, 2, 3, 3, 2, 4, 1, 2, 2, 2, 5, 5, 0, 1, 4, 1, 1, 3, 4, 5, 3, 1, 2,

#                0, 2, 0, 4, 5, 5, 4, 4, 5, 3, 1, 0, 1, 1, 1, 5, 4, 3, 2, 3, 0, 2, 4,

#                4, 4, 3, 2, 5, 2, 0, 2, 3, 0, 5, 1, 0, 5, 3, 0, 1, 4, 5, 5, 0, 5, 3,

#                5, 1, 0, 0, 0, 3, 0, 5, 5, 2, 1, 5, 5, 2, 4, 4, 0, 1, 1, 4, 1, 2, 2,

#                4, 1, 3, 5, 3, 4, 1, 1, 4, 3, 1, 5, 1, 3, 3, 4, 0, 3, 3, 3, 4, 5, 0,

#                3, 2, 2, 2, 2, 0, 4, 3, 2, 4, 2, 0, 4, 0, 4, 0, 2, 3, 5, 5, 2, 2, 2,

#                0, 1, 4, 2, 3, 5, 4, 3, 5, 3, 0, 3, 5, 4, 1, 1, 5, 0, 2, 4, 3, 2, 2,

#                1, 2, 0, 1, 0, 1, 0, 0, 4, 1, 4, 5, 0, 5, 1, 1, 1, 2, 4, 1, 5, 3, 0,

#                3, 4, 3, 1, 4, 4, 2, 0, 3, 3, 5, 2, 5, 2, 5, 5, 4, 4, 2, 4, 3, 5, 2,

#                1, 5, 0, 3, 0, 5, 3, 5, 0, 5, 5, 0, 2, 5, 0, 1, 1, 4, 1, 0, 0, 2, 4,

#                1, 0, 3, 4, 3, 1, 2, 2, 2, 2, 0, 4, 0, 0, 2, 3, 4, 4, 2, 1, 2, 1, 4,

#                4, 3, 1, 4, 0, 4, 5, 5, 1, 5, 3, 3, 5, 5, 4, 3, 5, 1, 3, 1, 3, 0, 1,

#                3, 0, 2, 5, 2, 2, 5, 3, 1, 0, 5, 2, 4, 3, 3]))

print(f'accuracy: {skm.accuracy_score(test_targets, test_preds):10.6f}')
# Output:
#   accuracy:   0.958333


"""
If data is unlabelled, we'd just do this: 
"""

# Unlabelled data
test_ds = dls.dataset.add_test(X)
test_dl = valid_dl.new(test_ds)
next(iter(test_dl))
# Output:
#   (TSTensor(samples:128, vars:24, len:51, device=cuda:0, dtype=torch.float32),)

test_probas, *_ = learn.get_preds(dl=test_dl, save_preds=None)
test_probas
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   TensorBase([[0.0033, 0.0049, 0.0082, 0.9645, 0.0076, 0.0116],

#               [0.0038, 0.0470, 0.9334, 0.0045, 0.0087, 0.0026],

#               [0.0069, 0.0981, 0.8684, 0.0075, 0.0147, 0.0044],

#               ...,

#               [0.0051, 0.0049, 0.0044, 0.0108, 0.9674, 0.0075],

#               [0.0045, 0.0084, 0.0135, 0.9502, 0.0102, 0.0131],

#               [0.0028, 0.0041, 0.0084, 0.9323, 0.0449, 0.0075]])

"""
## Summary ✅
"""

"""
This is all the code you need to train a TS model. As you can see, it's v2 is easier to use and faster compared to v1.
"""

dsid = 'NATOPS' 
X, y, splits = get_UCR_data(dsid, return_split=False)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
learn.fit_one_cycle(25, lr_max=1e-3)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>

"""
## New scikit-learn-like API 🎉
"""

"""
As of `tsai` version 0.2.15 I have added a new scikit-learn-like API to further simplify the learner creation. 

I will prepare a new tutorial to further demonstrate how you can use the new API.

This is how you can use it for Time Series Classification: 
"""

dsid = 'NATOPS' 
X, y, splits = get_UCR_data(dsid, return_split=False)
learn = TSClassifier(X, y, splits=splits, bs=[64, 128], batch_tfms=[TSStandardize()], arch=InceptionTime, metrics=accuracy)
learn.fit_one_cycle(25, lr_max=1e-3)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>



================================================
FILE: tutorial_nbs/01a_MultiClass_MultiLabel_TSClassification.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/01_Intro_to_Time_Series_Classification.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Doug Williams (https://github.com/williamsdoug) and Ignacio Oguiza (https://github.com/timeseriesAI/tsai). 

contact: oguiza@timeseriesAI.co
"""

"""
## Purpose 😇
"""

"""
The purpose of this notebook is to demonstrate both multi-class and multi-label classification using `tsai`. 

- Multi-class classification: While the output can take on multiple possible values, for any given sample the output can take on only a single value. In other words, the label values are mutually exclusive. Implication are:
  - CategoricalCrossEntropy (`nn.CrossEntropyLoss` in Pytorch, `CrossEntropyLossFlat` in fastai) is used as the loss function during training
  - Softmax is used to determine prediction since only one label value can be true, the predicted label is the value label value with the greatest probability. 
  - Softmax reduces the potential for spurious label predictions since only the label with the highest probability is selected
  - In both Pytorch and fastai the loss combines a Softmax layer and the CrossEntropyLoss in one single class, so Softmax shouldn't be added to the model.
 
- Multi-label classification: This is the more general case where an individual sample can have one or more labels, relaxing the mutual label exclusivity constraint. Implications are:
  - BinaryCrossEntropy (`nn.BCEWithLogitsLoss` in Pytorch, `BCEWithLogitsLossFlat` in fastai) is used as the loss function during training
  - Sigmoid is used to determine prediction since multiple labels may be true. In both Pytorch and fastai the loss combines a Sigmoid layer and the BCELoss in one single class, so Sigmoid shouldn't be added to the model.
  - Relative to multi-class classification, multi-label classification may be more prone to spurious false-positive labels.
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-glibc2.27

#   python          : 3.8.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
## Prepare data 🔢

For this example we will be using the UCR ECG5000 heartbeat dataset with is based on the [Physionet BIDMC Congestive Heart Failure Database](https://physionet.org/content/chfdb/1.0.0/]), specifically recording chf07.

For the purposes of this example the UCR labels will be mapped to more descriptive labels:

- 1 - Normal ('Nor')
- 2 - R-on-T premature ventricular contraction ('RoT')
- 3 - Premature ventricular contraction ('PVC')
- 4 - Supraventricular premature or ectopic beat, atrial or nodal ('SPC')
- 5 - Unclassifiable beat ('Unk')
"""

class_map = {
    '1':'Nor',  # N:1  - Normal
    '2':'RoT',  # r:2  - R-on-T premature ventricular contraction
    '3':'PVC',  # V:3  - Premature ventricular contraction
    '4':'SPC',  # S:4  - Supraventricular premature or ectopic beat (atrial or nodal)
    '5':'Unk',  # Q:5  - Unclassifiable beat
    }
class_map
# Output:
#   {'1': 'Nor', '2': 'RoT', '3': 'PVC', '4': 'SPC', '5': 'Unk'}

# dataset id
dsid = 'ECG5000' 
X, y, splits = get_UCR_data(dsid, split_data=False)
labeler = ReLabeler(class_map)
new_y = labeler(y) # map to more descriptive labels
X.shape, new_y.shape, splits, new_y
# Output:
#   ((5000, 1, 140),

#    (5000,),

#    ((#500) [0,1,2,3,4,5,6,7,8,9...],

#     (#4500) [500,501,502,503,504,505,506,507,508,509...]),

#    array(['Nor', 'Nor', 'Nor', ..., 'RoT', 'RoT', 'RoT'], dtype='<U3'))

label_counts = collections.Counter(new_y)
print('Counts by label:', dict(label_counts))
print(f'Naive Accuracy: {100*max(label_counts.values())/sum(label_counts.values()):0.2f}%')
# Output:
#   Counts by label: {'Nor': 2919, 'RoT': 1767, 'PVC': 96, 'SPC': 194, 'Unk': 24}

#   Naive Accuracy: 58.38%


"""
Note: naive accuracy is calculated by assuming all samples are predicted as 'Nor' (most frequent label).
"""

"""
## Multi-class classification
"""

"""
### Prepare dataloaders 💿
"""

tfms  = [None, TSClassification()] # TSClassification == Categorize
batch_tfms = TSStandardize()
dls = get_ts_dls(X, new_y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])
dls.dataset
# Output:
#   (#500) [(TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0)), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorCategory(0))] ...]

"""
### Visualize data
"""

dls.show_batch(sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
### Build learner 🏗
"""

"""
There are at least 2 equivalent ways to build a time series learner: 
"""

model = build_ts_model(InceptionTimePlus, dls=dls)
learn = Learner(dls, model, metrics=accuracy)

learn = ts_learner(dls, metrics=accuracy) # == ts_learner(dls, arch=InceptionTimePlus, metrics=accuracy) since InceptionTimePlus is the default arch

"""
### LR find 🔎
"""

learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.0012022644514217973)
#   <Figure size 432x288 with 1 Axes>

"""
### Train 🏃🏽‍♀️
"""

learn = ts_learner(dls, metrics=accuracy, cbs=ShowGraph())
learn.fit_one_cycle(10, lr_max=1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
Now that the model is trained, we'll save it to create predictions in the future: 
"""

PATH = Path('./models/Multiclass.pkl')
PATH.parent.mkdir(parents=True, exist_ok=True)
learn.export(PATH)

"""
### Visualize results 👁
"""

learn.show_results(sharey=True)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1296x864 with 9 Axes>

learn.show_probas()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x432 with 1 Axes>

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>

interp.most_confused(min_val=3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   [('SPC', 'RoT', 122),

#    ('PVC', 'Nor', 27),

#    ('RoT', 'Nor', 27),

#    ('SPC', 'Nor', 27),

#    ('PVC', 'RoT', 21),

#    ('RoT', 'PVC', 17),

#    ('Unk', 'Nor', 12),

#    ('Unk', 'RoT', 10),

#    ('SPC', 'PVC', 8)]

"""
### Create predictions 🌦
"""

"""
To get predictions we need to create a learner object from the saved file: 
"""

PATH = Path('./models/Multiclass.pkl')
learn_gpu = load_learner(PATH, cpu=False)

"""
We can now generate predictions using just the X as input. This can be done with a 'gpu' or a 'cpu'. And for many samples, or just one at a time: 
"""

# gpu, many samples
probas, _, preds = learn_gpu.get_X_preds(X[splits[1]])
preds[-10:]
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   array(['RoT', 'RoT', 'RoT', 'RoT', 'SPC', 'RoT', 'Nor', 'RoT', 'RoT',

#          'RoT'], dtype='<U3')

skm.accuracy_score(new_y[splits[1]], preds)
# Output:
#   0.9386666666666666

PATH = Path('./models/Multiclass.pkl')
learn_cpu = load_learner(PATH, cpu=True)

# cpu, single sample
probas, _, preds = learn_cpu.get_X_preds(X[-1][None]) # [None] is added to pass a 3D array with dimensions [batch_size x n_vars x seq_len]
preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   array(['RoT'], dtype='<U3')

"""
## Multi-label Classification
"""

"""
### Augment labels to demonstrate multi-label

- Create additional label premature ('Pre')
- Include with any sample where labels 'RoT','PVC','SPC' are already present


Note:  While in this example the new Pre label is a composite of existing labels, more typically multi-label classification problems include orthogonal label groups.  For example in ECG classification one might have labels related to timing (e.g.: premature), QRS shape (e.g.: block) and other factors (e.g.: ST elevation or depression)
"""

class_map = {
    '1':['Nor'],          # N:1  - Normal
    '2':['RoT', 'Pre'],   # r:2  - R-on-T premature ventricular contraction
    '3':['PVC', 'Pre'] ,  # V:3  - Premature ventricular contraction
    '4':['SPC', 'Pre'],   # S:4  - Supraventricular premature or ectopic beat (atrial or nodal)
    '5':['Unk'],          # Q:5  - Unclassifiable beat
    }
class_map
# Output:
#   {'1': ['Nor'],

#    '2': ['RoT', 'Pre'],

#    '3': ['PVC', 'Pre'],

#    '4': ['SPC', 'Pre'],

#    '5': ['Unk']}

labeler = ReLabeler(class_map)
y_multi = labeler(y)
y_multi
# Output:
#   array([list(['Nor']), list(['Nor']), list(['Nor']), ...,

#          list(['RoT', 'Pre']), list(['RoT', 'Pre']), list(['RoT', 'Pre'])],

#         dtype=object)

label_counts = collections.Counter([a for r in y_multi for a in r])
print('Counts by label:', dict(label_counts))
# Output:
#   Counts by label: {'Nor': 2919, 'RoT': 1767, 'Pre': 2057, 'PVC': 96, 'SPC': 194, 'Unk': 24}


"""
### Prepare Dataloaders

- Replace earlier ```tfms  = [None, [TSClassification()]]```  with ```tfms  = [None, TSMultiLabelClassification()]```
- TSMultiLabelClassification() is equivalent to [MultiCategorize(), OneHotEncode()] combined in a single transform.
- When creating dataloaders in multi-label problems, always leave inplace=True (default value) to avoid issues.
"""

tfms  = [None, TSMultiLabelClassification()] # TSMultiLabelClassification() == [MultiCategorize(), OneHotEncode()]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y_multi, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])
dls.dataset
# Output:
#   (#500) [(TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.])), (TSTensor(vars:1, len:140, device=cpu, dtype=torch.float32), TensorMultiCategory([1., 0., 0., 0., 0., 0.]))] ...]

dls.show_batch(sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
### Build Learner and Train

- Use ```metrics=accuracy_multi``` in place of ```metrics=accuracy``` used in earlier multi-class example

- accuracy_multi can be calculated by sample (default) or by predicted label. When using accuracy_multi by_sample=True, all predicted labels for each sample must be correct to be counted as a correct sample. This is sometimes difficult (when having too many labels). There are cases when labels are partially correct. If we want to account for these, we'll set by_sample to False. 

- when using amulti-label dataset, we need to choose a model is tsai ending in Plus. These models are essentially the same as the ones with the suffix Plus, but provide some additional flexibility. In our case we'll use ```InceptionTimePlus```. If you don't pass any architecture ```InceptionTimePlus``` will be use. When in doubt, use ```InceptionTimePlus```.
"""

def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True, by_sample=False):
    "Computes accuracy when `inp` and `targ` are the same size."
    if sigmoid: inp = inp.sigmoid()
    correct = (inp>thresh)==targ.bool()
    if by_sample:
        return (correct.float().mean(-1) == 1).float().mean()
    else:
        inp,targ = flatten_check(inp,targ)
        return correct.float().mean()

learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy_multi)
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.00019054606673307717)
#   <Figure size 432x288 with 1 Axes>

learn = ts_learner(dls, InceptionTimePlus, metrics=[partial(accuracy_multi, by_sample=True), partial(accuracy_multi, by_sample=False)], cbs=ShowGraph())
learn.fit_one_cycle(10, lr_max=1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 936x648 with 4 Axes>

"""
### Additional Multi-label Metrics
"""

"""
A naive classifier that always predicts no true labels would achieve 76% accuracy, so the classifier should do much better.  This also demonstrates the weakness of relying overly on the accuracy metric (with by_sample=False), due to the prevalance of false outputs.
"""

label_counts = collections.Counter([a for r in y_multi for a in r])
print(f'Naive Accuracy: {100*(1-sum(label_counts.values())/(len(y_multi)*len(label_counts))):0.2f}%')
# Output:
#   Naive Accuracy: 76.48%


"""
### Define Metrics

We have included a number of multilabel metrics in `tsai` based on definitions in [Wikipedia](https://en.wikipedia.org/wiki/Precision_and_recall#F-measure)
"""

def precision_multi(inp, targ, thresh=0.5, sigmoid=True):
    "Computes precision when `inp` and `targ` are the same size."
    
    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh
    
    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    precision = TP/(TP+FP)
    return precision

def recall_multi(inp, targ, thresh=0.5, sigmoid=True):
    "Computes recall when `inp` and `targ` are the same size."
    
    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh
    
    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()

    recall = TP/(TP+FN)
    return recall

def specificity_multi(inp, targ, thresh=0.5, sigmoid=True):
    "Computes specificity (true negative rate) when `inp` and `targ` are the same size."
    
    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh
    
    correct = pred==targ.bool()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    specificity = TN/(TN+FP)
    return specificity

def balanced_accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):
    "Computes balanced accuracy when `inp` and `targ` are the same size."
    
    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh
    
    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    TPR = TP/(TP+FN)
    TNR = TN/(TN+FP)
    balanced_accuracy = (TPR+TNR)/2
    return balanced_accuracy

def Fbeta_multi(inp, targ, beta=1.0, thresh=0.5, sigmoid=True):
    "Computes Fbeta when `inp` and `targ` are the same size."
    
    inp,targ = flatten_check(inp,targ)
    if sigmoid: inp = inp.sigmoid()
    pred = inp>thresh
    
    correct = pred==targ.bool()
    TP = torch.logical_and(correct,  (targ==1).bool()).sum()
    TN = torch.logical_and(correct,  (targ==0).bool()).sum()
    FN = torch.logical_and(~correct, (targ==1).bool()).sum()
    FP = torch.logical_and(~correct, (targ==0).bool()).sum()

    precision = TP/(TP+FP)
    recall = TP/(TP+FN)
    beta2 = beta*beta
    
    if precision+recall > 0:
        Fbeta = (1+beta2)*precision*recall/(beta2*precision+recall)
    else:
        Fbeta = 0
    return Fbeta

def F1_multi(*args, **kwargs):
    return Fbeta_multi(*args, **kwargs)  # beta defaults to 1.0

"""
### Train Classifier Including More Metrics
"""

metrics =[accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi, specificity_multi, F1_multi] 
learn = ts_learner(dls, InceptionTimePlus, metrics=metrics, cbs=ShowGraph())
learn.fit_one_cycle(10, lr_max=1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1944x648 with 8 Axes>

"""
### Optionally Use Class (Positive) Weights

- Include Per-label positive weights bias the loss function to give greater importance to samples where label is present with loss function
- `tsai` automatically calculates class weights. It's a dataloaders attribute called cws. **You should use dls.train.cws to avoid any leakage.**
"""

"""
### Prepare DataLoaders
"""

tfms  = [None, TSMultiLabelClassification()] # TSMultiLabelClassification() == [MultiCategorize(), OneHotEncode()]
batch_tfms = TSStandardize()
dls = get_ts_dls(X, y_multi, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=[64, 128])
dls.vocab, dls.train.cws
# Output:
#   (['Nor', 'PVC', 'Pre', 'RoT', 'SPC', 'Unk'],

#    tensor([  0.7123,  49.0000,   1.4272,   1.8249,  25.3158, 249.0000],

#           device='cuda:0'))

"""
### Build Learner and Train

- Include class weights with ```loss_func```
"""

metrics = [accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi,  specificity_multi, F1_multi]
learn = ts_learner(dls, InceptionTimePlus, metrics=metrics, loss_func=BCEWithLogitsLossFlat(pos_weight=dls.train.cws), cbs=ShowGraph())

learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.00015848931798245758)
#   <Figure size 432x288 with 1 Axes>

learn.fit_one_cycle(20, lr_max=1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1944x648 with 8 Axes>

"""
### Try Again with Reduced Weights (reduce by sqrt)
"""

metrics = [accuracy_multi, balanced_accuracy_multi, precision_multi, recall_multi,  specificity_multi, F1_multi]
learn = ts_learner(dls, InceptionTimePlus, metrics=metrics, loss_func=BCEWithLogitsLossFlat(pos_weight=dls.train.cws.sqrt()), cbs=ShowGraph())

learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.00013182566908653826)
#   <Figure size 432x288 with 1 Axes>

learn.fit_one_cycle(10, lr_max=1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1944x648 with 8 Axes>

"""
Let's save the learner for inference: 
"""

PATH = Path('./models/Multilabel.pkl')
PATH.parent.mkdir(parents=True, exist_ok=True)
learn.export(PATH)

"""
### Create predictions 🌦
"""

"""
To get predictions we need to create a learner object from the saved file: 
"""

PATH = Path('./models/Multilabel.pkl')
learn_gpu = load_learner(PATH, cpu=False)

"""
We can now generate predictions using just the X as input. This can be done with a 'gpu' or a 'cpu'. And for many samples, or just one at a time: 
"""

# gpu, many samples, multilabel
probas, _, preds = learn_gpu.get_X_preds(X[splits[1]])
preds[-10:]
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (#10) [['Pre', 'RoT', 'SPC'],['Pre', 'SPC'],['Pre', 'RoT', 'SPC'],['Pre', 'SPC'],['Pre', 'SPC'],['Pre', 'SPC'],['Pre', 'SPC'],['Pre', 'RoT', 'SPC'],['Pre', 'RoT'],['Pre', 'SPC']]

PATH = Path('./models/Multilabel.pkl')
learn_cpu = load_learner(PATH, cpu=True)

# cpu, single sample
probas, _, preds = learn_cpu.get_X_preds(X[-1][None])
preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (#1) [['Pre', 'SPC']]

"""
### Summary of Key Points: Multi-Label Classification

#### Basic Data Preparation
- Replace earlier ```tfms  = [None, TSClassification()]```  with ```tfms  = [None, TSMultiLabelClassification()]```

#### Basic Learner

- You can build a learnr using ```learn = ts_learner()``` or  ```learn = Learner()```
- If you choose ```ts_learner``` you can pass an architecture (rather than passing pre-created model) or leave it as None, in which case the default (InceptiontimePlus) will be used.
- Use ```metrics=accuracy_multi``` in place of ```metrics=accuracy``` used in earlier multi-class example
- If no loss_func is passed, `tsai` will set it to loss function ```loss_func=BCEWithLogitsLossFlat()```.
  
#### Multi-Label Metrics
- Remember you can use accuracy_multi(by_sample=True) which will consider as correct samples where all labels are correct. If by_sample=False, all labels for all samples will be considered, which may lead to a biased result.
- Consider using multi=label metrics, such as those included in this example.

#### Optionally Include Positive Weights with Loss Function
- Since large number of negative targets after application of binary encoding, label weighting may better optimize loss function for positive labels
- `tsai` automatically calculates multi class weights. 
- Remember to use the ones in the train set: dls.train.cws
- Include weights with loss function: ```BCEWithLogitsLossFlat(pos_weight=dls.train.cws)```
  - Weights must be in tensor form and placed on GPU (done by default is used dls.train.cws)
  - Strict weighting by False/True ratio may yield sub-optimal results.  Consider reduced weights: ```BCEWithLogitsLossFlat(pos_weight=dls.train.cws.sqrt())```
"""



================================================
FILE: tutorial_nbs/02_ROCKET_a_new_SOTA_classifier.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/02_ROCKET_a_new_SOTA_classifier.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## Purpose 😇
"""

"""
The purpose of this notebook is to introduce you to Rocket. 

ROCKET (RandOm Convolutional KErnel Transform) is a new Time Series Classification (TSC) method that has just been released (Oct 29th, 2019), and has achieved **state-of-the-art performance on the UCR univariate time series classification datasets, surpassing HIVE-COTE (the previous state of the art since 2017) in accuracy, with exceptional speed compared to other traditional DL methods.** 

To achieve these 2 things at once is **VERY IMPRESSIVE**. ROCKET is certainly a new TSC method you should try.

Authors:
Dempster, A., Petitjean, F., & Webb, G. I. (2019). ROCKET: Exceptionally fast and accurate time series classification using random convolutional kernels. arXiv preprint arXiv:1910.13051.

[paper](https://arxiv.org/pdf/1910.13051)

There are 2 main limitations to the original ROCKET method though:
- Released code doesn't handle multivariate data
- It doesn't run on a GPU, so it's slow when used with a large datasets

In this notebook you will learn: 
- a new ROCKET version we have developed in Pytorch, that handles both **univariate and multivariate** data, and uses **GPU**
- you will see how you can integrate the ROCKET features with fastai or other classifiers
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
## How to use ROCKET on GPU?
"""

"""
This method allows you to use ROCKET even with large and/or multivariate datasets on GPU in Pytorch. 
"""

"""
### 1️⃣ Generate features

First you prepare the input data and normalize it per sample. The input to ROCKET Pytorch is a 3d tensor of shape (samples, vars, len), preferrable on gpu.
"""

"""
The way to use ROCKET in Pytorch is the following:

* Create a dataset as you would normally do in `tsai`. 
* Create a TSDataLoaders with the following kwargs: 
    * drop_last=False. In this way we get features for every input sample.
    * shuffle_train=False
    * batch_tfms=[TSStandardize(by_sample=True)] so that input is normalized by sample, as recommended by the authors

"""

X, y, splits = get_UCR_data('HandMovementDirection', split_data=False)
tfms  = [None, [Categorize()]]
batch_tfms = [TSStandardize(by_sample=True)]
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, drop_last=False, shuffle_train=False, batch_tfms=batch_tfms, bs=10_000)

"""
☣️☣️ You will be able to create a dls (TSDataLoaders) object with unusually large batch sizes. I've tested it with a large dataset and a batch size = 100_000 and it worked fine. This is because ROCKET is not a usual Deep Learning model. It just applies convolutions (kernels) one at a time to create the features.
"""

"""
Instantiate a rocket model with the desired n_kernels (authors use 10_000) and kernel sizes (7, 9 and 11 in the original paper). 
"""

model = build_ts_model(ROCKET, dls=dls) # n_kernels=10_000, kss=[7, 9, 11] set by default, but you can pass other values as kwargs

"""
Now generate rocket features for the entire train and valid datasets using the create_rocket_features convenience function `create_rocket_features`.
"""

"""
And we now transform the original data, creating 20k features per sample
"""

X_train, y_train = create_rocket_features(dls.train, model)
X_valid, y_valid = create_rocket_features(dls.valid, model)
X_train.shape, X_valid.shape
# Output:
#   ((160, 20000), (74, 20000))

"""
### 2️⃣ Apply a classifier
"""

"""
Once you build the 20k features per sample, you can use them to train any classifier of your choice.
"""

"""
#### RidgeClassifierCV
"""

"""
And now you apply a classifier of your choice. 
With RidgeClassifierCV in particular, there's no need to normalize the calculated features before passing them to the classifier, as it does it internally (if normalize is set to True as recommended by the authors).
"""

from sklearn.linear_model import RidgeClassifierCV
ridge = RidgeClassifierCV(alphas=np.logspace(-8, 8, 17), normalize=True)
ridge.fit(X_train, y_train)
print(f'alpha: {ridge.alpha_:.2E}  train: {ridge.score(X_train, y_train):.5f}  valid: {ridge.score(X_valid, y_valid):.5f}')
# Output:
#   alpha: 1.00E+01  train: 1.00000  valid: 0.50000


"""
This result is amazing!! The previous state of the art (Inceptiontime) was .37837
"""

"""
#### Logistic Regression
"""

"""
In the case of other classifiers (like Logistic Regression), the authors recommend a per-feature normalization.
"""

eps = 1e-6
Cs = np.logspace(-5, 5, 11)
from sklearn.linear_model import LogisticRegression
best_loss = np.inf
for i, C in enumerate(Cs):
    f_mean = X_train.mean(axis=0, keepdims=True)
    f_std = X_train.std(axis=0, keepdims=True) + eps  # epsilon to avoid dividing by 0
    X_train_tfm2 = (X_train - f_mean) / f_std
    X_valid_tfm2 = (X_valid - f_mean) / f_std
    classifier = LogisticRegression(penalty='l2', C=C, n_jobs=-1)
    classifier.fit(X_train_tfm2, y_train)
    probas = classifier.predict_proba(X_train_tfm2)
    loss = nn.CrossEntropyLoss()(torch.tensor(probas), torch.tensor(y_train)).item()
    train_score = classifier.score(X_train_tfm2, y_train)
    val_score = classifier.score(X_valid_tfm2, y_valid)
    if loss < best_loss:
        best_eps = eps
        best_C = C
        best_loss = loss
        best_train_score = train_score
        best_val_score = val_score
    print('{:2} eps: {:.2E}  C: {:.2E}  loss: {:.5f}  train_acc: {:.5f}  valid_acc: {:.5f}'.format(
        i, eps, C, loss, train_score, val_score))
print('\nBest result:')
print('eps: {:.2E}  C: {:.2E}  train_loss: {:.5f}  train_acc: {:.5f}  valid_acc: {:.5f}'.format(
        best_eps, best_C, best_loss, best_train_score, best_val_score))
# Output:
#    0 eps: 1.00E-06  C: 1.00E-05  loss: 1.35134  train_acc: 0.81875  valid_acc: 0.40541

#    1 eps: 1.00E-06  C: 1.00E-04  loss: 1.15404  train_acc: 1.00000  valid_acc: 0.44595

#    2 eps: 1.00E-06  C: 1.00E-03  loss: 0.85360  train_acc: 1.00000  valid_acc: 0.48649

#    3 eps: 1.00E-06  C: 1.00E-02  loss: 0.76183  train_acc: 1.00000  valid_acc: 0.48649

#    4 eps: 1.00E-06  C: 1.00E-01  loss: 0.74625  train_acc: 1.00000  valid_acc: 0.50000

#    5 eps: 1.00E-06  C: 1.00E+00  loss: 0.74401  train_acc: 1.00000  valid_acc: 0.48649

#    6 eps: 1.00E-06  C: 1.00E+01  loss: 0.74371  train_acc: 1.00000  valid_acc: 0.48649

#    7 eps: 1.00E-06  C: 1.00E+02  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.50000

#    8 eps: 1.00E-06  C: 1.00E+03  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.51351

#    9 eps: 1.00E-06  C: 1.00E+04  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.51351

#   10 eps: 1.00E-06  C: 1.00E+05  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.52703

#   

#   Best result:

#   eps: 1.00E-06  C: 1.00E+05  train_loss: 0.74367  train_acc: 1.00000  valid_acc: 0.52703


"""
☣️ Note: Epsilon has a large impact on the result. You can actually test several values to find the one that best fits your problem, but bear in mind you can only select C and epsilon based on train data!!! 
"""

"""
##### RandomSearch
"""

"""
One way to do this would be to perform a random search using several epsilon and C values
"""

n_tests = 10
epss = np.logspace(-8, 0, 9)
Cs = np.logspace(-5, 5, 11)

from sklearn.linear_model import LogisticRegression
best_loss = np.inf
for i in range(n_tests):
    eps = random_choice(epss)
    C = random_choice(Cs)
    f_mean = X_train.mean(axis=0, keepdims=True)
    f_std = X_train.std(axis=0, keepdims=True) + eps  # epsilon
    X_train_tfm2 = (X_train - f_mean) / f_std
    X_valid_tfm2 = (X_valid - f_mean) / f_std
    classifier = LogisticRegression(penalty='l2', C=C, n_jobs=-1)
    classifier.fit(X_train_tfm2, y_train)
    probas = classifier.predict_proba(X_train_tfm2)
    loss = nn.CrossEntropyLoss()(torch.tensor(probas), torch.tensor(y_train)).item()
    train_score = classifier.score(X_train_tfm2, y_train)
    val_score = classifier.score(X_valid_tfm2, y_valid)
    if loss < best_loss:
        best_eps = eps
        best_C = C
        best_loss = loss
        best_train_score = train_score
        best_val_score = val_score
    print('{:2}  eps: {:.2E}  C: {:.2E}  loss: {:.5f}  train_acc: {:.5f}  valid_acc: {:.5f}'.format(
        i, eps, C, loss, train_score, val_score))
print('\nBest result:')
print('eps: {:.2E}  C: {:.2E}  train_loss: {:.5f}  train_acc: {:.5f}  valid_acc: {:.5f}'.format(
        best_eps, best_C, best_loss, best_train_score, best_val_score))
# Output:
#    0  eps: 1.00E-03  C: 1.00E-04  loss: 1.15656  train_acc: 1.00000  valid_acc: 0.44595

#    1  eps: 1.00E-04  C: 1.00E+02  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.50000

#    2  eps: 1.00E-06  C: 1.00E-04  loss: 1.15404  train_acc: 1.00000  valid_acc: 0.44595

#    3  eps: 1.00E-05  C: 1.00E+03  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.51351

#    4  eps: 1.00E-08  C: 1.00E-02  loss: 0.76183  train_acc: 1.00000  valid_acc: 0.48649

#    5  eps: 1.00E-05  C: 1.00E-05  loss: 1.35134  train_acc: 0.81875  valid_acc: 0.40541

#    6  eps: 1.00E-06  C: 1.00E+01  loss: 0.74371  train_acc: 1.00000  valid_acc: 0.48649

#    7  eps: 1.00E-08  C: 1.00E-01  loss: 0.74625  train_acc: 1.00000  valid_acc: 0.50000

#    8  eps: 1.00E-06  C: 1.00E+03  loss: 0.74367  train_acc: 1.00000  valid_acc: 0.51351

#    9  eps: 1.00E-05  C: 1.00E-01  loss: 0.74625  train_acc: 1.00000  valid_acc: 0.50000

#   

#   Best result:

#   eps: 1.00E-05  C: 1.00E+03  train_loss: 0.74367  train_acc: 1.00000  valid_acc: 0.51351


"""
In addition to this, I have also run the code on the TSC UCR multivariate datasets (all the ones that don't contain nan values), and the results are also very good, beating the previous state-of-the-art in this category as well by a large margin. For example, ROCKET reduces InceptionTime errors by 26% on average.
"""

"""
#### Fastai classifier head
"""

X = concat(X_train, X_valid)
y = concat(y_train, y_valid)
splits = get_predefined_splits(X_train, X_valid)

tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, batch_tfms=[TSStandardize(by_var=True)])# per feature normalization
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

def lin_zero_init(layer):
    if isinstance(layer, nn.Linear):
        nn.init.constant_(layer.weight.data, 0.)
        if layer.bias is not None: nn.init.constant_(layer.bias.data, 0.)

model = create_mlp_head(dls.vars, dls.c, dls.len)
model.apply(lin_zero_init)
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
learn.fit_one_cycle(50, lr_max=1e-4)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
#### XGBoost
"""

eps = 1e-6

# normalize 'per feature'
f_mean = X_train.mean(axis=0, keepdims=True)
f_std = X_train.std(axis=0, keepdims=True) + eps
X_train_norm = (X_train - f_mean) / f_std
X_valid_norm = (X_valid - f_mean) / f_std

import xgboost as xgb
classifier = xgb.XGBClassifier(max_depth=3,
                               learning_rate=0.1,
                               n_estimators=100,
                               verbosity=1,
                               objective='binary:logistic',
                               booster='gbtree',
                               tree_method='auto',
                               n_jobs=-1,
                               gpu_id=default_device().index,
                               gamma=0,
                               min_child_weight=1,
                               max_delta_step=0,
                               subsample=.5,
                               colsample_bytree=1,
                               colsample_bylevel=1,
                               colsample_bynode=1,
                               reg_alpha=0,
                               reg_lambda=1,
                               scale_pos_weight=1,
                               base_score=0.5,
                               random_state=0,
                               missing=None)

classifier.fit(X_train_norm, y_train)
preds = classifier.predict(X_valid_norm)
(preds == y_valid).mean()
# Output:
#   0.43243243243243246

"""
## Conclusions
"""

"""
ROCKET is a great method for TSC that has established a new level of performance both in terms of accuracy and time. It does it by successfully applying an approach quite different from the traditional DL approaches. The method uses 10k random kernels to generate features that are then classified by linear classifiers (although you may use a classifier of your choice).
The original method has 2 limitations (lack of multivariate and lack of GPU support) that are overcome by the Pytorch implementation shared in this notebook.

So this is all the code you need to train a state-of-the-art model using rocket and GPU in `tsai`:

```python
X, y, splits = get_UCR_data('HandMovementDirection', return_split=False)
tfms  = [None, [Categorize()]]
batch_tfms = [TSStandardize(by_sample=True)]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=64, drop_last=False, shuffle_train=False, batch_tfms=[TSStandardize(by_sample=True)])
model = create_model(ROCKET, dls=dls)
X_train, y_train = create_rocket_features(dls.train, model)
X_valid, y_valid = create_rocket_features(dls.valid, model)
ridge = RidgeClassifierCV(alphas=np.logspace(-8, 8, 17), normalize=True)
ridge.fit(X_train, y_train)
print(f'alpha: {ridge.alpha_:.2E}  train: {ridge.score(X_train, y_train):.5f}  valid: {ridge.score(X_valid, y_valid):.5f}')
```
"""



================================================
FILE: tutorial_nbs/03_Time_Series_Transforms.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/03_Time_Series_Transforms.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# Import libraries
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
computer_setup()
# Output:
#   /usr/local/lib/python3.6/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.

#     warnings.warn(problem)

#   tsai       : 0.2.15

#   fastai     : 2.2.5

#   fastcore   : 1.3.19

#   torch      : 1.7.0+cu101


"""
# Time Series/ Sequence Transforms
"""

seq_len = 500
time = np.arange(0, seq_len/10, 0.1)
trend = np.sin(np.arange(0, 1, 1/seq_len)*np.pi)*2
a1 = np.sin(time)
a2 = np.sin(time + 5)
a3 = np.sin(time + 10)
na1 = a1 + np.random.rand(seq_len)*.3
na2 = a2 + np.random.rand(seq_len)*.3
na3 = a3 + np.random.rand(seq_len)*.3
signal = TSTensor(np.stack((a1,a2,a3), axis=0)[None])
signal -= signal.mean()
noisy_signal = TSTensor(np.stack((na1,na2,na3), axis=0)[None])
noisy_signal -= noisy_signal.mean()
multi_freq_signal = TSTensor((np.random.rand(3, seq_len) - .5).cumsum(-1))[None]
multi_freq_signal -= multi_freq_signal.mean()
multi_freq_signal /= multi_freq_signal.std()

start = 0
stop = 100
for i, tfm in enumerate(all_TS_randaugs[start:stop]):
    _tfm = tfm[0] if isinstance(tfm, tuple) else tfm
    tfm_name = _tfm.func.__name__ if isinstance(_tfm, functools.partial) else _tfm.__name__
    s = noisy_signal if tfm_name in ['TSBlur', 'TSSmooth', 'TSLowRes', 'TSRandomLowRes', 'TSDenoise', 'TSRandomNoise', 
                                     'TSRandomNoise', 'TSRandomFreqNoise'] else signal
    s += trend
    s = TSTensor(s)
    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10, 6), sharex=True, sharey=True)
    ax[0].plot(s[0].T.cpu(), alpha=0.5)
    ax[0].set_title(f'{i:2} original', fontweight="bold")
    for _ in range(20):
        ts = RandAugment(tfm, N=5, M=10)(s, split_idx=0)
        if tfm_name == 'TSIdentity' or not torch.equal(s.data, ts.data): break
    ax[1].plot(ts[0].T.cpu())
    ax[1].set_title(f'{i:2} transformed: {tfm_name}', fontweight="bold")
    dif = (ts[0].T - s[0].T) if ts[0].T.shape == s[0].T.shape else torch.zeros(len(s[0]))
    ax[2].plot(dif.cpu())
    ax[2].set_title(f'{i:2} difference: {tfm_name}', fontweight="bold")
    plt.show()
    print()
    print()
beep()
# Output:
#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <Figure size 720x432 with 3 Axes>
#   

#   

#   <IPython.lib.display.Audio object>

"""
# Single transform
"""

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', on_disk=True, return_split=False)
tfms = [None, Categorize()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid)
xb, yb = next(iter(dls.train))
xb[0].show();
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>

for i in range(100): plt.plot(TSTimeNoise(.5)(xb, split_idx=0)[0].T.cpu(), color='gainsboro', alpha=.1)
plt.plot(xb[0].T.cpu())
plt.show()
# Output:
#   <Figure size 432x288 with 1 Axes>

dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, after_batch=[TSTimeWarp(magnitude=.2, ex=0)])
dls.show_batch(unique=True, sharex=True, sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
# Multiple transforms
"""

for i in range(10): plt.plot(compose_tfms(xb[0], [TSVerticalFlip(p=.5), TSHorizontalFlip(p=.5)], split_idx=0).T.cpu(), color='gainsboro')
plt.plot(xb[0].T.cpu())
plt.show()
# Output:
#   <Figure size 432x288 with 1 Axes>

dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128, num_workers=0, batch_tfms=[TSMagAddNoise(magnitude=0.05), TSMagScale()])
dls.train.show_batch(unique=True, sharex=True, sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

BB_tfms = [TSIdentity, TSMagScale, partial(TSRandomTimeStep), partial(TSTimeWarp, ex=0), 
           TSRandomRotate,partial(TSMagWarp, ex=0), partial(TSTimeNoise, ex=0)]
for i in range(10): 
    xb2 = RandAugment(BB_tfms, N=3, M=1)(xb, split_idx=0)
    test_eq(xb2.shape, xb.shape)
    assert not np.array_equal(xb2.data, xb.data)

BB_tfms = [
    (TSIdentity, 0., 1.),
    (TSMagScale, .02, .2),
    (partial(TSRandomTimeStep), .02, .2),
    (partial(TSTimeWarp, ex=[0,1,2]), .02, .2),
    (TSRandomRotate, .1, .5),
    (partial(TSMagWarp, ex=0), .02, .2),
    (partial(TSTimeNoise, ex=0), .05, .5),
]
for i in range(10): 
    xb2 = RandAugment(BB_tfms, N=3, M=1)(xb, split_idx=0)
    test_eq(xb2.shape, xb.shape)
    assert not np.array_equal(xb2.data, xb.data)

for i in range(20): plt.plot(RandAugment(BB_tfms, N=3, M=5)(xb, split_idx=0)[0].T.cpu(), color='gainsboro')
plt.plot(xb[0].T.cpu())
plt.show()
# Output:
#   <Figure size 432x288 with 1 Axes>

"""
# How to use time-series transforms?
"""

dsid = 'NATOPS' 
X, y, splits = get_UCR_data(dsid, return_split=False)

# type/ item transforms
tfms  = [None, [Categorize()]]

# batch transforms
TS_tfms = [
    TSIdentity,
    TSMagAddNoise,
    (TSMagScale, .02, .2),
    (partial(TSMagWarp, ex=0), .02, .2),
    (partial(TSTimeWarp, ex=[0,1,2]), .02, .2),
]
batch_tfms=[TSStandardize(), RandAugment(TS_tfms, N=3, M=5)]

dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=accuracy)
learn.fit_one_cycle(50, lr_max=1e-3)
learn.recorder.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 864x288 with 2 Axes>



================================================
FILE: tutorial_nbs/04_Intro_to_Time_Series_Regression.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/04_Intro_to_Time_Series_Regression.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## Purpose 😇
"""

"""
The purpose of this notebook is to show you how you can create a simple, end-to-end, state-of-the-art **time series regression** model using **`fastai`** and **`tsai`**.

A time series regression is a task in which you assign a continuous value to a univariate or multivariate time series. 
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
## Prepare data 🔢
"""

"""
We are going to select a dataset from the recently released Monash, UEA & UCR 
Time Series Extrinsic Regression Repository (2020) ([web](http://tseregression.org), [paper](https://arxiv.org/abs/2006.10996)). 

Please, feel free to select any other dataset to experiment with it. Here's the entire list.
"""

regression_list
# Output:
#   ['AppliancesEnergy',

#    'AustraliaRainfall',

#    'BeijingPM10Quality',

#    'BeijingPM25Quality',

#    'BenzeneConcentration',

#    'Covid3Month',

#    'FloodModeling1',

#    'FloodModeling2',

#    'FloodModeling3',

#    'HouseholdPowerConsumption1',

#    'HouseholdPowerConsumption2',

#    'IEEEPPG',

#    'LiveFuelMoistureContent',

#    'NewsHeadlineSentiment',

#    'NewsTitleSentiment']

dsid = 'AppliancesEnergy' 
X, y, splits = get_regression_data(dsid, split_data=False)
X.shape, y.shape, y[:10]
# Output:
#   119it [00:04, 29.40it/s]

#   66it [00:04, 16.43it/s]

#   ((137, 24, 144),

#    (137,),

#    memmap([19.38, 12.68,  5.34, 12.72, 13.25, 26.28, 13.1 , 14.06, 10.92,

#            10.46]))

"""
For regression tasks, we need to ensure y is a float. Let's check the format of the data:
"""

check_data(X, y, splits)
# Output:
#   X      - shape: [137 samples x 24 features x 144 timesteps]  type: memmap  dtype:float64  isnan: 0

#   y      - shape: (137,)  type: memmap  dtype:float64  isnan: 0

#   splits - n_splits: 2 shape: [95, 42]  overlap: False

#   <Figure size 1152x36 with 1 Axes>

tfms  = [None, [TSRegression()]]
batch_tfms = TSStandardize(by_sample=True, by_var=True)
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, bs=128)
dls.one_batch()
# Output:
#   (TSTensor(samples:95, vars:24, len:144, device=cuda:0, dtype=torch.float32),

#    tensor([12.0700, 23.0100, 10.1700,  9.9900, 21.3100, 14.6100, 16.7700, 13.3700,

#            11.5400, 11.9200, 10.5100, 10.1100,  8.7500, 12.7200, 10.5100, 12.5400,

#            20.4400, 13.6900, 11.3200, 16.2500, 16.2200, 19.6200, 10.6100, 16.4100,

#            10.8900, 10.6300, 26.2800, 16.0200,  5.3800, 10.8000, 11.8300, 11.6300,

#            13.8700, 22.7400, 18.5600, 13.2500, 12.6800,  8.6200,  9.6300, 11.5300,

#            15.6800, 14.6200, 11.9300, 21.6900,  7.0300, 19.2200, 14.2800, 19.3800,

#             5.3400, 17.3000, 13.5600, 11.0600, 21.4900, 13.1000, 19.9400, 11.2300,

#            10.4600, 23.4200, 17.6600, 22.1000, 10.3100, 18.1800, 11.4900, 19.0100,

#            11.6400, 17.5300, 10.2600, 12.7800, 14.8200, 12.2400, 12.9700, 16.5300,

#            11.4000, 13.2100, 14.0600, 16.0500, 10.2500, 10.6200, 12.0300, 10.9200,

#            14.9900, 12.6800, 12.9800, 17.0000, 13.2900, 14.8000,  9.1700, 21.9100,

#            10.8200, 20.7400, 14.7100,  9.6000, 21.7400, 15.8900,  9.8200],

#           device='cuda:0'))

"""
`TSDatasets` identifies this as a regression problem, as the 2nd output (the ys) are floats. That's why the number of classes is set to 1. This is required to be able to correctly use the time series models available in `timesereisAI`.
"""

dls.c
# Output:
#   1

dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
## Build learner 🏗
"""

"""
* Model: we can choose any of the time series models available in `timeseriesAI`. The same ones that work for classification also work for regression. In this case we'll use a state-of-the-art time series model called ` InceptionTime`.
* Loss: since this is a regression problem, we''l use a regression loss (`MSELossFlat`). However, there's not need to pass it to the Learner, as it will automatically infer the required loss.
* Metrics: we'll also choose regression metrics. (`mse` will return the same result as the loss we have selected. Just added it for demo purposes).
"""

learn = ts_learner(dls, InceptionTime, metrics=[mae, rmse], cbs=ShowGraph())
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=0.0012022644514217973)
#   <Figure size 432x288 with 1 Axes>

"""
It seems we can use a lr around 1e-2. Let's try it.
"""

learn.loss_func
# Output:
#   FlattenedLoss of MSELoss()

"""
## Train model 🚵🏼‍
"""

learn = ts_learner(dls, InceptionTime, metrics=[mae, rmse], cbs=ShowGraph())
learn.fit_one_cycle(50, 1e-2)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 936x648 with 4 Axes>

PATH = Path('./models/Regression.pkl')
PATH.parent.mkdir(parents=True, exist_ok=True)
learn.export(PATH)

del learn

"""
## Inference ⎘
"""

"""
We'll now upload the saved learner and create the predictions:
"""

PATH = Path('./models/Regression.pkl')
learn = load_learner(PATH, cpu=False)

probas, _, preds = learn.get_X_preds(X[splits[1]])
skm.mean_squared_error(y[splits[1]], preds, squared=False)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   2.488811726919921

"""
As you can see, this matches the valid rmse at the end of training, so the model is predicting correctly. Now you can pass any data and generate other predictions.
"""

"""
## Summary ✅
"""

"""
As you can see, to use fastai and timeseriesAI to perform a time series regression/ forecasting task is pretty easy. The only thing you need to make sure is that:

* Your data is correctly prepared (with ys as floats)
* Select the right metrics (Learner will automatically select the right loss, unless you want to pass a specific one yourself).
"""



================================================
FILE: tutorial_nbs/05_TS_archs_comparison.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/05_TS_archs_comparison.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
from IPython.display import clear_output
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
# Experiments 🧪
"""

"""
I've run a small test to show how you can build any model in the `tsai` library using the `create_model` functions.

The esiest way to do it is pass the architecture you want to use, a `TSDataLoaders` and any `kwargs` you'd like to use. The `create_model` function will pick up the necessary data from the `TSDataLoaders` object.

I've used 2 multivariate time series datasets. As you can see, it's difficult to predict which architecture will work best for which dataset.

Please, bear in mind that this is a very simple test without any hyperparameter tuning.
"""

dsid = 'NATOPS' 
bs = 64
X, y, splits = get_UCR_data(dsid, return_split=False)
print(X.shape)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])

archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), 
         (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), 
         (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),
         (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]

results = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'accuracy', 'time'])
for i, (arch, k) in enumerate(archs):
    model = create_model(arch, dls=dls, **k)
    print(model.__class__.__name__)
    learn = Learner(dls, model,  metrics=accuracy)
    start = time.time()
    learn.fit_one_cycle(100, 1e-3)
    elapsed = time.time() - start
    vals = learn.recorder.values[-1]
    results.loc[i] = [arch.__name__, k, count_parameters(model), vals[0], vals[1], vals[2], int(elapsed)]
    results.sort_values(by='accuracy', ascending=False, kind='stable', ignore_index=True, inplace=True)
    clear_output()
    display(results)
# Output:
#                arch                              hyperparams total params  \

#   0        LSTM_FCN                                       {}       347246   

#   1             FCN                                       {}       285446   

#   2        LSTM_FCN                       {'shuffle': False}       336446   

#   3    XceptionTime                                       {}       403420   

#   4          ResNet                                       {}       490758   

#   5          ResCNN                                       {}       268551   

#   6   InceptionTime                                       {}       460038   

#   7            mWDN                            {'levels': 4}       467038   

#   8     xresnet1d34                                       {}      7232518   

#   9    OmniScaleCNN                                       {}      5239596   

#   10           LSTM   {'n_layers': 3, 'bidirectional': True}       585206   

#   11           LSTM   {'n_layers': 2, 'bidirectional': True}       343606   

#   12           LSTM  {'n_layers': 2, 'bidirectional': False}       131806   

#   13           LSTM   {'n_layers': 1, 'bidirectional': True}       102006   

#   14           LSTM  {'n_layers': 1, 'bidirectional': False}        51006   

#   15           LSTM  {'n_layers': 3, 'bidirectional': False}       212606   

#   

#       train loss  valid loss  accuracy time  

#   0     0.074354    0.116819  0.966667    6  

#   1     0.074158    0.125400  0.961111    5  

#   2     0.066596    0.113484  0.961111    6  

#   3     0.399169    0.499384  0.961111    9  

#   4     0.025244    0.122984  0.955556    7  

#   5     0.041432    0.134848  0.950000    6  

#   6     0.026669    0.113258  0.938889    9  

#   7     0.025454    0.274648  0.927778    9  

#   8     0.022142    0.318501  0.916667   15  

#   9     0.193854    0.260377  0.883333   19  

#   10    0.353111    0.354646  0.833333    5  

#   11    0.322159    0.342655  0.822222    5  

#   12    0.365258    0.336271  0.816667    4  

#   13    0.386917    0.368431  0.816667    4  

#   14    0.379870    0.429362  0.800000    5  

#   15    0.581518    0.637237  0.716667    5  

dsid = 'LSST' 
bs = 64
X, y, splits = get_UCR_data(dsid, return_split=False)
print(X.shape)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[bs, bs*2])

archs = [(FCN, {}), (ResNet, {}), (xresnet1d34, {}), (ResCNN, {}), 
         (LSTM, {'n_layers':1, 'bidirectional': False}), (LSTM, {'n_layers':2, 'bidirectional': False}), (LSTM, {'n_layers':3, 'bidirectional': False}), 
         (LSTM, {'n_layers':1, 'bidirectional': True}), (LSTM, {'n_layers':2, 'bidirectional': True}), (LSTM, {'n_layers':3, 'bidirectional': True}),
         (LSTM_FCN, {}), (LSTM_FCN, {'shuffle': False}), (InceptionTime, {}), (XceptionTime, {}), (OmniScaleCNN, {}), (mWDN, {'levels': 4})]

results = pd.DataFrame(columns=['arch', 'hyperparams', 'total params', 'train loss', 'valid loss', 'accuracy', 'time'])
for i, (arch, k) in enumerate(archs):
    model = create_model(arch, dls=dls, **k)
    print(model.__class__.__name__)
    learn = Learner(dls, model,  metrics=accuracy)
    start = time.time()
    learn.fit_one_cycle(100, 1e-3)
    elapsed = time.time() - start
    vals = learn.recorder.values[-1]
    results.loc[i] = [arch.__name__, k, count_parameters(model), vals[0], vals[1], vals[2], int(elapsed)]
    results.sort_values(by='accuracy', ascending=False, kind='stable', ignore_index=True, inplace=True)
    clear_output()
    display(results)
# Output:
#                arch                              hyperparams total params  \

#   0    XceptionTime                                       {}       401580   

#   1          ResCNN                                       {}       260367   

#   2            LSTM   {'n_layers': 3, 'bidirectional': True}       572414   

#   3        LSTM_FCN                       {'shuffle': False}       314950   

#   4            LSTM   {'n_layers': 2, 'bidirectional': True}       330814   

#   5          ResNet                                       {}       482574   

#   6            LSTM  {'n_layers': 2, 'bidirectional': False}       125414   

#   7            LSTM  {'n_layers': 3, 'bidirectional': False}       206214   

#   8            LSTM   {'n_layers': 1, 'bidirectional': True}        89214   

#   9            LSTM  {'n_layers': 1, 'bidirectional': False}        44614   

#   10       LSTM_FCN                                       {}       326950   

#   11   OmniScaleCNN                                       {}      1432716   

#   12            FCN                                       {}       270350   

#   13           mWDN                            {'levels': 4}       461182   

#   14  InceptionTime                                       {}       457614   

#   15    xresnet1d34                                       {}      7234894   

#   

#       train loss  valid loss  accuracy time  

#   0     0.070966    1.596494  0.680049   92  

#   1     0.231670    1.220587  0.677210   56  

#   2     0.000120    2.694554  0.669100   50  

#   3     0.416285    1.403729  0.662206   45  

#   4     0.000262    2.415106  0.657745   44  

#   5     0.021112    1.656618  0.653690   71  

#   6     0.002257    2.448107  0.639092   35  

#   7     0.001700    2.582463  0.632198   39  

#   8     0.056981    1.748464  0.606650   34  

#   9     0.058143    1.877555  0.601379   31  

#   10    0.460975    1.571851  0.592863   46  

#   11    0.674799    1.878544  0.554745   89  

#   12    0.833404    1.675762  0.535280   40  

#   13    0.000141    2.827999  0.512571  111  

#   14    0.260041    3.254463  0.422952  100  

#   15    0.067009    4.703222  0.366586  174  



================================================
FILE: tutorial_nbs/06_TS_to_image_classification.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/06_TS_to_image_classification.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
## Introduction 🤝
"""

"""
Sometimes it may be useful to transform a univariate or multivariate time series into an image so that any of the techniques available for images can be used. 

These images can be created "on the fly" by transforms that work in the same way as any other transforms in fastai. I've added a few of these transforms to the tsai library. Most of the transforms come from the excellent `pyts` library (for more information please visit https://pyts.readthedocs.io).

I'd like to warn you up from that the transform of a TS to an image "on the fly" is slow, and can make you training way too long. If you are still interested in using TS as images, you may test wich ones work best on a small subset, and then create and save the output as images. You can then use a regular vision dataloader to train a vision model. 
"""

"""
## Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
## Available TS to Image transforms ⏳
"""

"""
The following time series to image transforms are available in the tsai library:

* **TSToPlot**: creates a matplotlib line plot
* **TSToMat**: creates a matplotlib imshow plot
* **TSToGADF**: creates an image based on a Gramian Angular Difference Filed transformation
* **TSToGASF**: creates an image based on a Gramian Angular Summation Filed transformation
* **TSToMTF**: creates an image based on a Markov Transition Field transformation
* **TSToRP**: creates an image based on a Recurrence Plot transformation

All transforms can be used with **univariate or multivariate time series**.
"""

dsid = 'NATOPS' # multivariate dataset
X, y, splits = get_UCR_data(dsid, return_split=False)
tfms = [None, Categorize()]
bts = [[TSNormalize(), TSToPlot()], 
       [TSNormalize(), TSToMat(cmap='viridis')],
       [TSNormalize(), TSToGADF(cmap='spring')],
       [TSNormalize(), TSToGASF(cmap='summer')],
       [TSNormalize(), TSToMTF(cmap='autumn')],
       [TSNormalize(), TSToRP(cmap='winter')]]
btns = ['Plot', 'Mat', 'GADF', 'GASF', 'MTF', 'RP']
for i, (bt, btn) in enumerate(zip(bts, btns)):
    dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
    dls = TSDataLoaders.from_dsets(dsets.train,
                                   dsets.valid,
                                   bs=[64, 128],
                                   batch_tfms=bt,
                                   shuffle=False)
    xb, yb = dls.train.one_batch()
    print(f'\n\ntfm: TSTo{btn} - batch shape: {xb.shape}')
    xb[0].show()
    plt.show()
# Output:
#   

#   

#   tfm: TSToPlot - batch shape: torch.Size([64, 3, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>
#   

#   

#   tfm: TSToMat - batch shape: torch.Size([64, 3, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>
#   

#   

#   tfm: TSToGADF - batch shape: torch.Size([64, 24, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>
#   

#   

#   tfm: TSToGASF - batch shape: torch.Size([64, 24, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>
#   

#   

#   tfm: TSToMTF - batch shape: torch.Size([64, 24, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>
#   

#   

#   tfm: TSToRP - batch shape: torch.Size([64, 24, 224, 224])

#   <PIL.Image.Image image mode=RGB size=224x224>

"""
## Univariate time series 🦄
"""

"""
Let's first see how all these transforms can be applied to univariate time series. 
"""

dsid = 'OliveOil'
X, y, splits = get_UCR_data(dsid, return_split=False)
epochs = 200

"""
### Raw data (InceptionTime)
"""

"""
As a benchmark, we'll first train a state-of-the-art TS model (Inceptiontime) that uses raw data. 
"""

tfms = [None, Categorize()]
batch_tfms = [TSStandardize()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
Even if these look like images, the actual data passed to the model is the raw data (batch_size x channels x sequence lentgh). 

This is different from the TS to image transforms that will see in a moment, in which the batch contains actual images. 
"""

model = create_model(InceptionTime, dls=dls)
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   

#   training time: 00:01:03


"""
### TSToPlot
"""

"""
All of these transforms are applied as batch transforms. We can use the same TSDatasets and TSDataLoaders we always use.

Some of these transforms require a previous normalization (TSToMat, TSToGASF, TSToGADF, TSToRP). In general, I'd recommend you to use TSNormalize in all cases. By default this transform will normalize each sample between (-1, 1), although you can also choose the option by_sample=False, in which case, it will normalize based on the entire training set. 

We'll train a vision model. In our case, we'll use xresnet34, which is part of the fastai library.

I will train all models in the same way, without any hyperparameter optimization. 

In the case of univariate time series, you may also pass a matplotlib cmap to the transform (all except TSToPlot). Bear in mind that all these transforms will create a 1 channel image for each variable (1 in the case of univariate TS). This may be converted into a 3 channel image by applying a cmap. This will add extra time to the batch creation process but in some cased it improves performance. 
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToPlot()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:04:12

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToMat
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToMat()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
One of the options you have is to use a pretrained model and just fine tune it, or train it entirely from scratch. Let's see how you could test this.
"""

model = create_model(xresnet34, dls=dls, pretrained=True)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:03:34

#   <Figure size 1440x288 with 3 Axes>

model = create_model(xresnet34, dls=dls) # by default xresnet models are pretrained=False
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:03:14

#   <Figure size 1440x288 with 3 Axes>

"""
In this case these 2 approaches have the same performance. We'll test this again later with a multivariate dataset. 
"""

"""
### TSToGADF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToGADF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:01:00

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToGASF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToGASF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:00:59

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToMTF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToMTF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:00:59

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToRP
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(by_sample=True, range=(0,1)), TSToRP()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:00:58

#   <Figure size 1440x288 with 3 Axes>

"""
## Multivariate  time series ✖️
"""

"""
In the case of multivariate time series they are used in the same way. 

The only differences are: 

* You may normalize data based on the training dataset or by sample. In either case you may also do it by variable (by_var=True) or not. 
* You won't be able to pass a cmap as multivariate time series will create a one channel image for each of the time series variables. 
"""

dsid = 'NATOPS'
X, y, splits = get_UCR_data(dsid, parent_dir='./data/UCR/', return_split=False)
epochs = 100

"""
### Raw data (InceptionTime)
"""

tfms = [TSStandardize(verbose=True), Categorize()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=None)
model = create_model(InceptionTime, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:00:09

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToPlot
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToPlot()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:24:27

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToMat
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToMat()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
xb,yb = first(dls.train)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
Let's check again if there's any difference between training a pre-trained model and training it from scratch.
"""

model = create_model(xresnet34, dls=dls, pretrained=True)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:04:52

#   <Figure size 1440x288 with 3 Axes>

model = create_model(xresnet34, dls=dls) # not pretrained
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:05:09

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToGADF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToGADF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:06:49

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToGASF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToGASF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:07:05

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToMTF
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(), TSToMTF()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:07:20

#   <Figure size 1440x288 with 3 Axes>

"""
### TSToRP
"""

tfms = [None, Categorize()]
batch_tfms = [TSNormalize(by_sample=True, range=(0,1)), TSToRP()]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=batch_tfms)
dls.show_batch()
# Output:
#   <Figure size 1296x864 with 9 Axes>

model = create_model(xresnet34, dls=dls)
learn = Learner(dls, model, metrics=accuracy)
start = time.time()
learn.fit_one_cycle(epochs, lr_max=1e-3)
print(f"\ntraining time: {time.strftime('%H:%M:%S', time.gmtime(time.time() - start))}")
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   

#   training time: 00:05:31

#   <Figure size 1440x288 with 3 Axes>

"""
## Conclusion ✅
"""

"""
As you have seen, these transforms are competitive if you compare them to a state-of-the-art raw TS model like InceptionTime (that take a 3d input - bs x nvars x seq_len) instead of the image models that take 4d inputs.

There are many ways in which you can transform univariate or multivariate time series into images. 

There are many options to explore all of this: 

* You can use many different TS to image transformations 
* You can also use different cmaps
* You can choose different image sizes
* You can normalize data by sample and/ or by_channel
* You can use pretrained models or train from scratch
* You can combine TS to image transforms with other transforms
* You can use different vision models


I hope you find this useful as an introduction to this field. 
"""



================================================
FILE: tutorial_nbs/07_Time_Series_Classification_with_Transformers.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/07_Time_Series_Classification_with_Transformers.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# TST (Time Series Transformer) 🤗
"""

"""

> This is an unofficial PyTorch implementation by Ignacio Oguiza of  - oguiza@timeseriesAI.co based on:

* Zerveas, G., Jayaraman, S., Patel, D., Bhamidipaty, A., & Eickhoff, C. (2020). **A Transformer-based Framework for Multivariate Time Series Representation Learning**. arXiv preprint arXiv:2010.02803v2.
* No official implementation available as far as I know (Oct 10th, 2020)

* This paper uses 'Attention is all you need' as a major reference:
    * Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). **Attention is all you need**. In Advances in neural information processing systems (pp. 5998-6008).

This implementation is adapted to work with the rest of the `tsai` library, and contain some hyperparameters that are not available in the original implementation. I included them to experiment with them. 
"""

"""
## TST *args and **kwargs
"""

"""
Usual values are the ones that appear in the "Attention is all you need" and "A Transformer-based Framework for Multivariate Time Series Representation Learning" papers. 

The default values are the ones selected as a default configuration in the latter.

* c_in: the number of features (aka variables, dimensions, channels) in the time series dataset. dls.var
* c_out: the number of target classes. dls.c
* seq_len: number of time steps in the time series. dls.len
* max_seq_len: useful to control the temporal resolution in long time series to avoid memory issues. Default. None.
* d_model: total dimension of the model (number of features created by the model). Usual values: 128-1024. Default: 128.
* n_heads:  parallel attention heads. Usual values: 8-16. Default: 16.
* d_k: size of the learned linear projection of queries and keys in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
* d_v: size of the learned linear projection of values in the MHA. Usual values: 16-512. Default: None -> (d_model/n_heads) = 32.
* d_ff: the dimension of the feedforward network model. Usual values: 256-4096. Default: 256.
* dropout: amount of residual dropout applied in the encoder. Usual values: 0.-0.3. Default: 0.1.
* activation: the activation function of intermediate layer, relu or gelu. Default: 'gelu'.
* num_layers: the number of sub-encoder-layers in the encoder. Usual values: 2-8. Default: 3.
* fc_dropout: dropout applied to the final fully connected layer. Usual values: 0-0.8. Default: 0.
* pe: type of positional encoder. Available types: None, 'gauss' (default), 'lin1d', 'exp1d', '2d', 'sincos', 'zeros'. Default: 'gauss'.
* learn_pe: learned positional encoder (True, default) or fixed positional encoder. Default: True.
* flatten: this will flattent the encoder output to be able to apply an mlp type of head. Default=True.
* custom_head: custom head that will be applied to the network. It must contain all kwargs (pass a partial function). Default: None.
* y_range: range of possible y values (used in regression tasks). Default: None
* kwargs: nn.Conv1d kwargs. If not {}, a nn.Conv1d with those kwargs will be applied to original time series.
"""

"""
## Tips on how to use transformers:
"""

"""
* In general, transformers require a lower lr compared to other time series models when used with the same datasets. It's important to use `learn.lr_find()` to learn what a good lr may be. 

* The paper authors recommend to standardize data by feature. This can be done by adding `TSStandardize(by_var=True` as a batch_tfm when creating the `TSDataLoaders`.

* When using TST with a long time series, you may use `max_w_len` to reduce the memory size and thus avoid gpu issues.`

* I've tried different types of positional encoders. In my experience, the default one works just fine.

* In some of the cases I've used it, you may need to increase the dropout > .1 and/ or fc_dropout > 0 in order to achieve a good performance. 

* You may also experiment with other key hyperparameters like d_model, n_layers, n_heads, etc, but I have not seen major difference in my experience. 
"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
computer_setup()
# Output:
#   tsai       : 0.2.4

#   fastai     : 2.1.5

#   fastcore   : 1.3.2

#   torch      : 1.7.0+cu101


"""
# Load data 🔢
"""

dsid = 'FaceDetection' 
X, y, splits = get_UCR_data(dsid, return_split=False)
print(X.shape, y.shape)
# Output:
#   (9414, 144, 62) (9414,)


"""
# InceptionTime ⎘
"""

"""
For comparison I will include a state-of-the-art time series model as Inception Time. 
"""

bs = 64
n_epochs = 100
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=bs, batch_tfms=TSStandardize())
dls.show_batch()
# Output:
#   <Figure size 1152x720 with 9 Axes>

model = InceptionTime(dls.vars, dls.c)
learn = Learner(dls, model, metrics=[RocAucBinary(), accuracy], cbs=ShowGraphCallback2())
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   SuggestedLRs(lr_min=0.025118863582611083, lr_steep=6.309573450380412e-07)
#   <Figure size 432x288 with 1 Axes>

start = time.time()
learn.fit_one_cycle(n_epochs, lr_max=1e-3)
print('\nElapsed time:', time.time() - start)
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   Elapsed time: 486.4021394252777


"""
We can see that even if valid loss goes up, the model doesn't overfit as there's no drop in performance.
"""

"""
# TST baseline 🧢
"""

bs = 64
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=bs, batch_tfms=TSStandardize(by_var=True))
dls.show_batch()
# Output:
#   <Figure size 1152x720 with 9 Axes>

model = TST(dls.vars, dls.c, dls.len)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   SuggestedLRs(lr_min=4.365158383734525e-06, lr_steep=1.5848931980144698e-06)
#   <Figure size 432x288 with 1 Axes>

model = TST(dls.vars, dls.c, dls.len)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
start = time.time()
learn.fit_one_cycle(n_epochs, lr_max=1e-4)
print('\nElapsed time:', time.time() - start)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   Elapsed time: 445.62548995018005

#   <Figure size 1296x288 with 3 Axes>

"""
# How to improve performance with TST? ➕
"""

"""
The model clearly overfits in this task. To try and improve performance I will increase dropout. There are 2 types of dropout in TST: 

* applied to the MHAttention and Feed-Forward layers. Usually 0-0.3. Default: 0.1.

* applied to the fully connected head. Usually 0-0.8. Default: 0.

Let's see what's the impact of these 2 hyperparameters, used independently and combined.
"""

model = TST(dls.vars, dls.c, dls.len, dropout=.3)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
start = time.time()
learn.fit_one_cycle(n_epochs, lr_max=1e-4)
print('\nElapsed time:', time.time() - start)
learn.plot_metrics()
beep()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   Elapsed time: 445.0662522315979

#   <Figure size 1296x288 with 3 Axes>
#   <IPython.lib.display.Audio object>

"""
dropout by itself reduces overfit, but it doesn't eliminate it.
"""

model = TST(dls.vars, dls.c, dls.len, dropout=.1, fc_dropout=.8)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
start = time.time()
learn.fit_one_cycle(n_epochs, lr_max=1e-4)
print('\nElapsed time:', time.time() - start)
learn.plot_metrics()
beep()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   Elapsed time: 453.8333086967468

#   <Figure size 1296x288 with 3 Axes>
#   <IPython.lib.display.Audio object>

"""
It still slightly overfits, although it's much better than the original settings. 

Now let's try both together.
"""

model = TST(dls.vars, dls.c, dls.len, dropout=.3, fc_dropout=.8)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
start = time.time()
learn.fit_one_cycle(n_epochs, lr_max=1e-4)
print('\nElapsed time:', time.time() - start)
learn.plot_metrics()
beep()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   Elapsed time: 445.771844625473

#   <Figure size 1296x288 with 3 Axes>
#   <IPython.lib.display.Audio object>

"""
Let's check what happens if we increase dropout a bit more...
"""

model = TST(dls.vars, dls.c, dls.len, dropout=0.3, fc_dropout=0.9)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
learn.fit_one_cycle(n_epochs, 1e-4) 
learn.plot_metrics()
beep()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1296x288 with 3 Axes>
#   <IPython.lib.display.Audio object>

"""
This is a great result, beyond InceptionTime and any other the state-of-the-art papers I've seen.
"""

"""
# Conclusion ✅
"""

"""
TST (Time Series Transformer) seems like a great addition to the world of time series models.

The model trains very smoothly and overfitting can be reduced/ eliminated by using dropout.

Also, TST is about 10% faster to train that InceptionTime.
Here's all the code you need to train a transformer model with `tsai`:

```
X, y, splits = get_UCR_data('FaceDetection', return_split=False)
tfms  = [None, [Categorize()]]
dsets = TSDatasets(X, y, tfms=tfms, splits=splits)
dls   = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=64, batch_tfms=TSStandardize(by_var=True))
model = TST(dls.vars, dls.c, dls.len, dropout=0.3, fc_dropout=0.9)
learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropyFlat(), 
                metrics=[RocAucBinary(), accuracy],  cbs=ShowGraphCallback2())
learn.fit_one_cycle(100, 1e-4) 
```
"""



================================================
FILE: tutorial_nbs/08_Self_Supervised_TSBERT.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/08_Self_Supervised_MVP.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# MVP (previously TSBERT): Self-Supervised Pretraining of Time Series Models 🤗
"""

"""
This is an unofficial PyTorch implementation created by Ignacio Oguiza (oguiza@timeseriesAI.co) based on:

* Zerveas, G., Jayaraman, S., Patel, D., Bhamidipaty, A., & Eickhoff, C. (2020). A Transformer-based Framework for Multivariate Time Series Representation Learning. arXiv preprint arXiv:2010.02803v2.. No official implementation available as far as I know (Oct 10th, 2020)
"""

"""
`MVP` is a self-supervised training method that can be used to pretrain time series models without using any labels. The approach is very similar to BERT.

`MVP` is performed in 2 steps: 

1. Pretrain the selected architecture without any labels. When training is finished, the pretrained model will be automatically saved to the given target_dir/fname.
2. Fine-tune or train the same architecture with pretrained=True indicating the weights_path (target_dir/fname).


In this notebook we'll use a UCR dataset (LSST) that contains around 2500 training and 2500 validation samples. To analyze the impact of `MVP` we'll:
1. use supervised learning to set a baseline using 10% or 100% of the labels.
2. pretrain a model using 100% of the training dataset without labels.
3. fine tune or train using 10% or 100% of the training dataset (with labels). 

A key difference between `MVP` and the original paper is that you can use any architecture of your choice as long as it has a "head" attribute and can take a custom_head kwarg. Architectures finished in Plus in the `tsai` library meet this criteria. To demonstrate how this works, we'll use InceptionTimePlus throughout this notebook.
"""

"""
### Results
"""

"""
<img src="https://github.com/timeseriesAI/tsai/blob/master/tutorial_nbs/images/TSBERT_data.jpg?raw=1">
<img src="https://github.com/timeseriesAI/tsai/blob/master/tutorial_nbs/images/TSBERT_chart.jpg?raw=1">
"""

"""
These results indicate the following: 

* Pretraining + fine-tuning/ training improves performance when compared to supervised learning (training from scratch).
* In this case, there's not much difference between fine-tuning and training a pretrained model. This may be dataset dependent. It'd be good to try both approaches. 
* The fewer labels available, the better pretraining seems to work. 
"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
from IPython.display import clear_output
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
# Prepare data 🏭
"""

"""
We'll first import the data.
"""

dsid = 'LSST'
X, y, splits = get_UCR_data(dsid, split_data=False)

"""
We'll now create 2 dataloaders with 100% of the training and 100% of validation samples.
One of them doesn't contain the y (unlabeled). The other one contains the labels. 
We'll use the unlabeled dataset (udls) to pretrain the model.
"""

# 100% train data
tfms = [None, TSClassification()]
batch_tfms = [TSStandardize(by_sample=True)]
check_data(X, y, splits)
dls100 = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
udls100 = get_ts_dls(X, splits=splits, tfms=tfms, batch_tfms=batch_tfms) # used in pretraining
# Output:
#   X      - shape: [4925 samples x 6 features x 36 timesteps]  type: memmap  dtype:float32  isnan: 0

#   y      - shape: (4925,)  type: memmap  dtype:<U2  n_classes: 14 (351 samples per class) ['15', '16', '42', '52', '53', '6', '62', '64', '65', '67', '88', '90', '92', '95']  isnan: False

#   splits - n_splits: 2 shape: [2459, 2466]  overlap: False

#   <Figure size 1152x36 with 1 Axes>

"""
We'll also need a labeled dataloaders with 10% of the training and 100% of validation data.
"""

# 10% train data
train_split010 = get_splits(y[splits[0]], valid_size=.1, show_plot=False)[1]
splits010 = (train_split010, splits[1])
check_data(X, y, splits010)
dls010 = get_ts_dls(X, y, splits=splits010, tfms=tfms, batch_tfms=batch_tfms)
# Output:
#   X      - shape: [4925 samples x 6 features x 36 timesteps]  type: memmap  dtype:float32  isnan: 0

#   y      - shape: (4925,)  type: memmap  dtype:<U2  n_classes: 14 (351 samples per class) ['15', '16', '42', '52', '53', '6', '62', '64', '65', '67', '88', '90', '92', '95']  isnan: False

#   splits - n_splits: 2 shape: [245, 2466]  overlap: False

#   <Figure size 1152x36 with 1 Axes>

"""
# Supervised 👀
"""

"""
First we'll train a model in a supervised way to set a baseline. We'll train using 10% and 100% of the training set. We'll run 10 tests.

We'll train all models with the same settings (50 epochs with 10% of labels, 20 and 50 epochs with 100% of labels and lr=1e-2) to see the impact of pretraining.
"""

# supervised 10%
n_epochs = 50
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls010, InceptionTimePlus, metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.551 +/- 0.012

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.553 +/- 0.012 in 10 tests


# supervised 100%
n_epochs = 50
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.704 +/- 0.008

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.705 +/- 0.008 in 10 tests


"""
I've also trained the model with all labels for 20 as it seems to be overfitting with 50 epochs.
"""

# supervised 100%
n_epochs = 20
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.704 +/- 0.007

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.704 +/- 0.007 in 10 tests


"""
This is a great result. Just for reference, in a recent review of multivariate time series models (Ruiz, A. P., Flynn, M., Large, J., Middlehurst, M., & Bagnall, A. (2020). The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances. Data Mining and Knowledge Discovery, 1-49.), the best performing classifier on this dataset is MUSE with an accuracy of **63.62**. 

Let's see if we can improve our baseline pretraining InceptionTime using `MVP`.
"""

"""
# Pretrain model  🏋️‍♂️
"""

"""
Now we'll train a model without any labels on the entire training set. To do that we need to use the `MVP` callback. You can get more details on this callback visiting [`tsai` documentation](https://timeseriesai.github.io/tsai/callback.MVP).
"""

# Unlabeled 100%
learn = ts_learner(udls100, InceptionTimePlus, cbs=[ShowGraph(), MVP(target_dir='./data/MVP', fname=f'{dsid}_200')])
learn.fit_one_cycle(200, 1e-2)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   

#   epochs: 200 best epoch: 194  val_loss: 0.390507 - pretrained weights_path='data/MVP/LSST_200.pth'

#   

#   <Figure size 936x288 with 2 Axes>

learn.MVP.show_preds(sharey=True)
# Output:
#   <Figure size 1296x864 with 9 Axes>

"""
# Fine-tune 🎻
"""

"""
There are at least 2 options to use the pretrained model weights: 

1.   Fine-tune
2.   Train


We'll start by fine-tuning the pretrained model.

In this case, we double the base_lr as the training lr will be the base_lr / 2. The only net change of the fine tuning then is just a training of the new head for 10 epochs. The rest of the training will be the same.

Before training though, we'll check that when the model is frozen only the last layer is trained: 
"""

learn = ts_learner(dls010, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
for p in learn.model.parameters():
    p.requires_grad=False
print(f'{"trainable params once manually frozen":40}: {count_parameters(learn.model):8}')
learn.freeze()
print(f'{"trainable params after learn.freeze()":40}: {count_parameters(learn.model):8}')
learn.unfreeze()
print(f'{"trainable params learn.unfreeze()":40}: {count_parameters(learn.model):8}')
# Output:
#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   trainable params once manually frozen   :        0

#   trainable params after learn.freeze()   :     3854

#   trainable params learn.unfreeze()       :   457614


"""
It seems to be working well.
"""

# self-supervised: fine-tuning with 10% labels
n_epochs = 50
freeze_epochs = 10
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls010, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fine_tune(n_epochs, base_lr=2e-2, freeze_epochs=freeze_epochs)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.607 +/- 0.003

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.607 +/- 0.002 in 10 tests


# self-supervised: fine-tuning with 100% labels
n_epochs = 50
freeze_epochs = 10
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fine_tune(n_epochs, base_lr=2e-2, freeze_epochs=freeze_epochs)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.711 +/- 0.002

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.711 +/- 0.002 in 10 tests


# self-supervised: fine-tuning with 100% labels
n_epochs = 20
freeze_epochs = 10
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fine_tune(n_epochs, base_lr=2e-2, freeze_epochs=freeze_epochs)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.705 +/- 0.003

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.705 +/- 0.003 in 10 tests


"""
# Train 🏃🏽‍♀️🏃🏽‍♀
"""

# self-supervised: train with 10% labels
n_epochs = 50
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls010, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.585 +/- 0.006

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.585 +/- 0.006 in 10 tests


# self-supervised: train with 100% labels
n_epochs = 50
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.720 +/- 0.004

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.721 +/- 0.004 in 10 tests


# self-supervised 100% + training
n_epochs = 20
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy)
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.726 +/- 0.008

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.726 +/- 0.007 in 10 tests


"""
# Adding data augmentation 🔎🔎
"""

"""
One last thing I'd like to test is the impact of data augmentation when using a pretrained model. 

I will compare the performance of a model trained from scratch and a pretrained model adding CutMix (CutMix1D in `tsai`). We'll see if the difference in performance still holds.
"""

# self-supervised 100% + training
n_epochs = 20
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, metrics=accuracy, cbs=CutMix1d())
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.704 +/- 0.007

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.705 +/- 0.008 in 10 tests


# self-supervised 100% + training with cutmix
n_epochs = 20
n_tests = 10
_result = []
for i in range(n_tests):
    clear_output()
    if i > 0: print(f'{i}/{n_tests} accuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f}')
    else: print(f'{i}/{n_tests}')
    learn = ts_learner(dls100, InceptionTimePlus, pretrained=True, weights_path=f'data/MVP/{dsid}_200.pth', metrics=accuracy, cbs=CutMix1d())
    learn.fit_one_cycle(n_epochs, 1e-2)
    _result.append(learn.recorder.values[-1][-1])
learn.plot_metrics()
print(f'\naccuracy: {np.mean(_result):.3f} +/- {np.std(_result):.3f} in {n_tests} tests')
# Output:
#   9/10 accuracy: 0.723 +/- 0.004

#   weights from data/MVP/LSST_200.pth successfully transferred!

#   

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 1440x288 with 3 Axes>
#   

#   accuracy: 0.723 +/- 0.004 in 10 tests


"""
As you can see CutMix improves performance in both cases, but the pretrained model still performs better.
"""

"""
# Conclusions ✅
"""

"""
`MVP` is the first self-supervised method added to the `tsai` library. And it seems to work pretty well. It shows something really interesting: self-supervised learning may improve performance, with or without additional unlabeled data.

In this notebook we've demonstrated how easy it is to use a self-supervised method in 2 steps: 

1. pretrain an architecture using the `MVP` callback.
2. fine-tune or train the same architecture using the pretrained model weights.

In all cases, performance has been better when using the pretrained model weights as a starting point. 

In this case, training has proven to be superior to fine-tuning. However, this will not always be the case. It's difficult to know a priori whether fine/tuning or training will provide better results. I'd recommend trying both approaches. 

In the case of using data augmentation (data augmentation), we've also seen that the pretrained model performs better than the one trained from scratch.

`MVP` has shown it can improve performance with a low number of labels (10%) as well as with all labels (100%). 

I'd encourage you to use `MVP` with your own datasets and share your experience.
"""



================================================
FILE: tutorial_nbs/09_PredictionDynamics.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/09_PredictionDynamics.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# PredictionDynamics: gain more insights during training

> Callback used to visualize model predictions during training. 
"""

"""
I've created this callback based on a [blog post](http://karpathy.github.io/2019/04/25/recipe/) by Andrej Karpathy I read some time ago. Some of the advice is a bit out-of-date but most of it is still very relevant. One of the things he recommended was to: 
>**visualize prediction dynamics**: I like to visualize model predictions on a fixed test batch during the course of training. The “dynamics” of how these predictions move will give you incredibly good intuition for how the training progresses. Many times it is possible to feel the network “struggle” to fit your data if it wiggles too much in some way, revealing instabilities. Very low or very high learning rates are also easily noticeable in the amount of jitter." A. Karpathy

I've used it lately, and I believe it can provide additional insights during training you don't get with the losses or metrics (that's not their goal). 

It's designed to work in **classfication, regression and forecasting tasks**. 

It's also model agnostic, meaning that you can use it with any deep learning model you want.

I encourage you to use it with your own datasets and share your findings!
"""

"""
# Import libraries
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
my_setup()
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
# PredictionDynamics in classification tasks
"""

"""
If you want to start visualizing the model's predictions of the validation dataset during training the only thing you really need to do is to add PredictionDynamics() to your callbacks (if any). That's it! 

At the end of every epoch you will be able to see a chart that will display the predictions of the validation set. In this way you will be able to see very quickly what is the impact of changes you've made not only on the loss and metrics, but at a much more granular level.
"""

X,y,splits = get_UCR_data('LSST', split_data=False)
tfms=[None, TSClassification()]
batch_tfms = [TSStandardize(by_sample=True)]
dls = get_ts_dls(X,y,splits=splits,tfms=tfms, batch_tfms=batch_tfms)
learn = ts_learner(dls, InceptionTimePlus, metrics=[accuracy, BalancedAccuracy()], cbs=PredictionDynamics())
timer.start()
learn.fit_one_cycle(50, 1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#       train_loss  valid_loss  accuracy  balanced_accuracy_score

#   49    0.000952    1.495504  0.691403                 0.536719
#   <Figure size 720x432 with 1 Axes>
#   Total time              : 78.142091

#   78.142091

"""
This callback adds some overhead to the training process, and thus it's a bit slower (in my experience just marginally).
In this case it's taken 78 seconds to train this model using this callback. Let's see how long does it take to train without the callback.
"""

learn = ts_learner(dls, InceptionTimePlus, metrics=[accuracy, BalancedAccuracy()])
timer.start()
learn.fit_one_cycle(50, 1e-3)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   Total time              : 56.166973

#   56.166973

"""
56 seconds vs 72. In this case, training time took about 16s longer. 

In most cases I've used the extra time is approx .3 seconds per epoch. I'll leave it up to you to decide if it's worthwhile adding the callback.
"""

"""
## Callback parameters
"""

"""
There are a few callback parameters you may want to tweak (although the default ones will work in most cases): 
* show_perc:  percent of samples from the valid set that will be displayed. Default: 1 (all). You can reduce it if the number is too high and the chart is too busy.
* alpha:      level of transparency. Default:0.3. 1 means no transparency.
* figsize:    size of the chart. You may want to expand it if too many classes.
* size:       size of each sample in the chart. Default:30. You may need to decrease it a bit if too many classes/ samples.
* color:      color used in regression plots.
* cmap:       color map used in classification plots.
"""

"""
## Use with context managers:
"""

"""
Sometimes training time per epoch is very small, and it may be difficult to see the chart correctly. In that case you can use the context managers:
"""

X, y, splits = get_UCR_data('LSST', split_data=False)
tfms=[None, TSClassification()]
batch_tfms = [TSStandardize(by_sample=True)]
dls = get_ts_dls(X,y,splits=splits,tfms=tfms, batch_tfms=batch_tfms)
learn = ts_learner(dls, InceptionTimePlus, metrics=[accuracy, BalancedAccuracy()], cbs=[ShowGraph(), PredictionDynamics()])
with ContextManagers([learn.no_logging()]): 
    learn.fit_one_cycle(50, 1e-3)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#       train_loss  valid_loss  accuracy  balanced_accuracy_score

#   49    0.000824     1.50876  0.711679                 0.551465
#   <Figure size 720x432 with 1 Axes>
#   <Figure size 936x648 with 4 Axes>
#   <Figure size 936x648 with 4 Axes>

"""
# PredictionDynamics in regression tasks
"""

X, y, splits = get_Monash_regression_data('AppliancesEnergy', split_data=False)
tfms=[None, TSRegression()]
batch_tfms = TSStandardize(by_sample=True, by_var=True)
dls = get_ts_dls(X,y,splits=splits,tfms=tfms, batch_tfms=batch_tfms)
learn = ts_learner(dls, TSTPlus, metrics=[mae, rmse], cbs=[ShowGraph(), PredictionDynamics(alpha=.5, size=75)])
with ContextManagers([learn.no_logging()]): 
    learn.fit_one_cycle(300, 3e-4)
learn.plot_metrics()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#        train_loss  valid_loss       mae     _rmse

#   299    0.427422    7.589998  2.040455  2.754995
#   <Figure size 720x432 with 1 Axes>
#   <Figure size 936x648 with 4 Axes>
#   <Figure size 936x648 with 4 Axes>

"""
# Conclusion
"""

"""
With this new addition there's something else to do while a model is training. You can get a better understanding of things like: 

* what are the easiest/ most difficult classes?
* is the model really focusing on the most frequent classes?
* how stable is training? how much change is there from epoch to epoch?
* how does the loss function impact predictions? (for example CrossEntropyLossFlat vs LabelSmoothingCrossEntropyFlat)
* how does adding class weights (in imbalanced datasets) change predictions?
and many more
....

I really encourage you to use PredictionDynamics with your own datasets and share your experience.

"""



================================================
FILE: tutorial_nbs/10_Time_Series_Classification_and_Regression_with_MiniRocket.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/10_Time_Series_Classification_and_Regression_with_MiniRocket.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Malcolm McLean and Ignacio Oguiza (oguiza@timeseriesAI.co) based on: 

* Dempster, A., Schmidt, D. F., & Webb, G. I. (2020). MINIROCKET: A Very Fast (Almost) Deterministic Transform for Time Series Classification. arXiv preprint arXiv:2012.08791.

* Original paper: https://arxiv.org/abs/2012.08791

* Original code:  https://github.com/angus924/minirocket
"""

"""
# MiniRocket 🚀

> A Very Fast (Almost) Deterministic Transform for Time Series Classification.
"""

"""
ROCKET is a type of time series classification and regression methods that is different to the 
ones you may be familiar with. Typical machine learning classifiers will 
optimize the weights of convolutions, fully-connected, and pooling layers, 
learning a configuration of weights that classifies the time series.

In contrast, ROCKET applies a large number of fixed, non-trainable, independent convolutions 
to the timeseries. It then extracts a number of features from each convolution 
output (a form of pooling), generating typically 10000 features per sample. (These 
features are simply floating point numbers.)

The features are stored so that they can be used multiple times. 
It then learns a simple linear head to predict each time series sample from its features. 
Typical PyTorch heads might be based on Linear layers. When the number of training samples is small,
sklearn's RidgeClassifier is often used.

The convolutions' fixed weights and the pooling method have been chosen experimentally to 
effectively predict a broad range of real-world time series.

The original ROCKET method used a selection of fixed convolutions with weights 
chosen according to a random distribution. Building upon the lessons learned 
from ROCKET, MiniRocket refines the convolutions to a specific pre-defined set 
that proved to be at least as effective ROCKET's. It is also much faster 
to calculate than the original ROCKET. Actually, the paper authors "suggest that MiniRocket should now be considered and used as the default variant of Rocket."

MiniROCKET was implemented in Python using numba acceleration and mathematical 
speedups specific to the algorithm. It runs quite fast, utilizing CPU cores in 
parallel. Here we present a 2 implementations of MiniRocket: 
 * a cpu version with an sklearn-like API (that can be used with small datasets - <10k samples), and
 * a PyTorch implementation of MiniRocket, optimized for 
the GPU. It runs faster (3-25x depending on your GPU) than the CPU version and offers some flexibility for further experimentation.

We'll demonstrate how you can use both of them througout this notebook.
"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI & SKTIME ****************
# stable = False # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null
# !pip install sktime -U  >> /dev/null

from tsai.basics import *
import sktime
import sklearn
my_setup(sktime, sklearn)
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   sktime          : 0.14.0

#   sklearn         : 1.0.2

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
# Using MiniRocket 🚀
"""

"""
* First, create the features for each timeseries sample using the MiniRocketFeatures module (MRF). 
MRF takes a minibatch of time series samples and outputs their features. Choosing an appropriate minibatch size
allows training sets of any size to be used without exhausting CPU or GPU memory.

    Typically, 10000 features will characterize each sample. These features are relatively
expensive to create, but once created they are fixed and may be used as the 
input for further training. They might be saved for example in memory or on disk.


* Next, the features are sent to a linear model. The original 
MiniRocket research used sklearn's RidgeClassifier. When the number of samples 
goes beyond the capacity of RidgeClassifier, a deep learning "Head" can be 
used instead to learn the classification/regression from minibatches of features.

For the following demos, we use the tsai package to handle timeseries efficiently and clearly. tsai is fully integrated with fastai, allowing fastai's training loop and other convenience to be used. To learn more about tsai, please check out the docs and tutorials at https://github.com/timeseriesAI/tsai

Let's get started.
"""

"""
## sklearn-type API (<10k samples) 🚶🏻‍♂️
"""

"""
We'll first import the models we are going to use:
"""

from tsai.models.MINIROCKET import *

"""
### Classifier
"""

# Univariate classification with sklearn-type API
dsid = 'OliveOil'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid)   # Download the UCR dataset

# Computes MiniRocket features using the original (non-PyTorch) MiniRocket code.
# It then sends them to a sklearn's RidgeClassifier (linear classifier).
model = MiniRocketClassifier()
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
print(f'valid accuracy    : {model.score(X_valid, y_valid):.3%} time: {t}')
# Output:
#   valid accuracy    : 93.333% time: 0.526145


# Multivariate classification with sklearn-type API
dsid = 'LSST'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid)
model = MiniRocketClassifier()
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
print(f'valid accuracy    : {model.score(X_valid, y_valid):.3%} time: {t}')
# Output:
#   valid accuracy    : 65.247% time: 8.533509


"""
One way to try to improve performance is to use an ensemble (that uses majority vote). Bear in mind that the ensemble will take longer since multiple models will be fitted.
"""

# Multivariate classification ensemble with sklearn-type API
dsid = 'LSST'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid)
model = MiniRocketVotingClassifier(n_estimators=5)
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
print(f'valid accuracy    : {model.score(X_valid, y_valid):.3%} time: {t}')
# Output:
#   valid accuracy    : 68.045% time: 45.066046


"""
In this case, we see an increase in accuracy although this may not be the case with other datasets.
"""

"""
Once a model is trained, you can always save it for future inference: 
"""

dsid = 'LSST'
X_train, y_train, X_valid, y_valid = get_UCR_data(dsid)
model = MiniRocketClassifier()
model.fit(X_train, y_train)
model.save(f'MiniRocket_{dsid}')
del model

model = load_minirocket(f'MiniRocket_{dsid}')
print(f'valid accuracy    : {model.score(X_valid, y_valid):.3%}')
# Output:
#   valid accuracy    : 65.207%


"""
### Regressor
"""

# Univariate regression with sklearn-type API
from sklearn.metrics import mean_squared_error, make_scorer
dsid = 'Covid3Month'
X_train, y_train, X_valid, y_valid = get_Monash_regression_data(dsid)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model = MiniRocketRegressor(scoring=rmse_scorer)
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
y_pred = model.predict(X_valid)
rmse = mean_squared_error(y_valid, y_pred, squared=False)
print(f'valid rmse        : {rmse:.5f} time: {t}')
# Output:
#   153it [00:00, 6948.12it/s]

#   74it [00:00, 6341.37it/s]

#   valid rmse        : 0.04162 time: 0.36316


# Univariate regression ensemble with sklearn-type API
from sklearn.metrics import mean_squared_error, make_scorer
dsid = 'Covid3Month'
X_train, y_train, X_valid, y_valid = get_Monash_regression_data(dsid)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model = MiniRocketVotingRegressor(n_estimators=5, scoring=rmse_scorer)
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
y_pred = model.predict(X_valid)
rmse = mean_squared_error(y_valid, y_pred, squared=False)
print(f'valid rmse        : {rmse:.5f} time: {t}')
# Output:
#   valid rmse        : 0.04162 time: 1.521828


# Multivariate regression with sklearn-type API
from sklearn.metrics import mean_squared_error, make_scorer
dsid = 'AppliancesEnergy'
X_train, y_train, X_valid, y_valid = get_Monash_regression_data(dsid)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model = MiniRocketRegressor(scoring=rmse_scorer)
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
y_pred = model.predict(X_valid)
rmse = mean_squared_error(y_valid, y_pred, squared=False)
print(f'valid rmse        : {rmse:.5f} time: {t}')
# Output:
#   119it [00:03, 30.50it/s]

#   66it [00:01, 38.38it/s]

#   valid rmse        : 2.44171 time: 0.683256


# Multivariate regression ensemble with sklearn-type API
from sklearn.metrics import mean_squared_error, make_scorer
dsid = 'AppliancesEnergy'
X_train, y_train, X_valid, y_valid = get_Monash_regression_data(dsid)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model = MiniRocketVotingRegressor(n_estimators=5, scoring=rmse_scorer)
timer.start(False)
model.fit(X_train, y_train)
t = timer.stop()
y_pred = model.predict(X_valid)
rmse = mean_squared_error(y_valid, y_pred, squared=False)
print(f'valid rmse        : {rmse:.5f} time: {t}')
# Output:
#   valid rmse        : 2.28944 time: 2.696218


"""
We'll also save this model for future inference:
"""

# Multivariate regression ensemble with sklearn-type API
from sklearn.metrics import mean_squared_error, make_scorer
dsid = 'AppliancesEnergy'
X_train, y_train, X_valid, y_valid = get_Monash_regression_data(dsid)
rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)
model = MiniRocketVotingRegressor(n_estimators=5, scoring=rmse_scorer)
model.fit(X_train, y_train)
model.save(f'MRVRegressor_{dsid}')
del model

model = load_minirocket(f'MRVRegressor_{dsid}')
y_pred = model.predict(X_valid)
rmse = mean_squared_error(y_valid, y_pred, squared=False)
print(f'valid rmse        : {rmse:.5f}')
# Output:
#   valid rmse        : 2.24403


"""
## Pytorch implementation (any # samples) 🏃
"""

from tsai.models.MINIROCKET_Pytorch import *
from tsai.models.utils import *

"""
### Offline feature calculation 
"""

"""
In the offline calculation, all features will be calculated in a first stage and then passed to the dataloader that will create batches. This features will ramain the same throughout training.

⚠️ In order to avoid leakage when using the offline feature calculation, it's important to fit MiniRocketFeatures using just the train samples.
"""

# Create the MiniRocket features and store them in memory.
dsid = 'LSST'
X, y, splits = get_UCR_data(dsid, split_data=False)

mrf = MiniRocketFeatures(X.shape[1], X.shape[2]).to(default_device())
X_train = X[splits[0]]
mrf.fit(X_train)
X_feat = get_minirocket_features(X, mrf, chunksize=1024, to_np=True)
X_feat.shape, type(X_feat)
# Output:
#   ((4925, 9996, 1), numpy.ndarray)

"""
👀 Note that X_train may be a np.ndarray or a torch.Tensor. In this case we'll pass a np.ndarray. 

If a torch.Tensor is passed, the model will move it to the right device (cuda) if necessary, so that it matches the model.
"""

"""
We'll save this model, as we'll need it to create features in the future.
"""

PATH = Path("./models/MRF.pt")
PATH.parent.mkdir(parents=True, exist_ok=True)
torch.save(mrf.state_dict(), PATH)

"""
As you can see the shape of the minirocket features is [sample_size x n_features x 1]. The last dimension (1) is added because `tsai` expects input data to have 3 dimensions, although in this case there's no longer a temporal dimension.

Once the features are calculated, we'll need to train a Pytorch model. We'll use a simple linear model:
"""

# Using tsai/fastai, create DataLoaders for the features in X_feat.
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_feat, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
                 
# model is a linear classifier Head
model = build_ts_model(MiniRocketHead, dls=dls)
model.head
# Output:
#   Sequential(

#     (0): Flatten(start_dim=1, end_dim=-1)

#     (1): BatchNorm1d(9996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#     (2): Linear(in_features=9996, out_features=14, bias=True)

#   )

# Using tsai/fastai, create DataLoaders for the features in X_feat.
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_feat, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
                 
# model is a linear classifier Head
model = build_ts_model(MiniRocketHead, dls=dls)
                 
# Drop into fastai and use it to find a good learning rate.
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=3.630780702224001e-05)
#   <Figure size 432x288 with 1 Axes>

# As above, use tsai to bring X_feat into fastai, and train.
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_feat, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(MiniRocketHead, dls=dls)
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(10, 3e-4)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   7.030589

"""
We'll now save the learner for inference: 
"""

PATH = Path('./models/MRL.pkl')
PATH.parent.mkdir(parents=True, exist_ok=True)
learn.export(PATH)

"""
#### Inference:
"""

"""
For inference we'll need to follow the same process as before: 

1. Create the features
2. Create predictions for those features
"""

"""
Let's recreate mrf (MiniRocketFeatures) to be able to create new features: 
"""

mrf = MiniRocketFeatures(X.shape[1], X.shape[2]).to(default_device())
PATH = Path("./models/MRF.pt")
mrf.load_state_dict(torch.load(PATH))
# Output:
#   <All keys matched successfully>

"""
We'll create new features. In this case we'll use the valid set to confirm the predictions accuracy matches the one at the end of training, but you can use any data: 
"""

new_feat = get_minirocket_features(X[splits[1]], mrf, chunksize=1024, to_np=True)
new_feat.shape, type(new_feat)
# Output:
#   ((2466, 9996, 1), numpy.ndarray)

"""
We'll now load the saved learner: 
"""

PATH = Path('./models/MRL.pkl')
learn = load_learner(PATH, cpu=False)

"""
and pass the newly created features
"""

probas, _, preds = learn.get_X_preds(new_feat)
preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   array(['6', '6', '65', ..., '42', '42', '95'], dtype='<U2')

sklearn.metrics.accuracy_score(y[splits[1]], preds)
# Output:
#   0.6719383617193836

"""
Ok, so the predictions match the ones at the end of training as this accuracy is the same on we got in the end.
"""

"""
### Online feature calculation
"""

"""
MiniRocket can also be used online, re-calculating the features each minibatch. In this scenario, you do not calculate fixed features one time. The online mode is a bit slower than the offline scanario, but offers more flexibility. Here are some potential uses:

* You can experiment with different scaling techniques (no standardization, standardize by sample, normalize, etc).
* You can use data augmentation is applied to the original time series.
* Another use of online calculation is to experiment with training the kernels and biases.
To do this requires modifications to the MRF code.
"""

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(MiniRocket, dls=dls)
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
learn.lr_find()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   SuggestedLRs(valley=5.248074739938602e-05)
#   <Figure size 432x288 with 1 Axes>

"""
Notice 2 important differences with the offline scenario: 

* in this case we pass X to the dataloader instead of X_tfm. The featurew will be calculated within the model.
* we use MiniRocket instead of MiniRocketHead. MiniRocket is a Pytorch version that calculates features on the fly before passing them to a linear head.
"""

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(MiniRocket, dls=dls)
model
# Output:
#   MiniRocket(

#     (backbone): MiniRocketFeatures()

#     (head): Sequential(

#       (0): Flatten(start_dim=1, end_dim=-1)

#       (1): BatchNorm1d(9996, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)

#       (2): Linear(in_features=9996, out_features=14, bias=True)

#     )

#   )

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(MiniRocket, dls=dls)
learn = Learner(dls, model, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(10, 3e-4)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   7.073542

"""
Since we calculate the minirocket features within the model, we now have the option to use data augmentation for example: 
"""

# MiniRocket with data augmentation
tfms = [None, TSClassification()]
batch_tfms = [TSStandardize(by_sample=True), TSMagScale(), TSWindowWarp()]
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms)
model = build_ts_model(MiniRocket, dls=dls)
learn = Learner(dls, model, metrics=accuracy, cbs=[ShowGraph()])
learn.fit_one_cycle(20, 3e-4)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
In this case, we can see that using MiniRocket (Pytorch implementation) with data augmentation achieves an accuracy of 69%+, compared to the sklearn-API implementation which is around 65%. 
"""

"""
Once you have trained the model, you can always save if for future use. We just need to export the learner:
"""

PATH = Path('./models/MiniRocket_aug.pkl')
PATH.parent.mkdir(parents=True, exist_ok=True)
learn.export(PATH)

del learn

"""
#### Inference
"""

"""
Let's first recreate the learner: 
"""

PATH = Path('./models/MiniRocket_aug.pkl')
learn = load_learner(PATH, cpu=False)

"""
We are now ready to generate predictions. We'll confirm it works well with the valid dataset: 
"""

probas, _, preds = learn.get_X_preds(X[splits[1]])
preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   array(['6', '62', '6', ..., '42', '90', '42'], dtype='<U2')

"""
We can see that the validation loss & metrics are the same we had when we saved it.
"""

sklearn.metrics.accuracy_score(y[splits[1]], preds)
# Output:
#   0.6889699918896999

"""
# Conclusion ✅
"""

"""
MiniRocket is a new type of algorithm that is significantly faster than any other method of comparable accuracy (including Rocket), and significantly more accurate than any other method of even roughly-similar computational expense. 

`tsai` supports the 2 variations of MiniRocket introduced in this notebook. A cpu version (that can be used with relatively small datasets, with <10k samples) and a gpu (Pytorch) version that can be used with datasets of any size. The Pytorch version can be used in an offline mode (pre-calculating all features before fitting the model) or in an online mode (calculating features on the fly). 

We believe MiniRocket is a great new tool, and encourange you to try it in your next Time Series Classification or Regression task. 
"""



================================================
FILE: tutorial_nbs/11_How_to_train_big_arrays_faster_with_tsai.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://github.com/timeseriesAI/tsai/blob/main/tutorial_nbs/11_How_to_train_big_arrays_faster_with_tsai.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# Purpose 😇
"""

"""
> In this notebook, we'll demonstrate how you can efficiently train a larger-than-memory dataset using **tsai**.

**Interested in speeding up training on larger-than-memory datasets?**

If you want train your models fast you need to have a good / multiple good GPUs. No question about that. 

But even the best GPU will crawl if your batch creation process is slow. Only when the dataloaders create batches faster than the GPU consumes them, you'll achieve 100% GPU usage. And shorter training times. This is particularly important with larger-than-memory datasets.

In this notebook we'll show you how to create really fast dataloaders to speed up your training.



"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null

from tsai.all import *
import zarr
my_setup(zarr)
# Output:
#   os             : Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic

#   python         : 3.7.11

#   tsai           : 0.2.23

#   fastai         : 2.5.2

#   fastcore       : 1.3.26

#   zarr           : 2.9.5

#   torch          : 1.9.0+cu102

#   n_cpus         : 2

#   device         : cuda (Tesla T4)


"""
# Zarr arrays ☦️
"""

"""
In addition to tsai, we'll make also need a library called [zarr](https://zarr.readthedocs.io). 


Zarr is a format for the storage of chunked, compressed, N-dimensional arrays. These documents describe the Zarr format and its Python implementation.

**Highlights**

- Create N-dimensional arrays with any NumPy dtype.
- Chunk arrays along any dimension.
- Compress and/or filter chunks using any NumCodecs codec.
- Store arrays in memory, on disk, inside a Zip file, on S3, …
- Read an array concurrently from multiple threads or processes.
- Write to an array concurrently from multiple threads or processes.
- Organize arrays into hierarchies via groups.
"""

"""
## Want to know more about zarr arrays?
"""

"""
We are going to briefly understand how we can use zarr arrays. Let's prepare a relatively small dataset that fits in memory. 

Note: For a more in-depth understanding of zarr arrays you can visit this [tutorial](https://zarr.readthedocs.io/en/stable/tutorial.html).
"""

path = Path('data')
if not os.path.exists(path): os.makedirs(path)

arr = np.random.rand(10_000, 10, 100)
np.save(path/'arr.npy', arr)

"""
We know that one of the data formats we can use for large datasets are memory-mapped arrays (np.memmap). They behave like normal arrays, except that they remain on disk. When you index them, only those indices are loaded in memory. That's great because it's what we need to create batches in tsai.
"""

memmap_arr = np.load(path/'arr.npy', mmap_mode='r+')
memmap_arr.shape
# Output:
#   (10000, 10, 100)

"""
### Create an on-disk zarr array & load data
"""

"""
For large datasets, we need to create an zarr array on disk. The array will initially be empty, with all values set to 0.
"""

zarr_arr = zarr.open(path/'zarr.zarr', mode='w', shape=arr.shape, dtype=arr.dtype)
zarr_arr
# Output:
#   <zarr.core.Array (10000, 10, 100) float64>

"""
They are array-like objects, like memmap arrays
"""

hasattr(memmap_arr, '__array__'), hasattr(zarr_arr, '__array__')
# Output:
#   (True, True)

"""
Although they are not np.ndarrays
"""

isinstance(memmap_arr, np.ndarray), isinstance(zarr_arr, np.ndarray)
# Output:
#   (True, False)

"""
To load data into the array we can: 

- assign it directly if the data fits in memory or if data is stored in a memmap array on disk: 

"""

zarr_arr[:] = memmap_arr

"""
- we can split data in chunks that fit memory. We can load data from an array, a dataframe, etc. 
"""

chunksize = 1_000

for i in range(len(memmap_arr) // chunksize + 1):
    zarr_arr[i * chunksize : (i + 1) * chunksize] = memmap_arr[i * chunksize : (i + 1) * chunksize]

"""
There is a function in `tsai` that helps you assign data in chunks in place:
"""

assign_in_chunks(zarr_arr, memmap_arr, chunksize=10_000, inplace=True, verbose=True)

"""
Once you load data, if you want to ensure your data is never modified, you may load the zarr array in mode 'r' (read only). This process is fast.

Otherwise you can continue working with your array in mode 'w'.

Note: even if zerr.open seems to indicate the opposite, there's no need to ever close zarr arrays. You can just delete as a regular array, and recursively remove if from its directory (if on disk).
"""

zarr_arr = zarr.open(path/'zarr.zarr', mode='r')

"""
### How to slice a zarr array?
"""

"""
Let's now create some indices to index the arrays. 

Indexing is used to obtain individual elements from an array. In tsai, it's used to create batches of data by the dataloader. 
"""

idxs = random_choice(len(arr), 64, False)

arr[idxs].shape, memmap_arr[idxs].shape
# Output:
#   ((64, 10, 100), (64, 10, 100))

"""
When memmap arrays are index, the index elements become a regular np.array. 
"""

type(arr[idxs]), type(memmap_arr[idxs])
# Output:
#   (numpy.ndarray, numpy.ndarray)

"""
Zarr arrays are unique in the way they need to be indexed.

If we try to apply indices in the same way as with memmap arrays, you'll get an error message.

Zarr arrays have an attribute called 'oindex' that is used to index the array.
"""

hasattr(zarr_arr, 'oindex')
# Output:
#   True

zarr_arr.oindex[idxs].shape, type(zarr_arr.oindex[idxs])
# Output:
#   ((64, 10, 100), numpy.ndarray)

np.array_equal(arr[idxs], memmap_arr[idxs]), np.array_equal(arr[idxs], zarr_arr.oindex[idxs])
# Output:
#   (True, True)

"""
tsai supports many types of array-like objects, like numpy arrays, memmap arrays, zarr arrays, xarrays, dask arrays, and even lists or L objects. 

That means you can use any of those types as data inputs. 
"""

"""
# In-memory datasets 🧠
"""

"""
Let's compare the performance of the 3 types of arrays we have created (np.array, np.memmap, zarr). They all fit in memory, although for comparison, np.memmap and zarr data are on disk. 
"""

%timeit arr[random_choice(len(arr), 512, False)]
# Output:
#   1000 loops, best of 5: 1.33 ms per loop


%timeit memmap_arr[random_choice(len(arr), 512, False)]
# Output:
#   1000 loops, best of 5: 1.33 ms per loop


"""
Now we'll create a zarr array. Since the array fits in memory, we'll set chunks to False, meaning no chunking will be applied. 
"""

zarr_arr = zarr.open(path/'zarr.zarr', mode='w', shape=arr.shape, dtype=arr.dtype, chunks=False) 
zarr_arr[:] = arr 
zarr_arr, zarr_arr.chunks
# Output:
#   (<zarr.core.Array (10000, 10, 100) float64>, (10000, 10, 100))

%timeit zarr_arr.oindex[random_choice(len(arr), 512, False)]
# Output:
#   10 loops, best of 5: 63 ms per loop


"""
⚠️ In order to improve performance, it's beneficial for zarr arrays to sort the indices. 
"""

%timeit zarr_arr.oindex[np.sort(random_choice(len(arr), 512, False))]
# Output:
#   10 loops, best of 5: 60.6 ms per loop


"""
We have learned 2 things: 

- For datasets that fit in memory, both numpy arrays and zarr arrays are very fast. Memmap arrays are slower.

- Chunks have a great impact on zarr arrays performance. Always choose chunks=False for datasets that fit in memory. 

⚠️ chunks=False means a single data containing all data in the dataset. We can only do this when data fits in memory. 
"""

"""
# Larger-than-memory datasets 🤯
"""

"""
We are going to create a larger-than_memory file with **dummy data**. 

Colab Pro (standard) has 13GB of RAM. However, the X_large file has 37GB. So we'll need to manage everything on disk.

Data creation will take around 10 min.


⚠️ Remember to delete this file when you finish!
"""

path = Path('data')

# Uncomment to create the data
# X_large = create_array((1_000_000, 10, 1000), fname='X_large', path='data', mode='r+')
# del X_large

X_large = np.load(path/'X_large.npy', mmap_mode='r+')
X_large.shape
# Output:
#   (1000000, 10, 1000)

y_large = np.array(['a', 'b', 'c'])[np.random.randint(0, 3, len(X_large))]
np.save(path/'y_large.npy', y_large)
del y_large
y_large = np.load(path/'y_large.npy', mmap_mode='r+')
y_large
# Output:
#   memmap(['b', 'b', 'a', ..., 'a', 'c', 'c'], dtype='<U1')

splits = TimeSplitter()(y_large)
# Output:
#   <Figure size 1152x36 with 1 Axes>

"""
Let's see what's the performance of memmap arrays when they are indexed (simulating a batch creation process): 
"""

np_res = %timeit -qo X_large[random_choice(len(X_large), 512, False)]
np_res
# Output:
#   <TimeitResult : 1 loop, best of 5: 1.72 s per loop>

"""
Let's now create a zarr array on disk with the same shape. In this case, since data doesn't fit in memory, we are going to use chunks to be able to improve performance. The recommended approach is to set chunks != -1 in the dimension we are going to use (in our case the first dimension). That's why we set chunks=(1, -1,-1),
For an in-depth review on chunks you can read [this](https://docs.dask.org/en/latest/array-chunks.html).

When creating a zarr array we need to use mode='a' (read if exist, otherwise write) or 'w' (always write or overwrite). There's no need to ever close the array. 

When an array's been created, you can always read it again bu setting mode='r'.

This step will also take about 10 min.

⚠️ Note that chunks stands for “chunk shape” rather than “number of chunks”, so specifying chunks=1 means that you will have many chunks, each with exactly one element.
"""

# X_large_zarr = zarr.open(path/'X_large.zarr', mode='w', shape=X_large.shape, dtype=X_large.dtype, chunks=(1, -1, -1)) # chunks=(1, -1, -1) == (1, None, None)
# X_large_zarr[:] = X_large

X_large_zarr = zarr.open(path/'X_large.zarr', mode='r')
X_large_zarr
# Output:
#   <zarr.core.Array (1000000, 10, 1000) float32>

zarr_res = %timeit -qo X_large_zarr.oindex[random_choice(len(X_large), 512, False)]
print(f'{zarr_res.best:.2f}s which is {1 - zarr_res.best/np_res.best:.1%} less')
# Output:
#   1.31s which is 24.0% less


"""
Excellent!!! 🙃 I'm starting to really like zarr arrays!!!

One more idea. Zarr arrays are a bit faster when the indices are sorted. Let's try it: 
"""

zarr_sorted_res = %timeit -qo X_large_zarr.oindex[np.sort(random_choice(len(X_large), 512, False))]
print(f'{zarr_sorted_res.best:.2f}s which is {1 - zarr_sorted_res.best/np_res.best:.1%} less')
# Output:
#   1.19s which is 30.8% less


"""

This is an excellent performance for a large, on-disk dataset like this. Indexing is around 30% faster than memmap arrays!!! 🚀

Zarr arrays are very useful when dealing with larger-then-memory datasets.

There are some important concepts to unsertand why zarr arrays are faster to index: 

- Chunks are parts of the array that are loaded in memory at the same time. This makes indexing more efficient. 

- Zarr arrays are compressed. This also improves the loading of data in memory. 

- Zarr arrays can be concurrently read and written by multiple threads or processes.
"""

"""
## Key learnings: 
"""

"""
- For datasets that fit in memory, use numpy arrays (or np.memmap arrays). 

- For larger than memory datasets, use zarr arrays. 

- Set up chunks=(1, -1, -1)

- Sort the indices before indexing the array. 


The tsai library applies all these learnings to achieve the fastest possible performance for larger-than-memory datasets.
"""

"""
# Training  🏃🏽‍♀️
"""

X_large_zarr = zarr.open(path/'X_large.zarr', mode='r') # mode='r' because we are reasing the zarr array we previously created
y_large_zarr = zarr.open(path/'y_large.zarr', mode='w', shape=y_large.shape, dtype=y_large.dtype, chunks=False) # y data is small and don't need to be chunked
y_large_zarr[:] = y_large
splits = TimeSplitter()(y_large)
# Output:
#   <Figure size 1152x36 with 1 Axes>

"""
When creating the dataloaders, there are 2 important things to remember:

1. If you are dealing with a classification task and need to transform the lavels, use TSClassification. It's vectorized version of Categorize that run much faster.

2. Set inplace to False. This is required when the data doesn't fit in memory. If you don't use it your system will crash and you will need to start again. 

3. Increasing num_workers=cpus may also reduce the training time. 


⚠️ Note: bear in mind we are using dummy data. We are not intereted in accuracy. We are interested in time/epoch.
"""

"""
## np.memmap
"""

"""
I've tried different num_workers, but num_workers=0 and num_workers=cpus seem to have the same performance. 

⚠️ if you are running this notebook on Windows changing num_workers won't have any effect, as it will be disabled with this message: **Due to IPython and Windows limitation, python multiprocessing isn't available now.**
"""

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large, y_large, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=0)
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 1:06:40.556316


tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large, y_large, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=cpus)
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 1:07:33.940965


"""
In this case, GPU utilization is very variable, although a lot of the time stays at 0%. That is because the dataloader takes time to build the batches because indexing is pretty slow with np.memmap arrays with such a large dataset.
"""

"""
## zarr arrays
"""

"""
We recommend to set num_workers = cpus. That will significantly speed up your training, as zarr array reading can be done in parallel.
"""

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large_zarr, y_large_zarr, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=0)
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 0:46:37.044966


tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large_zarr, y_large_zarr, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=2) # 1*cpus
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 0:26:07.003129


tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large_zarr, y_large_zarr, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=4) # 2*cpus
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 0:24:28.079497


tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large_zarr, y_large_zarr, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=8) # 4*cpus
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=ShowGraph())
timer.start()
learn.fit_one_cycle(1, 1e-2)
timer.stop()
# Output:
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   Total time        : 0:24:31.011945


"""
That's great. An interesting finding is that most of the time the GPU utilization is 100%. This means the batch creation process is no longer a bottleneck. That's why speed is much faster. To further reduce time, we'd need a better GPU and/ or multiple GPUs.
"""

"""
Setting num_workers>0 helps a lot because the bottleneck is batch creation, not the GPU. 

In any case, the goal is to ensure maximum utilization of your GPU. You can easily get a view of GPU utilization by running this code in your terminal during training: 

```
watch -n .2 nvidia-smi
```
"""

"""
I've run some additional tests (look below) to measure the impact of number of workers on a dataloader that uses memmap arrays vs zarr arrays. Here are the findings: 

- memmap arrays with num_workers > 0 degrades performance
- zarr arrays with num_workers > 0 improves performance

Remember that zarr arrays can be read in parallel while memmap arrays can't. 
"""

"""
<img src="https://github.com/timeseriesAI/tsai/blob/main/tutorial_nbs/images/ZarrvsMemmap.png?raw=true"  width="500">
"""

"""
# Conclusion ✅
"""

"""
In this notebook we have learned how we can train a model with a large dataset in tsai. By using zarr arrays,  setting the chunks parameter to (1,-1,-1) aand num_workers>0, we can really speed up training 2.5x!!

Key points: 

- if you dataset fits in memory, use np.arrays (or np.memmap).
- if your dataset doesn't fit in memory, our recommended format is zarr with chunks = (1, None, None)
- You should also try setting num_workers>0, as zarr arrays support parallel computing (which means that multiple concurrent read operations may occur). This usually improves performance too. 
- By using all this you'll be able to significantly reduce your training time when using out-of-memory datasets. 
- `tsai` currently supports multiple input data types, including: 

   * np.ndarray
   * list
   * L
   * np.memmap
   * dask.array
   * xarray
   * zarr

   The last 4 have the benefit that they can be used on-disk (out-of-core learning), with larger-than-memory datasets.

We hope you've find this tutorial useful. If you have any questions/ issues don't hesitate to visit [tsai](https://github.com/timeseriesAI/tsai) in GitHub!!
"""

"""
# Additional tests 🥴
"""

"""
We already know that it's faster to index large zarr arrays compared to memmap arrays. 
"""

%timeit X_large[np.sort(random_choice(len(X_large_zarr), 512, False))]
# Output:
#   1 loop, best of 5: 1.78 s per loop


%timeit X_large_zarr.oindex[np.sort(random_choice(len(X_large_zarr), 512, False))]
# Output:
#   1 loop, best of 5: 1.27 s per loop


"""
But another key difference is multiprocessing. 

Zarr arrays can be read in parallel by multiple workers, while memmap arrays can't. This means that when we increase num_workers with memmap arrays we usually see a drop in performance. However, performance improves considerably when using num_workers > 0 with zarr arrays.
"""

def cycle_dl_estimate(dl, iters=10):
    iters = min(iters, len(dl))
    iterator = iter(dl)
    timer.start(False)
    for _ in range(iters): next(iterator)
    t = timer.stop()
    return (t/iters * len(dl)).total_seconds()

tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large, y_large, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=0)
train_dl = dls.train
valid_dl = dls.valid

for nw in [0, 1, 2, 4, 8]:
    train_dl.fake_l.num_workers = nw
    print(f'{nw:2} {cycle_dl_estimate(train_dl)/60:.1f}')
# Output:
#    0 44.2

#    1 67.7

#    2 71.4

#    4 87.7

#    8 114.7


tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X_large_zarr, y_large_zarr, splits=splits, tfms=tfms, batch_tfms=batch_tfms, inplace=False, bs=[512, 1_024], num_workers=0)
train_dl = dls.train
valid_dl = dls.valid

for nw in [0, 1, 2, 4, 8]:
    train_dl.fake_l.num_workers = nw
    print(f'{nw:2} {cycle_dl_estimate(train_dl)/60:.1f}')
# Output:
#    0 49.1

#    1 35.0

#    2 26.4

#    4 30.6

#    8 40.4




================================================
FILE: tutorial_nbs/12_Experiment_tracking_with_W&B.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://github.com/timeseriesAI/tsai/blob/main/tutorial_nbs/12_Experiment_tracking_with_W%26B.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# Purpose 😇
"""

"""
This brief notebook will demonstrate how you can easily track your experiments using Weights & Biases (W&B).

You can find much more information on the W&B [Experiment tracking](https://docs.wandb.ai/guides/track) page.
"""

"""
# Import libraries 📚
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null
# !pip install wandb -U >> /dev/null

from tsai.all import *
from fastai.callback.wandb import *
import wandb
my_setup(wandb)
# Output:
#   os              : Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic

#   python          : 3.7.15

#   tsai            : 0.3.5

#   fastai          : 2.7.10

#   fastcore        : 1.5.27

#   wandb           : 0.13.5

#   torch           : 1.12.1+cu113

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [14.75] GB


"""
# Login to W&B 🔎
"""

wandb.login()
# Output:
#   ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.

#   [34m[1mwandb[0m: Currently logged in as: [33mtimeseriesai[0m. Use [1m`wandb login --relogin`[0m to force relogin

#   True

"""
# Create a configurable training script 🏋️‍♂️
"""

"""
In this notebook we'll run experiments with TSiT which is a new model developed by timeseriesAI inspired by ViT.

We'll first define a baseline we'll then try to improve: 
"""

X, y, splits = get_UCR_data('LSST', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
cbs = [ShowGraph()] 
learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, arch=TSiTPlus, arch_config={}, metrics=accuracy, cbs=cbs)
learn.fit_one_cycle(10, 1e-3)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
We'll now define which elements we'd like to test. These will be part of the config. 

Later we'll be able to modify the training script or the config.
"""

config = AttrDict (
    batch_tfms = TSStandardize(by_sample=True),
    arch_config = {},
    architecture = TSiTPlus,
    lr = 1e-3,
    n_epoch = 10,   
)

X, y, splits = get_UCR_data('LSST', split_data=False)
tfms = [None, TSClassification()]
cbs = [ShowGraph()] 
learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=config["batch_tfms"], arch=config["architecture"], 
                     arch_config=config["arch_config"], metrics=accuracy, cbs=cbs)
learn.fit_one_cycle(config["n_epoch"], config["lr"])
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
# Perform experiments with W&B 🛫
"""

"""
We just need to add 2 elements to have a configurable training script that can be tracked by W&B: 

- A context manager: 

    ```
    with wandb.init(project="LSST_v01", reinit=True, config=config):
    ```
    It may useful to pass a group, job type, tags, name, notes, etc. You can see the available options [here](https://docs.wandb.ai/ref/python/init).
- A callback: 

    ```
    WandbCallback()
    ```


⚠️ If you also want to save your best models, and set log_model=True in the WandbCallback, you'll need to add the SaveModelCallback as well.

There's currently a small bug in the integration between wandb and tsai that doesn't allow to log_preds. This can be used to show predictions in W&B. We recommend setting log_preds=False.
"""

# YOU CAN MODIFY YOUR CONFIG AND/OR TRAINING SCRIPT IN THIS CELL AND RE-RUN MANUAL EXPERIMENTS THAT WILL BE TRACKED BY W&B

config = AttrDict (
    batch_tfms = TSStandardize(by_sample=True),
    arch = TSiTPlus,
    arch_config = {},
    lr = 1e-3,
    n_epoch = 10,   
)

with wandb.init(project="LSST_v01", config=config, name='baseline'):
    X, y, splits = get_UCR_data('LSST', split_data=False)
    tfms = [None, TSClassification()]
    cbs = [ShowGraph(), WandbCallback(log_preds=False, log_model=False, dataset_name='LSST')] 
    learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=config.batch_tfms, arch=config.arch, 
                         arch_config=config.arch_config, metrics=accuracy, cbs=cbs)
    learn.fit_one_cycle(config.n_epoch, config.lr)
# Output:
#   [34m[1mwandb[0m: Currently logged in as: [33mtimeseriesai[0m. Use [1m`wandb login --relogin`[0m to force relogin

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>

"""
# Visualize results 🕸
"""

"""
You will be able to see your experiment results in the W&B website.

The links are displayed with the run details like this: 

```
Project page: https://wandb.ai/timeseriesai/LSST_v01
Run page: https://wandb.ai/timeseriesai/LSST_v01/runs/34lacjyd
```
"""

"""
# How to test multiple values: use loops? 🌀
"""

"""
We can even run loops. In this case we'll test if adding a convolution/s with different kernel sizes improves performance. You'll be able to check progress in the W&B website during the test. That's why are remove the ShowGraph callback.
"""

for ks in [None, 1, 3, 5, 7, [1, 3, 5, 7]]:

    if ks is None:
        feature_extractor = None
    else:
        feature_extractor = partial(MultiConv1d, kss=ks)
    config = AttrDict (
        batch_tfms = TSStandardize(by_sample=True),
        arch = TSiTPlus,
        arch_config = dict(feature_extractor=feature_extractor),
        lr = 1e-3,
        n_epoch = 10,   
        ks = ks, # we add this parameter here to be able to log it and visualize in wandb 
    )

    with wandb.init(project="LSST_v01", config=config, group='kss'):
        X, y, splits = get_UCR_data('LSST', split_data=False)
        tfms = [None, TSClassification()]
        cbs = [ShowGraph(), WandbCallback(log_preds=False, log_model=False, dataset_name='LSST')] 
        learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=config.batch_tfms, arch=config.arch, 
                            arch_config=config.arch_config, metrics=accuracy, cbs=cbs)
        learn.fit_one_cycle(config.n_epoch, config.lr)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.001 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=0.066324…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>
#   <IPython.core.display.HTML object>
#   VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=1.0, max…
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>

"""
In this case we've learned that setting a ks parameter can improve performance. That's a great finding!
"""

"""
# Conclusion ✅
"""

"""
`wandb` is a great tool that allows you to easily track your experiments. 

It's super-flexible. It allows you to track your dataset, data preprocessing, data transforms, architecutres, architecture configurations, training loop, etc. 

And you can group runs in projects to easily compare them. 

Here's all the code you need to start running experiments with W&B and `tsai`: 

```
from tsai.all import *
from fastai.callback.wandb import *
import wandb

config = AttrDict (
    batch_tfms = TSStandardize(by_sample=True),
    arch = TSiTPlus,
    arch_config = {},
    lr = 1e-3,
    n_epoch = 10,   
)

with wandb.init(project="LSST_v01", config=config, name='baseline'):
    X, y, splits = get_UCR_data('LSST', split_data=False)
    tfms = [None, TSClassification()]
    cbs = [ShowGraph(), WandbCallback(log_preds=False, log_model=False, dataset_name='LSST')] 
    learn = TSClassifier(X, y, splits=splits, tfms=tfms, batch_tfms=config.batch_tfms, arch=config.arch, 
                         arch_config=config.arch_config, metrics=accuracy, cbs=cbs)
    learn.fit_one_cycle(config.n_epoch, config.lr)
```

We've seen here just a small amount of everything W&B has to offer. I hope you'll start benefiting from it!
"""



================================================
FILE: tutorial_nbs/13_Hyperparameter_optimization_with_Optuna.ipynb
================================================
Error processing notebook: 'text/plain'


================================================
FILE: tutorial_nbs/14_Inference_Partial_Fit_and_Fine_Tune.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Purpose 😇
"""

"""
This is a brief notebook to demonstrate how you can save a learner once your model has been trained for later inference (to generate predictions) or to continue training it when new samples become available. 
"""

"""
# Install and load libraries 📚
"""

# **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
stable = False # Set to True for latest pip version or False for main branch in GitHub
!pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null
# Output:
#     Running command git clone -q https://github.com/timeseriesAI/tsai.git /tmp/pip-req-build-uoszu6pa


from tsai.all import *
my_setup()
# Output:
#   os             : Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic

#   python         : 3.7.13

#   tsai           : 0.3.2

#   fastai         : 2.6.0

#   fastcore       : 1.4.2

#   torch          : 1.10.0+cu111

#   device         : 1 gpu (['Tesla T4'])

#   cpu cores      : 2

#   RAM            : 12.69 GB

#   GPU memory     : [14.75] GB


"""
# Train model 🏃‍♀️
"""

X, y, splits = get_UCR_data('LSST', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls = get_ts_dls(X, y, splits=splits, tfms=tfms, batch_tfms=batch_tfms, path='/data/')
learn = ts_learner(dls, InceptionTimePlus, metrics=accuracy, cbs=[ShowGraph()])
learn.fit_one_cycle(10, 1e-2)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 1440x288 with 3 Axes>

"""
# Inference: learn.export and load_learner 🚚
"""

"""
If you have finished training, you can export the model for inference using the `export` method.
"""

learn.export('exported.pth')

"""
When you need to generate predictions you just fo this:
"""

new_X, *_ = get_UCR_data('LSST', split_data=False)
learn1 = load_learner('/data/exported.pth', cpu=False) # set cpu to True or False depending on your environment
preds, _, decoded_preds = learn1.get_X_preds(new_X)
preds, _, decoded_preds
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   (TensorBase([[1.2905e-03, 1.5663e-04, 8.7045e-02,  ..., 4.4778e-02, 6.6327e-05,

#             2.5620e-03],

#            [5.1583e-05, 5.3598e-07, 4.0279e-02,  ..., 1.6094e-04, 8.1969e-08,

#             3.4691e-03],

#            [2.1993e-02, 1.3445e-05, 1.8652e-01,  ..., 1.3897e-01, 2.7750e-05,

#             3.2740e-02],

#            ...,

#            [8.9264e-04, 5.0546e-05, 2.5908e-01,  ..., 3.3627e-03, 7.0707e-05,

#             6.4735e-01],

#            [1.9133e-02, 3.7902e-06, 2.5041e-01,  ..., 6.3816e-01, 5.1981e-05,

#             1.9923e-02],

#            [1.4637e-04, 1.6800e-06, 5.7432e-01,  ..., 7.2760e-04, 8.9442e-07,

#             2.3213e-01]]),

#    None,

#    array(['6', '6', '62', ..., '95', '90', '42'], dtype='<U2'))

"""
# Partial fit or fine tuning 🏋️‍♂️
"""

"""
There's another way to export the learner keeping the optimizer state in case we need to keep training the model on some new data. `save` will save the model and optimizer state.
"""

learn.save('test')
# Output:
#   Path('/data/models/test.pth')

"""
When we have some new data, we'll create a new learner as before and load the model weights and optimizer state. Then we can fit the model on some more epochs or fine tune it. You can try both methods and see which one works best in your case.
"""

"""
## Incremental learning: 🙇🏽‍♀️
"""

new_X, new_y, new_splits = get_UCR_data('LSST', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls2 = get_ts_dls(new_X, new_y, splits=new_splits, tfms=tfms, batch_tfms=batch_tfms, path='/data/')
learn2 = ts_learner(dls2, InceptionTimePlus, metrics=accuracy, cbs=[ShowGraph()])
learn2 = learn2.load('/data/models/test', device=device)
learn2.fit_one_cycle(1)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart


"""
## Fine-tuning 📻
"""

new_X, new_y, new_splits = get_UCR_data('LSST', split_data=False)
tfms = [None, TSClassification()]
batch_tfms = TSStandardize(by_sample=True)
dls3 = get_ts_dls(new_X, new_y, splits=new_splits, tfms=tfms, batch_tfms=batch_tfms, path='/data/')
learn3 = ts_learner(dls3, InceptionTimePlus, metrics=accuracy, cbs=[ShowGraph()])
learn3 = learn3.load('/data/models/test', device=device)
learn3.fine_tune(1)
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   not enough values to plot a chart

#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   not enough values to plot a chart




================================================
FILE: tutorial_nbs/15_PatchTST_a_new_transformer_for_LTSF.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
<a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/15_PatchTST_a_new_transformer_for_LTSF.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

"""
created by Ignacio Oguiza - email: oguiza@timeseriesAI.co
"""

"""
# Purpose 😇
"""

"""
In this notebook, we are going to learn how to use a new state-of-the-art time series transformer called **PatchTST** to create a long-term multivariate time series forecast (LTSF). PatchTST was introduced in the following paper:

* paper: Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). **A Time Series is Worth 64 Words: Long-term Forecasting with Transformers**. arXiv preprint arXiv:2211.14730.
* arxiv link: https://arxiv.org/abs/2211.14730
* official repository: https://github.com/yuqinie98/PatchTST

The paper will be presented at the **ICLR 2023** Conference later this year. Here's the summary of the paper review by ICLR reviewers:

"The paper applies transformer to long term forecasting problems of multi-dimensional time series. The method is very simple: Take channels independently, break them into patches and predict the patches into the future using the transformer. The main advantage of this paper is that previous papers have applied transformers to this problem but it resulted in a very weak performance, being beaten by a simple linear methods. This paper found a way to apply the transformer successfully, beating the previous methods."

I'd like to thank the authors for publishing this paper, and for making their code available.

Below you can see the results of publised in the paper.
"""

"""
![download.png](attachment:download.png)
"""

"""
# Install & import libraries 📚
"""

"""
You'll need tsai >= 0.3.5 to be able to run this tutorial.
"""

# # **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************
# stable = True # Set to True for latest pip version or False for main branch in GitHub
# !pip install {"tsai -U" if stable else "git+https://github.com/timeseriesAI/tsai.git"} >> /dev/null
# Output:
#     Running command git clone --filter=blob:none --quiet https://github.com/timeseriesAI/tsai.git /tmp/pip-req-build-ex6o8mf1


import sklearn
from tsai.basics import *
my_setup(sklearn)
# Output:
#   os              : Linux-5.10.147+-x86_64-with-glibc2.29

#   python          : 3.8.10

#   tsai            : 0.3.5

#   fastai          : 2.7.11

#   fastcore        : 1.5.28

#   sklearn         : 1.0.2

#   torch           : 1.13.1+cu116

#   device          : 1 gpu (['Tesla T4'])

#   cpu cores       : 1

#   threads per cpu : 2

#   RAM             : 12.68 GB

#   GPU memory      : [15.0] GB


"""
# Load and prepare data 🔢
"""

"""
The starting point for this tutorial will be a dataframe that contains our long-term time series data. 

`tsai` allows you to easily download and prepare data from 9 popular datasets, including weather, traffic, electricity, exchange rate, ILI, and four ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2). These datasets have been extensively utilized for long-term time series forecasting benchmarking.

You can download all data from here: https://cloud.tsinghua.edu.cn/d/e1ccfff39ad541908bae/

Here are the statistics of these datasets:
"""

"""
| Datasets | Weather | Traffic | Electricity | Exchange | ILI | ETTh1 | ETTh2 | ETTm1 | ETTm2 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Features | 21 | 862 | 321 | 8 | 7 | 7 | 7 | 7 | 7 |
| Timesteps | 52696 | 17544 | 26304 | 7588 | 966 | 17420 | 17420 | 69680 | 69680 |

"""

"""
## Data preparation steps
"""

"""
There are 5 steps required to prepare data for a forecasting task in `tsai`:

1. Prepare a dataframe with your data, including the variable you want to predict. 
2. Preprocess your data.
3. Define train, valid and test splits.
4. Scale your data using the train split. 
5. Apply a sliding window to prepare your input and output data.
"""

"""
### Prepare dataframe
"""

"""
In this case, we are going to download the dataframe using get_long_term_forecasting_data. You can use any of the following datasets: "ETTh1", "ETTh2", "ETTm1", "ETTm2", "electricity", "exchange_rate", "traffic", "weather", or "ILI".

We are going to use a small dataset called ILI. ILI includes the weekly recorded **influenza-like illness (ILI)** patients data from Centers for
Disease Control and Prevention of the United States between 2002 and 2021, which describes the ratio of patients seen with ILI and the total number of the patients.

The task is a multivariate long-term time series forecasting (LTSF), where multiple variables are predicted simultaneously for multiple time steps.
"""

dsid = "ILI"
df_raw = get_long_term_forecasting_data(dsid)
df_raw
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#             date  % WEIGHTED ILI  %UNWEIGHTED ILI  AGE 0-4  AGE 5-24  ILITOTAL  \

#   0   2002-01-01        1.222620         1.166680      582       805      2060   

#   1   2002-01-08        1.333440         1.216500      683       872      2267   

#   2   2002-01-15        1.319290         1.130570      642       878      2176   

#   3   2002-01-22        1.494840         1.252460      728      1045      2599   

#   4   2002-01-29        1.471950         1.302370      823      1189      2907   

#   ..         ...             ...              ...      ...       ...       ...   

#   961 2020-06-02        0.839059         0.846722     2756      3528     12913   

#   962 2020-06-09        0.895958         0.908885     3203      3778     13979   

#   963 2020-06-16        0.910926         0.941625     3478      3796     14389   

#   964 2020-06-23        0.946945         0.972185     3734      3818     14999   

#   965 2020-06-30        0.963716         1.013760     3955      3843     15307   

#   

#        NUM. OF PROVIDERS       OT  

#   0                  754   176569  

#   1                  785   186355  

#   2                  831   192469  

#   3                  863   207512  

#   4                  909   223208  

#   ..                 ...      ...  

#   961               3258  1525058  

#   962               3254  1538038  

#   963               3177  1528103  

#   964               3066  1542813  

#   965               3027  1509928  

#   

#   [966 rows x 8 columns]

"""
### Proprocess dataframe
"""

"""
`tsai` provides some sklearn-style transforms that can be used to build a preprocessing pipeline. In this case we'll use the following transforms: 

* TSShrinkDataFrame: to save some memory and set the right dtypes.
* TSDropDuplicates: to ensure there are no duplicate timestamps.
* TSAddMissingTimestamps: to fill any missing timestamps. 
* TSFillMissing: to fill any missing data (forward fill, then 0).

All these transforms can be applied to the entire dataset. In other words, they are not dependent on the training set. Other transforms will be applied later, when the training split is available.

You can read about all available transforms in the [docs](https://timeseriesai.github.io/tsai/data.preprocessing.html#sklearn-api-transforms).
"""

datetime_col = "date"
freq = '7D'
columns = df_raw.columns[1:]
method = 'ffill'
value = 0

# pipeline
preproc_pipe = sklearn.pipeline.Pipeline([
    ('shrinker', TSShrinkDataFrame()), # shrink dataframe memory usage
    ('drop_duplicates', TSDropDuplicates(datetime_col=datetime_col)), # drop duplicate rows (if any)
    ('add_mts', TSAddMissingTimestamps(datetime_col=datetime_col, freq=freq)), # ass missing timestamps (if any)
    ('fill_missing', TSFillMissing(columns=columns, method=method, value=value)), # fill missing data (1st ffill. 2nd value=0)
    ], 
    verbose=True)
mkdir('data', exist_ok=True, parents=True)
save_object(preproc_pipe, 'data/preproc_pipe.pkl')
preproc_pipe = load_object('data/preproc_pipe.pkl')

df = preproc_pipe.fit_transform(df_raw)
df
# Output:
#   data directory already exists.

#   Pipeline saved as data/preproc_pipe.pkl

#   Initial memory usage: 67.92 KB  

#   Final memory usage  : 37.73 KB   (-44.4%)

#   [Pipeline] .......... (step 1 of 4) Processing shrinker, total=   0.0s

#   [Pipeline] ... (step 2 of 4) Processing drop_duplicates, total=   0.0s

#   [Pipeline] ........... (step 3 of 4) Processing add_mts, total=   0.0s

#   [Pipeline] ...... (step 4 of 4) Processing fill_missing, total=   0.0s

#             date  % WEIGHTED ILI  %UNWEIGHTED ILI  AGE 0-4  AGE 5-24  ILITOTAL  \

#   0   2002-01-01        1.222620         1.166680      582       805      2060   

#   1   2002-01-08        1.333440         1.216500      683       872      2267   

#   2   2002-01-15        1.319290         1.130570      642       878      2176   

#   3   2002-01-22        1.494840         1.252460      728      1045      2599   

#   4   2002-01-29        1.471950         1.302370      823      1189      2907   

#   ..         ...             ...              ...      ...       ...       ...   

#   961 2020-06-02        0.839059         0.846722     2756      3528     12913   

#   962 2020-06-09        0.895958         0.908885     3203      3778     13979   

#   963 2020-06-16        0.910926         0.941625     3478      3796     14389   

#   964 2020-06-23        0.946945         0.972185     3734      3818     14999   

#   965 2020-06-30        0.963716         1.013760     3955      3843     15307   

#   

#        NUM. OF PROVIDERS       OT  

#   0                  754   176569  

#   1                  785   186355  

#   2                  831   192469  

#   3                  863   207512  

#   4                  909   223208  

#   ..                 ...      ...  

#   961               3258  1525058  

#   962               3254  1538038  

#   963               3177  1528103  

#   964               3066  1542813  

#   965               3027  1509928  

#   

#   [966 rows x 8 columns]

"""
### Define splits
"""

"""
So we have transformed a multivariate time series with 966 time steps and 7 features (excluding the datetime) into:

* 803 input samples, with 7 features and 104 historical time steps
* 803 input samples, with 7 features and 60 future time steps.
"""

"""
It's very easy to create time forecasting splits in `tsai`. You can use as function called `get_forecasting_splits`:
"""

fcst_history = 104 # # steps in the past
fcst_horizon = 60  # # steps in the future
valid_size   = 0.1  # int or float indicating the size of the training set
test_size    = 0.2  # int or float indicating the size of the test set

splits = get_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, datetime_col=datetime_col,
                                valid_size=valid_size, test_size=test_size)
splits
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   ((#480) [0,1,2,3,4,5,6,7,8,9...],

#    (#68) [539,540,541,542,543,544,545,546,547,548...],

#    (#137) [666,667,668,669,670,671,672,673,674,675...])

"""
However, in this example, we are going to apply the same splits they used in the original paper. You can use `get_forecasting splits` to use them. 
"""

splits = get_long_term_forecasting_splits(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, dsid=dsid)
splits
# Output:
#   <Figure size 1152x36 with 1 Axes>
#   ((#513) [0,1,2,3,4,5,6,7,8,9...],

#    (#38) [572,573,574,575,576,577,578,579,580,581...],

#    (#134) [669,670,671,672,673,674,675,676,677,678...])

"""
### Scale dataframe
"""

"""
Now that we have defined the splits for this particular experiment, we'll scale the data: 
"""

columns = df.columns[1:]
train_split = splits[0]

# pipeline
exp_pipe = sklearn.pipeline.Pipeline([
    ('scaler', TSStandardScaler(columns=columns)), # standardize data using train_split
    ], 
    verbose=True)
save_object(exp_pipe, 'data/exp_pipe.pkl')
exp_pipe = load_object('data/exp_pipe.pkl')

df_scaled = exp_pipe.fit_transform(df, scaler__idxs=train_split)
df_scaled
# Output:
#   data directory already exists.

#   Pipeline saved as data/exp_pipe.pkl

#   [Pipeline] ............ (step 1 of 1) Processing scaler, total=   0.0s

#             date  % WEIGHTED ILI  %UNWEIGHTED ILI   AGE 0-4  AGE 5-24  ILITOTAL  \

#   0   2002-01-01       -0.388910        -0.435545 -0.868236 -0.578640 -0.709860   

#   1   2002-01-08       -0.299851        -0.392230 -0.818759 -0.563340 -0.685642   

#   2   2002-01-15       -0.311222        -0.466939 -0.838844 -0.561970 -0.696289   

#   3   2002-01-22       -0.170144        -0.360966 -0.796715 -0.523832 -0.646799   

#   4   2002-01-29       -0.188539        -0.317573 -0.750177 -0.490947 -0.610764   

#   ..         ...             ...              ...       ...       ...       ...   

#   961 2020-06-02       -0.697154        -0.713722  0.196745  0.043204  0.559907   

#   962 2020-06-09       -0.651428        -0.659677  0.415718  0.100296  0.684625   

#   963 2020-06-16       -0.639399        -0.631212  0.550432  0.104406  0.732594   

#   964 2020-06-23       -0.610453        -0.604642  0.675839  0.109430  0.803962   

#   965 2020-06-30       -0.596975        -0.568496  0.784101  0.115139  0.839997   

#   

#        NUM. OF PROVIDERS        OT  

#   0            -0.924247 -1.159122  

#   1            -0.859891 -1.113758  

#   2            -0.764394 -1.085416  

#   3            -0.697961 -1.015684  

#   4            -0.602464 -0.942924  

#   ..                 ...       ...  

#   961           4.274116  5.091879  

#   962           4.265812  5.152048  

#   963           4.105958  5.105994  

#   964           3.875520  5.174183  

#   965           3.794555  5.021743  

#   

#   [966 rows x 8 columns]

"""
### Apply a sliding window
"""

"""
We'll approach the time series forecasting task as a supervised learning problem. Remember that `tsai` requires that both inputs and outputs have the following shape: 

![text.png](attachment:text.png)
"""

"""
To get those inputs and outputs we're going to use a function called `prepare_forecasting_data` that applies a sliding window along the dataframe:

![sliding_window.png](attachment:sliding_window.png)
"""

"""
To use `prepare_forecasting_data` we need to define some settings: 
"""

x_vars = df.columns[1:]
y_vars = df.columns[1:]

X, y = prepare_forecasting_data(df, fcst_history=fcst_history, fcst_horizon=fcst_horizon, x_vars=x_vars, y_vars=y_vars)
X.shape, y.shape
# Output:
#   ((803, 7, 104), (803, 7, 60))

"""
# Prepare the forecaster 🏋️‍♂️
"""

"""
Now we'll instantiate the forecaster. In `tsai` there's a class called TSForecaster. We are going to use the same settings they used in the paper. 

You can find ILI specific settings here: https://github.com/yuqinie98/PatchTST/blob/main/PatchTST_supervised/scripts/PatchTST/illness.sh

and default model settings here: https://github.com/yuqinie98/PatchTST/blob/main/PatchTST_supervised/run_longExp.py
"""

arch_config = dict(
    n_layers=3,  # number of encoder layers
    n_heads=4,  # number of heads
    d_model=16,  # dimension of model
    d_ff=128,  # dimension of fully connected network
    attn_dropout=0.0, # dropout applied to the attention weights
    dropout=0.3,  # dropout applied to all linear layers in the encoder except q,k&v projections
    patch_len=24,  # length of the patch applied to the time series to create patches
    stride=2,  # stride used when creating patches
    padding_patch=True,  # padding_patch
)

learn = TSForecaster(X, y, splits=splits, batch_size=16, path="models", pipelines=[preproc_pipe, exp_pipe],
                     arch="PatchTST", arch_config=arch_config, metrics=[mse, mae], cbs=ShowGraph())

"""
☢️ This is **not good practice**, but all papers using these long-term forecasting datasets have published there data using drop_last=True in the validtion set. You should never use it in your practice. But if you want to try and replicate the results from the paper, you may want to uncomment the following line and set `learn.dls.valid.drop_last=True`. 
"""

# learn.dls.valid.drop_last = True

learn.summary()
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   not enough values to plot a chart

#   PatchTST (Input shape: 16 x 7 x 104)

#   ============================================================================

#   Layer (type)         Output Shape         Param #    Trainable 

#   ============================================================================

#                        16 x 7 x 60         

#   RevIN                                     14         True      

#   ____________________________________________________________________________

#                        16 x 7 x 106        

#   ReplicationPad1d                                               

#   ____________________________________________________________________________

#                        16 x 24 x 42        

#   Unfold                                                         

#   ____________________________________________________________________________

#                        16 x 7 x 42 x 16    

#   Linear                                    400        True      

#   Dropout                                                        

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Dropout                                                        

#   Linear                                    272        True      

#   Dropout                                                        

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   ____________________________________________________________________________

#                        16 x 42 x 128       

#   Linear                                    2176       True      

#   GELU                                                           

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Linear                                    2064       True      

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Dropout                                                        

#   Linear                                    272        True      

#   Dropout                                                        

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   ____________________________________________________________________________

#                        16 x 42 x 128       

#   Linear                                    2176       True      

#   GELU                                                           

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Linear                                    2064       True      

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Linear                                    272        True      

#   Dropout                                                        

#   Linear                                    272        True      

#   Dropout                                                        

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   ____________________________________________________________________________

#                        16 x 42 x 128       

#   Linear                                    2176       True      

#   GELU                                                           

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Linear                                    2064       True      

#   Dropout                                                        

#   ____________________________________________________________________________

#                        16 x 16 x 42        

#   Transpose                                                      

#   BatchNorm1d                               32         True      

#   ____________________________________________________________________________

#                        16 x 42 x 16        

#   Transpose                                                      

#   ____________________________________________________________________________

#                        16 x 7 x 672        

#   Flatten                                                        

#   ____________________________________________________________________________

#                        16 x 7 x 60         

#   Linear                                    40380      True      

#   ____________________________________________________________________________

#   

#   Total params: 56,970

#   Total trainable params: 56,970

#   Total non-trainable params: 0

#   

#   Optimizer used: <function Adam>

#   Loss function: FlattenedLoss of MSELoss()

#   

#   Callbacks:

#     - TrainEvalCallback

#     - CastToTensor

#     - Recorder

#     - ProgressCallback

#     - ShowGraph

"""
As you can see this is a very small model, with only 57k parameters!
"""

"""
# Train model 🏃🏿‍♂️
"""

"""
In this case we'll use the same number of epochs and learning rate they used in the paper. 

⚠️ Whenever you need to look for a good learning rate to train a model you can use:
```python
lr_max = learn.lr_find().valley
```
"""

learn = TSForecaster(X, y, splits=splits, batch_size=16, path="models", pipelines=[preproc_pipe, exp_pipe],
                     arch="PatchTST", arch_config=arch_config, metrics=[mse, mae], cbs=[ShowGraph()])

n_epochs = 100
lr_max = 0.0025
learn.fit_one_cycle(n_epochs, lr_max=lr_max)
learn.export('patchTST.pt')
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   <Figure size 432x288 with 1 Axes>
#   <Figure size 936x648 with 4 Axes>

"""
# Evaluate model 🕵️‍♀️
"""

"""
## Valid split
"""

"""
First we are going to check that the valid predictions match the results we got during training. But you can skip this step since it's not required.
"""

from tsai.inference import load_learner
from sklearn.metrics import mean_squared_error, mean_absolute_error

learn = load_learner('models/patchTST.pt')
scaled_preds, *_ = learn.get_X_preds(X[splits[1]])
scaled_preds = to_np(scaled_preds)
print(f"scaled_preds.shape: {scaled_preds.shape}")

scaled_y_true = y[splits[1]]
results_df = pd.DataFrame(columns=["mse", "mae"])
results_df.loc["valid", "mse"] = mean_squared_error(scaled_y_true.flatten(), scaled_preds.flatten())
results_df.loc["valid", "mae"] = mean_absolute_error(scaled_y_true.flatten(), scaled_preds.flatten())
results_df
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   scaled_preds.shape: (38, 7, 60)

#               mse       mae

#   valid  0.345804  0.374178

"""
## Test split
"""

"""
So now we'll use the test split to measure performance (this is the one you that is published in the paper). 

⚠️ You may find some differences due to randomness of the process. In addition to that, the authors used a test dataloader that drop the last batch if incomplete, which means that not all samples are used to measure performance. In `tsai` we are using all samples.
"""

from tsai.inference import load_learner
from sklearn.metrics import mean_squared_error, mean_absolute_error

learn = load_learner('models/patchTST.pt')
y_test_preds, *_ = learn.get_X_preds(X[splits[2]])
y_test_preds = to_np(y_test_preds)
print(f"y_test_preds.shape: {y_test_preds.shape}")

y_test = y[splits[2]]
results_df = pd.DataFrame(columns=["mse", "mae"])
results_df.loc["test", "mse"] = mean_squared_error(y_test.flatten(), y_test_preds.flatten())
results_df.loc["test", "mae"] = mean_absolute_error(y_test.flatten(), y_test_preds.flatten())
results_df
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#   y_test_preds.shape: (134, 7, 60)

#              mse       mae

#   test  1.534231  0.799998

"""
### Visualize predictions
"""

X_test = X[splits[2]]
y_test = y[splits[2]]
plot_forecast(X_test, y_test, y_test_preds, sel_vars=True)
# Output:
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>
#   <Figure size 576x288 with 1 Axes>

"""
# Inference 🚀 
"""

"""
## Prepare dataframe
"""

"""
If you want to use the model with new data, you'll need to first prepare the data following the process we defined before. 

Let's assume we want to create a prediction for '2020-06-30'. In our case, we need a history of 104 time steps to predict the next 60 days. We'll prepare data in the following way: 
"""

fcst_date = "2020-06-30"

dates = pd.date_range(start=None, end=fcst_date, periods=fcst_history, freq=freq)
dates
# Output:
#   DatetimeIndex(['2018-07-10', '2018-07-17', '2018-07-24', '2018-07-31',

#                  '2018-08-07', '2018-08-14', '2018-08-21', '2018-08-28',

#                  '2018-09-04', '2018-09-11',

#                  ...

#                  '2020-04-28', '2020-05-05', '2020-05-12', '2020-05-19',

#                  '2020-05-26', '2020-06-02', '2020-06-09', '2020-06-16',

#                  '2020-06-23', '2020-06-30'],

#                 dtype='datetime64[ns]', length=104, freq='7D')

new_df = get_long_term_forecasting_data(dsid, return_df=True)
new_df = new_df[new_df[datetime_col].isin(dates)].reset_index(drop=True)
new_df
# Output:
#             date  % WEIGHTED ILI  %UNWEIGHTED ILI  AGE 0-4  AGE 5-24  ILITOTAL  \

#   0   2018-07-10        2.286760         2.266120     6754     10005     27854   

#   1   2018-07-17        2.012170         1.964840     6325      7904     23147   

#   2   2018-07-24        1.713230         1.722010     5698      6621     20610   

#   3   2018-07-31        1.566780         1.572800     5369      6207     18864   

#   4   2018-08-07        1.498270         1.457180     4789      5906     17107   

#   ..         ...             ...              ...      ...       ...       ...   

#   99  2020-06-02        0.839059         0.846722     2756      3528     12913   

#   100 2020-06-09        0.895958         0.908885     3203      3778     13979   

#   101 2020-06-16        0.910926         0.941625     3478      3796     14389   

#   102 2020-06-23        0.946945         0.972185     3734      3818     14999   

#   103 2020-06-30        0.963716         1.013760     3955      3843     15307   

#   

#        NUM. OF PROVIDERS       OT  

#   0                 2568  1229148  

#   1                 2542  1178058  

#   2                 2516  1196855  

#   3                 2485  1199386  

#   4                 2444  1173980  

#   ..                 ...      ...  

#   99                3258  1525058  

#   100               3254  1538038  

#   101               3177  1528103  

#   102               3066  1542813  

#   103               3027  1509928  

#   

#   [104 rows x 8 columns]

"""
## Preprocess dataframe
"""

from tsai.inference import load_learner

learn = load_learner('models/patchTST.pt')
new_df = learn.transform(new_df)
new_df
# Output:
#   Initial memory usage: 6.62 KB   

#   Final memory usage  : 3.38 KB    (-49.1%)

#             date  % WEIGHTED ILI  %UNWEIGHTED ILI   AGE 0-4  AGE 5-24  ILITOTAL  \

#   0   2018-07-10        0.466273         0.520330  2.155252  1.522339  2.307957   

#   1   2018-07-17        0.245602         0.258392  1.945097  1.042539  1.757253   

#   2   2018-07-24        0.005362         0.047270  1.637947  0.749544  1.460432   

#   3   2018-07-31       -0.112330        -0.082456  1.476780  0.655000  1.256155   

#   4   2018-08-07       -0.167387        -0.182978  1.192654  0.586261  1.050592   

#   ..         ...             ...              ...       ...       ...       ...   

#   99  2020-06-02       -0.697154        -0.713722  0.196745  0.043204  0.559907   

#   100 2020-06-09       -0.651428        -0.659677  0.415718  0.100296  0.684625   

#   101 2020-06-16       -0.639399        -0.631212  0.550432  0.104406  0.732594   

#   102 2020-06-23       -0.610453        -0.604642  0.675839  0.109430  0.803962   

#   103 2020-06-30       -0.596975        -0.568496  0.784101  0.115139  0.839997   

#   

#        NUM. OF PROVIDERS        OT  

#   0             2.841660  3.720170  

#   1             2.787683  3.483340  

#   2             2.733706  3.570474  

#   3             2.669350  3.582207  

#   4             2.584233  3.464436  

#   ..                 ...       ...  

#   99            4.274116  5.091879  

#   100           4.265812  5.152048  

#   101           4.105958  5.105994  

#   102           3.875520  5.174183  

#   103           3.794555  5.021743  

#   

#   [104 rows x 8 columns]

"""
## Apply sliding window
"""

x_feat = new_df.columns[1:]
new_X, _ = prepare_forecasting_data(new_df, fcst_history=fcst_history, fcst_horizon=0, x_vars=x_vars, y_vars=None)
new_X.shape
# Output:
#   (1, 7, 104)

"""
## Cast predictions
"""

new_scaled_preds, *_ = learn.get_X_preds(new_X)

new_scaled_preds = to_np(new_scaled_preds).swapaxes(1,2).reshape(-1, len(y_vars))
dates = pd.date_range(start=fcst_date, periods=fcst_horizon + 1, freq='7D')[1:]
preds_df = pd.DataFrame(dates, columns=[datetime_col])
preds_df.loc[:, y_vars] = new_scaled_preds
preds_df = learn.inverse_transform(preds_df)
preds_df
# Output:
#   <IPython.core.display.HTML object>
#   <IPython.core.display.HTML object>
#            date  % WEIGHTED ILI  %UNWEIGHTED ILI       AGE 0-4      AGE 5-24  \

#   0  2020-07-07        1.411405         1.591912   2702.484841   3332.729258   

#   1  2020-07-14        1.158573         1.290422   2218.531072   2579.458693   

#   2  2020-07-21        0.976981         1.071673   2071.280693   2982.152038   

#   3  2020-07-28        0.864371         0.942170   2075.758784   3694.024325   

#   4  2020-08-04        0.842937         0.925972   2110.089350   4409.159154   

#   5  2020-08-11        0.830736         0.907552   2196.719302   5443.275954   

#   6  2020-08-18        0.824093         0.910349   2374.147513   6513.932715   

#   7  2020-08-25        0.838693         0.988355   2342.311507   6335.618813   

#   8  2020-09-01        0.857786         1.100826   2174.361215   5172.548823   

#   9  2020-09-08        0.897425         1.191296   2298.593304   4835.880476   

#   10 2020-09-15        0.929066         1.277326   2403.423011   4836.815652   

#   11 2020-09-22        1.005786         1.451736   2366.960229   4946.945534   

#   12 2020-09-29        1.052060         1.624004   2154.857600   4641.439955   

#   13 2020-10-06        0.952962         1.521194   2011.039889   4609.024371   

#   14 2020-10-13        0.775218         1.249543   1913.729149   4564.133866   

#   15 2020-10-20        0.621133         0.971701   1941.265439   5010.430969   

#   16 2020-10-27        0.479081         0.731611   2135.351552   5452.592733   

#   17 2020-11-03        0.377170         0.575832   2262.961799   5483.482491   

#   18 2020-11-10        0.329128         0.489898   2577.009487   6049.818211   

#   19 2020-11-17        0.409451         0.549002   3170.148406   7986.377921   

#   20 2020-11-24        0.576136         0.736760   3871.406976  10577.198365   

#   21 2020-12-01        0.750226         0.936262   4419.460440  12819.594867   

#   22 2020-12-08        0.901229         1.095970   4992.888899  13501.629240   

#   23 2020-12-15        1.093728         1.283268   5540.935185  13499.067230   

#   24 2020-12-22        1.294767         1.484959   6309.568185  14148.514800   

#   25 2020-12-29        1.473360         1.727058   7112.021938  15853.113699   

#   26 2021-01-05        1.735037         2.132600   8317.052175  18584.748635   

#   27 2021-01-12        1.964189         2.525607   9188.190908  20427.971685   

#   28 2021-01-19        2.119312         2.739661  10084.885565  21021.533196   

#   29 2021-01-26        2.280924         2.860568  11464.390012  21103.179251   

#   30 2021-02-02        2.512907         3.056032  13033.252807  21090.914177   

#   31 2021-02-09        2.860601         3.520307  14393.599437  20978.455100   

#   32 2021-02-16        3.350611         4.291435  15698.116188  21661.968840   

#   33 2021-02-23        3.795318         5.040864  16393.904659  22417.901640   

#   34 2021-03-02        4.259235         5.704739  17227.064066  24796.476169   

#   35 2021-03-09        4.772121         6.198393  18268.585842  28877.567833   

#   36 2021-03-16        5.345978         6.551620  19706.546866  33068.754927   

#   37 2021-03-23        5.825665         6.726284  20868.354599  34819.133831   

#   38 2021-03-30        5.995909         6.601132  20726.445709  33609.739905   

#   39 2021-04-06        5.723745         6.072481  18766.327954  30116.294370   

#   40 2021-04-13        5.523819         5.745318  16821.766951  28363.626989   

#   41 2021-04-20        5.449153         5.649627  15495.438429  27708.322501   

#   42 2021-04-27        5.570456         5.863615  14835.044441  26813.379265   

#   43 2021-05-04        5.601265         6.000551  13904.033819  24561.368440   

#   44 2021-05-11        5.380745         5.805802  12126.761932  20104.314882   

#   45 2021-05-18        4.849405         5.254680   9638.561432  14424.572926   

#   46 2021-05-25        4.258407         4.653505   7170.828449   9890.580250   

#   47 2021-06-01        3.678226         4.062641   5221.782298   7039.982553   

#   48 2021-06-08        3.201160         3.567064   4067.364679   5718.023843   

#   49 2021-06-15        2.714641         3.075546   3149.567733   4227.802997   

#   50 2021-06-22        2.166506         2.510758   2089.121511   2164.549343   

#   51 2021-06-29        1.628706         1.899248   1164.661817    469.308462   

#   52 2021-07-06        1.155281         1.318703    456.058152   -849.421374   

#   53 2021-07-13        0.785731         0.860348      0.568072  -1727.343010   

#   54 2021-07-20        0.555837         0.592325   -103.794163  -1766.483087   

#   55 2021-07-27        0.357325         0.353936   -131.383990  -1299.873652   

#   56 2021-08-03        0.264329         0.232104     94.367543   -461.147426   

#   57 2021-08-10        0.252918         0.202202    393.785391    236.775270   

#   58 2021-08-17        0.308432         0.270190    522.895148    398.831267   

#   59 2021-08-24        0.351958         0.332750    514.549771    255.883855   

#   

#            ILITOTAL  NUM. OF PROVIDERS            OT  

#   0    17439.662198        3080.320316  1.342750e+06  

#   1    14030.595373        3066.143876  1.326612e+06  

#   2    12263.867698        3060.660311  1.342087e+06  

#   3    11775.541865        3049.166623  1.364134e+06  

#   4    12181.050698        3030.611186  1.386885e+06  

#   5    12223.428181        3005.961789  1.401025e+06  

#   6    11808.576963        2985.465491  1.395366e+06  

#   7    11544.068963        2967.074970  1.399139e+06  

#   8    11660.298057        2940.809491  1.386037e+06  

#   9    12828.926618        2923.562815  1.386792e+06  

#   10   13519.800538        2889.795275  1.382223e+06  

#   11   14913.654047        2876.090613  1.384362e+06  

#   12   15767.764470        2854.507203  1.374647e+06  

#   13   15220.053510        2833.764565  1.377211e+06  

#   14   13353.708030        2814.412226  1.366981e+06  

#   15   11887.493575        2801.313365  1.373712e+06  

#   16   10948.119749        2804.629482  1.396905e+06  

#   17   10580.607087        2806.798882  1.447871e+06  

#   18   10677.091744        2806.715276  1.501868e+06  

#   19   12751.867479        2822.747823  1.578970e+06  

#   20   15642.055438        2834.115298  1.631351e+06  

#   21   18592.547582        2842.341104  1.677509e+06  

#   22   20888.320806        2857.210742  1.714638e+06  

#   23   23528.232899        2890.156000  1.772600e+06  

#   24   26269.423621        2991.217331  1.869280e+06  

#   25   28846.811324        3171.841339  1.973652e+06  

#   26   32443.341275        3345.058722  2.056525e+06  

#   27   35072.670969        3462.316597  2.074185e+06  

#   28   36649.356658        3511.999428  2.059325e+06  

#   29   39314.352275        3535.432169  2.032153e+06  

#   30   43351.407937        3550.155152  1.997569e+06  

#   31   48585.487142        3559.303154  1.948657e+06  

#   32   55116.724284        3560.076972  1.888864e+06  

#   33   60966.216939        3546.928039  1.832773e+06  

#   34   68858.330569        3534.595876  1.810894e+06  

#   35   78943.134306        3513.075745  1.792829e+06  

#   36   90582.444099        3489.990522  1.766018e+06  

#   37  100768.739416        3477.687299  1.739864e+06  

#   38  105414.072082        3487.797004  1.739581e+06  

#   39  101081.210564        3491.607064  1.754498e+06  

#   40   95450.420813        3492.218493  1.754715e+06  

#   41   91212.480944        3501.864917  1.745771e+06  

#   42   90690.350737        3504.816405  1.720940e+06  

#   43   89710.534337        3494.827975  1.684229e+06  

#   44   83474.846287        3456.169006  1.629007e+06  

#   45   71112.485398        3417.275755  1.566887e+06  

#   46   57844.126097        3377.540010  1.523612e+06  

#   47   46071.273892        3337.848824  1.484148e+06  

#   48   37832.624917        3294.872415  1.439670e+06  

#   49   30278.163775        3239.496315  1.390818e+06  

#   50   22088.471385        3181.159999  1.317185e+06  

#   51   15069.857015        3133.789205  1.253520e+06  

#   52    9308.579545        3107.641211  1.199926e+06  

#   53    5164.320293        3078.653358  1.170062e+06  

#   54    3042.336423        3063.932442  1.176924e+06  

#   55    1501.923929        3061.778775  1.198950e+06  

#   56    1776.416227        3071.228817  1.234750e+06  

#   57    2958.777657        3098.257204  1.271416e+06  

#   58    3993.215780        3126.045054  1.286108e+06  

#   59    4335.253657        3146.962255  1.308007e+06  

"""
# Conclusion ✅
"""

"""
In this notebook we have covered the following topics:

* PatchTST: a new state-of-the-art transformer for long-term multivariate time series forecasting.
* how to prepare data for a time series task.
* how to use PatchTST within the tsai framework.
* how to use predict multiple variables and multiple steps into the future.
* how to visualize predictions and compare them to true values.

I hope you've found this helpful. Now it's your opportunity to start creating your own forecasts!
"""



================================================
FILE: tutorial_nbs/data/UCR/NATOPS/X.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/data/UCR/NATOPS/X_train.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/data/UCR/NATOPS/X_valid.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/data/UCR/NATOPS/y.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/data/UCR/NATOPS/y_train.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/data/UCR/NATOPS/y_valid.npy
================================================
[Non-text file]


================================================
FILE: tutorial_nbs/export/dls
================================================
[Non-text file]



================================================
FILE: .github/workflows/deploy.yaml
================================================
name: Deploy to GitHub Pages
on:
  push:
    branches: [ "main", "master" ]
  workflow_dispatch:
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps: [uses: fastai/workflows/quarto-ghp@master]



================================================
FILE: .github/workflows/test.yaml
================================================
name: CI
on:  [workflow_dispatch, pull_request, push]

jobs:
  test:
    runs-on: ubuntu-latest
    steps: [uses: fastai/workflows/nbdev-ci@master]

